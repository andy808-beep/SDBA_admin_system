{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/@supabase/node-fetch/browser.js"],"sourcesContent":["\"use strict\";\n\n// ref: https://github.com/tc39/proposal-global\nvar getGlobal = function() {\n    // the only reliable means to get the global object is\n    // `Function('return this')()`\n    // However, this causes CSP violations in Chrome apps.\n    if (typeof self !== 'undefined') { return self; }\n    if (typeof window !== 'undefined') { return window; }\n    if (typeof global !== 'undefined') { return global; }\n    throw new Error('unable to locate global object');\n}\n\nvar globalObject = getGlobal();\n\nexport const fetch = globalObject.fetch;\n\nexport default globalObject.fetch.bind(globalObject);\n\nexport const Headers = globalObject.Headers;\nexport const Request = globalObject.Request;\nexport const Response = globalObject.Response;\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;AAEA,+CAA+C;AAC/C,IAAI,YAAY;IACZ,sDAAsD;IACtD,8BAA8B;IAC9B,sDAAsD;IACtD,IAAI,OAAO,SAAS,aAAa;QAAE,OAAO;IAAM;IAChD;;IACA,wCAAmC;QAAE;IAAe;;;AAExD;AAEA,IAAI,eAAe;AAEZ,MAAM,QAAQ,aAAa,KAAK;uCAExB,aAAa,KAAK,CAAC,IAAI,CAAC;AAEhC,MAAM,UAAU,aAAa,OAAO;AACpC,MAAM,UAAU,aAAa,OAAO;AACpC,MAAM,WAAW,aAAa,QAAQ","ignoreList":[0]}},
    {"offset": {"line": 43, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/functions-js/dist/module/helper.js","sources":["turbopack:///[project]/node_modules/@supabase/functions-js/src/helper.ts"],"sourcesContent":["import { Fetch } from './types'\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  let _fetch: Fetch\n  if (customFetch) {\n    _fetch = customFetch\n  } else if (typeof fetch === 'undefined') {\n    _fetch = (...args) =>\n      import('@supabase/node-fetch' as any).then(({ default: fetch }) => fetch(...args))\n  } else {\n    _fetch = fetch\n  }\n  return (...args) => _fetch(...args)\n}\n"],"names":[],"mappings":";;;;AAEO,MAAM,YAAY,GAAG,CAAC,WAAmB,EAAS,EAAE;IACzD,IAAI,MAAa,CAAA;IACjB,IAAI,WAAW,EAAE;QACf,MAAM,GAAG,WAAW,CAAA;KACrB,MAAM,IAAI,OAAO,KAAK,KAAK,WAAW,EAAE;QACvC,MAAM,GAAG,CAAC,GAAG,IAAI,EAAE,CACjB,CADmB,KACb,CAAC,sBAA6B,CAAC,+GAAC,IAAI,CAAC,CAAC,EAAE,OAAO,EAAE,MAAK,EAAE,EAAE,CAAG,CAAD,IAAM,CAAC,IAAG,IAAI,CAAC,CAAC,CAAA;KACrF,MAAM;QACL,MAAM,GAAG,KAAK,CAAA;KACf;IACD,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,KAAO,CAAC,GAAG,IAAI,CAAC,CAAA;AACrC,CAAC,CAAA"}},
    {"offset": {"line": 62, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/functions-js/dist/module/types.js","sources":["turbopack:///[project]/node_modules/@supabase/functions-js/src/types.ts"],"sourcesContent":["export type Fetch = typeof fetch\n\n/**\n * Response format\n */\nexport interface FunctionsResponseSuccess<T> {\n  data: T\n  error: null\n  response?: Response\n}\nexport interface FunctionsResponseFailure {\n  data: null\n  error: any\n  response?: Response\n}\nexport type FunctionsResponse<T> = FunctionsResponseSuccess<T> | FunctionsResponseFailure\n\nexport class FunctionsError extends Error {\n  context: any\n  constructor(message: string, name = 'FunctionsError', context?: any) {\n    super(message)\n    this.name = name\n    this.context = context\n  }\n}\n\nexport class FunctionsFetchError extends FunctionsError {\n  constructor(context: any) {\n    super('Failed to send a request to the Edge Function', 'FunctionsFetchError', context)\n  }\n}\n\nexport class FunctionsRelayError extends FunctionsError {\n  constructor(context: any) {\n    super('Relay Error invoking the Edge Function', 'FunctionsRelayError', context)\n  }\n}\n\nexport class FunctionsHttpError extends FunctionsError {\n  constructor(context: any) {\n    super('Edge Function returned a non-2xx status code', 'FunctionsHttpError', context)\n  }\n}\n// Define the enum for the 'region' property\nexport enum FunctionRegion {\n  Any = 'any',\n  ApNortheast1 = 'ap-northeast-1',\n  ApNortheast2 = 'ap-northeast-2',\n  ApSouth1 = 'ap-south-1',\n  ApSoutheast1 = 'ap-southeast-1',\n  ApSoutheast2 = 'ap-southeast-2',\n  CaCentral1 = 'ca-central-1',\n  EuCentral1 = 'eu-central-1',\n  EuWest1 = 'eu-west-1',\n  EuWest2 = 'eu-west-2',\n  EuWest3 = 'eu-west-3',\n  SaEast1 = 'sa-east-1',\n  UsEast1 = 'us-east-1',\n  UsWest1 = 'us-west-1',\n  UsWest2 = 'us-west-2',\n}\n\nexport type FunctionInvokeOptions = {\n  /**\n   * Object representing the headers to send with the request.\n   */\n  headers?: { [key: string]: string }\n  /**\n   * The HTTP verb of the request\n   */\n  method?: 'POST' | 'GET' | 'PUT' | 'PATCH' | 'DELETE'\n  /**\n   * The Region to invoke the function in.\n   */\n  region?: FunctionRegion\n  /**\n   * The body of the request.\n   */\n  body?:\n    | File\n    | Blob\n    | ArrayBuffer\n    | FormData\n    | ReadableStream<Uint8Array>\n    | Record<string, any>\n    | string\n  /**\n   * The AbortSignal to use for the request.\n   * */\n  signal?: AbortSignal\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAiBM,MAAO,cAAe,SAAQ,KAAK;IAEvC,YAAY,OAAe,EAAE,IAAI,GAAG,gBAAgB,EAAE,OAAa,CAAA;QACjE,KAAK,CAAC,OAAO,CAAC,CAAA;QACd,IAAI,CAAC,IAAI,GAAG,IAAI,CAAA;QAChB,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;IACxB,CAAC;CACF;AAEK,MAAO,mBAAoB,SAAQ,cAAc;IACrD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,+CAA+C,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAA;IACxF,CAAC;CACF;AAEK,MAAO,mBAAoB,SAAQ,cAAc;IACrD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,wCAAwC,EAAE,qBAAqB,EAAE,OAAO,CAAC,CAAA;IACjF,CAAC;CACF;AAEK,MAAO,kBAAmB,SAAQ,cAAc;IACpD,YAAY,OAAY,CAAA;QACtB,KAAK,CAAC,8CAA8C,EAAE,oBAAoB,EAAE,OAAO,CAAC,CAAA;IACtF,CAAC;CACF;AAED,IAAY,cAgBX;AAhBD,CAAA,SAAY,cAAc;IACxB,cAAA,CAAA,MAAA,GAAA,KAAW,CAAA;IACX,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,WAAA,GAAA,YAAuB,CAAA;IACvB,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,eAAA,GAAA,gBAA+B,CAAA;IAC/B,cAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B,cAAA,CAAA,aAAA,GAAA,cAA2B,CAAA;IAC3B,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;IACrB,cAAA,CAAA,UAAA,GAAA,WAAqB,CAAA;AACvB,CAAC,EAhBW,cAAc,IAAA,CAAd,cAAc,GAAA,CAAA,CAAA,GAgBzB"}},
    {"offset": {"line": 118, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/functions-js/dist/module/FunctionsClient.js","sources":["turbopack:///[project]/node_modules/@supabase/functions-js/src/FunctionsClient.ts"],"sourcesContent":["import { resolveFetch } from './helper'\nimport {\n  Fetch,\n  FunctionInvokeOptions,\n  FunctionRegion,\n  FunctionsFetchError,\n  FunctionsHttpError,\n  FunctionsRelayError,\n  FunctionsResponse,\n} from './types'\n\nexport class FunctionsClient {\n  protected url: string\n  protected headers: Record<string, string>\n  protected region: FunctionRegion\n  protected fetch: Fetch\n\n  constructor(\n    url: string,\n    {\n      headers = {},\n      customFetch,\n      region = FunctionRegion.Any,\n    }: {\n      headers?: Record<string, string>\n      customFetch?: Fetch\n      region?: FunctionRegion\n    } = {}\n  ) {\n    this.url = url\n    this.headers = headers\n    this.region = region\n    this.fetch = resolveFetch(customFetch)\n  }\n\n  /**\n   * Updates the authorization header\n   * @param token - the new jwt token sent in the authorisation header\n   */\n  setAuth(token: string) {\n    this.headers.Authorization = `Bearer ${token}`\n  }\n\n  /**\n   * Invokes a function\n   * @param functionName - The name of the Function to invoke.\n   * @param options - Options for invoking the Function.\n   */\n  async invoke<T = any>(\n    functionName: string,\n    options: FunctionInvokeOptions = {}\n  ): Promise<FunctionsResponse<T>> {\n    try {\n      const { headers, method, body: functionArgs, signal } = options\n      let _headers: Record<string, string> = {}\n      let { region } = options\n      if (!region) {\n        region = this.region\n      }\n      // Add region as query parameter using URL API\n      const url = new URL(`${this.url}/${functionName}`)\n      if (region && region !== 'any') {\n        _headers['x-region'] = region\n        url.searchParams.set('forceFunctionRegion', region)\n      }\n      let body: any\n      if (\n        functionArgs &&\n        ((headers && !Object.prototype.hasOwnProperty.call(headers, 'Content-Type')) || !headers)\n      ) {\n        if (\n          (typeof Blob !== 'undefined' && functionArgs instanceof Blob) ||\n          functionArgs instanceof ArrayBuffer\n        ) {\n          // will work for File as File inherits Blob\n          // also works for ArrayBuffer as it is the same underlying structure as a Blob\n          _headers['Content-Type'] = 'application/octet-stream'\n          body = functionArgs\n        } else if (typeof functionArgs === 'string') {\n          // plain string\n          _headers['Content-Type'] = 'text/plain'\n          body = functionArgs\n        } else if (typeof FormData !== 'undefined' && functionArgs instanceof FormData) {\n          // don't set content-type headers\n          // Request will automatically add the right boundary value\n          body = functionArgs\n        } else {\n          // default, assume this is JSON\n          _headers['Content-Type'] = 'application/json'\n          body = JSON.stringify(functionArgs)\n        }\n      }\n\n      const response = await this.fetch(url.toString(), {\n        method: method || 'POST',\n        // headers priority is (high to low):\n        // 1. invoke-level headers\n        // 2. client-level headers\n        // 3. default Content-Type header\n        headers: { ..._headers, ...this.headers, ...headers },\n        body,\n        signal,\n      }).catch((fetchError) => {\n        if (fetchError.name === 'AbortError') {\n          throw fetchError\n        }\n        throw new FunctionsFetchError(fetchError)\n      })\n\n      const isRelayError = response.headers.get('x-relay-error')\n      if (isRelayError && isRelayError === 'true') {\n        throw new FunctionsRelayError(response)\n      }\n\n      if (!response.ok) {\n        throw new FunctionsHttpError(response)\n      }\n\n      let responseType = (response.headers.get('Content-Type') ?? 'text/plain').split(';')[0].trim()\n      let data: any\n      if (responseType === 'application/json') {\n        data = await response.json()\n      } else if (responseType === 'application/octet-stream') {\n        data = await response.blob()\n      } else if (responseType === 'text/event-stream') {\n        data = response\n      } else if (responseType === 'multipart/form-data') {\n        data = await response.formData()\n      } else {\n        // default to text\n        data = await response.text()\n      }\n\n      return { data, error: null, response }\n    } catch (error) {\n      if (error instanceof Error && error.name === 'AbortError') {\n        return { data: null, error: new FunctionsFetchError(error) }\n      }\n      return {\n        data: null,\n        error,\n        response:\n          error instanceof FunctionsHttpError || error instanceof FunctionsRelayError\n            ? error.context\n            : undefined,\n      }\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,YAAY,EAAE,MAAM,UAAU,CAAA;AACvC,OAAO,EAGL,cAAc,EACd,mBAAmB,EACnB,kBAAkB,EAClB,mBAAmB,GAEpB,MAAM,SAAS,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEV,MAAO,eAAe;IAM1B,YACE,GAAW,EACX,EACE,OAAO,GAAG,CAAA,CAAE,EACZ,WAAW,EACX,MAAM,GAAG,kMAAc,CAAC,GAAG,EAAA,GAKzB,CAAA,CAAE,CAAA;QAEN,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;QACd,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;QACtB,IAAI,CAAC,MAAM,GAAG,MAAM,CAAA;QACpB,IAAI,CAAC,KAAK,OAAG,iMAAY,EAAC,WAAW,CAAC,CAAA;IACxC,CAAC;IAED;;;OAGG,CACH,OAAO,CAAC,KAAa,EAAA;QACnB,IAAI,CAAC,OAAO,CAAC,aAAa,GAAG,CAAA,OAAA,EAAU,KAAK,EAAE,CAAA;IAChD,CAAC;IAED;;;;OAIG,CACG,MAAM,CACV,YAAoB,EACpB,UAAiC,CAAA,CAAE,EAAA;;;YAEnC,IAAI;gBACF,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,IAAI,EAAE,YAAY,EAAE,MAAM,EAAE,GAAG,OAAO,CAAA;gBAC/D,IAAI,QAAQ,GAA2B,CAAA,CAAE,CAAA;gBACzC,IAAI,EAAE,MAAM,EAAE,GAAG,OAAO,CAAA;gBACxB,IAAI,CAAC,MAAM,EAAE;oBACX,MAAM,GAAG,IAAI,CAAC,MAAM,CAAA;iBACrB;gBACD,8CAA8C;gBAC9C,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAA,CAAA,EAAI,YAAY,EAAE,CAAC,CAAA;gBAClD,IAAI,MAAM,IAAI,MAAM,KAAK,KAAK,EAAE;oBAC9B,QAAQ,CAAC,UAAU,CAAC,GAAG,MAAM,CAAA;oBAC7B,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,qBAAqB,EAAE,MAAM,CAAC,CAAA;iBACpD;gBACD,IAAI,IAAS,CAAA;gBACb,IACE,YAAY,IACZ,CAAC,AAAC,OAAO,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,OAAO,EAAE,cAAc,CAAC,CAAC,GAAI,CAAC,OAAO,CAAC,EACzF;oBACA,IACE,AAAC,OAAO,IAAI,KAAK,WAAW,IAAI,YAAY,YAAY,IAAI,CAAC,GAC7D,YAAY,YAAY,WAAW,EACnC;wBACA,2CAA2C;wBAC3C,8EAA8E;wBAC9E,QAAQ,CAAC,cAAc,CAAC,GAAG,0BAA0B,CAAA;wBACrD,IAAI,GAAG,YAAY,CAAA;qBACpB,MAAM,IAAI,OAAO,YAAY,KAAK,QAAQ,EAAE;wBAC3C,eAAe;wBACf,QAAQ,CAAC,cAAc,CAAC,GAAG,YAAY,CAAA;wBACvC,IAAI,GAAG,YAAY,CAAA;qBACpB,MAAM,IAAI,OAAO,QAAQ,KAAK,WAAW,IAAI,YAAY,YAAY,QAAQ,EAAE;wBAC9E,iCAAiC;wBACjC,0DAA0D;wBAC1D,IAAI,GAAG,YAAY,CAAA;qBACpB,MAAM;wBACL,+BAA+B;wBAC/B,QAAQ,CAAC,cAAc,CAAC,GAAG,kBAAkB,CAAA;wBAC7C,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAA;qBACpC;iBACF;gBAED,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,QAAQ,EAAE,EAAE;oBAChD,MAAM,EAAE,MAAM,IAAI,MAAM;oBACxB,qCAAqC;oBACrC,0BAA0B;oBAC1B,0BAA0B;oBAC1B,iCAAiC;oBACjC,OAAO,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,QAAQ,GAAK,IAAI,CAAC,OAAO,GAAK,OAAO,CAAE;oBACrD,IAAI;oBACJ,MAAM;iBACP,CAAC,CAAC,KAAK,CAAC,CAAC,UAAU,EAAE,EAAE;oBACtB,IAAI,UAAU,CAAC,IAAI,KAAK,YAAY,EAAE;wBACpC,MAAM,UAAU,CAAA;qBACjB;oBACD,MAAM,IAAI,uMAAmB,CAAC,UAAU,CAAC,CAAA;gBAC3C,CAAC,CAAC,CAAA;gBAEF,MAAM,YAAY,GAAG,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,eAAe,CAAC,CAAA;gBAC1D,IAAI,YAAY,IAAI,YAAY,KAAK,MAAM,EAAE;oBAC3C,MAAM,IAAI,uMAAmB,CAAC,QAAQ,CAAC,CAAA;iBACxC;gBAED,IAAI,CAAC,QAAQ,CAAC,EAAE,EAAE;oBAChB,MAAM,IAAI,sMAAkB,CAAC,QAAQ,CAAC,CAAA;iBACvC;gBAED,IAAI,YAAY,GAAG,CAAC,CAAA,KAAA,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC,cAAc,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,YAAY,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAA;gBAC9F,IAAI,IAAS,CAAA;gBACb,IAAI,YAAY,KAAK,kBAAkB,EAAE;oBACvC,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;iBAC7B,MAAM,IAAI,YAAY,KAAK,0BAA0B,EAAE;oBACtD,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;iBAC7B,MAAM,IAAI,YAAY,KAAK,mBAAmB,EAAE;oBAC/C,IAAI,GAAG,QAAQ,CAAA;iBAChB,MAAM,IAAI,YAAY,KAAK,qBAAqB,EAAE;oBACjD,IAAI,GAAG,MAAM,QAAQ,CAAC,QAAQ,EAAE,CAAA;iBACjC,MAAM;oBACL,kBAAkB;oBAClB,IAAI,GAAG,MAAM,QAAQ,CAAC,IAAI,EAAE,CAAA;iBAC7B;gBAED,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;oBAAE,QAAQ;gBAAA,CAAE,CAAA;aACvC,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,KAAK,YAAY,KAAK,IAAI,KAAK,CAAC,IAAI,KAAK,YAAY,EAAE;oBACzD,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK,EAAE,IAAI,uMAAmB,CAAC,KAAK,CAAC;oBAAA,CAAE,CAAA;iBAC7D;gBACD,OAAO;oBACL,IAAI,EAAE,IAAI;oBACV,KAAK;oBACL,QAAQ,EACN,KAAK,YAAY,sMAAkB,IAAI,KAAK,YAAY,uMAAmB,GACvE,KAAK,CAAC,OAAO,GACb,SAAS;iBAChB,CAAA;aACF;;KACF;CACF"}},
    {"offset": {"line": 268, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/PostgrestError.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/PostgrestError.ts"],"sourcesContent":["/**\n * Error format\n *\n * {@link https://postgrest.org/en/stable/api.html?highlight=options#errors-and-http-status-codes}\n */\nexport default class PostgrestError extends Error {\n  details: string\n  hint: string\n  code: string\n\n  constructor(context: { message: string; details: string; hint: string; code: string }) {\n    super(context.message)\n    this.name = 'PostgrestError'\n    this.details = context.details\n    this.hint = context.hint\n    this.code = context.code\n  }\n}\n"],"names":[],"mappings":";;;AAAA;;;;GAIG,CACH,MAAqB,cAAe,SAAQ,KAAK;IAK/C,YAAY,OAAyE,CAAA;QACnF,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,CAAA;QACtB,IAAI,CAAC,IAAI,GAAG,gBAAgB,CAAA;QAC5B,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC,OAAO,CAAA;QAC9B,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC,IAAI,CAAA;QACxB,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC,IAAI,CAAA;IAC1B,CAAC;CACF;AAZD,QAAA,OAAA,GAAA,eAYC"}},
    {"offset": {"line": 289, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/PostgrestBuilder.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/PostgrestBuilder.ts"],"sourcesContent":["// @ts-ignore\nimport nodeFetch from '@supabase/node-fetch'\n\nimport type {\n  Fetch,\n  PostgrestSingleResponse,\n  PostgrestResponseSuccess,\n  CheckMatchingArrayTypes,\n  MergePartialResult,\n  IsValidResultOverride,\n  ClientServerOptions,\n} from './types'\nimport PostgrestError from './PostgrestError'\nimport { ContainsNull } from './select-query-parser/types'\n\nexport default abstract class PostgrestBuilder<\n  ClientOptions extends ClientServerOptions,\n  Result,\n  ThrowOnError extends boolean = false\n> implements\n    PromiseLike<\n      ThrowOnError extends true ? PostgrestResponseSuccess<Result> : PostgrestSingleResponse<Result>\n    >\n{\n  protected method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n  protected url: URL\n  protected headers: Headers\n  protected schema?: string\n  protected body?: unknown\n  protected shouldThrowOnError = false\n  protected signal?: AbortSignal\n  protected fetch: Fetch\n  protected isMaybeSingle: boolean\n\n  constructor(builder: {\n    method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n    url: URL\n    headers: HeadersInit\n    schema?: string\n    body?: unknown\n    shouldThrowOnError?: boolean\n    signal?: AbortSignal\n    fetch?: Fetch\n    isMaybeSingle?: boolean\n  }) {\n    this.method = builder.method\n    this.url = builder.url\n    this.headers = new Headers(builder.headers)\n    this.schema = builder.schema\n    this.body = builder.body\n    this.shouldThrowOnError = builder.shouldThrowOnError ?? false\n    this.signal = builder.signal\n    this.isMaybeSingle = builder.isMaybeSingle ?? false\n\n    if (builder.fetch) {\n      this.fetch = builder.fetch\n    } else if (typeof fetch === 'undefined') {\n      this.fetch = nodeFetch\n    } else {\n      this.fetch = fetch\n    }\n  }\n\n  /**\n   * If there's an error with the query, throwOnError will reject the promise by\n   * throwing the error instead of returning it as part of a successful response.\n   *\n   * {@link https://github.com/supabase/supabase-js/issues/92}\n   */\n  throwOnError(): this & PostgrestBuilder<ClientOptions, Result, true> {\n    this.shouldThrowOnError = true\n    return this as this & PostgrestBuilder<ClientOptions, Result, true>\n  }\n\n  /**\n   * Set an HTTP header for the request.\n   */\n  setHeader(name: string, value: string): this {\n    this.headers = new Headers(this.headers)\n    this.headers.set(name, value)\n    return this\n  }\n\n  then<\n    TResult1 = ThrowOnError extends true\n      ? PostgrestResponseSuccess<Result>\n      : PostgrestSingleResponse<Result>,\n    TResult2 = never\n  >(\n    onfulfilled?:\n      | ((\n          value: ThrowOnError extends true\n            ? PostgrestResponseSuccess<Result>\n            : PostgrestSingleResponse<Result>\n        ) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null\n  ): PromiseLike<TResult1 | TResult2> {\n    // https://postgrest.org/en/stable/api.html#switching-schemas\n    if (this.schema === undefined) {\n      // skip\n    } else if (['GET', 'HEAD'].includes(this.method)) {\n      this.headers.set('Accept-Profile', this.schema)\n    } else {\n      this.headers.set('Content-Profile', this.schema)\n    }\n    if (this.method !== 'GET' && this.method !== 'HEAD') {\n      this.headers.set('Content-Type', 'application/json')\n    }\n\n    // NOTE: Invoke w/o `this` to avoid illegal invocation error.\n    // https://github.com/supabase/postgrest-js/pull/247\n    const _fetch = this.fetch\n    let res = _fetch(this.url.toString(), {\n      method: this.method,\n      headers: this.headers,\n      body: JSON.stringify(this.body),\n      signal: this.signal,\n    }).then(async (res) => {\n      let error = null\n      let data = null\n      let count: number | null = null\n      let status = res.status\n      let statusText = res.statusText\n\n      if (res.ok) {\n        if (this.method !== 'HEAD') {\n          const body = await res.text()\n          if (body === '') {\n            // Prefer: return=minimal\n          } else if (this.headers.get('Accept') === 'text/csv') {\n            data = body\n          } else if (\n            this.headers.get('Accept') &&\n            this.headers.get('Accept')?.includes('application/vnd.pgrst.plan+text')\n          ) {\n            data = body\n          } else {\n            data = JSON.parse(body)\n          }\n        }\n\n        const countHeader = this.headers.get('Prefer')?.match(/count=(exact|planned|estimated)/)\n        const contentRange = res.headers.get('content-range')?.split('/')\n        if (countHeader && contentRange && contentRange.length > 1) {\n          count = parseInt(contentRange[1])\n        }\n\n        // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n        // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n        if (this.isMaybeSingle && this.method === 'GET' && Array.isArray(data)) {\n          if (data.length > 1) {\n            error = {\n              // https://github.com/PostgREST/postgrest/blob/a867d79c42419af16c18c3fb019eba8df992626f/src/PostgREST/Error.hs#L553\n              code: 'PGRST116',\n              details: `Results contain ${data.length} rows, application/vnd.pgrst.object+json requires 1 row`,\n              hint: null,\n              message: 'JSON object requested, multiple (or no) rows returned',\n            }\n            data = null\n            count = null\n            status = 406\n            statusText = 'Not Acceptable'\n          } else if (data.length === 1) {\n            data = data[0]\n          } else {\n            data = null\n          }\n        }\n      } else {\n        const body = await res.text()\n\n        try {\n          error = JSON.parse(body)\n\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (Array.isArray(error) && res.status === 404) {\n            data = []\n            error = null\n            status = 200\n            statusText = 'OK'\n          }\n        } catch {\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (res.status === 404 && body === '') {\n            status = 204\n            statusText = 'No Content'\n          } else {\n            error = {\n              message: body,\n            }\n          }\n        }\n\n        if (error && this.isMaybeSingle && error?.details?.includes('0 rows')) {\n          error = null\n          status = 200\n          statusText = 'OK'\n        }\n\n        if (error && this.shouldThrowOnError) {\n          throw new PostgrestError(error)\n        }\n      }\n\n      const postgrestResponse = {\n        error,\n        data,\n        count,\n        status,\n        statusText,\n      }\n\n      return postgrestResponse\n    })\n    if (!this.shouldThrowOnError) {\n      res = res.catch((fetchError) => ({\n        error: {\n          message: `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`,\n          details: `${fetchError?.stack ?? ''}`,\n          hint: '',\n          code: `${fetchError?.code ?? ''}`,\n        },\n        data: null,\n        count: null,\n        status: 0,\n        statusText: '',\n      }))\n    }\n\n    return res.then(onfulfilled, onrejected)\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestBuilder<\n    ClientOptions,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    /* istanbul ignore next */\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n\n  /**\n   * Override the type of the returned `data` field in the response.\n   *\n   * @typeParam NewResult - The new type to cast the response data to\n   * @typeParam Options - Optional type configuration (defaults to { merge: true })\n   * @typeParam Options.merge - When true, merges the new type with existing return type. When false, replaces the existing types entirely (defaults to true)\n   * @example\n   * ```typescript\n   * // Merge with existing types (default behavior)\n   * const query = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ custom_field: string }>()\n   *\n   * // Replace existing types completely\n   * const replaceQuery = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ id: number; name: string }, { merge: false }>()\n   * ```\n   * @returns A PostgrestBuilder instance with the new type\n   */\n  overrideTypes<\n    NewResult,\n    Options extends { merge?: boolean } = { merge: true }\n  >(): PostgrestBuilder<\n    ClientOptions,\n    IsValidResultOverride<Result, NewResult, false, false> extends true\n      ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n        ContainsNull<Result> extends true\n        ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n        : MergePartialResult<NewResult, Result, Options>\n      : CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      IsValidResultOverride<Result, NewResult, false, false> extends true\n        ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n          ContainsNull<Result> extends true\n          ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n          : MergePartialResult<NewResult, Result, Options>\n        : CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA,aAAa;AACb,MAAA,eAAA,iDAA4C;AAW5C,MAAA,mBAAA,6CAA6C;AAG7C,MAA8B,gBAAgB;IAmB5C,YAAY,OAUX,CAAA;;QAfS,IAAA,CAAA,kBAAkB,GAAG,KAAK,CAAA;QAgBlC,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAA;QAC5B,IAAI,CAAC,GAAG,GAAG,OAAO,CAAC,GAAG,CAAA;QACtB,IAAI,CAAC,OAAO,GAAG,IAAI,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAA;QAC3C,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAA;QAC5B,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC,IAAI,CAAA;QACxB,IAAI,CAAC,kBAAkB,GAAG,CAAA,KAAA,OAAO,CAAC,kBAAkB,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK,CAAA;QAC7D,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAA;QAC5B,IAAI,CAAC,aAAa,GAAG,CAAA,KAAA,OAAO,CAAC,aAAa,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK,CAAA;QAEnD,IAAI,OAAO,CAAC,KAAK,EAAE;YACjB,IAAI,CAAC,KAAK,GAAG,OAAO,CAAC,KAAK,CAAA;SAC3B,MAAM,IAAI,OAAO,KAAK,KAAK,WAAW,EAAE;YACvC,IAAI,CAAC,KAAK,GAAG,aAAA,OAAS,CAAA;SACvB,MAAM;YACL,IAAI,CAAC,KAAK,GAAG,KAAK,CAAA;SACnB;IACH,CAAC;IAED;;;;;OAKG,CACH,YAAY,GAAA;QACV,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAA;QAC9B,OAAO,IAA4D,CAAA;IACrE,CAAC;IAED;;OAEG,CACH,SAAS,CAAC,IAAY,EAAE,KAAa,EAAA;QACnC,IAAI,CAAC,OAAO,GAAG,IAAI,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAA;QACxC,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,IAAI,EAAE,KAAK,CAAC,CAAA;QAC7B,OAAO,IAAI,CAAA;IACb,CAAC;IAED,IAAI,CAMF,WAOQ,EACR,UAAmF,EAAA;QAEnF,6DAA6D;QAC7D,IAAI,IAAI,CAAC,MAAM,KAAK,SAAS,EAAE;QAC7B,OAAO;SACR,MAAM,IAAI;YAAC,KAAK;YAAE,MAAM;SAAC,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,CAAC,EAAE;YAChD,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,gBAAgB,EAAE,IAAI,CAAC,MAAM,CAAC,CAAA;SAChD,MAAM;YACL,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,iBAAiB,EAAE,IAAI,CAAC,MAAM,CAAC,CAAA;SACjD;QACD,IAAI,IAAI,CAAC,MAAM,KAAK,KAAK,IAAI,IAAI,CAAC,MAAM,KAAK,MAAM,EAAE;YACnD,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,cAAc,EAAE,kBAAkB,CAAC,CAAA;SACrD;QAED,6DAA6D;QAC7D,oDAAoD;QACpD,MAAM,MAAM,GAAG,IAAI,CAAC,KAAK,CAAA;QACzB,IAAI,GAAG,GAAG,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,QAAQ,EAAE,EAAE;YACpC,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,IAAI,EAAE,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC;YAC/B,MAAM,EAAE,IAAI,CAAC,MAAM;SACpB,CAAC,CAAC,IAAI,CAAC,KAAK,EAAE,GAAG,EAAE,EAAE;;YACpB,IAAI,KAAK,GAAG,IAAI,CAAA;YAChB,IAAI,IAAI,GAAG,IAAI,CAAA;YACf,IAAI,KAAK,GAAkB,IAAI,CAAA;YAC/B,IAAI,MAAM,GAAG,GAAG,CAAC,MAAM,CAAA;YACvB,IAAI,UAAU,GAAG,GAAG,CAAC,UAAU,CAAA;YAE/B,IAAI,GAAG,CAAC,EAAE,EAAE;gBACV,IAAI,IAAI,CAAC,MAAM,KAAK,MAAM,EAAE;oBAC1B,MAAM,IAAI,GAAG,MAAM,GAAG,CAAC,IAAI,EAAE,CAAA;oBAC7B,IAAI,IAAI,KAAK,EAAE,EAAE;oBACf,yBAAyB;qBAC1B,MAAM,IAAI,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,UAAU,EAAE;wBACpD,IAAI,GAAG,IAAI,CAAA;qBACZ,MAAM,IACL,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,KAC1B,CAAA,KAAA,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,QAAQ,CAAC,iCAAiC,CAAC,CAAA,EACvE;wBACA,IAAI,GAAG,IAAI,CAAA;qBACZ,MAAM;wBACL,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAA;qBACxB;iBACF;gBAED,MAAM,WAAW,GAAG,CAAA,KAAA,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,CAAC,iCAAiC,CAAC,CAAA;gBACxF,MAAM,YAAY,GAAG,CAAA,KAAA,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,eAAe,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,CAAC,GAAG,CAAC,CAAA;gBACjE,IAAI,WAAW,IAAI,YAAY,IAAI,YAAY,CAAC,MAAM,GAAG,CAAC,EAAE;oBAC1D,KAAK,GAAG,QAAQ,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAA;iBAClC;gBAED,gFAAgF;gBAChF,kEAAkE;gBAClE,IAAI,IAAI,CAAC,aAAa,IAAI,IAAI,CAAC,MAAM,KAAK,KAAK,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;oBACtE,IAAI,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE;wBACnB,KAAK,GAAG;4BACN,mHAAmH;4BACnH,IAAI,EAAE,UAAU;4BAChB,OAAO,EAAE,CAAA,gBAAA,EAAmB,IAAI,CAAC,MAAM,CAAA,uDAAA,CAAyD;4BAChG,IAAI,EAAE,IAAI;4BACV,OAAO,EAAE,uDAAuD;yBACjE,CAAA;wBACD,IAAI,GAAG,IAAI,CAAA;wBACX,KAAK,GAAG,IAAI,CAAA;wBACZ,MAAM,GAAG,GAAG,CAAA;wBACZ,UAAU,GAAG,gBAAgB,CAAA;qBAC9B,MAAM,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;wBAC5B,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAA;qBACf,MAAM;wBACL,IAAI,GAAG,IAAI,CAAA;qBACZ;iBACF;aACF,MAAM;gBACL,MAAM,IAAI,GAAG,MAAM,GAAG,CAAC,IAAI,EAAE,CAAA;gBAE7B,IAAI;oBACF,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAA;oBAExB,qEAAqE;oBACrE,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,IAAI,GAAG,CAAC,MAAM,KAAK,GAAG,EAAE;wBAC9C,IAAI,GAAG,EAAE,CAAA;wBACT,KAAK,GAAG,IAAI,CAAA;wBACZ,MAAM,GAAG,GAAG,CAAA;wBACZ,UAAU,GAAG,IAAI,CAAA;qBAClB;iBACF,CAAC,OAAA,IAAM;oBACN,qEAAqE;oBACrE,IAAI,GAAG,CAAC,MAAM,KAAK,GAAG,IAAI,IAAI,KAAK,EAAE,EAAE;wBACrC,MAAM,GAAG,GAAG,CAAA;wBACZ,UAAU,GAAG,YAAY,CAAA;qBAC1B,MAAM;wBACL,KAAK,GAAG;4BACN,OAAO,EAAE,IAAI;yBACd,CAAA;qBACF;iBACF;gBAED,IAAI,KAAK,IAAI,IAAI,CAAC,aAAa,IAAA,CAAI,CAAA,KAAA,KAAK,KAAA,QAAL,KAAK,KAAA,KAAA,IAAA,KAAA,IAAL,KAAK,CAAE,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,QAAQ,CAAC,QAAQ,CAAC,CAAA,EAAE;oBACrE,KAAK,GAAG,IAAI,CAAA;oBACZ,MAAM,GAAG,GAAG,CAAA;oBACZ,UAAU,GAAG,IAAI,CAAA;iBAClB;gBAED,IAAI,KAAK,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBACpC,MAAM,IAAI,iBAAA,OAAc,CAAC,KAAK,CAAC,CAAA;iBAChC;aACF;YAED,MAAM,iBAAiB,GAAG;gBACxB,KAAK;gBACL,IAAI;gBACJ,KAAK;gBACL,MAAM;gBACN,UAAU;aACX,CAAA;YAED,OAAO,iBAAiB,CAAA;QAC1B,CAAC,CAAC,CAAA;QACF,IAAI,CAAC,IAAI,CAAC,kBAAkB,EAAE;YAC5B,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,CAAC,UAAU,EAAE,EAAE;;gBAAC,OAAA,AAAC;oBAC/B,KAAK,EAAE;wBACL,OAAO,EAAE,GAAG,CAAA,KAAA,UAAU,KAAA,QAAV,UAAU,KAAA,KAAA,IAAA,KAAA,IAAV,UAAU,CAAE,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,YAAY,CAAA,EAAA,EAAK,UAAU,KAAA,QAAV,UAAU,KAAA,KAAA,IAAA,KAAA,IAAV,UAAU,CAAE,OAAO,EAAE;wBACtE,OAAO,EAAE,GAAG,CAAA,KAAA,UAAU,KAAA,QAAV,UAAU,KAAA,KAAA,IAAA,KAAA,IAAV,UAAU,CAAE,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,EAAE,EAAE;wBACrC,IAAI,EAAE,EAAE;wBACR,IAAI,EAAE,GAAG,CAAA,KAAA,UAAU,KAAA,QAAV,UAAU,KAAA,KAAA,IAAA,KAAA,IAAV,UAAU,CAAE,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,EAAE,EAAE;qBAClC;oBACD,IAAI,EAAE,IAAI;oBACV,KAAK,EAAE,IAAI;oBACX,MAAM,EAAE,CAAC;oBACT,UAAU,EAAE,EAAE;iBACf,CAAC,CAAA;aAAA,CAAC,CAAA;SACJ;QAED,OAAO,GAAG,CAAC,IAAI,CAAC,WAAW,EAAE,UAAU,CAAC,CAAA;IAC1C,CAAC;IAED;;;;;OAKG,CACH,OAAO,GAAA;QAKL,wBAAA,EAA0B,CAC1B,OAAO,IAIN,CAAA;IACH,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;OAqBG,CACH,aAAa,GAAA;QAaX,OAAO,IASN,CAAA;IACH,CAAC;CACF;AA5RD,QAAA,OAAA,GAAA,iBA4RC"}},
    {"offset": {"line": 502, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/PostgrestTransformBuilder.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/PostgrestTransformBuilder.ts"],"sourcesContent":["import PostgrestBuilder from './PostgrestBuilder'\nimport { InvalidMethodError } from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport {\n  GenericSchema,\n  CheckMatchingArrayTypes,\n  ClientServerOptions,\n  MaxAffectedEnabled,\n} from './types'\n\nexport default class PostgrestTransformBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown\n> extends PostgrestBuilder<ClientOptions, Result> {\n  /**\n   * Perform a SELECT on the query result.\n   *\n   * By default, `.insert()`, `.update()`, `.upsert()`, and `.delete()` do not\n   * return modified rows. By calling this method, modified rows are returned in\n   * `data`.\n   *\n   * @param columns - The columns to retrieve, separated by commas\n   */\n  select<\n    Query extends string = '*',\n    NewResultOne = GetResult<Schema, Row, RelationName, Relationships, Query, ClientOptions>\n  >(\n    columns?: Query\n  ): PostgrestTransformBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    NewResultOne[],\n    RelationName,\n    Relationships,\n    Method\n  > {\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n    this.headers.append('Prefer', 'return=representation')\n    return this as unknown as PostgrestTransformBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      NewResultOne[],\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: undefined }\n  ): this\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: string }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: undefined }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: string }\n  ): this\n  /**\n   * Order the query result by `column`.\n   *\n   * You can call this method multiple times to order by multiple columns.\n   *\n   * You can order referenced tables, but it only affects the ordering of the\n   * parent table if you use `!inner` in the query.\n   *\n   * @param column - The column to order by\n   * @param options - Named parameters\n   * @param options.ascending - If `true`, the result will be in ascending order\n   * @param options.nullsFirst - If `true`, `null`s appear first. If `false`,\n   * `null`s appear last.\n   * @param options.referencedTable - Set this to order a referenced table by\n   * its columns\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  order(\n    column: string,\n    {\n      ascending = true,\n      nullsFirst,\n      foreignTable,\n      referencedTable = foreignTable,\n    }: {\n      ascending?: boolean\n      nullsFirst?: boolean\n      foreignTable?: string\n      referencedTable?: string\n    } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.order` : 'order'\n    const existingOrder = this.url.searchParams.get(key)\n\n    this.url.searchParams.set(\n      key,\n      `${existingOrder ? `${existingOrder},` : ''}${column}.${ascending ? 'asc' : 'desc'}${\n        nullsFirst === undefined ? '' : nullsFirst ? '.nullsfirst' : '.nullslast'\n      }`\n    )\n    return this\n  }\n\n  /**\n   * Limit the query result by `count`.\n   *\n   * @param count - The maximum number of rows to return\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  limit(\n    count: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(key, `${count}`)\n    return this\n  }\n\n  /**\n   * Limit the query result by starting at an offset `from` and ending at the offset `to`.\n   * Only records within this range are returned.\n   * This respects the query order and if there is no order clause the range could behave unexpectedly.\n   * The `from` and `to` values are 0-based and inclusive: `range(1, 3)` will include the second, third\n   * and fourth rows of the query.\n   *\n   * @param from - The starting index from which to limit the result\n   * @param to - The last index to which to limit the result\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  range(\n    from: number,\n    to: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const keyOffset =\n      typeof referencedTable === 'undefined' ? 'offset' : `${referencedTable}.offset`\n    const keyLimit = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(keyOffset, `${from}`)\n    // Range is inclusive, so add 1\n    this.url.searchParams.set(keyLimit, `${to - from + 1}`)\n    return this\n  }\n\n  /**\n   * Set the AbortSignal for the fetch request.\n   *\n   * @param signal - The AbortSignal to use for the fetch request\n   */\n  abortSignal(signal: AbortSignal): this {\n    this.signal = signal\n    return this\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be one row (e.g. using `.limit(1)`), otherwise this\n   * returns an error.\n   */\n  single<ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never>(): PostgrestBuilder<\n    ClientOptions,\n    ResultOne\n  > {\n    this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne>\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be zero or one row (e.g. using `.limit(1)`), otherwise\n   * this returns an error.\n   */\n  maybeSingle<\n    ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never\n  >(): PostgrestBuilder<ClientOptions, ResultOne | null> {\n    // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n    // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n    if (this.method === 'GET') {\n      this.headers.set('Accept', 'application/json')\n    } else {\n      this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    }\n    this.isMaybeSingle = true\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne | null>\n  }\n\n  /**\n   * Return `data` as a string in CSV format.\n   */\n  csv(): PostgrestBuilder<ClientOptions, string> {\n    this.headers.set('Accept', 'text/csv')\n    return this as unknown as PostgrestBuilder<ClientOptions, string>\n  }\n\n  /**\n   * Return `data` as an object in [GeoJSON](https://geojson.org) format.\n   */\n  geojson(): PostgrestBuilder<ClientOptions, Record<string, unknown>> {\n    this.headers.set('Accept', 'application/geo+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>>\n  }\n\n  /**\n   * Return `data` as the EXPLAIN plan for the query.\n   *\n   * You need to enable the\n   * [db_plan_enabled](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain)\n   * setting before using this method.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.analyze - If `true`, the query will be executed and the\n   * actual run time will be returned\n   *\n   * @param options.verbose - If `true`, the query identifier will be returned\n   * and `data` will include the output columns of the query\n   *\n   * @param options.settings - If `true`, include information on configuration\n   * parameters that affect query planning\n   *\n   * @param options.buffers - If `true`, include information on buffer usage\n   *\n   * @param options.wal - If `true`, include information on WAL record generation\n   *\n   * @param options.format - The format of the output, can be `\"text\"` (default)\n   * or `\"json\"`\n   */\n  explain({\n    analyze = false,\n    verbose = false,\n    settings = false,\n    buffers = false,\n    wal = false,\n    format = 'text',\n  }: {\n    analyze?: boolean\n    verbose?: boolean\n    settings?: boolean\n    buffers?: boolean\n    wal?: boolean\n    format?: 'json' | 'text'\n  } = {}) {\n    const options = [\n      analyze ? 'analyze' : null,\n      verbose ? 'verbose' : null,\n      settings ? 'settings' : null,\n      buffers ? 'buffers' : null,\n      wal ? 'wal' : null,\n    ]\n      .filter(Boolean)\n      .join('|')\n    // An Accept header can carry multiple media types but postgrest-js always sends one\n    const forMediatype = this.headers.get('Accept') ?? 'application/json'\n    this.headers.set(\n      'Accept',\n      `application/vnd.pgrst.plan+${format}; for=\"${forMediatype}\"; options=${options};`\n    )\n    if (format === 'json') {\n      return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>[]>\n    } else {\n      return this as unknown as PostgrestBuilder<ClientOptions, string>\n    }\n  }\n\n  /**\n   * Rollback the query.\n   *\n   * `data` will still be returned, but the query is not committed.\n   */\n  rollback(): this {\n    this.headers.append('Prefer', 'tx=rollback')\n    return this\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestTransformBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    RelationName,\n    Relationships,\n    Method\n  > {\n    return this as unknown as PostgrestTransformBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  /**\n   * Set the maximum number of rows that can be affected by the query.\n   * Only available in PostgREST v13+ and only works with PATCH and DELETE methods.\n   *\n   * @param value - The maximum number of rows that can be affected\n   */\n  maxAffected(value: number): MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n    ? // TODO: update the RPC case to only work on RPC that returns SETOF rows\n      Method extends 'PATCH' | 'DELETE' | 'RPC'\n      ? this\n      : InvalidMethodError<'maxAffected method only available on update or delete'>\n    : InvalidMethodError<'maxAffected method only available on postgrest 13+'> {\n    this.headers.append('Prefer', 'handling=strict')\n    this.headers.append('Prefer', `max-affected=${value}`)\n    return this as unknown as MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n      ? Method extends 'PATCH' | 'DELETE' | 'RPC'\n        ? this\n        : InvalidMethodError<'maxAffected method only available on update or delete'>\n      : InvalidMethodError<'maxAffected method only available on postgrest 13+'>\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA,MAAA,qBAAA,+CAAiD;AAUjD,MAAqB,yBAQnB,SAAQ,mBAAA,OAAuC;IAC/C;;;;;;;;OAQG,CACH,MAAM,CAIJ,OAAe,EAAA;QAUf,wCAAwC;QACxC,IAAI,MAAM,GAAG,KAAK,CAAA;QAClB,MAAM,cAAc,GAAG,CAAC,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAP,OAAO,GAAI,GAAG,CAAC,CACpC,KAAK,CAAC,EAAE,CAAC,CACT,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE;YACT,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,EAAE;gBAC3B,OAAO,EAAE,CAAA;aACV;YACD,IAAI,CAAC,KAAK,GAAG,EAAE;gBACb,MAAM,GAAG,CAAC,MAAM,CAAA;aACjB;YACD,OAAO,CAAC,CAAA;QACV,CAAC,CAAC,CACD,IAAI,CAAC,EAAE,CAAC,CAAA;QACX,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,QAAQ,EAAE,cAAc,CAAC,CAAA;QACnD,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,uBAAuB,CAAC,CAAA;QACtD,OAAO,IAQN,CAAA;IACH,CAAC;IAwBD;;;;;;;;;;;;;;;;;OAiBG,CACH,KAAK,CACH,MAAc,EACd,EACE,SAAS,GAAG,IAAI,EAChB,UAAU,EACV,YAAY,EACZ,eAAe,GAAG,YAAY,EAAA,GAM5B,CAAA,CAAE,EAAA;QAEN,MAAM,GAAG,GAAG,eAAe,CAAC,CAAC,CAAC,GAAG,eAAe,CAAA,MAAA,CAAQ,CAAC,CAAC,CAAC,OAAO,CAAA;QAClE,MAAM,aAAa,GAAG,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,CAAC,CAAA;QAEpD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CACvB,GAAG,EACH,GAAG,aAAa,CAAC,CAAC,CAAC,GAAG,aAAa,CAAA,CAAA,CAAG,CAAC,CAAC,CAAC,EAAE,GAAG,MAAM,CAAA,CAAA,EAAI,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,GAChF,UAAU,KAAK,SAAS,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,aAAa,CAAC,CAAC,CAAC,YAC/D,EAAE,CACH,CAAA;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;;;;;OASG,CACH,KAAK,CACH,KAAa,EACb,EACE,YAAY,EACZ,eAAe,GAAG,YAAY,EAAA,GACyB,CAAA,CAAE,EAAA;QAE3D,MAAM,GAAG,GAAG,OAAO,eAAe,KAAK,WAAW,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,eAAe,CAAA,MAAA,CAAQ,CAAA;QACzF,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,GAAG,EAAE,GAAG,KAAK,EAAE,CAAC,CAAA;QAC1C,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;;;;;;;;;;OAcG,CACH,KAAK,CACH,IAAY,EACZ,EAAU,EACV,EACE,YAAY,EACZ,eAAe,GAAG,YAAY,EAAA,GACyB,CAAA,CAAE,EAAA;QAE3D,MAAM,SAAS,GACb,OAAO,eAAe,KAAK,WAAW,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,GAAG,eAAe,CAAA,OAAA,CAAS,CAAA;QACjF,MAAM,QAAQ,GAAG,OAAO,eAAe,KAAK,WAAW,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,eAAe,CAAA,MAAA,CAAQ,CAAA;QAC9F,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,SAAS,EAAE,GAAG,IAAI,EAAE,CAAC,CAAA;QAC/C,+BAA+B;QAC/B,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,QAAQ,EAAE,GAAG,EAAE,GAAG,IAAI,GAAG,CAAC,EAAE,CAAC,CAAA;QACvD,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;OAIG,CACH,WAAW,CAAC,MAAmB,EAAA;QAC7B,IAAI,CAAC,MAAM,GAAG,MAAM,CAAA;QACpB,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;OAKG,CACH,MAAM,GAAA;QAIJ,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,mCAAmC,CAAC,CAAA;QAC/D,OAAO,IAA6D,CAAA;IACtE,CAAC;IAED;;;;;OAKG,CACH,WAAW,GAAA;QAGT,gFAAgF;QAChF,kEAAkE;QAClE,IAAI,IAAI,CAAC,MAAM,KAAK,KAAK,EAAE;YACzB,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,kBAAkB,CAAC,CAAA;SAC/C,MAAM;YACL,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,mCAAmC,CAAC,CAAA;SAChE;QACD,IAAI,CAAC,aAAa,GAAG,IAAI,CAAA;QACzB,OAAO,IAAoE,CAAA;IAC7E,CAAC;IAED;;OAEG,CACH,GAAG,GAAA;QACD,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAA;QACtC,OAAO,IAA0D,CAAA;IACnE,CAAC;IAED;;OAEG,CACH,OAAO,GAAA;QACL,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,sBAAsB,CAAC,CAAA;QAClD,OAAO,IAA2E,CAAA;IACpF,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;OAwBG,CACH,OAAO,CAAC,EACN,OAAO,GAAG,KAAK,EACf,OAAO,GAAG,KAAK,EACf,QAAQ,GAAG,KAAK,EAChB,OAAO,GAAG,KAAK,EACf,GAAG,GAAG,KAAK,EACX,MAAM,GAAG,MAAM,EAAA,GAQb,CAAA,CAAE,EAAA;;QACJ,MAAM,OAAO,GAAG;YACd,OAAO,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI;YAC1B,OAAO,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI;YAC1B,QAAQ,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,IAAI;YAC5B,OAAO,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI;YAC1B,GAAG,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI;SACnB,CACE,MAAM,CAAC,OAAO,CAAC,CACf,IAAI,CAAC,GAAG,CAAC,CAAA;QACZ,oFAAoF;QACpF,MAAM,YAAY,GAAG,CAAA,KAAA,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,kBAAkB,CAAA;QACrE,IAAI,CAAC,OAAO,CAAC,GAAG,CACd,QAAQ,EACR,CAAA,2BAAA,EAA8B,MAAM,CAAA,OAAA,EAAU,YAAY,CAAA,WAAA,EAAc,OAAO,CAAA,CAAA,CAAG,CACnF,CAAA;QACD,IAAI,MAAM,KAAK,MAAM,EAAE;YACrB,OAAO,IAA6E,CAAA;SACrF,MAAM;YACL,OAAO,IAA0D,CAAA;SAClE;IACH,CAAC;IAED;;;;OAIG,CACH,QAAQ,GAAA;QACN,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,aAAa,CAAC,CAAA;QAC5C,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;OAKG,CACH,OAAO,GAAA;QASL,OAAO,IAQN,CAAA;IACH,CAAC;IAED;;;;;OAKG,CACH,WAAW,CAAC,KAAa,EAAA;QAMvB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,iBAAiB,CAAC,CAAA;QAChD,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,aAAA,EAAgB,KAAK,EAAE,CAAC,CAAA;QACtD,OAAO,IAIqE,CAAA;IAC9E,CAAC;CACF;AArWD,QAAA,OAAA,GAAA,0BAqWC"}},
    {"offset": {"line": 714, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/PostgrestFilterBuilder.ts"],"sourcesContent":["import PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport { JsonPathToAccessor, JsonPathToType } from './select-query-parser/utils'\nimport { ClientServerOptions, GenericSchema } from './types'\n\ntype FilterOperator =\n  | 'eq'\n  | 'neq'\n  | 'gt'\n  | 'gte'\n  | 'lt'\n  | 'lte'\n  | 'like'\n  | 'ilike'\n  | 'is'\n  | 'in'\n  | 'cs'\n  | 'cd'\n  | 'sl'\n  | 'sr'\n  | 'nxl'\n  | 'nxr'\n  | 'adj'\n  | 'ov'\n  | 'fts'\n  | 'plfts'\n  | 'phfts'\n  | 'wfts'\n\nexport type IsStringOperator<Path extends string> = Path extends `${string}->>${string}`\n  ? true\n  : false\n\n// Match relationship filters with `table.column` syntax and resolve underlying\n// column value. If not matched, fallback to generic type.\n// TODO: Validate the relationship itself ala select-query-parser. Currently we\n// assume that all tables have valid relationships to each other, despite\n// nonexistent foreign keys.\ntype ResolveFilterValue<\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  ColumnName extends string\n> = ColumnName extends `${infer RelationshipTable}.${infer Remainder}`\n  ? Remainder extends `${infer _}.${infer _}`\n    ? ResolveFilterValue<Schema, Row, Remainder>\n    : ResolveFilterRelationshipValue<Schema, RelationshipTable, Remainder>\n  : ColumnName extends keyof Row\n  ? Row[ColumnName]\n  : // If the column selection is a jsonpath like `data->value` or `data->>value` we attempt to match\n  // the expected type with the parsed custom json type\n  IsStringOperator<ColumnName> extends true\n  ? string\n  : JsonPathToType<Row, JsonPathToAccessor<ColumnName>> extends infer JsonPathValue\n  ? JsonPathValue extends never\n    ? never\n    : JsonPathValue\n  : never\n\ntype ResolveFilterRelationshipValue<\n  Schema extends GenericSchema,\n  RelationshipTable extends string,\n  RelationshipColumn extends string\n> = Schema['Tables'] & Schema['Views'] extends infer TablesAndViews\n  ? RelationshipTable extends keyof TablesAndViews\n    ? 'Row' extends keyof TablesAndViews[RelationshipTable]\n      ? RelationshipColumn extends keyof TablesAndViews[RelationshipTable]['Row']\n        ? TablesAndViews[RelationshipTable]['Row'][RelationshipColumn]\n        : unknown\n      : unknown\n    : unknown\n  : never\n\nexport type InvalidMethodError<S extends string> = { Error: S }\n\nexport default class PostgrestFilterBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown\n> extends PostgrestTransformBuilder<\n  ClientOptions,\n  Schema,\n  Row,\n  Result,\n  RelationName,\n  Relationships,\n  Method\n> {\n  /**\n   * Match only rows where `column` is equal to `value`.\n   *\n   * To check if the value of `column` is NULL, you should use `.is()` instead.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  eq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? NonNullable<unknown>\n      : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n      // type resolution error\n      ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n      ? NonNullable<ResolvedFilterValue>\n      : // We should never enter this case as all the branches are covered above\n        never\n  ): this {\n    this.url.searchParams.append(column, `eq.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is not equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  neq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n      ? ResolvedFilterValue\n      : never\n  ): this {\n    this.url.searchParams.append(column, `neq.${value}`)\n    return this\n  }\n\n  gt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gt.${value}`)\n    return this\n  }\n\n  gte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gte.${value}`)\n    return this\n  }\n\n  lt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lt.${value}`)\n    return this\n  }\n\n  lte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lte.${value}`)\n    return this\n  }\n\n  like<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  like(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  like(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `like.${pattern}`)\n    return this\n  }\n\n  likeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  likeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilike<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  ilike(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  ilike(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `ilike.${pattern}`)\n    return this\n  }\n\n  ilikeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilikeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  is<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: Row[ColumnName] & (boolean | null)\n  ): this\n  is(column: string, value: boolean | null): this\n  /**\n   * Match only rows where `column` IS `value`.\n   *\n   * For non-boolean columns, this is only relevant for checking if the value of\n   * `column` is NULL by setting `value` to `null`.\n   *\n   * For boolean columns, you can also set `value` to `true` or `false` and it\n   * will behave the same way as `.eq()`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  is(column: string, value: boolean | null): this {\n    this.url.searchParams.append(column, `is.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  in<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n        // type resolution error\n        ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : // We should never enter this case as all the branches are covered above\n          never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && new RegExp('[,()]').test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `in.(${cleanedValues})`)\n    return this\n  }\n\n  contains<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * `column` contains every element appearing in `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range types can be inclusive '[', ']' or exclusive '(', ')' so just\n      // keep it simple and accept a string\n      this.url.searchParams.append(column, `cs.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cs.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cs.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  containedBy<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * every element appearing in `column` is contained by `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `cd.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cd.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cd.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  rangeGt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is greater than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sr.${range}`)\n    return this\n  }\n\n  rangeGte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or greater than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxl.${range}`)\n    return this\n  }\n\n  rangeLt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is less than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sl.${range}`)\n    return this\n  }\n\n  rangeLte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or less than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxr.${range}`)\n    return this\n  }\n\n  rangeAdjacent<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeAdjacent(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where `column` is\n   * mutually exclusive to `range` and there can be no element between the two\n   * ranges.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeAdjacent(column: string, range: string): this {\n    this.url.searchParams.append(column, `adj.${range}`)\n    return this\n  }\n\n  overlaps<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]>\n  ): this\n  overlaps(column: string, value: string | readonly unknown[]): this\n  /**\n   * Only relevant for array and range columns. Match only rows where\n   * `column` and `value` have an element in common.\n   *\n   * @param column - The array or range column to filter on\n   * @param value - The array or range value to filter with\n   */\n  overlaps(column: string, value: string | readonly unknown[]): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `ov.${value}`)\n    } else {\n      // array\n      this.url.searchParams.append(column, `ov.{${value.join(',')}}`)\n    }\n    return this\n  }\n\n  textSearch<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  textSearch(\n    column: string,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  /**\n   * Only relevant for text and tsvector columns. Match only rows where\n   * `column` matches the query string in `query`.\n   *\n   * @param column - The text or tsvector column to filter on\n   * @param query - The query text to match with\n   * @param options - Named parameters\n   * @param options.config - The text search configuration to use\n   * @param options.type - Change how the `query` text is interpreted\n   */\n  textSearch(\n    column: string,\n    query: string,\n    { config, type }: { config?: string; type?: 'plain' | 'phrase' | 'websearch' } = {}\n  ): this {\n    let typePart = ''\n    if (type === 'plain') {\n      typePart = 'pl'\n    } else if (type === 'phrase') {\n      typePart = 'ph'\n    } else if (type === 'websearch') {\n      typePart = 'w'\n    }\n    const configPart = config === undefined ? '' : `(${config})`\n    this.url.searchParams.append(column, `${typePart}fts${configPart}.${query}`)\n    return this\n  }\n\n  match<ColumnName extends string & keyof Row>(query: Record<ColumnName, Row[ColumnName]>): this\n  match(query: Record<string, unknown>): this\n  /**\n   * Match only rows where each column in `query` keys is equal to its\n   * associated value. Shorthand for multiple `.eq()`s.\n   *\n   * @param query - The object to filter with, with column names as keys mapped\n   * to their filter values\n   */\n  match(query: Record<string, unknown>): this {\n    Object.entries(query).forEach(([column, value]) => {\n      this.url.searchParams.append(column, `eq.${value}`)\n    })\n    return this\n  }\n\n  not<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: FilterOperator,\n    value: Row[ColumnName]\n  ): this\n  not(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which doesn't satisfy the filter.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to be negated to filter with, following\n   * PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  not(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `not.${operator}.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows which satisfy at least one of the filters.\n   *\n   * Unlike most filters, `filters` is used as-is and needs to follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure it's properly sanitized.\n   *\n   * It's currently not possible to do an `.or()` filter across multiple tables.\n   *\n   * @param filters - The filters to use, following PostgREST syntax\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to filter on referenced tables\n   * instead of the parent table\n   * @param options.foreignTable - Deprecated, use `referencedTable` instead\n   */\n  or(\n    filters: string,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.or` : 'or'\n    this.url.searchParams.append(key, `(${filters})`)\n    return this\n  }\n\n  filter<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: `${'' | 'not.'}${FilterOperator}`,\n    value: unknown\n  ): this\n  filter(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which satisfy the filter. This is an escape hatch - you\n   * should use the specific filter methods wherever possible.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to filter with, following PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  filter(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `${operator}.${value}`)\n    return this\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA,MAAA,8BAAA,wDAAmE;AAyEnE,MAAqB,sBAQnB,SAAQ,4BAAA,OAQT;IACC;;;;;;;OAOG,CACH,EAAE,CACA,MAAkB,EAClB,KAOS,EAAA;QAET,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACnD,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;OAKG,CACH,GAAG,CACD,MAAkB,EAClB,KAIS,EAAA;QAET,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,EAAE,CAAC,CAAA;QACpD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;OAKG,CACH,EAAE,CAAC,MAAc,EAAE,KAAc,EAAA;QAC/B,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACnD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;OAKG,CACH,GAAG,CAAC,MAAc,EAAE,KAAc,EAAA;QAChC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,EAAE,CAAC,CAAA;QACpD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;OAKG,CACH,EAAE,CAAC,MAAc,EAAE,KAAc,EAAA;QAC/B,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACnD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;OAKG,CACH,GAAG,CAAC,MAAc,EAAE,KAAc,EAAA;QAChC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,EAAE,CAAC,CAAA;QACpD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;OAKG,CACH,IAAI,CAAC,MAAc,EAAE,OAAe,EAAA;QAClC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,KAAA,EAAQ,OAAO,EAAE,CAAC,CAAA;QACvD,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;OAKG,CACH,SAAS,CAAC,MAAc,EAAE,QAA2B,EAAA;QACnD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,WAAA,EAAc,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;QACzE,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;OAKG,CACH,SAAS,CAAC,MAAc,EAAE,QAA2B,EAAA;QACnD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,WAAA,EAAc,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;QACzE,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;OAKG,CACH,KAAK,CAAC,MAAc,EAAE,OAAe,EAAA;QACnC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,MAAA,EAAS,OAAO,EAAE,CAAC,CAAA;QACxD,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;OAKG,CACH,UAAU,CAAC,MAAc,EAAE,QAA2B,EAAA;QACpD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,YAAA,EAAe,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;QAC1E,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;OAKG,CACH,UAAU,CAAC,MAAc,EAAE,QAA2B,EAAA;QACpD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,YAAA,EAAe,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;QAC1E,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;;;;;;;OAWG,CACH,EAAE,CAAC,MAAc,EAAE,KAAqB,EAAA;QACtC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACnD,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;OAKG,CACH,EAAE,CACA,MAAkB,EAClB,MASC,EAAA;QAED,MAAM,aAAa,GAAG,KAAK,CAAC,IAAI,CAAC,IAAI,GAAG,CAAC,MAAM,CAAC,CAAC,CAC9C,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE;YACT,uCAAuC;YACvC,+DAA+D;YAC/D,IAAI,OAAO,CAAC,KAAK,QAAQ,IAAI,IAAI,MAAM,CAAC,OAAO,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,OAAO,CAAA,CAAA,EAAI,CAAC,CAAA,CAAA,CAAG,CAAA;iBACpE,OAAO,GAAG,CAAC,EAAE,CAAA;QACpB,CAAC,CAAC,CACD,IAAI,CAAC,GAAG,CAAC,CAAA;QACZ,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,aAAa,CAAA,CAAA,CAAG,CAAC,CAAA;QAC7D,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;;OAMG,CACH,QAAQ,CAAC,MAAc,EAAE,KAA4D,EAAA;QACnF,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;YAC7B,sEAAsE;YACtE,qCAAqC;YACrC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;SACpD,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE;YAC/B,QAAQ;YACR,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;SAChE,MAAM;YACL,OAAO;YACP,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,EAAE,CAAC,CAAA;SACpE;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;;OAMG,CACH,WAAW,CAAC,MAAc,EAAE,KAA4D,EAAA;QACtF,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;YAC7B,QAAQ;YACR,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;SACpD,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE;YAC/B,QAAQ;YACR,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;SAChE,MAAM;YACL,OAAO;YACP,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,EAAE,CAAC,CAAA;SACpE;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;;OAMG,CACH,OAAO,CAAC,MAAc,EAAE,KAAa,EAAA;QACnC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACnD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;;;OAOG,CACH,QAAQ,CAAC,MAAc,EAAE,KAAa,EAAA;QACpC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,EAAE,CAAC,CAAA;QACpD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;;OAMG,CACH,OAAO,CAAC,MAAc,EAAE,KAAa,EAAA;QACnC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACnD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;;;OAOG,CACH,QAAQ,CAAC,MAAc,EAAE,KAAa,EAAA;QACpC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,EAAE,CAAC,CAAA;QACpD,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;;;OAOG,CACH,aAAa,CAAC,MAAc,EAAE,KAAa,EAAA;QACzC,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,EAAE,CAAC,CAAA;QACpD,OAAO,IAAI,CAAA;IACb,CAAC;IAOD;;;;;;OAMG,CACH,QAAQ,CAAC,MAAc,EAAE,KAAkC,EAAA;QACzD,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;YAC7B,QAAQ;YACR,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;SACpD,MAAM;YACL,QAAQ;YACR,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAA;SAChE;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IAYD;;;;;;;;;OASG,CACH,UAAU,CACR,MAAc,EACd,KAAa,EACb,EAAE,MAAM,EAAE,IAAI,EAAA,GAAmE,CAAA,CAAE,EAAA;QAEnF,IAAI,QAAQ,GAAG,EAAE,CAAA;QACjB,IAAI,IAAI,KAAK,OAAO,EAAE;YACpB,QAAQ,GAAG,IAAI,CAAA;SAChB,MAAM,IAAI,IAAI,KAAK,QAAQ,EAAE;YAC5B,QAAQ,GAAG,IAAI,CAAA;SAChB,MAAM,IAAI,IAAI,KAAK,WAAW,EAAE;YAC/B,QAAQ,GAAG,GAAG,CAAA;SACf;QACD,MAAM,UAAU,GAAG,MAAM,KAAK,SAAS,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAA,CAAA,EAAI,MAAM,CAAA,CAAA,CAAG,CAAA;QAC5D,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,GAAG,QAAQ,CAAA,GAAA,EAAM,UAAU,CAAA,CAAA,EAAI,KAAK,EAAE,CAAC,CAAA;QAC5E,OAAO,IAAI,CAAA;IACb,CAAC;IAID;;;;;;OAMG,CACH,KAAK,CAAC,KAA8B,EAAA;QAClC,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,MAAM,EAAE,KAAK,CAAC,EAAE,EAAE;YAChD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,GAAA,EAAM,KAAK,EAAE,CAAC,CAAA;QACrD,CAAC,CAAC,CAAA;QACF,OAAO,IAAI,CAAA;IACb,CAAC;IAQD;;;;;;;;;;;;OAYG,CACH,GAAG,CAAC,MAAc,EAAE,QAAgB,EAAE,KAAc,EAAA;QAClD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,CAAA,IAAA,EAAO,QAAQ,CAAA,CAAA,EAAI,KAAK,EAAE,CAAC,CAAA;QAChE,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;;;;;;;;;;OAcG,CACH,EAAE,CACA,OAAe,EACf,EACE,YAAY,EACZ,eAAe,GAAG,YAAY,EAAA,GACyB,CAAA,CAAE,EAAA;QAE3D,MAAM,GAAG,GAAG,eAAe,CAAC,CAAC,CAAC,GAAG,eAAe,CAAA,GAAA,CAAK,CAAC,CAAC,CAAC,IAAI,CAAA;QAC5D,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,GAAG,EAAE,CAAA,CAAA,EAAI,OAAO,CAAA,CAAA,CAAG,CAAC,CAAA;QACjD,OAAO,IAAI,CAAA;IACb,CAAC;IAQD;;;;;;;;;;;;OAYG,CACH,MAAM,CAAC,MAAc,EAAE,QAAgB,EAAE,KAAc,EAAA;QACrD,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE,GAAG,QAAQ,CAAA,CAAA,EAAI,KAAK,EAAE,CAAC,CAAA;QAC5D,OAAO,IAAI,CAAA;IACb,CAAC;CACF;AAlhBD,QAAA,OAAA,GAAA,uBAkhBC"}},
    {"offset": {"line": 1063, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/PostgrestQueryBuilder.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/PostgrestQueryBuilder.ts"],"sourcesContent":["import PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport { ClientServerOptions, Fetch, GenericSchema, GenericTable, GenericView } from './types'\n\nexport default class PostgrestQueryBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Relation extends GenericTable | GenericView,\n  RelationName = unknown,\n  Relationships = Relation extends { Relationships: infer R } ? R : unknown\n> {\n  url: URL\n  headers: Headers\n  schema?: string\n  signal?: AbortSignal\n  fetch?: Fetch\n\n  constructor(\n    url: URL,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: string\n      fetch?: Fetch\n    }\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schema = schema\n    this.fetch = fetch\n  }\n\n  /**\n   * Perform a SELECT query on the table or view.\n   *\n   * @param columns - The columns to retrieve, separated by commas. Columns can be renamed when returned with `customName:columnName`\n   *\n   * @param options - Named parameters\n   *\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   *\n   * @param options.count - Count algorithm to use to count rows in the table or view.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  select<\n    Query extends string = '*',\n    ResultOne = GetResult<\n      Schema,\n      Relation['Row'],\n      RelationName,\n      Relationships,\n      Query,\n      ClientOptions\n    >\n  >(\n    columns?: Query,\n    {\n      head = false,\n      count,\n    }: {\n      head?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    ResultOne[],\n    RelationName,\n    Relationships,\n    'GET'\n  > {\n    const method = head ? 'HEAD' : 'GET'\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      fetch: this.fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk inserts.\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an INSERT into the table or view.\n   *\n   * By default, inserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to insert. Pass an object to insert a single row\n   * or an array to insert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count inserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. Only applies for bulk\n   * inserts.\n   */\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      count,\n      defaultToNull = true,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      this.headers.append('Prefer', `missing=default`)\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        this.url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk upserts.\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an UPSERT on the table or view. Depending on the column(s) passed\n   * to `onConflict`, `.upsert()` allows you to perform the equivalent of\n   * `.insert()` if a row with the corresponding `onConflict` columns doesn't\n   * exist, or if it does exist, perform an alternative action depending on\n   * `ignoreDuplicates`.\n   *\n   * By default, upserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to upsert with. Pass an object to upsert a\n   * single row or an array to upsert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.onConflict - Comma-separated UNIQUE column(s) to specify how\n   * duplicate rows are determined. Two rows are duplicates if all the\n   * `onConflict` columns are equal.\n   *\n   * @param options.ignoreDuplicates - If `true`, duplicate rows are ignored. If\n   * `false`, duplicate rows are merged with existing rows.\n   *\n   * @param options.count - Count algorithm to use to count upserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. This only applies when\n   * inserting new rows, not when merging with existing rows under\n   * `ignoreDuplicates: false`. This also only applies when doing bulk upserts.\n   */\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      onConflict,\n      ignoreDuplicates = false,\n      count,\n      defaultToNull = true,\n    }: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n\n    this.headers.append('Prefer', `resolution=${ignoreDuplicates ? 'ignore' : 'merge'}-duplicates`)\n\n    if (onConflict !== undefined) this.url.searchParams.set('on_conflict', onConflict)\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      this.headers.append('Prefer', 'missing=default')\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        this.url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform an UPDATE on the table or view.\n   *\n   * By default, updated rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param values - The values to update with\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count updated rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  update<Row extends Relation extends { Update: unknown } ? Relation['Update'] : never>(\n    values: Row,\n    {\n      count,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'PATCH'\n  > {\n    const method = 'PATCH'\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform a DELETE on the table or view.\n   *\n   * By default, deleted rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count deleted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  delete({\n    count,\n  }: {\n    count?: 'exact' | 'planned' | 'estimated'\n  } = {}): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'DELETE'\n  > {\n    const method = 'DELETE'\n    if (count) {\n      this.headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url: this.url,\n      headers: this.headers,\n      schema: this.schema,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA,MAAA,2BAAA,qDAA6D;AAI7D,MAAqB,qBAAqB;IAaxC,YACE,GAAQ,EACR,EACE,OAAO,GAAG,CAAA,CAAE,EACZ,MAAM,SACN,MAAK,EAKN,CAAA;QAED,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;QACd,IAAI,CAAC,OAAO,GAAG,IAAI,OAAO,CAAC,OAAO,CAAC,CAAA;QACnC,IAAI,CAAC,MAAM,GAAG,MAAM,CAAA;QACpB,IAAI,CAAC,KAAK,GAAG,KAAK,CAAA;IACpB,CAAC;IAED;;;;;;;;;;;;;;;;;;;;OAoBG,CACH,MAAM,CAWJ,OAAe,EACf,EACE,IAAI,GAAG,KAAK,EACZ,KAAK,EAAA,GAIH,CAAA,CAAE,EAAA;QAUN,MAAM,MAAM,GAAG,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAA;QACpC,wCAAwC;QACxC,IAAI,MAAM,GAAG,KAAK,CAAA;QAClB,MAAM,cAAc,GAAG,CAAC,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAP,OAAO,GAAI,GAAG,CAAC,CACpC,KAAK,CAAC,EAAE,CAAC,CACT,GAAG,CAAC,CAAC,CAAC,EAAE,EAAE;YACT,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,EAAE;gBAC3B,OAAO,EAAE,CAAA;aACV;YACD,IAAI,CAAC,KAAK,GAAG,EAAE;gBACb,MAAM,GAAG,CAAC,MAAM,CAAA;aACjB;YACD,OAAO,CAAC,CAAA;QACV,CAAC,CAAC,CACD,IAAI,CAAC,EAAE,CAAC,CAAA;QACX,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,QAAQ,EAAE,cAAc,CAAC,CAAA;QAEnD,IAAI,KAAK,EAAE;YACT,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAA;SAChD;QAED,OAAO,IAAI,yBAAA,OAAsB,CAAC;YAChC,MAAM;YACN,GAAG,EAAE,IAAI,CAAC,GAAG;YACb,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,KAAK,EAAE,IAAI,CAAC,KAAK;SAClB,CAAC,CAAA;IACJ,CAAC;IAgCD;;;;;;;;;;;;;;;;;;;;;;;;;OAyBG,CACH,MAAM,CACJ,MAAmB,EACnB,EACE,KAAK,EACL,aAAa,GAAG,IAAI,EAAA,GAIlB,CAAA,CAAE,EAAA;;QAUN,MAAM,MAAM,GAAG,MAAM,CAAA;QAErB,IAAI,KAAK,EAAE;YACT,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAA;SAChD;QACD,IAAI,CAAC,aAAa,EAAE;YAClB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,eAAA,CAAiB,CAAC,CAAA;SACjD;QAED,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACzB,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC,EAAE,CAAG,CAAD,EAAI,CAAC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,EAAc,CAAC,CAAA;YACrF,IAAI,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE;gBACtB,MAAM,aAAa,GAAG,CAAC;uBAAG,IAAI,GAAG,CAAC,OAAO,CAAC;iBAAC,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,CAAG,CAAA,AAAD,CAAC,EAAI,MAAM,CAAA,CAAA,CAAG,CAAC,CAAA;gBAC1E,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,SAAS,EAAE,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAA;aAC9D;SACF;QAED,OAAO,IAAI,yBAAA,OAAsB,CAAC;YAChC,MAAM;YACN,GAAG,EAAE,IAAI,CAAC,GAAG;YACb,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,IAAI,EAAE,MAAM;YACZ,KAAK,EAAE,CAAA,KAAA,IAAI,CAAC,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;SAC3B,CAAC,CAAA;IACJ,CAAC;IAoCD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAqCG,CACH,MAAM,CACJ,MAAmB,EACnB,EACE,UAAU,EACV,gBAAgB,GAAG,KAAK,EACxB,KAAK,EACL,aAAa,GAAG,IAAI,EAAA,GAMlB,CAAA,CAAE,EAAA;;QAUN,MAAM,MAAM,GAAG,MAAM,CAAA;QAErB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,WAAA,EAAc,gBAAgB,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,OAAO,CAAA,WAAA,CAAa,CAAC,CAAA;QAE/F,IAAI,UAAU,KAAK,SAAS,EAAE,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,aAAa,EAAE,UAAU,CAAC,CAAA;QAClF,IAAI,KAAK,EAAE;YACT,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAA;SAChD;QACD,IAAI,CAAC,aAAa,EAAE;YAClB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,iBAAiB,CAAC,CAAA;SACjD;QAED,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACzB,MAAM,OAAO,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,CAAC,EAAE,CAAG,CAAD,EAAI,CAAC,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,EAAc,CAAC,CAAA;YACrF,IAAI,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE;gBACtB,MAAM,aAAa,GAAG,CAAC;uBAAG,IAAI,GAAG,CAAC,OAAO,CAAC;iBAAC,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,CAAG,CAAD,AAAC,CAAA,EAAI,MAAM,CAAA,CAAA,CAAG,CAAC,CAAA;gBAC1E,IAAI,CAAC,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,SAAS,EAAE,aAAa,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAA;aAC9D;SACF;QAED,OAAO,IAAI,yBAAA,OAAsB,CAAC;YAChC,MAAM;YACN,GAAG,EAAE,IAAI,CAAC,GAAG;YACb,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,IAAI,EAAE,MAAM;YACZ,KAAK,EAAE,CAAA,KAAA,IAAI,CAAC,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;SAC3B,CAAC,CAAA;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;OAoBG,CACH,MAAM,CACJ,MAAW,EACX,EACE,KAAK,EAAA,GAGH,CAAA,CAAE,EAAA;;QAUN,MAAM,MAAM,GAAG,OAAO,CAAA;QACtB,IAAI,KAAK,EAAE;YACT,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAA;SAChD;QAED,OAAO,IAAI,yBAAA,OAAsB,CAAC;YAChC,MAAM;YACN,GAAG,EAAE,IAAI,CAAC,GAAG;YACb,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,IAAI,EAAE,MAAM;YACZ,KAAK,EAAE,CAAA,KAAA,IAAI,CAAC,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;SAC3B,CAAC,CAAA;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;OAkBG,CACH,MAAM,CAAC,EACL,KAAK,EAAA,GAGH,CAAA,CAAE,EAAA;;QASJ,MAAM,MAAM,GAAG,QAAQ,CAAA;QACvB,IAAI,KAAK,EAAE;YACT,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAA;SAChD;QAED,OAAO,IAAI,yBAAA,OAAsB,CAAC;YAChC,MAAM;YACN,GAAG,EAAE,IAAI,CAAC,GAAG;YACb,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,KAAK,EAAE,CAAA,KAAA,IAAI,CAAC,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;SAC3B,CAAC,CAAA;IACJ,CAAC;CACF;AAhbD,QAAA,OAAA,GAAA,sBAgbC"}},
    {"offset": {"line": 1315, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/PostgrestClient.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/PostgrestClient.ts"],"sourcesContent":["import PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { Fetch, GenericSchema, ClientServerOptions } from './types'\n\n/**\n * PostgREST client.\n *\n * @typeParam Database - Types for the schema from the [type\n * generator](https://supabase.com/docs/reference/javascript/next/typescript-support)\n *\n * @typeParam SchemaName - Postgres schema to switch to. Must be a string\n * literal, the same one passed to the constructor. If the schema is not\n * `\"public\"`, this must be supplied manually.\n */\nexport default class PostgrestClient<\n  Database = any,\n  ClientOptions extends ClientServerOptions = Database extends {\n    __InternalSupabase: infer I extends ClientServerOptions\n  }\n    ? I\n    : {},\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = 'public' extends keyof Omit<\n    Database,\n    '__InternalSupabase'\n  >\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  Schema extends GenericSchema = Omit<\n    Database,\n    '__InternalSupabase'\n  >[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : any\n> {\n  url: string\n  headers: Headers\n  schemaName?: SchemaName\n  fetch?: Fetch\n\n  // TODO: Add back shouldThrowOnError once we figure out the typings\n  /**\n   * Creates a PostgREST client.\n   *\n   * @param url - URL of the PostgREST endpoint\n   * @param options - Named parameters\n   * @param options.headers - Custom headers\n   * @param options.schema - Postgres schema to switch to\n   * @param options.fetch - Custom fetch\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: SchemaName\n      fetch?: Fetch\n    } = {}\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schemaName = schema\n    this.fetch = fetch\n  }\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName]\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any, any> {\n    const url = new URL(`${this.url}/${relation}`)\n    return new PostgrestQueryBuilder(url, {\n      headers: new Headers(this.headers),\n      schema: this.schemaName,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return new PostgrestClient(this.url, {\n      headers: this.headers,\n      schema,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  rpc<FnName extends string & keyof Schema['Functions'], Fn extends Schema['Functions'][FnName]>(\n    fn: FnName,\n    args: Fn['Args'] = {},\n    {\n      head = false,\n      get = false,\n      count,\n    }: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Fn['Returns'] extends any[]\n      ? Fn['Returns'][number] extends Record<string, unknown>\n        ? Fn['Returns'][number]\n        : never\n      : never,\n    Fn['Returns'],\n    FnName,\n    null,\n    'RPC'\n  > {\n    let method: 'HEAD' | 'GET' | 'POST'\n    const url = new URL(`${this.url}/rpc/${fn}`)\n    let body: unknown | undefined\n    if (head || get) {\n      method = head ? 'HEAD' : 'GET'\n      Object.entries(args)\n        // params with undefined value needs to be filtered out, otherwise it'll\n        // show up as `?param=undefined`\n        .filter(([_, value]) => value !== undefined)\n        // array values need special syntax\n        .map(([name, value]) => [name, Array.isArray(value) ? `{${value.join(',')}}` : `${value}`])\n        .forEach(([name, value]) => {\n          url.searchParams.append(name, value)\n        })\n    } else {\n      method = 'POST'\n      body = args\n    }\n\n    const headers = new Headers(this.headers)\n    if (count) {\n      headers.set('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schemaName,\n      body,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA,MAAA,0BAAA,oDAA2D;AAC3D,MAAA,2BAAA,qDAA6D;AAG7D;;;;;;;;;GASG,CACH,MAAqB,eAAe;IA0BlC,mEAAmE;IACnE;;;;;;;;OAQG,CACH,YACE,GAAW,EACX,EACE,OAAO,GAAG,CAAA,CAAE,EACZ,MAAM,SACN,MAAK,EAAA,GAKH,CAAA,CAAE,CAAA;QAEN,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;QACd,IAAI,CAAC,OAAO,GAAG,IAAI,OAAO,CAAC,OAAO,CAAC,CAAA;QACnC,IAAI,CAAC,UAAU,GAAG,MAAM,CAAA;QACxB,IAAI,CAAC,KAAK,GAAG,KAAK,CAAA;IACpB,CAAC;IAQD;;;;OAIG,CACH,IAAI,CAAC,QAAgB,EAAA;QACnB,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAA,CAAA,EAAI,QAAQ,EAAE,CAAC,CAAA;QAC9C,OAAO,IAAI,wBAAA,OAAqB,CAAC,GAAG,EAAE;YACpC,OAAO,EAAE,IAAI,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC;YAClC,MAAM,EAAE,IAAI,CAAC,UAAU;YACvB,KAAK,EAAE,IAAI,CAAC,KAAK;SAClB,CAAC,CAAA;IACJ,CAAC;IAED;;;;;;OAMG,CACH,MAAM,CACJ,MAAqB,EAAA;QAOrB,OAAO,IAAI,eAAe,CAAC,IAAI,CAAC,GAAG,EAAE;YACnC,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM;YACN,KAAK,EAAE,IAAI,CAAC,KAAK;SAClB,CAAC,CAAA;IACJ,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;OAsBG,CACH,GAAG,CACD,EAAU,EACV,OAAmB,CAAA,CAAE,EACrB,EACE,IAAI,GAAG,KAAK,EACZ,GAAG,GAAG,KAAK,EACX,KAAK,EAAA,GAKH,CAAA,CAAE,EAAA;;QAcN,IAAI,MAA+B,CAAA;QACnC,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,GAAG,IAAI,CAAC,GAAG,CAAA,KAAA,EAAQ,EAAE,EAAE,CAAC,CAAA;QAC5C,IAAI,IAAyB,CAAA;QAC7B,IAAI,IAAI,IAAI,GAAG,EAAE;YACf,MAAM,GAAG,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAA;YAC9B,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,AAClB,wEAAwE;YACxE,gCAAgC;aAC/B,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,EAAE,CAAG,CAAD,IAAM,KAAK,SAAS,CAAC,AAC5C,mCAAmC;aAClC,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,KAAK,CAAC,EAAE,CAAG,CAAD;oBAAE,IAAI;oBAAE,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAA,CAAA,EAAI,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA,CAAA,CAAG,CAAC,CAAC,CAAC,GAAG,KAAK,EAAE;iBAAC,CAAC,CAC1F,OAAO,CAAC,CAAC,CAAC,IAAI,EAAE,KAAK,CAAC,EAAE,EAAE;gBACzB,GAAG,CAAC,YAAY,CAAC,MAAM,CAAC,IAAI,EAAE,KAAK,CAAC,CAAA;YACtC,CAAC,CAAC,CAAA;SACL,MAAM;YACL,MAAM,GAAG,MAAM,CAAA;YACf,IAAI,GAAG,IAAI,CAAA;SACZ;QAED,MAAM,OAAO,GAAG,IAAI,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAA;QACzC,IAAI,KAAK,EAAE;YACT,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAA,MAAA,EAAS,KAAK,EAAE,CAAC,CAAA;SACxC;QAED,OAAO,IAAI,yBAAA,OAAsB,CAAC;YAChC,MAAM;YACN,GAAG;YACH,OAAO;YACP,MAAM,EAAE,IAAI,CAAC,UAAU;YACvB,IAAI;YACJ,KAAK,EAAE,CAAA,KAAA,IAAI,CAAC,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK;SAC3B,CAAC,CAAA;IACJ,CAAC;CACF;AAjLD,QAAA,OAAA,GAAA,gBAiLC"}},
    {"offset": {"line": 1436, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/cjs/index.js","sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/src/index.ts"],"sourcesContent":["// Always update wrapper.mjs when updating this file.\nimport PostgrestClient from './PostgrestClient'\nimport PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestError from './PostgrestError'\n\nexport {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport default {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport type {\n  PostgrestResponse,\n  PostgrestResponseFailure,\n  PostgrestResponseSuccess,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n  ClientServerOptions as PostgrestClientOptions,\n} from './types'\n// https://github.com/supabase/postgrest-js/issues/551\n// To be replaced with a helper type that only uses public types\nexport type { GetResult as UnstableGetResult } from './select-query-parser/result'\n"],"names":[],"mappings":";;;;;;;;;AAAA,qDAAqD;AACrD,MAAA,oBAAA,8CAA+C;AAQ7C,QAAA,eAAA,GARK,kBAAA,OAAe,CAQL;AAPjB,MAAA,0BAAA,oDAA2D;AAQzD,QAAA,qBAAA,GARK,wBAAA,OAAqB,CAQL;AAPvB,MAAA,2BAAA,qDAA6D;AAQ3D,QAAA,sBAAA,GARK,yBAAA,OAAsB,CAQL;AAPxB,MAAA,8BAAA,wDAAmE;AAQjE,QAAA,yBAAA,GARK,4BAAA,OAAyB,CAQL;AAP3B,MAAA,qBAAA,+CAAiD;AAQ/C,QAAA,gBAAA,GARK,mBAAA,OAAgB,CAQL;AAPlB,MAAA,mBAAA,6CAA6C;AAQ3C,QAAA,cAAA,GARK,iBAAA,OAAc,CAQL;AAEhB,QAAA,OAAA,GAAe;IACb,eAAe,EAAf,kBAAA,OAAe;IACf,qBAAqB,EAArB,wBAAA,OAAqB;IACrB,sBAAsB,EAAtB,yBAAA,OAAsB;IACtB,yBAAyB,EAAzB,4BAAA,OAAyB;IACzB,gBAAgB,EAAhB,mBAAA,OAAgB;IAChB,cAAc,EAAd,iBAAA,OAAc;CACf,CAAA"}},
    {"offset": {"line": 1470, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/@supabase/postgrest-js/dist/esm/wrapper.mjs"],"sourcesContent":["import index from '../cjs/index.js'\nconst {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n} = index\n\nexport {\n  PostgrestBuilder,\n  PostgrestClient,\n  PostgrestFilterBuilder,\n  PostgrestQueryBuilder,\n  PostgrestTransformBuilder,\n  PostgrestError,\n}\n\n// compatibility with CJS output\nexport default {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAA;;AACA,MAAM,EACJ,eAAe,EACf,qBAAqB,EACrB,sBAAsB,EACtB,yBAAyB,EACzB,gBAAgB,EAChB,cAAc,EACf,GAAG,wLAAK;;uCAYM;IACb;IACA;IACA;IACA;IACA;IACA;AACF","ignoreList":[0]}},
    {"offset": {"line": 1502, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/websocket-factory.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/websocket-factory.ts"],"sourcesContent":["export interface WebSocketLike {\n  readonly CONNECTING: number\n  readonly OPEN: number\n  readonly CLOSING: number\n  readonly CLOSED: number\n  readonly readyState: number\n  readonly url: string\n  readonly protocol: string\n\n  close(code?: number, reason?: string): void\n  send(data: string | ArrayBufferLike | Blob | ArrayBufferView): void\n\n  onopen: ((this: any, ev: Event) => any) | null\n  onmessage: ((this: any, ev: MessageEvent) => any) | null\n  onclose: ((this: any, ev: CloseEvent) => any) | null\n  onerror: ((this: any, ev: Event) => any) | null\n\n  addEventListener(type: string, listener: EventListener): void\n  removeEventListener(type: string, listener: EventListener): void\n\n  // Add additional properties that may exist on WebSocket implementations\n  binaryType?: string\n  bufferedAmount?: number\n  extensions?: string\n  dispatchEvent?: (event: Event) => boolean\n}\n\nexport interface WebSocketEnvironment {\n  type: 'native' | 'ws' | 'cloudflare' | 'unsupported'\n  constructor?: any\n  error?: string\n  workaround?: string\n}\n\nexport class WebSocketFactory {\n  private static detectEnvironment(): WebSocketEnvironment {\n    if (typeof WebSocket !== 'undefined') {\n      return { type: 'native', constructor: WebSocket }\n    }\n\n    if (\n      typeof globalThis !== 'undefined' &&\n      typeof (globalThis as any).WebSocket !== 'undefined'\n    ) {\n      return { type: 'native', constructor: (globalThis as any).WebSocket }\n    }\n\n    if (\n      typeof global !== 'undefined' &&\n      typeof (global as any).WebSocket !== 'undefined'\n    ) {\n      return { type: 'native', constructor: (global as any).WebSocket }\n    }\n\n    if (\n      typeof globalThis !== 'undefined' &&\n      typeof (globalThis as any).WebSocketPair !== 'undefined' &&\n      typeof globalThis.WebSocket === 'undefined'\n    ) {\n      return {\n        type: 'cloudflare',\n        error:\n          'Cloudflare Workers detected. WebSocket clients are not supported in Cloudflare Workers.',\n        workaround:\n          'Use Cloudflare Workers WebSocket API for server-side WebSocket handling, or deploy to a different runtime.',\n      }\n    }\n\n    if (\n      (typeof globalThis !== 'undefined' && (globalThis as any).EdgeRuntime) ||\n      (typeof navigator !== 'undefined' &&\n        navigator.userAgent?.includes('Vercel-Edge'))\n    ) {\n      return {\n        type: 'unsupported',\n        error:\n          'Edge runtime detected (Vercel Edge/Netlify Edge). WebSockets are not supported in edge functions.',\n        workaround:\n          'Use serverless functions or a different deployment target for WebSocket functionality.',\n      }\n    }\n\n    if (typeof process !== 'undefined') {\n      // Use dynamic property access to avoid Next.js Edge Runtime static analysis warnings\n      const processVersions = (process as any)['versions']\n      if (processVersions && processVersions['node']) {\n        // Remove 'v' prefix if present and parse the major version\n        const versionString = processVersions['node']\n        const nodeVersion = parseInt(\n          versionString.replace(/^v/, '').split('.')[0]\n        )\n\n        // Node.js 22+ should have native WebSocket\n        if (nodeVersion >= 22) {\n          // Check if native WebSocket is available (should be in Node.js 22+)\n          if (typeof globalThis.WebSocket !== 'undefined') {\n            return { type: 'native', constructor: globalThis.WebSocket }\n          }\n          // If not available, user needs to provide it\n          return {\n            type: 'unsupported',\n            error: `Node.js ${nodeVersion} detected but native WebSocket not found.`,\n            workaround:\n              'Provide a WebSocket implementation via the transport option.',\n          }\n        }\n\n        // Node.js < 22 doesn't have native WebSocket\n        return {\n          type: 'unsupported',\n          error: `Node.js ${nodeVersion} detected without native WebSocket support.`,\n          workaround:\n            'For Node.js < 22, install \"ws\" package and provide it via the transport option:\\n' +\n            'import ws from \"ws\"\\n' +\n            'new RealtimeClient(url, { transport: ws })',\n        }\n      }\n    }\n\n    return {\n      type: 'unsupported',\n      error: 'Unknown JavaScript runtime without WebSocket support.',\n      workaround:\n        \"Ensure you're running in a supported environment (browser, Node.js, Deno) or provide a custom WebSocket implementation.\",\n    }\n  }\n\n  public static getWebSocketConstructor(): typeof WebSocket {\n    const env = this.detectEnvironment()\n    if (env.constructor) {\n      return env.constructor\n    }\n    let errorMessage =\n      env.error || 'WebSocket not supported in this environment.'\n    if (env.workaround) {\n      errorMessage += `\\n\\nSuggested solution: ${env.workaround}`\n    }\n    throw new Error(errorMessage)\n  }\n\n  public static createWebSocket(\n    url: string | URL,\n    protocols?: string | string[]\n  ): WebSocketLike {\n    const WS = this.getWebSocketConstructor()\n    return new WS(url, protocols)\n  }\n\n  public static isWebSocketSupported(): boolean {\n    try {\n      const env = this.detectEnvironment()\n      return env.type === 'native' || env.type === 'ws'\n    } catch {\n      return false\n    }\n  }\n}\n\nexport default WebSocketFactory\n"],"names":[],"mappings":";;;;;;AAkCM,MAAO,gBAAgB;IACnB,MAAM,CAAC,iBAAiB,GAAA;;QAC9B,IAAI,OAAO,SAAS,KAAK,WAAW,EAAE,CAAC;YACrC,OAAO;gBAAE,IAAI,EAAE,QAAQ;gBAAE,WAAW,EAAE,SAAS;YAAA,CAAE,CAAA;QACnD,CAAC;QAED,IACE,OAAO,UAAU,KAAK,WAAW,IACjC,OAAQ,UAAkB,CAAC,SAAS,KAAK,WAAW,EACpD,CAAC;YACD,OAAO;gBAAE,IAAI,EAAE,QAAQ;gBAAE,WAAW,EAAG,UAAkB,CAAC,SAAS;YAAA,CAAE,CAAA;QACvE,CAAC;QAED,IACE,OAAO,MAAM,kCAAK,WAAW,IAC7B,OAAQ,MAAc,mDAAC,SAAS,KAAK,WAAW,EAChD,CAAC;YACD,OAAO;gBAAE,IAAI,EAAE,QAAQ;gBAAE,WAAW,EAAG,MAAc,mDAAC,SAAS;YAAA,CAAE,CAAA;QACnE,CAAC;QAED,IACE,OAAO,UAAU,KAAK,WAAW,IACjC,OAAQ,UAAkB,CAAC,aAAa,KAAK,WAAW,IACxD,OAAO,UAAU,CAAC,SAAS,KAAK,WAAW,EAC3C,CAAC;YACD,OAAO;gBACL,IAAI,EAAE,YAAY;gBAClB,KAAK,EACH,yFAAyF;gBAC3F,UAAU,EACR,4GAA4G;aAC/G,CAAA;QACH,CAAC;QAED,IACE,AAAC,OAAO,UAAU,KAAK,WAAW,IAAK,UAAkB,CAAC,WAAW,CAAC,GACrE,OAAO,SAAS,KAAK,WAAW,KAC/B,CAAA,KAAA,SAAS,CAAC,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,QAAQ,CAAC,aAAa,CAAC,CAAA,CAAC,CAC/C,CAAC;YACD,OAAO;gBACL,IAAI,EAAE,aAAa;gBACnB,KAAK,EACH,mGAAmG;gBACrG,UAAU,EACR,wFAAwF;aAC3F,CAAA;QACH,CAAC;QAED,IAAI,OAAO,OAAO,KAAK,WAAW,EAAE,CAAC;YACnC,qFAAqF;YACrF,MAAM,eAAe,GAAI,OAAe,CAAC,UAAU,CAAC,CAAA;YACpD,IAAI,eAAe,IAAI,eAAe,CAAC,MAAM,CAAC,EAAE,CAAC;gBAC/C,2DAA2D;gBAC3D,MAAM,aAAa,GAAG,eAAe,CAAC,MAAM,CAAC,CAAA;gBAC7C,MAAM,WAAW,GAAG,QAAQ,CAC1B,aAAa,CAAC,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAC9C,CAAA;gBAED,2CAA2C;gBAC3C,IAAI,WAAW,IAAI,EAAE,EAAE,CAAC;oBACtB,oEAAoE;oBACpE,IAAI,OAAO,UAAU,CAAC,SAAS,KAAK,WAAW,EAAE,CAAC;wBAChD,OAAO;4BAAE,IAAI,EAAE,QAAQ;4BAAE,WAAW,EAAE,UAAU,CAAC,SAAS;wBAAA,CAAE,CAAA;oBAC9D,CAAC;oBACD,6CAA6C;oBAC7C,OAAO;wBACL,IAAI,EAAE,aAAa;wBACnB,KAAK,EAAE,CAAA,QAAA,EAAW,WAAW,CAAA,yCAAA,CAA2C;wBACxE,UAAU,EACR,8DAA8D;qBACjE,CAAA;gBACH,CAAC;gBAED,6CAA6C;gBAC7C,OAAO;oBACL,IAAI,EAAE,aAAa;oBACnB,KAAK,EAAE,CAAA,QAAA,EAAW,WAAW,CAAA,2CAAA,CAA6C;oBAC1E,UAAU,EACR,mFAAmF,GACnF,uBAAuB,GACvB,4CAA4C;iBAC/C,CAAA;YACH,CAAC;QACH,CAAC;QAED,OAAO;YACL,IAAI,EAAE,aAAa;YACnB,KAAK,EAAE,uDAAuD;YAC9D,UAAU,EACR,yHAAyH;SAC5H,CAAA;IACH,CAAC;IAEM,MAAM,CAAC,uBAAuB,GAAA;QACnC,MAAM,GAAG,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAA;QACpC,IAAI,GAAG,CAAC,WAAW,EAAE,CAAC;YACpB,OAAO,GAAG,CAAC,WAAW,CAAA;QACxB,CAAC;QACD,IAAI,YAAY,GACd,GAAG,CAAC,KAAK,IAAI,8CAA8C,CAAA;QAC7D,IAAI,GAAG,CAAC,UAAU,EAAE,CAAC;YACnB,YAAY,IAAI,CAAA,wBAAA,EAA2B,GAAG,CAAC,UAAU,EAAE,CAAA;QAC7D,CAAC;QACD,MAAM,IAAI,KAAK,CAAC,YAAY,CAAC,CAAA;IAC/B,CAAC;IAEM,MAAM,CAAC,eAAe,CAC3B,GAAiB,EACjB,SAA6B,EAAA;QAE7B,MAAM,EAAE,GAAG,IAAI,CAAC,uBAAuB,EAAE,CAAA;QACzC,OAAO,IAAI,EAAE,CAAC,GAAG,EAAE,SAAS,CAAC,CAAA;IAC/B,CAAC;IAEM,MAAM,CAAC,oBAAoB,GAAA;QAChC,IAAI,CAAC;YACH,MAAM,GAAG,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAA;YACpC,OAAO,GAAG,CAAC,IAAI,KAAK,QAAQ,IAAI,GAAG,CAAC,IAAI,KAAK,IAAI,CAAA;QACnD,CAAC,CAAC,OAAA,IAAM,CAAC;YACP,OAAO,KAAK,CAAA;QACd,CAAC;IACH,CAAC;CACF;uCAEc,gBAAgB,CAAA"}},
    {"offset": {"line": 1610, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/version.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/version.ts"],"sourcesContent":["export const version = '2.15.5'\n"],"names":[],"mappings":";;;;AAAO,MAAM,OAAO,GAAG,iBAAiB,CAAA"}},
    {"offset": {"line": 1619, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/constants.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/constants.ts"],"sourcesContent":["import { version } from './version'\n\nexport const DEFAULT_VERSION = `realtime-js/${version}`\nexport const VSN: string = '1.0.0'\n\nexport const VERSION = version\n\nexport const DEFAULT_TIMEOUT = 10000\n\nexport const WS_CLOSE_NORMAL = 1000\nexport const MAX_PUSH_BUFFER_SIZE = 100\n\nexport enum SOCKET_STATES {\n  connecting = 0,\n  open = 1,\n  closing = 2,\n  closed = 3,\n}\n\nexport enum CHANNEL_STATES {\n  closed = 'closed',\n  errored = 'errored',\n  joined = 'joined',\n  joining = 'joining',\n  leaving = 'leaving',\n}\n\nexport enum CHANNEL_EVENTS {\n  close = 'phx_close',\n  error = 'phx_error',\n  join = 'phx_join',\n  reply = 'phx_reply',\n  leave = 'phx_leave',\n  access_token = 'access_token',\n}\n\nexport enum TRANSPORTS {\n  websocket = 'websocket',\n}\n\nexport enum CONNECTION_STATE {\n  Connecting = 'connecting',\n  Open = 'open',\n  Closing = 'closing',\n  Closed = 'closed',\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AAAA,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAA;;AAE5B,MAAM,eAAe,GAAG,CAAA,YAAA,EAAe,mMAAO,EAAE,CAAA;AAChD,MAAM,GAAG,GAAW,OAAO,CAAA;AAE3B,MAAM,OAAO,GAAG,mMAAO,CAAA;AAEvB,MAAM,eAAe,GAAG,KAAK,CAAA;AAE7B,MAAM,eAAe,GAAG,IAAI,CAAA;AAC5B,MAAM,oBAAoB,GAAG,GAAG,CAAA;AAEvC,IAAY,aAKX;AALD,CAAA,SAAY,aAAa;IACvB,aAAA,CAAA,aAAA,CAAA,aAAA,GAAA,EAAA,GAAA,YAAc,CAAA;IACd,aAAA,CAAA,aAAA,CAAA,OAAA,GAAA,EAAA,GAAA,MAAQ,CAAA;IACR,aAAA,CAAA,aAAA,CAAA,UAAA,GAAA,EAAA,GAAA,SAAW,CAAA;IACX,aAAA,CAAA,aAAA,CAAA,SAAA,GAAA,EAAA,GAAA,QAAU,CAAA;AACZ,CAAC,EALW,aAAa,IAAA,CAAb,aAAa,GAAA,CAAA,CAAA,GAKxB;AAED,IAAY,cAMX;AAND,CAAA,SAAY,cAAc;IACxB,cAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,cAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,cAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,cAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,cAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;AACrB,CAAC,EANW,cAAc,IAAA,CAAd,cAAc,GAAA,CAAA,CAAA,GAMzB;AAED,IAAY,cAOX;AAPD,CAAA,SAAY,cAAc;IACxB,cAAA,CAAA,QAAA,GAAA,WAAmB,CAAA;IACnB,cAAA,CAAA,QAAA,GAAA,WAAmB,CAAA;IACnB,cAAA,CAAA,OAAA,GAAA,UAAiB,CAAA;IACjB,cAAA,CAAA,QAAA,GAAA,WAAmB,CAAA;IACnB,cAAA,CAAA,QAAA,GAAA,WAAmB,CAAA;IACnB,cAAA,CAAA,eAAA,GAAA,cAA6B,CAAA;AAC/B,CAAC,EAPW,cAAc,IAAA,CAAd,cAAc,GAAA,CAAA,CAAA,GAOzB;AAED,IAAY,UAEX;AAFD,CAAA,SAAY,UAAU;IACpB,UAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;AACzB,CAAC,EAFW,UAAU,IAAA,CAAV,UAAU,GAAA,CAAA,CAAA,GAErB;AAED,IAAY,gBAKX;AALD,CAAA,SAAY,gBAAgB;IAC1B,gBAAA,CAAA,aAAA,GAAA,YAAyB,CAAA;IACzB,gBAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,gBAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,gBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;AACnB,CAAC,EALW,gBAAgB,IAAA,CAAhB,gBAAgB,GAAA,CAAA,CAAA,GAK3B"}},
    {"offset": {"line": 1690, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/serializer.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/serializer.ts"],"sourcesContent":["// This file draws heavily from https://github.com/phoenixframework/phoenix/commit/cf098e9cf7a44ee6479d31d911a97d3c7430c6fe\n// License: https://github.com/phoenixframework/phoenix/blob/master/LICENSE.md\n\nexport default class Serializer {\n  HEADER_LENGTH = 1\n\n  decode(rawPayload: ArrayBuffer | string, callback: Function) {\n    if (rawPayload.constructor === ArrayBuffer) {\n      return callback(this._binaryDecode(rawPayload))\n    }\n\n    if (typeof rawPayload === 'string') {\n      return callback(JSON.parse(rawPayload))\n    }\n\n    return callback({})\n  }\n\n  private _binaryDecode(buffer: ArrayBuffer) {\n    const view = new DataView(buffer)\n    const decoder = new TextDecoder()\n\n    return this._decodeBroadcast(buffer, view, decoder)\n  }\n\n  private _decodeBroadcast(\n    buffer: ArrayBuffer,\n    view: DataView,\n    decoder: TextDecoder\n  ): {\n    ref: null\n    topic: string\n    event: string\n    payload: { [key: string]: any }\n  } {\n    const topicSize = view.getUint8(1)\n    const eventSize = view.getUint8(2)\n    let offset = this.HEADER_LENGTH + 2\n    const topic = decoder.decode(buffer.slice(offset, offset + topicSize))\n    offset = offset + topicSize\n    const event = decoder.decode(buffer.slice(offset, offset + eventSize))\n    offset = offset + eventSize\n    const data = JSON.parse(\n      decoder.decode(buffer.slice(offset, buffer.byteLength))\n    )\n\n    return { ref: null, topic: topic, event: event, payload: data }\n  }\n}\n"],"names":[],"mappings":"AAAA,2HAA2H;AAC3H,8EAA8E;;;;;AAEhE,MAAO,UAAU;IAA/B,aAAA;QACE,IAAA,CAAA,aAAa,GAAG,CAAC,CAAA;IA4CnB,CAAC;IA1CC,MAAM,CAAC,UAAgC,EAAE,QAAkB,EAAA;QACzD,IAAI,UAAU,CAAC,WAAW,KAAK,WAAW,EAAE,CAAC;YAC3C,OAAO,QAAQ,CAAC,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC,CAAA;QACjD,CAAC;QAED,IAAI,OAAO,UAAU,KAAK,QAAQ,EAAE,CAAC;YACnC,OAAO,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC,CAAA;QACzC,CAAC;QAED,OAAO,QAAQ,CAAC,CAAA,CAAE,CAAC,CAAA;IACrB,CAAC;IAEO,aAAa,CAAC,MAAmB,EAAA;QACvC,MAAM,IAAI,GAAG,IAAI,QAAQ,CAAC,MAAM,CAAC,CAAA;QACjC,MAAM,OAAO,GAAG,IAAI,WAAW,EAAE,CAAA;QAEjC,OAAO,IAAI,CAAC,gBAAgB,CAAC,MAAM,EAAE,IAAI,EAAE,OAAO,CAAC,CAAA;IACrD,CAAC;IAEO,gBAAgB,CACtB,MAAmB,EACnB,IAAc,EACd,OAAoB,EAAA;QAOpB,MAAM,SAAS,GAAG,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAA;QAClC,MAAM,SAAS,GAAG,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAA;QAClC,IAAI,MAAM,GAAG,IAAI,CAAC,aAAa,GAAG,CAAC,CAAA;QACnC,MAAM,KAAK,GAAG,OAAO,CAAC,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,GAAG,SAAS,CAAC,CAAC,CAAA;QACtE,MAAM,GAAG,MAAM,GAAG,SAAS,CAAA;QAC3B,MAAM,KAAK,GAAG,OAAO,CAAC,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,GAAG,SAAS,CAAC,CAAC,CAAA;QACtE,MAAM,GAAG,MAAM,GAAG,SAAS,CAAA;QAC3B,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CACrB,OAAO,CAAC,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,CAAC,UAAU,CAAC,CAAC,CACxD,CAAA;QAED,OAAO;YAAE,GAAG,EAAE,IAAI;YAAE,KAAK,EAAE,KAAK;YAAE,KAAK,EAAE,KAAK;YAAE,OAAO,EAAE,IAAI;QAAA,CAAE,CAAA;IACjE,CAAC;CACF"}},
    {"offset": {"line": 1735, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/timer.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/timer.ts"],"sourcesContent":["/**\n * Creates a timer that accepts a `timerCalc` function to perform calculated timeout retries, such as exponential backoff.\n *\n * @example\n *    let reconnectTimer = new Timer(() => this.connect(), function(tries){\n *      return [1000, 5000, 10000][tries - 1] || 10000\n *    })\n *    reconnectTimer.scheduleTimeout() // fires after 1000\n *    reconnectTimer.scheduleTimeout() // fires after 5000\n *    reconnectTimer.reset()\n *    reconnectTimer.scheduleTimeout() // fires after 1000\n */\nexport default class Timer {\n  timer: number | undefined = undefined\n  tries: number = 0\n\n  constructor(public callback: Function, public timerCalc: Function) {\n    this.callback = callback\n    this.timerCalc = timerCalc\n  }\n\n  reset() {\n    this.tries = 0\n    clearTimeout(this.timer)\n    this.timer = undefined\n  }\n\n  // Cancels any previous scheduleTimeout and schedules callback\n  scheduleTimeout() {\n    clearTimeout(this.timer)\n\n    this.timer = <any>setTimeout(() => {\n      this.tries = this.tries + 1\n      this.callback()\n    }, this.timerCalc(this.tries + 1))\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;GAWG;;;;AACW,MAAO,KAAK;IAIxB,YAAmB,QAAkB,EAAS,SAAmB,CAAA;QAA9C,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAU;QAAS,IAAA,CAAA,SAAS,GAAT,SAAS,CAAU;QAHjE,IAAA,CAAA,KAAK,GAAuB,SAAS,CAAA;QACrC,IAAA,CAAA,KAAK,GAAW,CAAC,CAAA;QAGf,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAA;QACxB,IAAI,CAAC,SAAS,GAAG,SAAS,CAAA;IAC5B,CAAC;IAED,KAAK,GAAA;QACH,IAAI,CAAC,KAAK,GAAG,CAAC,CAAA;QACd,YAAY,CAAC,IAAI,CAAC,KAAK,CAAC,CAAA;QACxB,IAAI,CAAC,KAAK,GAAG,SAAS,CAAA;IACxB,CAAC;IAED,8DAA8D;IAC9D,eAAe,GAAA;QACb,YAAY,CAAC,IAAI,CAAC,KAAK,CAAC,CAAA;QAExB,IAAI,CAAC,KAAK,GAAQ,UAAU,CAAC,GAAG,EAAE;YAChC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAA;YAC3B,IAAI,CAAC,QAAQ,EAAE,CAAA;QACjB,CAAC,EAAE,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAA;IACpC,CAAC;CACF"}},
    {"offset": {"line": 1777, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/transformers.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/transformers.ts"],"sourcesContent":["/**\n * Helpers to convert the change Payload into native JS types.\n */\n\n// Adapted from epgsql (src/epgsql_binary.erl), this module licensed under\n// 3-clause BSD found here: https://raw.githubusercontent.com/epgsql/epgsql/devel/LICENSE\n\nexport enum PostgresTypes {\n  abstime = 'abstime',\n  bool = 'bool',\n  date = 'date',\n  daterange = 'daterange',\n  float4 = 'float4',\n  float8 = 'float8',\n  int2 = 'int2',\n  int4 = 'int4',\n  int4range = 'int4range',\n  int8 = 'int8',\n  int8range = 'int8range',\n  json = 'json',\n  jsonb = 'jsonb',\n  money = 'money',\n  numeric = 'numeric',\n  oid = 'oid',\n  reltime = 'reltime',\n  text = 'text',\n  time = 'time',\n  timestamp = 'timestamp',\n  timestamptz = 'timestamptz',\n  timetz = 'timetz',\n  tsrange = 'tsrange',\n  tstzrange = 'tstzrange',\n}\n\ntype Columns = {\n  name: string // the column name. eg: \"user_id\"\n  type: string // the column type. eg: \"uuid\"\n  flags?: string[] // any special flags for the column. eg: [\"key\"]\n  type_modifier?: number // the type modifier. eg: 4294967295\n}[]\n\ntype BaseValue = null | string | number | boolean\ntype RecordValue = BaseValue | BaseValue[]\n\ntype Record = {\n  [key: string]: RecordValue\n}\n\n/**\n * Takes an array of columns and an object of string values then converts each string value\n * to its mapped type.\n *\n * @param {{name: String, type: String}[]} columns\n * @param {Object} record\n * @param {Object} options The map of various options that can be applied to the mapper\n * @param {Array} options.skipTypes The array of types that should not be converted\n *\n * @example convertChangeData([{name: 'first_name', type: 'text'}, {name: 'age', type: 'int4'}], {first_name: 'Paul', age:'33'}, {})\n * //=>{ first_name: 'Paul', age: 33 }\n */\nexport const convertChangeData = (\n  columns: Columns,\n  record: Record,\n  options: { skipTypes?: string[] } = {}\n): Record => {\n  const skipTypes = options.skipTypes ?? []\n\n  return Object.keys(record).reduce((acc, rec_key) => {\n    acc[rec_key] = convertColumn(rec_key, columns, record, skipTypes)\n    return acc\n  }, {} as Record)\n}\n\n/**\n * Converts the value of an individual column.\n *\n * @param {String} columnName The column that you want to convert\n * @param {{name: String, type: String}[]} columns All of the columns\n * @param {Object} record The map of string values\n * @param {Array} skipTypes An array of types that should not be converted\n * @return {object} Useless information\n *\n * @example convertColumn('age', [{name: 'first_name', type: 'text'}, {name: 'age', type: 'int4'}], {first_name: 'Paul', age: '33'}, [])\n * //=> 33\n * @example convertColumn('age', [{name: 'first_name', type: 'text'}, {name: 'age', type: 'int4'}], {first_name: 'Paul', age: '33'}, ['int4'])\n * //=> \"33\"\n */\nexport const convertColumn = (\n  columnName: string,\n  columns: Columns,\n  record: Record,\n  skipTypes: string[]\n): RecordValue => {\n  const column = columns.find((x) => x.name === columnName)\n  const colType = column?.type\n  const value = record[columnName]\n\n  if (colType && !skipTypes.includes(colType)) {\n    return convertCell(colType, value)\n  }\n\n  return noop(value)\n}\n\n/**\n * If the value of the cell is `null`, returns null.\n * Otherwise converts the string value to the correct type.\n * @param {String} type A postgres column type\n * @param {String} value The cell value\n *\n * @example convertCell('bool', 't')\n * //=> true\n * @example convertCell('int8', '10')\n * //=> 10\n * @example convertCell('_int4', '{1,2,3,4}')\n * //=> [1,2,3,4]\n */\nexport const convertCell = (type: string, value: RecordValue): RecordValue => {\n  // if data type is an array\n  if (type.charAt(0) === '_') {\n    const dataType = type.slice(1, type.length)\n    return toArray(value, dataType)\n  }\n\n  // If not null, convert to correct type.\n  switch (type) {\n    case PostgresTypes.bool:\n      return toBoolean(value)\n    case PostgresTypes.float4:\n    case PostgresTypes.float8:\n    case PostgresTypes.int2:\n    case PostgresTypes.int4:\n    case PostgresTypes.int8:\n    case PostgresTypes.numeric:\n    case PostgresTypes.oid:\n      return toNumber(value)\n    case PostgresTypes.json:\n    case PostgresTypes.jsonb:\n      return toJson(value)\n    case PostgresTypes.timestamp:\n      return toTimestampString(value) // Format to be consistent with PostgREST\n    case PostgresTypes.abstime: // To allow users to cast it based on Timezone\n    case PostgresTypes.date: // To allow users to cast it based on Timezone\n    case PostgresTypes.daterange:\n    case PostgresTypes.int4range:\n    case PostgresTypes.int8range:\n    case PostgresTypes.money:\n    case PostgresTypes.reltime: // To allow users to cast it based on Timezone\n    case PostgresTypes.text:\n    case PostgresTypes.time: // To allow users to cast it based on Timezone\n    case PostgresTypes.timestamptz: // To allow users to cast it based on Timezone\n    case PostgresTypes.timetz: // To allow users to cast it based on Timezone\n    case PostgresTypes.tsrange:\n    case PostgresTypes.tstzrange:\n      return noop(value)\n    default:\n      // Return the value for remaining types\n      return noop(value)\n  }\n}\n\nconst noop = (value: RecordValue): RecordValue => {\n  return value\n}\nexport const toBoolean = (value: RecordValue): RecordValue => {\n  switch (value) {\n    case 't':\n      return true\n    case 'f':\n      return false\n    default:\n      return value\n  }\n}\nexport const toNumber = (value: RecordValue): RecordValue => {\n  if (typeof value === 'string') {\n    const parsedValue = parseFloat(value)\n    if (!Number.isNaN(parsedValue)) {\n      return parsedValue\n    }\n  }\n  return value\n}\nexport const toJson = (value: RecordValue): RecordValue => {\n  if (typeof value === 'string') {\n    try {\n      return JSON.parse(value)\n    } catch (error) {\n      console.log(`JSON parse error: ${error}`)\n      return value\n    }\n  }\n  return value\n}\n\n/**\n * Converts a Postgres Array into a native JS array\n *\n * @example toArray('{}', 'int4')\n * //=> []\n * @example toArray('{\"[2021-01-01,2021-12-31)\",\"(2021-01-01,2021-12-32]\"}', 'daterange')\n * //=> ['[2021-01-01,2021-12-31)', '(2021-01-01,2021-12-32]']\n * @example toArray([1,2,3,4], 'int4')\n * //=> [1,2,3,4]\n */\nexport const toArray = (value: RecordValue, type: string): RecordValue => {\n  if (typeof value !== 'string') {\n    return value\n  }\n\n  const lastIdx = value.length - 1\n  const closeBrace = value[lastIdx]\n  const openBrace = value[0]\n\n  // Confirm value is a Postgres array by checking curly brackets\n  if (openBrace === '{' && closeBrace === '}') {\n    let arr\n    const valTrim = value.slice(1, lastIdx)\n\n    // TODO: find a better solution to separate Postgres array data\n    try {\n      arr = JSON.parse('[' + valTrim + ']')\n    } catch (_) {\n      // WARNING: splitting on comma does not cover all edge cases\n      arr = valTrim ? valTrim.split(',') : []\n    }\n\n    return arr.map((val: BaseValue) => convertCell(type, val))\n  }\n\n  return value\n}\n\n/**\n * Fixes timestamp to be ISO-8601. Swaps the space between the date and time for a 'T'\n * See https://github.com/supabase/supabase/issues/18\n *\n * @example toTimestampString('2019-09-10 00:00:00')\n * //=> '2019-09-10T00:00:00'\n */\nexport const toTimestampString = (value: RecordValue): RecordValue => {\n  if (typeof value === 'string') {\n    return value.replace(' ', 'T')\n  }\n\n  return value\n}\n\nexport const httpEndpointURL = (socketUrl: string): string => {\n  let url = socketUrl\n  url = url.replace(/^ws/i, 'http')\n  url = url.replace(/(\\/socket\\/websocket|\\/socket|\\/websocket)\\/?$/i, '')\n  return url.replace(/\\/+$/, '') + '/api/broadcast'\n}\n"],"names":[],"mappings":"AAAA;;GAEG,CAEH,0EAA0E;AAC1E,yFAAyF;;;;;;;;;;;;;;;;;;;;;;;AAEzF,IAAY,aAyBX;AAzBD,CAAA,SAAY,aAAa;IACvB,aAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB,aAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,aAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,QAAA,GAAA,OAAe,CAAA;IACf,aAAA,CAAA,QAAA,GAAA,OAAe,CAAA;IACf,aAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,aAAA,CAAA,MAAA,GAAA,KAAW,CAAA;IACX,aAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,aAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB,aAAA,CAAA,cAAA,GAAA,aAA2B,CAAA;IAC3B,aAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,aAAA,CAAA,UAAA,GAAA,SAAmB,CAAA;IACnB,aAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;AACzB,CAAC,EAzBW,aAAa,IAAA,CAAb,aAAa,GAAA,CAAA,CAAA,GAyBxB;AA4BM,MAAM,iBAAiB,GAAG,CAC/B,OAAgB,EAChB,MAAc,EACd,UAAoC,CAAA,CAAE,EAC9B,EAAE;;IACV,MAAM,SAAS,GAAG,CAAA,KAAA,OAAO,CAAC,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,EAAE,CAAA;IAEzC,OAAO,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,OAAO,EAAE,EAAE;QACjD,GAAG,CAAC,OAAO,CAAC,GAAG,aAAa,CAAC,OAAO,EAAE,OAAO,EAAE,MAAM,EAAE,SAAS,CAAC,CAAA;QACjE,OAAO,GAAG,CAAA;IACZ,CAAC,EAAE,CAAA,CAAY,CAAC,CAAA;AAClB,CAAC,CAAA;AAgBM,MAAM,aAAa,GAAG,CAC3B,UAAkB,EAClB,OAAgB,EAChB,MAAc,EACd,SAAmB,EACN,EAAE;IACf,MAAM,MAAM,GAAG,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,IAAI,KAAK,UAAU,CAAC,CAAA;IACzD,MAAM,OAAO,GAAG,MAAM,KAAA,QAAN,MAAM,KAAA,KAAA,IAAA,KAAA,IAAN,MAAM,CAAE,IAAI,CAAA;IAC5B,MAAM,KAAK,GAAG,MAAM,CAAC,UAAU,CAAC,CAAA;IAEhC,IAAI,OAAO,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,OAAO,CAAC,EAAE,CAAC;QAC5C,OAAO,WAAW,CAAC,OAAO,EAAE,KAAK,CAAC,CAAA;IACpC,CAAC;IAED,OAAO,IAAI,CAAC,KAAK,CAAC,CAAA;AACpB,CAAC,CAAA;AAeM,MAAM,WAAW,GAAG,CAAC,IAAY,EAAE,KAAkB,EAAe,EAAE;IAC3E,2BAA2B;IAC3B,IAAI,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,GAAG,EAAE,CAAC;QAC3B,MAAM,QAAQ,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,CAAA;QAC3C,OAAO,OAAO,CAAC,KAAK,EAAE,QAAQ,CAAC,CAAA;IACjC,CAAC;IAED,wCAAwC;IACxC,OAAQ,IAAI,EAAE,CAAC;QACb,KAAK,aAAa,CAAC,IAAI;YACrB,OAAO,SAAS,CAAC,KAAK,CAAC,CAAA;QACzB,KAAK,aAAa,CAAC,MAAM,CAAC;QAC1B,KAAK,aAAa,CAAC,MAAM,CAAC;QAC1B,KAAK,aAAa,CAAC,IAAI,CAAC;QACxB,KAAK,aAAa,CAAC,IAAI,CAAC;QACxB,KAAK,aAAa,CAAC,IAAI,CAAC;QACxB,KAAK,aAAa,CAAC,OAAO,CAAC;QAC3B,KAAK,aAAa,CAAC,GAAG;YACpB,OAAO,QAAQ,CAAC,KAAK,CAAC,CAAA;QACxB,KAAK,aAAa,CAAC,IAAI,CAAC;QACxB,KAAK,aAAa,CAAC,KAAK;YACtB,OAAO,MAAM,CAAC,KAAK,CAAC,CAAA;QACtB,KAAK,aAAa,CAAC,SAAS;YAC1B,OAAO,iBAAiB,CAAC,KAAK,CAAC,CAAA,CAAC,yCAAyC;QAC3E,KAAK,aAAa,CAAC,OAAO,CAAC,CAAC,8CAA8C;QAC1E,KAAK,aAAa,CAAC,IAAI,CAAC,CAAC,8CAA8C;QACvE,KAAK,aAAa,CAAC,SAAS,CAAC;QAC7B,KAAK,aAAa,CAAC,SAAS,CAAC;QAC7B,KAAK,aAAa,CAAC,SAAS,CAAC;QAC7B,KAAK,aAAa,CAAC,KAAK,CAAC;QACzB,KAAK,aAAa,CAAC,OAAO,CAAC,CAAC,8CAA8C;QAC1E,KAAK,aAAa,CAAC,IAAI,CAAC;QACxB,KAAK,aAAa,CAAC,IAAI,CAAC,CAAC,8CAA8C;QACvE,KAAK,aAAa,CAAC,WAAW,CAAC,CAAC,8CAA8C;QAC9E,KAAK,aAAa,CAAC,MAAM,CAAC,CAAC,8CAA8C;QACzE,KAAK,aAAa,CAAC,OAAO,CAAC;QAC3B,KAAK,aAAa,CAAC,SAAS;YAC1B,OAAO,IAAI,CAAC,KAAK,CAAC,CAAA;QACpB;YACE,uCAAuC;YACvC,OAAO,IAAI,CAAC,KAAK,CAAC,CAAA;IACtB,CAAC;AACH,CAAC,CAAA;AAED,MAAM,IAAI,GAAG,CAAC,KAAkB,EAAe,EAAE;IAC/C,OAAO,KAAK,CAAA;AACd,CAAC,CAAA;AACM,MAAM,SAAS,GAAG,CAAC,KAAkB,EAAe,EAAE;IAC3D,OAAQ,KAAK,EAAE,CAAC;QACd,KAAK,GAAG;YACN,OAAO,IAAI,CAAA;QACb,KAAK,GAAG;YACN,OAAO,KAAK,CAAA;QACd;YACE,OAAO,KAAK,CAAA;IAChB,CAAC;AACH,CAAC,CAAA;AACM,MAAM,QAAQ,GAAG,CAAC,KAAkB,EAAe,EAAE;IAC1D,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;QAC9B,MAAM,WAAW,GAAG,UAAU,CAAC,KAAK,CAAC,CAAA;QACrC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,WAAW,CAAC,EAAE,CAAC;YAC/B,OAAO,WAAW,CAAA;QACpB,CAAC;IACH,CAAC;IACD,OAAO,KAAK,CAAA;AACd,CAAC,CAAA;AACM,MAAM,MAAM,GAAG,CAAC,KAAkB,EAAe,EAAE;IACxD,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;QAC9B,IAAI,CAAC;YACH,OAAO,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,CAAA;QAC1B,CAAC,CAAC,OAAO,KAAK,EAAE,CAAC;YACf,OAAO,CAAC,GAAG,CAAC,CAAA,kBAAA,EAAqB,KAAK,EAAE,CAAC,CAAA;YACzC,OAAO,KAAK,CAAA;QACd,CAAC;IACH,CAAC;IACD,OAAO,KAAK,CAAA;AACd,CAAC,CAAA;AAYM,MAAM,OAAO,GAAG,CAAC,KAAkB,EAAE,IAAY,EAAe,EAAE;IACvE,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;QAC9B,OAAO,KAAK,CAAA;IACd,CAAC;IAED,MAAM,OAAO,GAAG,KAAK,CAAC,MAAM,GAAG,CAAC,CAAA;IAChC,MAAM,UAAU,GAAG,KAAK,CAAC,OAAO,CAAC,CAAA;IACjC,MAAM,SAAS,GAAG,KAAK,CAAC,CAAC,CAAC,CAAA;IAE1B,+DAA+D;IAC/D,IAAI,SAAS,KAAK,GAAG,IAAI,UAAU,KAAK,GAAG,EAAE,CAAC;QAC5C,IAAI,GAAG,CAAA;QACP,MAAM,OAAO,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,OAAO,CAAC,CAAA;QAEvC,+DAA+D;QAC/D,IAAI,CAAC;YACH,GAAG,GAAG,IAAI,CAAC,KAAK,CAAC,GAAG,GAAG,OAAO,GAAG,GAAG,CAAC,CAAA;QACvC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;YACX,4DAA4D;YAC5D,GAAG,GAAG,OAAO,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAA;QACzC,CAAC;QAED,OAAO,GAAG,CAAC,GAAG,CAAC,CAAC,GAAc,EAAE,CAAG,CAAD,UAAY,CAAC,IAAI,EAAE,GAAG,CAAC,CAAC,CAAA;IAC5D,CAAC;IAED,OAAO,KAAK,CAAA;AACd,CAAC,CAAA;AASM,MAAM,iBAAiB,GAAG,CAAC,KAAkB,EAAe,EAAE;IACnE,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;QAC9B,OAAO,KAAK,CAAC,OAAO,CAAC,GAAG,EAAE,GAAG,CAAC,CAAA;IAChC,CAAC;IAED,OAAO,KAAK,CAAA;AACd,CAAC,CAAA;AAEM,MAAM,eAAe,GAAG,CAAC,SAAiB,EAAU,EAAE;IAC3D,IAAI,GAAG,GAAG,SAAS,CAAA;IACnB,GAAG,GAAG,GAAG,CAAC,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,CAAA;IACjC,GAAG,GAAG,GAAG,CAAC,OAAO,CAAC,iDAAiD,EAAE,EAAE,CAAC,CAAA;IACxE,OAAO,GAAG,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,GAAG,gBAAgB,CAAA;AACnD,CAAC,CAAA"}},
    {"offset": {"line": 1960, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/lib/push.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/lib/push.ts"],"sourcesContent":["import { DEFAULT_TIMEOUT } from '../lib/constants'\nimport type RealtimeChannel from '../RealtimeChannel'\n\nexport default class Push {\n  sent: boolean = false\n  timeoutTimer: number | undefined = undefined\n  ref: string = ''\n  receivedResp: {\n    status: string\n    response: { [key: string]: any }\n  } | null = null\n  recHooks: {\n    status: string\n    callback: Function\n  }[] = []\n  refEvent: string | null = null\n\n  /**\n   * Initializes the Push\n   *\n   * @param channel The Channel\n   * @param event The event, for example `\"phx_join\"`\n   * @param payload The payload, for example `{user_id: 123}`\n   * @param timeout The push timeout in milliseconds\n   */\n  constructor(\n    public channel: RealtimeChannel,\n    public event: string,\n    public payload: { [key: string]: any } = {},\n    public timeout: number = DEFAULT_TIMEOUT\n  ) {}\n\n  resend(timeout: number) {\n    this.timeout = timeout\n    this._cancelRefEvent()\n    this.ref = ''\n    this.refEvent = null\n    this.receivedResp = null\n    this.sent = false\n    this.send()\n  }\n\n  send() {\n    if (this._hasReceived('timeout')) {\n      return\n    }\n    this.startTimeout()\n    this.sent = true\n    this.channel.socket.push({\n      topic: this.channel.topic,\n      event: this.event,\n      payload: this.payload,\n      ref: this.ref,\n      join_ref: this.channel._joinRef(),\n    })\n  }\n\n  updatePayload(payload: { [key: string]: any }): void {\n    this.payload = { ...this.payload, ...payload }\n  }\n\n  receive(status: string, callback: Function) {\n    if (this._hasReceived(status)) {\n      callback(this.receivedResp?.response)\n    }\n\n    this.recHooks.push({ status, callback })\n    return this\n  }\n\n  startTimeout() {\n    if (this.timeoutTimer) {\n      return\n    }\n    this.ref = this.channel.socket._makeRef()\n    this.refEvent = this.channel._replyEventName(this.ref)\n\n    const callback = (payload: any) => {\n      this._cancelRefEvent()\n      this._cancelTimeout()\n      this.receivedResp = payload\n      this._matchReceive(payload)\n    }\n\n    this.channel._on(this.refEvent, {}, callback)\n\n    this.timeoutTimer = <any>setTimeout(() => {\n      this.trigger('timeout', {})\n    }, this.timeout)\n  }\n\n  trigger(status: string, response: any) {\n    if (this.refEvent)\n      this.channel._trigger(this.refEvent, { status, response })\n  }\n\n  destroy() {\n    this._cancelRefEvent()\n    this._cancelTimeout()\n  }\n\n  private _cancelRefEvent() {\n    if (!this.refEvent) {\n      return\n    }\n\n    this.channel._off(this.refEvent, {})\n  }\n\n  private _cancelTimeout() {\n    clearTimeout(this.timeoutTimer)\n    this.timeoutTimer = undefined\n  }\n\n  private _matchReceive({\n    status,\n    response,\n  }: {\n    status: string\n    response: Function\n  }) {\n    this.recHooks\n      .filter((h) => h.status === status)\n      .forEach((h) => h.callback(response))\n  }\n\n  private _hasReceived(status: string) {\n    return this.receivedResp && this.receivedResp.status === status\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,eAAe,EAAE,MAAM,kBAAkB,CAAA;;AAGpC,MAAO,IAAI;IAcvB;;;;;;;OAOG,CACH,YACS,OAAwB,EACxB,KAAa,EACb,UAAkC,CAAA,CAAE,EACpC,UAAkB,6MAAe,CAAA;QAHjC,IAAA,CAAA,OAAO,GAAP,OAAO,CAAiB;QACxB,IAAA,CAAA,KAAK,GAAL,KAAK,CAAQ;QACb,IAAA,CAAA,OAAO,GAAP,OAAO,CAA6B;QACpC,IAAA,CAAA,OAAO,GAAP,OAAO,CAA0B;QAzB1C,IAAA,CAAA,IAAI,GAAY,KAAK,CAAA;QACrB,IAAA,CAAA,YAAY,GAAuB,SAAS,CAAA;QAC5C,IAAA,CAAA,GAAG,GAAW,EAAE,CAAA;QAChB,IAAA,CAAA,YAAY,GAGD,IAAI,CAAA;QACf,IAAA,CAAA,QAAQ,GAGF,EAAE,CAAA;QACR,IAAA,CAAA,QAAQ,GAAkB,IAAI,CAAA;IAe3B,CAAC;IAEJ,MAAM,CAAC,OAAe,EAAA;QACpB,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;QACtB,IAAI,CAAC,eAAe,EAAE,CAAA;QACtB,IAAI,CAAC,GAAG,GAAG,EAAE,CAAA;QACb,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAA;QACpB,IAAI,CAAC,YAAY,GAAG,IAAI,CAAA;QACxB,IAAI,CAAC,IAAI,GAAG,KAAK,CAAA;QACjB,IAAI,CAAC,IAAI,EAAE,CAAA;IACb,CAAC;IAED,IAAI,GAAA;QACF,IAAI,IAAI,CAAC,YAAY,CAAC,SAAS,CAAC,EAAE,CAAC;YACjC,OAAM;QACR,CAAC;QACD,IAAI,CAAC,YAAY,EAAE,CAAA;QACnB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAA;QAChB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,IAAI,CAAC;YACvB,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,KAAK;YACzB,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,GAAG,EAAE,IAAI,CAAC,GAAG;YACb,QAAQ,EAAE,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE;SAClC,CAAC,CAAA;IACJ,CAAC;IAED,aAAa,CAAC,OAA+B,EAAA;QAC3C,IAAI,CAAC,OAAO,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,IAAI,CAAC,OAAO,GAAK,OAAO,CAAE,CAAA;IAChD,CAAC;IAED,OAAO,CAAC,MAAc,EAAE,QAAkB,EAAA;;QACxC,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,CAAC,EAAE,CAAC;YAC9B,QAAQ,CAAC,CAAA,KAAA,IAAI,CAAC,YAAY,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,QAAQ,CAAC,CAAA;QACvC,CAAC;QAED,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC;YAAE,MAAM;YAAE,QAAQ;QAAA,CAAE,CAAC,CAAA;QACxC,OAAO,IAAI,CAAA;IACb,CAAC;IAED,YAAY,GAAA;QACV,IAAI,IAAI,CAAC,YAAY,EAAE,CAAC;YACtB,OAAM;QACR,CAAC;QACD,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,QAAQ,EAAE,CAAA;QACzC,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,OAAO,CAAC,eAAe,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA;QAEtD,MAAM,QAAQ,GAAG,CAAC,OAAY,EAAE,EAAE;YAChC,IAAI,CAAC,eAAe,EAAE,CAAA;YACtB,IAAI,CAAC,cAAc,EAAE,CAAA;YACrB,IAAI,CAAC,YAAY,GAAG,OAAO,CAAA;YAC3B,IAAI,CAAC,aAAa,CAAC,OAAO,CAAC,CAAA;QAC7B,CAAC,CAAA;QAED,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAA,CAAE,EAAE,QAAQ,CAAC,CAAA;QAE7C,IAAI,CAAC,YAAY,GAAQ,UAAU,CAAC,GAAG,EAAE;YACvC,IAAI,CAAC,OAAO,CAAC,SAAS,EAAE,CAAA,CAAE,CAAC,CAAA;QAC7B,CAAC,EAAE,IAAI,CAAC,OAAO,CAAC,CAAA;IAClB,CAAC;IAED,OAAO,CAAC,MAAc,EAAE,QAAa,EAAA;QACnC,IAAI,IAAI,CAAC,QAAQ,EACf,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,EAAE;YAAE,MAAM;YAAE,QAAQ;QAAA,CAAE,CAAC,CAAA;IAC9D,CAAC;IAED,OAAO,GAAA;QACL,IAAI,CAAC,eAAe,EAAE,CAAA;QACtB,IAAI,CAAC,cAAc,EAAE,CAAA;IACvB,CAAC;IAEO,eAAe,GAAA;QACrB,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC;YACnB,OAAM;QACR,CAAC;QAED,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAA,CAAE,CAAC,CAAA;IACtC,CAAC;IAEO,cAAc,GAAA;QACpB,YAAY,CAAC,IAAI,CAAC,YAAY,CAAC,CAAA;QAC/B,IAAI,CAAC,YAAY,GAAG,SAAS,CAAA;IAC/B,CAAC;IAEO,aAAa,CAAC,EACpB,MAAM,EACN,QAAQ,EAIT,EAAA;QACC,IAAI,CAAC,QAAQ,CACV,MAAM,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,MAAM,KAAK,MAAM,CAAC,CAClC,OAAO,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAC,CAAA;IACzC,CAAC;IAEO,YAAY,CAAC,MAAc,EAAA;QACjC,OAAO,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,MAAM,CAAA;IACjE,CAAC;CACF"}},
    {"offset": {"line": 2071, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/RealtimePresence.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/RealtimePresence.ts"],"sourcesContent":["/*\n  This file draws heavily from https://github.com/phoenixframework/phoenix/blob/d344ec0a732ab4ee204215b31de69cf4be72e3bf/assets/js/phoenix/presence.js\n  License: https://github.com/phoenixframework/phoenix/blob/d344ec0a732ab4ee204215b31de69cf4be72e3bf/LICENSE.md\n*/\n\nimport type {\n  PresenceOpts,\n  PresenceOnJoinCallback,\n  PresenceOnLeaveCallback,\n} from 'phoenix'\nimport type RealtimeChannel from './RealtimeChannel'\n\ntype Presence<T extends { [key: string]: any } = {}> = {\n  presence_ref: string\n} & T\n\nexport type RealtimePresenceState<T extends { [key: string]: any } = {}> = {\n  [key: string]: Presence<T>[]\n}\n\nexport type RealtimePresenceJoinPayload<T extends { [key: string]: any }> = {\n  event: `${REALTIME_PRESENCE_LISTEN_EVENTS.JOIN}`\n  key: string\n  currentPresences: Presence<T>[]\n  newPresences: Presence<T>[]\n}\n\nexport type RealtimePresenceLeavePayload<T extends { [key: string]: any }> = {\n  event: `${REALTIME_PRESENCE_LISTEN_EVENTS.LEAVE}`\n  key: string\n  currentPresences: Presence<T>[]\n  leftPresences: Presence<T>[]\n}\n\nexport enum REALTIME_PRESENCE_LISTEN_EVENTS {\n  SYNC = 'sync',\n  JOIN = 'join',\n  LEAVE = 'leave',\n}\n\ntype PresenceDiff = {\n  joins: RealtimePresenceState\n  leaves: RealtimePresenceState\n}\n\ntype RawPresenceState = {\n  [key: string]: {\n    metas: {\n      phx_ref?: string\n      phx_ref_prev?: string\n      [key: string]: any\n    }[]\n  }\n}\n\ntype RawPresenceDiff = {\n  joins: RawPresenceState\n  leaves: RawPresenceState\n}\n\ntype PresenceChooser<T> = (key: string, presences: Presence[]) => T\n\nexport default class RealtimePresence {\n  state: RealtimePresenceState = {}\n  pendingDiffs: RawPresenceDiff[] = []\n  joinRef: string | null = null\n  enabled: boolean = false\n  caller: {\n    onJoin: PresenceOnJoinCallback\n    onLeave: PresenceOnLeaveCallback\n    onSync: () => void\n  } = {\n    onJoin: () => {},\n    onLeave: () => {},\n    onSync: () => {},\n  }\n\n  /**\n   * Initializes the Presence.\n   *\n   * @param channel - The RealtimeChannel\n   * @param opts - The options,\n   *        for example `{events: {state: 'state', diff: 'diff'}}`\n   */\n  constructor(public channel: RealtimeChannel, opts?: PresenceOpts) {\n    const events = opts?.events || {\n      state: 'presence_state',\n      diff: 'presence_diff',\n    }\n\n    this.channel._on(events.state, {}, (newState: RawPresenceState) => {\n      const { onJoin, onLeave, onSync } = this.caller\n\n      this.joinRef = this.channel._joinRef()\n\n      this.state = RealtimePresence.syncState(\n        this.state,\n        newState,\n        onJoin,\n        onLeave\n      )\n\n      this.pendingDiffs.forEach((diff) => {\n        this.state = RealtimePresence.syncDiff(\n          this.state,\n          diff,\n          onJoin,\n          onLeave\n        )\n      })\n\n      this.pendingDiffs = []\n\n      onSync()\n    })\n\n    this.channel._on(events.diff, {}, (diff: RawPresenceDiff) => {\n      const { onJoin, onLeave, onSync } = this.caller\n\n      if (this.inPendingSyncState()) {\n        this.pendingDiffs.push(diff)\n      } else {\n        this.state = RealtimePresence.syncDiff(\n          this.state,\n          diff,\n          onJoin,\n          onLeave\n        )\n\n        onSync()\n      }\n    })\n\n    this.onJoin((key, currentPresences, newPresences) => {\n      this.channel._trigger('presence', {\n        event: 'join',\n        key,\n        currentPresences,\n        newPresences,\n      })\n    })\n\n    this.onLeave((key, currentPresences, leftPresences) => {\n      this.channel._trigger('presence', {\n        event: 'leave',\n        key,\n        currentPresences,\n        leftPresences,\n      })\n    })\n\n    this.onSync(() => {\n      this.channel._trigger('presence', { event: 'sync' })\n    })\n  }\n\n  /**\n   * Used to sync the list of presences on the server with the\n   * client's state.\n   *\n   * An optional `onJoin` and `onLeave` callback can be provided to\n   * react to changes in the client's local presences across\n   * disconnects and reconnects with the server.\n   *\n   * @internal\n   */\n  private static syncState(\n    currentState: RealtimePresenceState,\n    newState: RawPresenceState | RealtimePresenceState,\n    onJoin: PresenceOnJoinCallback,\n    onLeave: PresenceOnLeaveCallback\n  ): RealtimePresenceState {\n    const state = this.cloneDeep(currentState)\n    const transformedState = this.transformState(newState)\n    const joins: RealtimePresenceState = {}\n    const leaves: RealtimePresenceState = {}\n\n    this.map(state, (key: string, presences: Presence[]) => {\n      if (!transformedState[key]) {\n        leaves[key] = presences\n      }\n    })\n\n    this.map(transformedState, (key, newPresences: Presence[]) => {\n      const currentPresences: Presence[] = state[key]\n\n      if (currentPresences) {\n        const newPresenceRefs = newPresences.map(\n          (m: Presence) => m.presence_ref\n        )\n        const curPresenceRefs = currentPresences.map(\n          (m: Presence) => m.presence_ref\n        )\n        const joinedPresences: Presence[] = newPresences.filter(\n          (m: Presence) => curPresenceRefs.indexOf(m.presence_ref) < 0\n        )\n        const leftPresences: Presence[] = currentPresences.filter(\n          (m: Presence) => newPresenceRefs.indexOf(m.presence_ref) < 0\n        )\n\n        if (joinedPresences.length > 0) {\n          joins[key] = joinedPresences\n        }\n\n        if (leftPresences.length > 0) {\n          leaves[key] = leftPresences\n        }\n      } else {\n        joins[key] = newPresences\n      }\n    })\n\n    return this.syncDiff(state, { joins, leaves }, onJoin, onLeave)\n  }\n\n  /**\n   * Used to sync a diff of presence join and leave events from the\n   * server, as they happen.\n   *\n   * Like `syncState`, `syncDiff` accepts optional `onJoin` and\n   * `onLeave` callbacks to react to a user joining or leaving from a\n   * device.\n   *\n   * @internal\n   */\n  private static syncDiff(\n    state: RealtimePresenceState,\n    diff: RawPresenceDiff | PresenceDiff,\n    onJoin: PresenceOnJoinCallback,\n    onLeave: PresenceOnLeaveCallback\n  ): RealtimePresenceState {\n    const { joins, leaves } = {\n      joins: this.transformState(diff.joins),\n      leaves: this.transformState(diff.leaves),\n    }\n\n    if (!onJoin) {\n      onJoin = () => {}\n    }\n\n    if (!onLeave) {\n      onLeave = () => {}\n    }\n\n    this.map(joins, (key, newPresences: Presence[]) => {\n      const currentPresences: Presence[] = state[key] ?? []\n      state[key] = this.cloneDeep(newPresences)\n\n      if (currentPresences.length > 0) {\n        const joinedPresenceRefs = state[key].map(\n          (m: Presence) => m.presence_ref\n        )\n        const curPresences: Presence[] = currentPresences.filter(\n          (m: Presence) => joinedPresenceRefs.indexOf(m.presence_ref) < 0\n        )\n\n        state[key].unshift(...curPresences)\n      }\n\n      onJoin(key, currentPresences, newPresences)\n    })\n\n    this.map(leaves, (key, leftPresences: Presence[]) => {\n      let currentPresences: Presence[] = state[key]\n\n      if (!currentPresences) return\n\n      const presenceRefsToRemove = leftPresences.map(\n        (m: Presence) => m.presence_ref\n      )\n      currentPresences = currentPresences.filter(\n        (m: Presence) => presenceRefsToRemove.indexOf(m.presence_ref) < 0\n      )\n\n      state[key] = currentPresences\n\n      onLeave(key, currentPresences, leftPresences)\n\n      if (currentPresences.length === 0) delete state[key]\n    })\n\n    return state\n  }\n\n  /** @internal */\n  private static map<T = any>(\n    obj: RealtimePresenceState,\n    func: PresenceChooser<T>\n  ): T[] {\n    return Object.getOwnPropertyNames(obj).map((key) => func(key, obj[key]))\n  }\n\n  /**\n   * Remove 'metas' key\n   * Change 'phx_ref' to 'presence_ref'\n   * Remove 'phx_ref' and 'phx_ref_prev'\n   *\n   * @example\n   * // returns {\n   *  abc123: [\n   *    { presence_ref: '2', user_id: 1 },\n   *    { presence_ref: '3', user_id: 2 }\n   *  ]\n   * }\n   * RealtimePresence.transformState({\n   *  abc123: {\n   *    metas: [\n   *      { phx_ref: '2', phx_ref_prev: '1' user_id: 1 },\n   *      { phx_ref: '3', user_id: 2 }\n   *    ]\n   *  }\n   * })\n   *\n   * @internal\n   */\n  private static transformState(\n    state: RawPresenceState | RealtimePresenceState\n  ): RealtimePresenceState {\n    state = this.cloneDeep(state)\n\n    return Object.getOwnPropertyNames(state).reduce((newState, key) => {\n      const presences = state[key]\n\n      if ('metas' in presences) {\n        newState[key] = presences.metas.map((presence) => {\n          presence['presence_ref'] = presence['phx_ref']\n\n          delete presence['phx_ref']\n          delete presence['phx_ref_prev']\n\n          return presence\n        }) as Presence[]\n      } else {\n        newState[key] = presences\n      }\n\n      return newState\n    }, {} as RealtimePresenceState)\n  }\n\n  /** @internal */\n  private static cloneDeep(obj: { [key: string]: any }) {\n    return JSON.parse(JSON.stringify(obj))\n  }\n\n  /** @internal */\n  private onJoin(callback: PresenceOnJoinCallback): void {\n    this.caller.onJoin = callback\n  }\n\n  /** @internal */\n  private onLeave(callback: PresenceOnLeaveCallback): void {\n    this.caller.onLeave = callback\n  }\n\n  /** @internal */\n  private onSync(callback: () => void): void {\n    this.caller.onSync = callback\n  }\n\n  /** @internal */\n  private inPendingSyncState(): boolean {\n    return !this.joinRef || this.joinRef !== this.channel._joinRef()\n  }\n}\n"],"names":[],"mappings":"AAAA;;;EAGE;;;;;;AA+BF,IAAY,+BAIX;AAJD,CAAA,SAAY,+BAA+B;IACzC,+BAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,+BAAA,CAAA,OAAA,GAAA,MAAa,CAAA;IACb,+BAAA,CAAA,QAAA,GAAA,OAAe,CAAA;AACjB,CAAC,EAJW,+BAA+B,IAAA,CAA/B,+BAA+B,GAAA,CAAA,CAAA,GAI1C;AAwBa,MAAO,gBAAgB;IAenC;;;;;;OAMG,CACH,YAAmB,OAAwB,EAAE,IAAmB,CAAA;QAA7C,IAAA,CAAA,OAAO,GAAP,OAAO,CAAiB;QArB3C,IAAA,CAAA,KAAK,GAA0B,CAAA,CAAE,CAAA;QACjC,IAAA,CAAA,YAAY,GAAsB,EAAE,CAAA;QACpC,IAAA,CAAA,OAAO,GAAkB,IAAI,CAAA;QAC7B,IAAA,CAAA,OAAO,GAAY,KAAK,CAAA;QACxB,IAAA,CAAA,MAAM,GAIF;YACF,MAAM,EAAE,GAAG,EAAE,AAAE,CAAC;YAChB,OAAO,EAAE,GAAG,EAAI,AAAF,CAAG;YACjB,MAAM,EAAE,GAAG,EAAE,AAAE,CAAC;SACjB,CAAA;QAUC,MAAM,MAAM,GAAG,CAAA,IAAI,KAAA,QAAJ,IAAI,KAAA,KAAA,IAAA,KAAA,IAAJ,IAAI,CAAE,MAAM,KAAI;YAC7B,KAAK,EAAE,gBAAgB;YACvB,IAAI,EAAE,eAAe;SACtB,CAAA;QAED,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,KAAK,EAAE,CAAA,CAAE,EAAE,CAAC,QAA0B,EAAE,EAAE;YAChE,MAAM,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG,IAAI,CAAC,MAAM,CAAA;YAE/C,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE,CAAA;YAEtC,IAAI,CAAC,KAAK,GAAG,gBAAgB,CAAC,SAAS,CACrC,IAAI,CAAC,KAAK,EACV,QAAQ,EACR,MAAM,EACN,OAAO,CACR,CAAA;YAED,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,EAAE;gBACjC,IAAI,CAAC,KAAK,GAAG,gBAAgB,CAAC,QAAQ,CACpC,IAAI,CAAC,KAAK,EACV,IAAI,EACJ,MAAM,EACN,OAAO,CACR,CAAA;YACH,CAAC,CAAC,CAAA;YAEF,IAAI,CAAC,YAAY,GAAG,EAAE,CAAA;YAEtB,MAAM,EAAE,CAAA;QACV,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,IAAI,EAAE,CAAA,CAAE,EAAE,CAAC,IAAqB,EAAE,EAAE;YAC1D,MAAM,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG,IAAI,CAAC,MAAM,CAAA;YAE/C,IAAI,IAAI,CAAC,kBAAkB,EAAE,EAAE,CAAC;gBAC9B,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,CAAA;YAC9B,CAAC,MAAM,CAAC;gBACN,IAAI,CAAC,KAAK,GAAG,gBAAgB,CAAC,QAAQ,CACpC,IAAI,CAAC,KAAK,EACV,IAAI,EACJ,MAAM,EACN,OAAO,CACR,CAAA;gBAED,MAAM,EAAE,CAAA;YACV,CAAC;QACH,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,gBAAgB,EAAE,YAAY,EAAE,EAAE;YAClD,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,UAAU,EAAE;gBAChC,KAAK,EAAE,MAAM;gBACb,GAAG;gBACH,gBAAgB;gBAChB,YAAY;aACb,CAAC,CAAA;QACJ,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,OAAO,CAAC,CAAC,GAAG,EAAE,gBAAgB,EAAE,aAAa,EAAE,EAAE;YACpD,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,UAAU,EAAE;gBAChC,KAAK,EAAE,OAAO;gBACd,GAAG;gBACH,gBAAgB;gBAChB,aAAa;aACd,CAAC,CAAA;QACJ,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,MAAM,CAAC,GAAG,EAAE;YACf,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,UAAU,EAAE;gBAAE,KAAK,EAAE,MAAM;YAAA,CAAE,CAAC,CAAA;QACtD,CAAC,CAAC,CAAA;IACJ,CAAC;IAED;;;;;;;;;OASG,CACK,MAAM,CAAC,SAAS,CACtB,YAAmC,EACnC,QAAkD,EAClD,MAA8B,EAC9B,OAAgC,EAAA;QAEhC,MAAM,KAAK,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAA;QAC1C,MAAM,gBAAgB,GAAG,IAAI,CAAC,cAAc,CAAC,QAAQ,CAAC,CAAA;QACtD,MAAM,KAAK,GAA0B,CAAA,CAAE,CAAA;QACvC,MAAM,MAAM,GAA0B,CAAA,CAAE,CAAA;QAExC,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,CAAC,GAAW,EAAE,SAAqB,EAAE,EAAE;YACrD,IAAI,CAAC,gBAAgB,CAAC,GAAG,CAAC,EAAE,CAAC;gBAC3B,MAAM,CAAC,GAAG,CAAC,GAAG,SAAS,CAAA;YACzB,CAAC;QACH,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,GAAG,CAAC,gBAAgB,EAAE,CAAC,GAAG,EAAE,YAAwB,EAAE,EAAE;YAC3D,MAAM,gBAAgB,GAAe,KAAK,CAAC,GAAG,CAAC,CAAA;YAE/C,IAAI,gBAAgB,EAAE,CAAC;gBACrB,MAAM,eAAe,GAAG,YAAY,CAAC,GAAG,CACtC,CAAC,CAAW,EAAE,CAAG,CAAD,AAAE,CAAC,YAAY,CAChC,CAAA;gBACD,MAAM,eAAe,GAAG,gBAAgB,CAAC,GAAG,CAC1C,CAAC,CAAW,EAAE,CAAG,CAAD,AAAE,CAAC,YAAY,CAChC,CAAA;gBACD,MAAM,eAAe,GAAe,YAAY,CAAC,MAAM,CACrD,CAAC,CAAW,EAAE,CAAG,CAAD,cAAgB,CAAC,OAAO,CAAC,CAAC,CAAC,YAAY,CAAC,GAAG,CAAC,CAC7D,CAAA;gBACD,MAAM,aAAa,GAAe,gBAAgB,CAAC,MAAM,CACvD,CAAC,CAAW,EAAE,CAAG,CAAD,cAAgB,CAAC,OAAO,CAAC,CAAC,CAAC,YAAY,CAAC,GAAG,CAAC,CAC7D,CAAA;gBAED,IAAI,eAAe,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;oBAC/B,KAAK,CAAC,GAAG,CAAC,GAAG,eAAe,CAAA;gBAC9B,CAAC;gBAED,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;oBAC7B,MAAM,CAAC,GAAG,CAAC,GAAG,aAAa,CAAA;gBAC7B,CAAC;YACH,CAAC,MAAM,CAAC;gBACN,KAAK,CAAC,GAAG,CAAC,GAAG,YAAY,CAAA;YAC3B,CAAC;QACH,CAAC,CAAC,CAAA;QAEF,OAAO,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE;YAAE,KAAK;YAAE,MAAM;QAAA,CAAE,EAAE,MAAM,EAAE,OAAO,CAAC,CAAA;IACjE,CAAC;IAED;;;;;;;;;OASG,CACK,MAAM,CAAC,QAAQ,CACrB,KAA4B,EAC5B,IAAoC,EACpC,MAA8B,EAC9B,OAAgC,EAAA;QAEhC,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,GAAG;YACxB,KAAK,EAAE,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC;YACtC,MAAM,EAAE,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,MAAM,CAAC;SACzC,CAAA;QAED,IAAI,CAAC,MAAM,EAAE,CAAC;YACZ,MAAM,GAAG,GAAG,EAAE,AAAE,CAAC,CAAA;QACnB,CAAC;QAED,IAAI,CAAC,OAAO,EAAE,CAAC;YACb,OAAO,GAAG,GAAG,EAAE,AAAE,CAAC,CAAA;QACpB,CAAC;QAED,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,CAAC,GAAG,EAAE,YAAwB,EAAE,EAAE;;YAChD,MAAM,gBAAgB,GAAe,CAAA,KAAA,KAAK,CAAC,GAAG,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,EAAE,CAAA;YACrD,KAAK,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC,YAAY,CAAC,CAAA;YAEzC,IAAI,gBAAgB,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;gBAChC,MAAM,kBAAkB,GAAG,KAAK,CAAC,GAAG,CAAC,CAAC,GAAG,CACvC,CAAC,CAAW,EAAE,CAAG,CAAD,AAAE,CAAC,YAAY,CAChC,CAAA;gBACD,MAAM,YAAY,GAAe,gBAAgB,CAAC,MAAM,CACtD,CAAC,CAAW,EAAE,CAAG,CAAD,iBAAmB,CAAC,OAAO,CAAC,CAAC,CAAC,YAAY,CAAC,GAAG,CAAC,CAChE,CAAA;gBAED,KAAK,CAAC,GAAG,CAAC,CAAC,OAAO,CAAC,GAAG,YAAY,CAAC,CAAA;YACrC,CAAC;YAED,MAAM,CAAC,GAAG,EAAE,gBAAgB,EAAE,YAAY,CAAC,CAAA;QAC7C,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE,CAAC,GAAG,EAAE,aAAyB,EAAE,EAAE;YAClD,IAAI,gBAAgB,GAAe,KAAK,CAAC,GAAG,CAAC,CAAA;YAE7C,IAAI,CAAC,gBAAgB,EAAE,OAAM;YAE7B,MAAM,oBAAoB,GAAG,aAAa,CAAC,GAAG,CAC5C,CAAC,CAAW,EAAE,CAAG,CAAD,AAAE,CAAC,YAAY,CAChC,CAAA;YACD,gBAAgB,GAAG,gBAAgB,CAAC,MAAM,CACxC,CAAC,CAAW,EAAE,CAAG,CAAD,mBAAqB,CAAC,OAAO,CAAC,CAAC,CAAC,YAAY,CAAC,GAAG,CAAC,CAClE,CAAA;YAED,KAAK,CAAC,GAAG,CAAC,GAAG,gBAAgB,CAAA;YAE7B,OAAO,CAAC,GAAG,EAAE,gBAAgB,EAAE,aAAa,CAAC,CAAA;YAE7C,IAAI,gBAAgB,CAAC,MAAM,KAAK,CAAC,EAAE,OAAO,KAAK,CAAC,GAAG,CAAC,CAAA;QACtD,CAAC,CAAC,CAAA;QAEF,OAAO,KAAK,CAAA;IACd,CAAC;IAED,cAAA,EAAgB,CACR,MAAM,CAAC,GAAG,CAChB,GAA0B,EAC1B,IAAwB,EAAA;QAExB,OAAO,MAAM,CAAC,mBAAmB,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE,CAAG,CAAD,GAAK,CAAC,GAAG,EAAE,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,CAAA;IAC1E,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;OAsBG,CACK,MAAM,CAAC,cAAc,CAC3B,KAA+C,EAAA;QAE/C,KAAK,GAAG,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,CAAA;QAE7B,OAAO,MAAM,CAAC,mBAAmB,CAAC,KAAK,CAAC,CAAC,MAAM,CAAC,CAAC,QAAQ,EAAE,GAAG,EAAE,EAAE;YAChE,MAAM,SAAS,GAAG,KAAK,CAAC,GAAG,CAAC,CAAA;YAE5B,IAAI,OAAO,IAAI,SAAS,EAAE,CAAC;gBACzB,QAAQ,CAAC,GAAG,CAAC,GAAG,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,QAAQ,EAAE,EAAE;oBAC/C,QAAQ,CAAC,cAAc,CAAC,GAAG,QAAQ,CAAC,SAAS,CAAC,CAAA;oBAE9C,OAAO,QAAQ,CAAC,SAAS,CAAC,CAAA;oBAC1B,OAAO,QAAQ,CAAC,cAAc,CAAC,CAAA;oBAE/B,OAAO,QAAQ,CAAA;gBACjB,CAAC,CAAe,CAAA;YAClB,CAAC,MAAM,CAAC;gBACN,QAAQ,CAAC,GAAG,CAAC,GAAG,SAAS,CAAA;YAC3B,CAAC;YAED,OAAO,QAAQ,CAAA;QACjB,CAAC,EAAE,CAAA,CAA2B,CAAC,CAAA;IACjC,CAAC;IAED,cAAA,EAAgB,CACR,MAAM,CAAC,SAAS,CAAC,GAA2B,EAAA;QAClD,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAAA;IACxC,CAAC;IAED,cAAA,EAAgB,CACR,MAAM,CAAC,QAAgC,EAAA;QAC7C,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,QAAQ,CAAA;IAC/B,CAAC;IAED,cAAA,EAAgB,CACR,OAAO,CAAC,QAAiC,EAAA;QAC/C,IAAI,CAAC,MAAM,CAAC,OAAO,GAAG,QAAQ,CAAA;IAChC,CAAC;IAED,cAAA,EAAgB,CACR,MAAM,CAAC,QAAoB,EAAA;QACjC,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,QAAQ,CAAA;IAC/B,CAAC;IAED,cAAA,EAAgB,CACR,kBAAkB,GAAA;QACxB,OAAO,CAAC,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,KAAK,IAAI,CAAC,OAAO,CAAC,QAAQ,EAAE,CAAA;IAClE,CAAC;CACF"}},
    {"offset": {"line": 2294, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/RealtimeChannel.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/RealtimeChannel.ts"],"sourcesContent":["import {\n  CHANNEL_EVENTS,\n  CHANNEL_STATES,\n  MAX_PUSH_BUFFER_SIZE,\n} from './lib/constants'\nimport Push from './lib/push'\nimport type RealtimeClient from './RealtimeClient'\nimport Timer from './lib/timer'\nimport RealtimePresence, {\n  REALTIME_PRESENCE_LISTEN_EVENTS,\n} from './RealtimePresence'\nimport type {\n  RealtimePresenceJoinPayload,\n  RealtimePresenceLeavePayload,\n  RealtimePresenceState,\n} from './RealtimePresence'\nimport * as Transformers from './lib/transformers'\nimport { httpEndpointURL } from './lib/transformers'\n\nexport type RealtimeChannelOptions = {\n  config: {\n    /**\n     * self option enables client to receive message it broadcast\n     * ack option instructs server to acknowledge that broadcast message was received\n     */\n    broadcast?: { self?: boolean; ack?: boolean }\n    /**\n     * key option is used to track presence payload across clients\n     */\n    presence?: { key?: string; enabled?: boolean }\n    /**\n     * defines if the channel is private or not and if RLS policies will be used to check data\n     */\n    private?: boolean\n  }\n}\n\ntype RealtimePostgresChangesPayloadBase = {\n  schema: string\n  table: string\n  commit_timestamp: string\n  errors: string[]\n}\n\nexport type RealtimePostgresInsertPayload<T extends { [key: string]: any }> =\n  RealtimePostgresChangesPayloadBase & {\n    eventType: `${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.INSERT}`\n    new: T\n    old: {}\n  }\n\nexport type RealtimePostgresUpdatePayload<T extends { [key: string]: any }> =\n  RealtimePostgresChangesPayloadBase & {\n    eventType: `${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.UPDATE}`\n    new: T\n    old: Partial<T>\n  }\n\nexport type RealtimePostgresDeletePayload<T extends { [key: string]: any }> =\n  RealtimePostgresChangesPayloadBase & {\n    eventType: `${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.DELETE}`\n    new: {}\n    old: Partial<T>\n  }\n\nexport type RealtimePostgresChangesPayload<T extends { [key: string]: any }> =\n  | RealtimePostgresInsertPayload<T>\n  | RealtimePostgresUpdatePayload<T>\n  | RealtimePostgresDeletePayload<T>\n\nexport type RealtimePostgresChangesFilter<\n  T extends `${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT}`\n> = {\n  /**\n   * The type of database change to listen to.\n   */\n  event: T\n  /**\n   * The database schema to listen to.\n   */\n  schema: string\n  /**\n   * The database table to listen to.\n   */\n  table?: string\n  /**\n   * Receive database changes when filter is matched.\n   */\n  filter?: string\n}\n\nexport type RealtimeChannelSendResponse = 'ok' | 'timed out' | 'error'\n\nexport enum REALTIME_POSTGRES_CHANGES_LISTEN_EVENT {\n  ALL = '*',\n  INSERT = 'INSERT',\n  UPDATE = 'UPDATE',\n  DELETE = 'DELETE',\n}\n\nexport enum REALTIME_LISTEN_TYPES {\n  BROADCAST = 'broadcast',\n  PRESENCE = 'presence',\n  POSTGRES_CHANGES = 'postgres_changes',\n  SYSTEM = 'system',\n}\n\nexport enum REALTIME_SUBSCRIBE_STATES {\n  SUBSCRIBED = 'SUBSCRIBED',\n  TIMED_OUT = 'TIMED_OUT',\n  CLOSED = 'CLOSED',\n  CHANNEL_ERROR = 'CHANNEL_ERROR',\n}\n\nexport const REALTIME_CHANNEL_STATES = CHANNEL_STATES\n\ninterface PostgresChangesFilters {\n  postgres_changes: {\n    id: string\n    event: string\n    schema?: string\n    table?: string\n    filter?: string\n  }[]\n}\n/** A channel is the basic building block of Realtime\n * and narrows the scope of data flow to subscribed clients.\n * You can think of a channel as a chatroom where participants are able to see who's online\n * and send and receive messages.\n */\nexport default class RealtimeChannel {\n  bindings: {\n    [key: string]: {\n      type: string\n      filter: { [key: string]: any }\n      callback: Function\n      id?: string\n    }[]\n  } = {}\n  timeout: number\n  state: CHANNEL_STATES = CHANNEL_STATES.closed\n  joinedOnce = false\n  joinPush: Push\n  rejoinTimer: Timer\n  pushBuffer: Push[] = []\n  presence: RealtimePresence\n  broadcastEndpointURL: string\n  subTopic: string\n  private: boolean\n\n  constructor(\n    /** Topic name can be any string. */\n    public topic: string,\n    public params: RealtimeChannelOptions = { config: {} },\n    public socket: RealtimeClient\n  ) {\n    this.subTopic = topic.replace(/^realtime:/i, '')\n    this.params.config = {\n      ...{\n        broadcast: { ack: false, self: false },\n        presence: { key: '', enabled: false },\n        private: false,\n      },\n      ...params.config,\n    }\n    this.timeout = this.socket.timeout\n    this.joinPush = new Push(\n      this,\n      CHANNEL_EVENTS.join,\n      this.params,\n      this.timeout\n    )\n    this.rejoinTimer = new Timer(\n      () => this._rejoinUntilConnected(),\n      this.socket.reconnectAfterMs\n    )\n    this.joinPush.receive('ok', () => {\n      this.state = CHANNEL_STATES.joined\n      this.rejoinTimer.reset()\n      this.pushBuffer.forEach((pushEvent: Push) => pushEvent.send())\n      this.pushBuffer = []\n    })\n    this._onClose(() => {\n      this.rejoinTimer.reset()\n      this.socket.log('channel', `close ${this.topic} ${this._joinRef()}`)\n      this.state = CHANNEL_STATES.closed\n      this.socket._remove(this)\n    })\n    this._onError((reason: string) => {\n      if (this._isLeaving() || this._isClosed()) {\n        return\n      }\n      this.socket.log('channel', `error ${this.topic}`, reason)\n      this.state = CHANNEL_STATES.errored\n      this.rejoinTimer.scheduleTimeout()\n    })\n    this.joinPush.receive('timeout', () => {\n      if (!this._isJoining()) {\n        return\n      }\n      this.socket.log('channel', `timeout ${this.topic}`, this.joinPush.timeout)\n      this.state = CHANNEL_STATES.errored\n      this.rejoinTimer.scheduleTimeout()\n    })\n\n    this.joinPush.receive('error', (reason: any) => {\n      if (this._isLeaving() || this._isClosed()) {\n        return\n      }\n      this.socket.log('channel', `error ${this.topic}`, reason)\n      this.state = CHANNEL_STATES.errored\n      this.rejoinTimer.scheduleTimeout()\n    })\n    this._on(CHANNEL_EVENTS.reply, {}, (payload: any, ref: string) => {\n      this._trigger(this._replyEventName(ref), payload)\n    })\n\n    this.presence = new RealtimePresence(this)\n\n    this.broadcastEndpointURL = httpEndpointURL(this.socket.endPoint)\n    this.private = this.params.config.private || false\n  }\n\n  /** Subscribe registers your client with the server */\n  subscribe(\n    callback?: (status: REALTIME_SUBSCRIBE_STATES, err?: Error) => void,\n    timeout = this.timeout\n  ): RealtimeChannel {\n    if (!this.socket.isConnected()) {\n      this.socket.connect()\n    }\n    if (this.state == CHANNEL_STATES.closed) {\n      const {\n        config: { broadcast, presence, private: isPrivate },\n      } = this.params\n\n      const postgres_changes =\n        this.bindings.postgres_changes?.map((r) => r.filter) ?? []\n\n      const presence_enabled =\n        (!!this.bindings[REALTIME_LISTEN_TYPES.PRESENCE] &&\n          this.bindings[REALTIME_LISTEN_TYPES.PRESENCE].length > 0) ||\n        this.params.config.presence?.enabled === true\n      const accessTokenPayload: { access_token?: string } = {}\n      const config = {\n        broadcast,\n        presence: { ...presence, enabled: presence_enabled },\n        postgres_changes,\n        private: isPrivate,\n      }\n\n      if (this.socket.accessTokenValue) {\n        accessTokenPayload.access_token = this.socket.accessTokenValue\n      }\n\n      this._onError((e: Error) =>\n        callback?.(REALTIME_SUBSCRIBE_STATES.CHANNEL_ERROR, e)\n      )\n\n      this._onClose(() => callback?.(REALTIME_SUBSCRIBE_STATES.CLOSED))\n\n      this.updateJoinPayload({ ...{ config }, ...accessTokenPayload })\n\n      this.joinedOnce = true\n      this._rejoin(timeout)\n\n      this.joinPush\n        .receive('ok', async ({ postgres_changes }: PostgresChangesFilters) => {\n          this.socket.setAuth()\n          if (postgres_changes === undefined) {\n            callback?.(REALTIME_SUBSCRIBE_STATES.SUBSCRIBED)\n            return\n          } else {\n            const clientPostgresBindings = this.bindings.postgres_changes\n            const bindingsLen = clientPostgresBindings?.length ?? 0\n            const newPostgresBindings = []\n\n            for (let i = 0; i < bindingsLen; i++) {\n              const clientPostgresBinding = clientPostgresBindings[i]\n              const {\n                filter: { event, schema, table, filter },\n              } = clientPostgresBinding\n              const serverPostgresFilter =\n                postgres_changes && postgres_changes[i]\n\n              if (\n                serverPostgresFilter &&\n                serverPostgresFilter.event === event &&\n                serverPostgresFilter.schema === schema &&\n                serverPostgresFilter.table === table &&\n                serverPostgresFilter.filter === filter\n              ) {\n                newPostgresBindings.push({\n                  ...clientPostgresBinding,\n                  id: serverPostgresFilter.id,\n                })\n              } else {\n                this.unsubscribe()\n                this.state = CHANNEL_STATES.errored\n\n                callback?.(\n                  REALTIME_SUBSCRIBE_STATES.CHANNEL_ERROR,\n                  new Error(\n                    'mismatch between server and client bindings for postgres changes'\n                  )\n                )\n                return\n              }\n            }\n\n            this.bindings.postgres_changes = newPostgresBindings\n\n            callback && callback(REALTIME_SUBSCRIBE_STATES.SUBSCRIBED)\n            return\n          }\n        })\n        .receive('error', (error: { [key: string]: any }) => {\n          this.state = CHANNEL_STATES.errored\n          callback?.(\n            REALTIME_SUBSCRIBE_STATES.CHANNEL_ERROR,\n            new Error(\n              JSON.stringify(Object.values(error).join(', ') || 'error')\n            )\n          )\n          return\n        })\n        .receive('timeout', () => {\n          callback?.(REALTIME_SUBSCRIBE_STATES.TIMED_OUT)\n          return\n        })\n    }\n    return this\n  }\n\n  presenceState<\n    T extends { [key: string]: any } = {}\n  >(): RealtimePresenceState<T> {\n    return this.presence.state as RealtimePresenceState<T>\n  }\n\n  async track(\n    payload: { [key: string]: any },\n    opts: { [key: string]: any } = {}\n  ): Promise<RealtimeChannelSendResponse> {\n    return await this.send(\n      {\n        type: 'presence',\n        event: 'track',\n        payload,\n      },\n      opts.timeout || this.timeout\n    )\n  }\n\n  async untrack(\n    opts: { [key: string]: any } = {}\n  ): Promise<RealtimeChannelSendResponse> {\n    return await this.send(\n      {\n        type: 'presence',\n        event: 'untrack',\n      },\n      opts\n    )\n  }\n\n  /**\n   * Creates an event handler that listens to changes.\n   */\n  on(\n    type: `${REALTIME_LISTEN_TYPES.PRESENCE}`,\n    filter: { event: `${REALTIME_PRESENCE_LISTEN_EVENTS.SYNC}` },\n    callback: () => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.PRESENCE}`,\n    filter: { event: `${REALTIME_PRESENCE_LISTEN_EVENTS.JOIN}` },\n    callback: (payload: RealtimePresenceJoinPayload<T>) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.PRESENCE}`,\n    filter: { event: `${REALTIME_PRESENCE_LISTEN_EVENTS.LEAVE}` },\n    callback: (payload: RealtimePresenceLeavePayload<T>) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.POSTGRES_CHANGES}`,\n    filter: RealtimePostgresChangesFilter<`${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.ALL}`>,\n    callback: (payload: RealtimePostgresChangesPayload<T>) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.POSTGRES_CHANGES}`,\n    filter: RealtimePostgresChangesFilter<`${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.INSERT}`>,\n    callback: (payload: RealtimePostgresInsertPayload<T>) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.POSTGRES_CHANGES}`,\n    filter: RealtimePostgresChangesFilter<`${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.UPDATE}`>,\n    callback: (payload: RealtimePostgresUpdatePayload<T>) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.POSTGRES_CHANGES}`,\n    filter: RealtimePostgresChangesFilter<`${REALTIME_POSTGRES_CHANGES_LISTEN_EVENT.DELETE}`>,\n    callback: (payload: RealtimePostgresDeletePayload<T>) => void\n  ): RealtimeChannel\n  /**\n   * The following is placed here to display on supabase.com/docs/reference/javascript/subscribe.\n   * @param type One of \"broadcast\", \"presence\", or \"postgres_changes\".\n   * @param filter Custom object specific to the Realtime feature detailing which payloads to receive.\n   * @param callback Function to be invoked when event handler is triggered.\n   */\n  on(\n    type: `${REALTIME_LISTEN_TYPES.BROADCAST}`,\n    filter: { event: string },\n    callback: (payload: {\n      type: `${REALTIME_LISTEN_TYPES.BROADCAST}`\n      event: string\n      [key: string]: any\n    }) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.BROADCAST}`,\n    filter: { event: string },\n    callback: (payload: {\n      type: `${REALTIME_LISTEN_TYPES.BROADCAST}`\n      event: string\n      payload: T\n    }) => void\n  ): RealtimeChannel\n  on<T extends { [key: string]: any }>(\n    type: `${REALTIME_LISTEN_TYPES.SYSTEM}`,\n    filter: {},\n    callback: (payload: any) => void\n  ): RealtimeChannel\n  on(\n    type: `${REALTIME_LISTEN_TYPES}`,\n    filter: { event: string; [key: string]: string },\n    callback: (payload: any) => void\n  ): RealtimeChannel {\n    if (\n      this.state === CHANNEL_STATES.joined &&\n      type === REALTIME_LISTEN_TYPES.PRESENCE\n    ) {\n      this.socket.log(\n        'channel',\n        `resubscribe to ${this.topic} due to change in presence callbacks on joined channel`\n      )\n      this.unsubscribe().then(() => this.subscribe())\n    }\n    return this._on(type, filter, callback)\n  }\n  /**\n   * Sends a message into the channel.\n   *\n   * @param args Arguments to send to channel\n   * @param args.type The type of event to send\n   * @param args.event The name of the event being sent\n   * @param args.payload Payload to be sent\n   * @param opts Options to be used during the send process\n   */\n  async send(\n    args: {\n      type: 'broadcast' | 'presence' | 'postgres_changes'\n      event: string\n      payload?: any\n      [key: string]: any\n    },\n    opts: { [key: string]: any } = {}\n  ): Promise<RealtimeChannelSendResponse> {\n    if (!this._canPush() && args.type === 'broadcast') {\n      const { event, payload: endpoint_payload } = args\n      const authorization = this.socket.accessTokenValue\n        ? `Bearer ${this.socket.accessTokenValue}`\n        : ''\n      const options = {\n        method: 'POST',\n        headers: {\n          Authorization: authorization,\n          apikey: this.socket.apiKey ? this.socket.apiKey : '',\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          messages: [\n            {\n              topic: this.subTopic,\n              event,\n              payload: endpoint_payload,\n              private: this.private,\n            },\n          ],\n        }),\n      }\n\n      try {\n        const response = await this._fetchWithTimeout(\n          this.broadcastEndpointURL,\n          options,\n          opts.timeout ?? this.timeout\n        )\n\n        await response.body?.cancel()\n        return response.ok ? 'ok' : 'error'\n      } catch (error: any) {\n        if (error.name === 'AbortError') {\n          return 'timed out'\n        } else {\n          return 'error'\n        }\n      }\n    } else {\n      return new Promise((resolve) => {\n        const push = this._push(args.type, args, opts.timeout || this.timeout)\n\n        if (args.type === 'broadcast' && !this.params?.config?.broadcast?.ack) {\n          resolve('ok')\n        }\n\n        push.receive('ok', () => resolve('ok'))\n        push.receive('error', () => resolve('error'))\n        push.receive('timeout', () => resolve('timed out'))\n      })\n    }\n  }\n\n  updateJoinPayload(payload: { [key: string]: any }): void {\n    this.joinPush.updatePayload(payload)\n  }\n\n  /**\n   * Leaves the channel.\n   *\n   * Unsubscribes from server events, and instructs channel to terminate on server.\n   * Triggers onClose() hooks.\n   *\n   * To receive leave acknowledgements, use the a `receive` hook to bind to the server ack, ie:\n   * channel.unsubscribe().receive(\"ok\", () => alert(\"left!\") )\n   */\n  unsubscribe(timeout = this.timeout): Promise<'ok' | 'timed out' | 'error'> {\n    this.state = CHANNEL_STATES.leaving\n    const onClose = () => {\n      this.socket.log('channel', `leave ${this.topic}`)\n      this._trigger(CHANNEL_EVENTS.close, 'leave', this._joinRef())\n    }\n\n    this.joinPush.destroy()\n\n    let leavePush: Push | null = null\n\n    return new Promise<RealtimeChannelSendResponse>((resolve) => {\n      leavePush = new Push(this, CHANNEL_EVENTS.leave, {}, timeout)\n      leavePush\n        .receive('ok', () => {\n          onClose()\n          resolve('ok')\n        })\n        .receive('timeout', () => {\n          onClose()\n          resolve('timed out')\n        })\n        .receive('error', () => {\n          resolve('error')\n        })\n\n      leavePush.send()\n      if (!this._canPush()) {\n        leavePush.trigger('ok', {})\n      }\n    }).finally(() => {\n      leavePush?.destroy()\n    })\n  }\n  /**\n   * Teardown the channel.\n   *\n   * Destroys and stops related timers.\n   */\n  teardown() {\n    this.pushBuffer.forEach((push: Push) => push.destroy())\n    this.pushBuffer = []\n    this.rejoinTimer.reset()\n    this.joinPush.destroy()\n    this.state = CHANNEL_STATES.closed\n    this.bindings = {}\n  }\n\n  /** @internal */\n\n  async _fetchWithTimeout(\n    url: string,\n    options: { [key: string]: any },\n    timeout: number\n  ) {\n    const controller = new AbortController()\n    const id = setTimeout(() => controller.abort(), timeout)\n\n    const response = await this.socket.fetch(url, {\n      ...options,\n      signal: controller.signal,\n    })\n\n    clearTimeout(id)\n\n    return response\n  }\n\n  /** @internal */\n  _push(\n    event: string,\n    payload: { [key: string]: any },\n    timeout = this.timeout\n  ) {\n    if (!this.joinedOnce) {\n      throw `tried to push '${event}' to '${this.topic}' before joining. Use channel.subscribe() before pushing events`\n    }\n    let pushEvent = new Push(this, event, payload, timeout)\n    if (this._canPush()) {\n      pushEvent.send()\n    } else {\n      this._addToPushBuffer(pushEvent)\n    }\n\n    return pushEvent\n  }\n\n  /** @internal */\n  _addToPushBuffer(pushEvent: Push) {\n    pushEvent.startTimeout()\n    this.pushBuffer.push(pushEvent)\n\n    // Enforce buffer size limit\n    if (this.pushBuffer.length > MAX_PUSH_BUFFER_SIZE) {\n      const removedPush = this.pushBuffer.shift()\n      if (removedPush) {\n        removedPush.destroy()\n        this.socket.log(\n          'channel',\n          `discarded push due to buffer overflow: ${removedPush.event}`,\n          removedPush.payload\n        )\n      }\n    }\n  }\n\n  /**\n   * Overridable message hook\n   *\n   * Receives all events for specialized message handling before dispatching to the channel callbacks.\n   * Must return the payload, modified or unmodified.\n   *\n   * @internal\n   */\n  _onMessage(_event: string, payload: any, _ref?: string) {\n    return payload\n  }\n\n  /** @internal */\n  _isMember(topic: string): boolean {\n    return this.topic === topic\n  }\n\n  /** @internal */\n  _joinRef(): string {\n    return this.joinPush.ref\n  }\n\n  /** @internal */\n  _trigger(type: string, payload?: any, ref?: string) {\n    const typeLower = type.toLocaleLowerCase()\n    const { close, error, leave, join } = CHANNEL_EVENTS\n    const events: string[] = [close, error, leave, join]\n    if (ref && events.indexOf(typeLower) >= 0 && ref !== this._joinRef()) {\n      return\n    }\n    let handledPayload = this._onMessage(typeLower, payload, ref)\n    if (payload && !handledPayload) {\n      throw 'channel onMessage callbacks must return the payload, modified or unmodified'\n    }\n\n    if (['insert', 'update', 'delete'].includes(typeLower)) {\n      this.bindings.postgres_changes\n        ?.filter((bind) => {\n          return (\n            bind.filter?.event === '*' ||\n            bind.filter?.event?.toLocaleLowerCase() === typeLower\n          )\n        })\n        .map((bind) => bind.callback(handledPayload, ref))\n    } else {\n      this.bindings[typeLower]\n        ?.filter((bind) => {\n          if (\n            ['broadcast', 'presence', 'postgres_changes'].includes(typeLower)\n          ) {\n            if ('id' in bind) {\n              const bindId = bind.id\n              const bindEvent = bind.filter?.event\n              return (\n                bindId &&\n                payload.ids?.includes(bindId) &&\n                (bindEvent === '*' ||\n                  bindEvent?.toLocaleLowerCase() ===\n                    payload.data?.type.toLocaleLowerCase())\n              )\n            } else {\n              const bindEvent = bind?.filter?.event?.toLocaleLowerCase()\n              return (\n                bindEvent === '*' ||\n                bindEvent === payload?.event?.toLocaleLowerCase()\n              )\n            }\n          } else {\n            return bind.type.toLocaleLowerCase() === typeLower\n          }\n        })\n        .map((bind) => {\n          if (typeof handledPayload === 'object' && 'ids' in handledPayload) {\n            const postgresChanges = handledPayload.data\n            const { schema, table, commit_timestamp, type, errors } =\n              postgresChanges\n            const enrichedPayload = {\n              schema: schema,\n              table: table,\n              commit_timestamp: commit_timestamp,\n              eventType: type,\n              new: {},\n              old: {},\n              errors: errors,\n            }\n            handledPayload = {\n              ...enrichedPayload,\n              ...this._getPayloadRecords(postgresChanges),\n            }\n          }\n          bind.callback(handledPayload, ref)\n        })\n    }\n  }\n\n  /** @internal */\n  _isClosed(): boolean {\n    return this.state === CHANNEL_STATES.closed\n  }\n\n  /** @internal */\n  _isJoined(): boolean {\n    return this.state === CHANNEL_STATES.joined\n  }\n\n  /** @internal */\n  _isJoining(): boolean {\n    return this.state === CHANNEL_STATES.joining\n  }\n\n  /** @internal */\n  _isLeaving(): boolean {\n    return this.state === CHANNEL_STATES.leaving\n  }\n\n  /** @internal */\n  _replyEventName(ref: string): string {\n    return `chan_reply_${ref}`\n  }\n\n  /** @internal */\n  _on(type: string, filter: { [key: string]: any }, callback: Function) {\n    const typeLower = type.toLocaleLowerCase()\n    const binding = {\n      type: typeLower,\n      filter: filter,\n      callback: callback,\n    }\n\n    if (this.bindings[typeLower]) {\n      this.bindings[typeLower].push(binding)\n    } else {\n      this.bindings[typeLower] = [binding]\n    }\n\n    return this\n  }\n\n  /** @internal */\n  _off(type: string, filter: { [key: string]: any }) {\n    const typeLower = type.toLocaleLowerCase()\n\n    if (this.bindings[typeLower]) {\n      this.bindings[typeLower] = this.bindings[typeLower].filter((bind) => {\n        return !(\n          bind.type?.toLocaleLowerCase() === typeLower &&\n          RealtimeChannel.isEqual(bind.filter, filter)\n        )\n      })\n    }\n    return this\n  }\n\n  /** @internal */\n  private static isEqual(\n    obj1: { [key: string]: string },\n    obj2: { [key: string]: string }\n  ) {\n    if (Object.keys(obj1).length !== Object.keys(obj2).length) {\n      return false\n    }\n\n    for (const k in obj1) {\n      if (obj1[k] !== obj2[k]) {\n        return false\n      }\n    }\n\n    return true\n  }\n\n  /** @internal */\n  private _rejoinUntilConnected() {\n    this.rejoinTimer.scheduleTimeout()\n    if (this.socket.isConnected()) {\n      this._rejoin()\n    }\n  }\n\n  /**\n   * Registers a callback that will be executed when the channel closes.\n   *\n   * @internal\n   */\n  private _onClose(callback: Function) {\n    this._on(CHANNEL_EVENTS.close, {}, callback)\n  }\n\n  /**\n   * Registers a callback that will be executed when the channel encounteres an error.\n   *\n   * @internal\n   */\n  private _onError(callback: Function) {\n    this._on(CHANNEL_EVENTS.error, {}, (reason: string) => callback(reason))\n  }\n\n  /**\n   * Returns `true` if the socket is connected and the channel has been joined.\n   *\n   * @internal\n   */\n  private _canPush(): boolean {\n    return this.socket.isConnected() && this._isJoined()\n  }\n\n  /** @internal */\n  private _rejoin(timeout = this.timeout): void {\n    if (this._isLeaving()) {\n      return\n    }\n    this.socket._leaveOpenTopic(this.topic)\n    this.state = CHANNEL_STATES.joining\n    this.joinPush.resend(timeout)\n  }\n\n  /** @internal */\n  private _getPayloadRecords(payload: any) {\n    const records = {\n      new: {},\n      old: {},\n    }\n\n    if (payload.type === 'INSERT' || payload.type === 'UPDATE') {\n      records.new = Transformers.convertChangeData(\n        payload.columns,\n        payload.record\n      )\n    }\n\n    if (payload.type === 'UPDATE' || payload.type === 'DELETE') {\n      records.old = Transformers.convertChangeData(\n        payload.columns,\n        payload.old_record\n      )\n    }\n\n    return records\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA,OAAO,EACL,cAAc,EACd,cAAc,EACd,oBAAoB,GACrB,MAAM,iBAAiB,CAAA;AACxB,OAAO,IAAI,MAAM,YAAY,CAAA;AAE7B,OAAO,KAAK,MAAM,aAAa,CAAA;AAC/B,OAAO,gBAEN,MAAM,oBAAoB,CAAA;AAM3B,OAAO,KAAK,YAAY,MAAM,oBAAoB,CAAA;;;;;;;AA6ElD,IAAY,sCAKX;AALD,CAAA,SAAY,sCAAsC;IAChD,sCAAA,CAAA,MAAA,GAAA,GAAS,CAAA;IACT,sCAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,sCAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,sCAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;AACnB,CAAC,EALW,sCAAsC,IAAA,CAAtC,sCAAsC,GAAA,CAAA,CAAA,GAKjD;AAED,IAAY,qBAKX;AALD,CAAA,SAAY,qBAAqB;IAC/B,qBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB,qBAAA,CAAA,WAAA,GAAA,UAAqB,CAAA;IACrB,qBAAA,CAAA,mBAAA,GAAA,kBAAqC,CAAA;IACrC,qBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;AACnB,CAAC,EALW,qBAAqB,IAAA,CAArB,qBAAqB,GAAA,CAAA,CAAA,GAKhC;AAED,IAAY,yBAKX;AALD,CAAA,SAAY,yBAAyB;IACnC,yBAAA,CAAA,aAAA,GAAA,YAAyB,CAAA;IACzB,yBAAA,CAAA,YAAA,GAAA,WAAuB,CAAA;IACvB,yBAAA,CAAA,SAAA,GAAA,QAAiB,CAAA;IACjB,yBAAA,CAAA,gBAAA,GAAA,eAA+B,CAAA;AACjC,CAAC,EALW,yBAAyB,IAAA,CAAzB,yBAAyB,GAAA,CAAA,CAAA,GAKpC;AAEM,MAAM,uBAAuB,GAAG,4MAAc,CAAA;AAgBvC,MAAO,eAAe;IAoBlC,YACE,kCAAA,EAAoC,CAC7B,KAAa,EACb,SAAiC;QAAE,MAAM,EAAE,CAAA,CAAE;IAAA,CAAE,EAC/C,MAAsB,CAAA;QAFtB,IAAA,CAAA,KAAK,GAAL,KAAK,CAAQ;QACb,IAAA,CAAA,MAAM,GAAN,MAAM,CAAyC;QAC/C,IAAA,CAAA,MAAM,GAAN,MAAM,CAAgB;QAvB/B,IAAA,CAAA,QAAQ,GAOJ,CAAA,CAAE,CAAA;QAEN,IAAA,CAAA,KAAK,GAAmB,4MAAc,CAAC,MAAM,CAAA;QAC7C,IAAA,CAAA,UAAU,GAAG,KAAK,CAAA;QAGlB,IAAA,CAAA,UAAU,GAAW,EAAE,CAAA;QAYrB,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC,OAAO,CAAC,aAAa,EAAE,EAAE,CAAC,CAAA;QAChD,IAAI,CAAC,MAAM,CAAC,MAAM,GAAA,OAAA,MAAA,CACb;YACD,SAAS,EAAE;gBAAE,GAAG,EAAE,KAAK;gBAAE,IAAI,EAAE,KAAK;YAAA,CAAE;YACtC,QAAQ,EAAE;gBAAE,GAAG,EAAE,EAAE;gBAAE,OAAO,EAAE,KAAK;YAAA,CAAE;YACrC,OAAO,EAAE,KAAK;SACf,EACE,MAAM,CAAC,MAAM,CACjB,CAAA;QACD,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,MAAM,CAAC,OAAO,CAAA;QAClC,IAAI,CAAC,QAAQ,GAAG,IAAI,gMAAI,CACtB,IAAI,EACJ,4MAAc,CAAC,IAAI,EACnB,IAAI,CAAC,MAAM,EACX,IAAI,CAAC,OAAO,CACb,CAAA;QACD,IAAI,CAAC,WAAW,GAAG,IAAI,iMAAK,CAC1B,GAAG,CAAG,CAAD,GAAK,CAAC,qBAAqB,EAAE,EAClC,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAC7B,CAAA;QACD,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,IAAI,EAAE,GAAG,EAAE;YAC/B,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,MAAM,CAAA;YAClC,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,CAAA;YACxB,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,SAAe,EAAE,CAAG,CAAD,QAAU,CAAC,IAAI,EAAE,CAAC,CAAA;YAC9D,IAAI,CAAC,UAAU,GAAG,EAAE,CAAA;QACtB,CAAC,CAAC,CAAA;QACF,IAAI,CAAC,QAAQ,CAAC,GAAG,EAAE;YACjB,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,CAAA;YACxB,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,CAAA,MAAA,EAAS,IAAI,CAAC,KAAK,CAAA,CAAA,EAAI,IAAI,CAAC,QAAQ,EAAE,EAAE,CAAC,CAAA;YACpE,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,MAAM,CAAA;YAClC,IAAI,CAAC,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA;QAC3B,CAAC,CAAC,CAAA;QACF,IAAI,CAAC,QAAQ,CAAC,CAAC,MAAc,EAAE,EAAE;YAC/B,IAAI,IAAI,CAAC,UAAU,EAAE,IAAI,IAAI,CAAC,SAAS,EAAE,EAAE,CAAC;gBAC1C,OAAM;YACR,CAAC;YACD,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,CAAA,MAAA,EAAS,IAAI,CAAC,KAAK,EAAE,EAAE,MAAM,CAAC,CAAA;YACzD,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;YACnC,IAAI,CAAC,WAAW,CAAC,eAAe,EAAE,CAAA;QACpC,CAAC,CAAC,CAAA;QACF,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,SAAS,EAAE,GAAG,EAAE;YACpC,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,EAAE,CAAC;gBACvB,OAAM;YACR,CAAC;YACD,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,CAAA,QAAA,EAAW,IAAI,CAAC,KAAK,EAAE,EAAE,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAA;YAC1E,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;YACnC,IAAI,CAAC,WAAW,CAAC,eAAe,EAAE,CAAA;QACpC,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC,MAAW,EAAE,EAAE;YAC7C,IAAI,IAAI,CAAC,UAAU,EAAE,IAAI,IAAI,CAAC,SAAS,EAAE,EAAE,CAAC;gBAC1C,OAAM;YACR,CAAC;YACD,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,CAAA,MAAA,EAAS,IAAI,CAAC,KAAK,EAAE,EAAE,MAAM,CAAC,CAAA;YACzD,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;YACnC,IAAI,CAAC,WAAW,CAAC,eAAe,EAAE,CAAA;QACpC,CAAC,CAAC,CAAA;QACF,IAAI,CAAC,GAAG,CAAC,4MAAc,CAAC,KAAK,EAAE,CAAA,CAAE,EAAE,CAAC,OAAY,EAAE,GAAW,EAAE,EAAE;YAC/D,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,eAAe,CAAC,GAAG,CAAC,EAAE,OAAO,CAAC,CAAA;QACnD,CAAC,CAAC,CAAA;QAEF,IAAI,CAAC,QAAQ,GAAG,IAAI,qMAAgB,CAAC,IAAI,CAAC,CAAA;QAE1C,IAAI,CAAC,oBAAoB,OAAG,gNAAe,EAAC,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,CAAA;QACjE,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,OAAO,IAAI,KAAK,CAAA;IACpD,CAAC;IAED,oDAAA,EAAsD,CACtD,SAAS,CACP,QAAmE,EACnE,OAAO,GAAG,IAAI,CAAC,OAAO,EAAA;;QAEtB,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,WAAW,EAAE,EAAE,CAAC;YAC/B,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE,CAAA;QACvB,CAAC;QACD,IAAI,IAAI,CAAC,KAAK,IAAI,4MAAc,CAAC,MAAM,EAAE,CAAC;YACxC,MAAM,EACJ,MAAM,EAAE,EAAE,SAAS,EAAE,QAAQ,EAAE,OAAO,EAAE,SAAS,EAAE,EACpD,GAAG,IAAI,CAAC,MAAM,CAAA;YAEf,MAAM,gBAAgB,GACpB,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,QAAQ,CAAC,gBAAgB,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,GAAG,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,MAAM,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,EAAE,CAAA;YAE5D,MAAM,gBAAgB,GACpB,AAAC,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,qBAAqB,CAAC,QAAQ,CAAC,IAC9C,IAAI,CAAC,QAAQ,CAAC,qBAAqB,CAAC,QAAQ,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC,GAC3D,CAAA,CAAA,KAAA,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,QAAQ,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,OAAO,MAAK,IAAI,CAAA;YAC/C,MAAM,kBAAkB,GAA8B,CAAA,CAAE,CAAA;YACxD,MAAM,MAAM,GAAG;gBACb,SAAS;gBACT,QAAQ,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,QAAQ,GAAA;oBAAE,OAAO,EAAE,gBAAgB;gBAAA,EAAE;gBACpD,gBAAgB;gBAChB,OAAO,EAAE,SAAS;aACnB,CAAA;YAED,IAAI,IAAI,CAAC,MAAM,CAAC,gBAAgB,EAAE,CAAC;gBACjC,kBAAkB,CAAC,YAAY,GAAG,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAA;YAChE,CAAC;YAED,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAQ,EAAE,CACvB,CADyB,OACjB,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CAAG,yBAAyB,CAAC,aAAa,EAAE,CAAC,CAAC,CACvD,CAAA;YAED,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAG,CAAD,OAAS,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CAAG,yBAAyB,CAAC,MAAM,CAAC,CAAC,CAAA;YAEjE,IAAI,CAAC,iBAAiB,CAAA,OAAA,MAAA,CAAM;gBAAE,MAAM;YAAA,CAAE,EAAK,kBAAkB,EAAG,CAAA;YAEhE,IAAI,CAAC,UAAU,GAAG,IAAI,CAAA;YACtB,IAAI,CAAC,OAAO,CAAC,OAAO,CAAC,CAAA;YAErB,IAAI,CAAC,QAAQ,CACV,OAAO,CAAC,IAAI,EAAE,KAAK,EAAE,EAAE,gBAAgB,EAA0B,EAAE,EAAE;;gBACpE,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE,CAAA;gBACrB,IAAI,gBAAgB,KAAK,SAAS,EAAE,CAAC;oBACnC,QAAQ,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CAAG,yBAAyB,CAAC,UAAU,CAAC,CAAA;oBAChD,OAAM;gBACR,CAAC,MAAM,CAAC;oBACN,MAAM,sBAAsB,GAAG,IAAI,CAAC,QAAQ,CAAC,gBAAgB,CAAA;oBAC7D,MAAM,WAAW,GAAG,CAAA,KAAA,sBAAsB,KAAA,QAAtB,sBAAsB,KAAA,KAAA,IAAA,KAAA,IAAtB,sBAAsB,CAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAC,CAAA;oBACvD,MAAM,mBAAmB,GAAG,EAAE,CAAA;oBAE9B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,EAAE,CAAC,EAAE,CAAE,CAAC;wBACrC,MAAM,qBAAqB,GAAG,sBAAsB,CAAC,CAAC,CAAC,CAAA;wBACvD,MAAM,EACJ,MAAM,EAAE,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,EACzC,GAAG,qBAAqB,CAAA;wBACzB,MAAM,oBAAoB,GACxB,gBAAgB,IAAI,gBAAgB,CAAC,CAAC,CAAC,CAAA;wBAEzC,IACE,oBAAoB,IACpB,oBAAoB,CAAC,KAAK,KAAK,KAAK,IACpC,oBAAoB,CAAC,MAAM,KAAK,MAAM,IACtC,oBAAoB,CAAC,KAAK,KAAK,KAAK,IACpC,oBAAoB,CAAC,MAAM,KAAK,MAAM,EACtC,CAAC;4BACD,mBAAmB,CAAC,IAAI,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACnB,qBAAqB,GAAA;gCACxB,EAAE,EAAE,oBAAoB,CAAC,EAAE;4BAAA,GAC3B,CAAA;wBACJ,CAAC,MAAM,CAAC;4BACN,IAAI,CAAC,WAAW,EAAE,CAAA;4BAClB,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;4BAEnC,QAAQ,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CACN,yBAAyB,CAAC,aAAa,EACvC,IAAI,KAAK,CACP,kEAAkE,CACnE,CACF,CAAA;4BACD,OAAM;wBACR,CAAC;oBACH,CAAC;oBAED,IAAI,CAAC,QAAQ,CAAC,gBAAgB,GAAG,mBAAmB,CAAA;oBAEpD,QAAQ,IAAI,QAAQ,CAAC,yBAAyB,CAAC,UAAU,CAAC,CAAA;oBAC1D,OAAM;gBACR,CAAC;YACH,CAAC,CAAC,CACD,OAAO,CAAC,OAAO,EAAE,CAAC,KAA6B,EAAE,EAAE;gBAClD,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;gBACnC,QAAQ,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CACN,yBAAyB,CAAC,aAAa,EACvC,IAAI,KAAK,CACP,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,OAAO,CAAC,CAC3D,CACF,CAAA;gBACD,OAAM;YACR,CAAC,CAAC,CACD,OAAO,CAAC,SAAS,EAAE,GAAG,EAAE;gBACvB,QAAQ,KAAA,QAAR,QAAQ,KAAA,KAAA,IAAA,KAAA,IAAR,QAAQ,CAAG,yBAAyB,CAAC,SAAS,CAAC,CAAA;gBAC/C,OAAM;YACR,CAAC,CAAC,CAAA;QACN,CAAC;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IAED,aAAa,GAAA;QAGX,OAAO,IAAI,CAAC,QAAQ,CAAC,KAAiC,CAAA;IACxD,CAAC;IAED,KAAK,CAAC,KAAK,CACT,OAA+B,EAC/B,OAA+B,CAAA,CAAE,EAAA;QAEjC,OAAO,MAAM,IAAI,CAAC,IAAI,CACpB;YACE,IAAI,EAAE,UAAU;YAChB,KAAK,EAAE,OAAO;YACd,OAAO;SACR,EACD,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,CAC7B,CAAA;IACH,CAAC;IAED,KAAK,CAAC,OAAO,CACX,OAA+B,CAAA,CAAE,EAAA;QAEjC,OAAO,MAAM,IAAI,CAAC,IAAI,CACpB;YACE,IAAI,EAAE,UAAU;YAChB,KAAK,EAAE,SAAS;SACjB,EACD,IAAI,CACL,CAAA;IACH,CAAC;IAqED,EAAE,CACA,IAAgC,EAChC,MAAgD,EAChD,QAAgC,EAAA;QAEhC,IACE,IAAI,CAAC,KAAK,KAAK,4MAAc,CAAC,MAAM,IACpC,IAAI,KAAK,qBAAqB,CAAC,QAAQ,EACvC,CAAC;YACD,IAAI,CAAC,MAAM,CAAC,GAAG,CACb,SAAS,EACT,CAAA,eAAA,EAAkB,IAAI,CAAC,KAAK,CAAA,sDAAA,CAAwD,CACrF,CAAA;YACD,IAAI,CAAC,WAAW,EAAE,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,SAAS,EAAE,CAAC,CAAA;QACjD,CAAC;QACD,OAAO,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,MAAM,EAAE,QAAQ,CAAC,CAAA;IACzC,CAAC;IACD;;;;;;;;OAQG,CACH,KAAK,CAAC,IAAI,CACR,IAKC,EACD,OAA+B,CAAA,CAAE,EAAA;;QAEjC,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,IAAI,IAAI,CAAC,IAAI,KAAK,WAAW,EAAE,CAAC;YAClD,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,gBAAgB,EAAE,GAAG,IAAI,CAAA;YACjD,MAAM,aAAa,GAAG,IAAI,CAAC,MAAM,CAAC,gBAAgB,GAC9C,CAAA,OAAA,EAAU,IAAI,CAAC,MAAM,CAAC,gBAAgB,EAAE,GACxC,EAAE,CAAA;YACN,MAAM,OAAO,GAAG;gBACd,MAAM,EAAE,MAAM;gBACd,OAAO,EAAE;oBACP,aAAa,EAAE,aAAa;oBAC5B,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE;oBACpD,cAAc,EAAE,kBAAkB;iBACnC;gBACD,IAAI,EAAE,IAAI,CAAC,SAAS,CAAC;oBACnB,QAAQ,EAAE;wBACR;4BACE,KAAK,EAAE,IAAI,CAAC,QAAQ;4BACpB,KAAK;4BACL,OAAO,EAAE,gBAAgB;4BACzB,OAAO,EAAE,IAAI,CAAC,OAAO;yBACtB;qBACF;iBACF,CAAC;aACH,CAAA;YAED,IAAI,CAAC;gBACH,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,iBAAiB,CAC3C,IAAI,CAAC,oBAAoB,EACzB,OAAO,EACP,CAAA,KAAA,IAAI,CAAC,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,IAAI,CAAC,OAAO,CAC7B,CAAA;gBAED,MAAM,CAAA,CAAA,KAAA,QAAQ,CAAC,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,MAAM,EAAE,CAAA,CAAA;gBAC7B,OAAO,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,OAAO,CAAA;YACrC,CAAC,CAAC,OAAO,KAAU,EAAE,CAAC;gBACpB,IAAI,KAAK,CAAC,IAAI,KAAK,YAAY,EAAE,CAAC;oBAChC,OAAO,WAAW,CAAA;gBACpB,CAAC,MAAM,CAAC;oBACN,OAAO,OAAO,CAAA;gBAChB,CAAC;YACH,CAAC;QACH,CAAC,MAAM,CAAC;YACN,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;;gBAC7B,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,CAAC,CAAA;gBAEtE,IAAI,IAAI,CAAC,IAAI,KAAK,WAAW,IAAI,CAAC,CAAA,CAAA,KAAA,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,GAAG,CAAA,EAAE,CAAC;oBACtE,OAAO,CAAC,IAAI,CAAC,CAAA;gBACf,CAAC;gBAED,IAAI,CAAC,OAAO,CAAC,IAAI,EAAE,GAAG,CAAG,CAAD,MAAQ,CAAC,IAAI,CAAC,CAAC,CAAA;gBACvC,IAAI,CAAC,OAAO,CAAC,OAAO,EAAE,GAAG,CAAG,CAAD,MAAQ,CAAC,OAAO,CAAC,CAAC,CAAA;gBAC7C,IAAI,CAAC,OAAO,CAAC,SAAS,EAAE,GAAG,CAAG,CAAD,MAAQ,CAAC,WAAW,CAAC,CAAC,CAAA;YACrD,CAAC,CAAC,CAAA;QACJ,CAAC;IACH,CAAC;IAED,iBAAiB,CAAC,OAA+B,EAAA;QAC/C,IAAI,CAAC,QAAQ,CAAC,aAAa,CAAC,OAAO,CAAC,CAAA;IACtC,CAAC;IAED;;;;;;;;OAQG,CACH,WAAW,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,EAAA;QAChC,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;QACnC,MAAM,OAAO,GAAG,GAAG,EAAE;YACnB,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,SAAS,EAAE,CAAA,MAAA,EAAS,IAAI,CAAC,KAAK,EAAE,CAAC,CAAA;YACjD,IAAI,CAAC,QAAQ,CAAC,4MAAc,CAAC,KAAK,EAAE,OAAO,EAAE,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAA;QAC/D,CAAC,CAAA;QAED,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA;QAEvB,IAAI,SAAS,GAAgB,IAAI,CAAA;QAEjC,OAAO,IAAI,OAAO,CAA8B,CAAC,OAAO,EAAE,EAAE;YAC1D,SAAS,GAAG,IAAI,gMAAI,CAAC,IAAI,EAAE,4MAAc,CAAC,KAAK,EAAE,CAAA,CAAE,EAAE,OAAO,CAAC,CAAA;YAC7D,SAAS,CACN,OAAO,CAAC,IAAI,EAAE,GAAG,EAAE;gBAClB,OAAO,EAAE,CAAA;gBACT,OAAO,CAAC,IAAI,CAAC,CAAA;YACf,CAAC,CAAC,CACD,OAAO,CAAC,SAAS,EAAE,GAAG,EAAE;gBACvB,OAAO,EAAE,CAAA;gBACT,OAAO,CAAC,WAAW,CAAC,CAAA;YACtB,CAAC,CAAC,CACD,OAAO,CAAC,OAAO,EAAE,GAAG,EAAE;gBACrB,OAAO,CAAC,OAAO,CAAC,CAAA;YAClB,CAAC,CAAC,CAAA;YAEJ,SAAS,CAAC,IAAI,EAAE,CAAA;YAChB,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,EAAE,CAAC;gBACrB,SAAS,CAAC,OAAO,CAAC,IAAI,EAAE,CAAA,CAAE,CAAC,CAAA;YAC7B,CAAC;QACH,CAAC,CAAC,CAAC,OAAO,CAAC,GAAG,EAAE;YACd,SAAS,KAAA,QAAT,SAAS,KAAA,KAAA,IAAA,KAAA,IAAT,SAAS,CAAE,OAAO,EAAE,CAAA;QACtB,CAAC,CAAC,CAAA;IACJ,CAAC;IACD;;;;OAIG,CACH,QAAQ,GAAA;QACN,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,IAAU,EAAE,CAAG,CAAD,GAAK,CAAC,OAAO,EAAE,CAAC,CAAA;QACvD,IAAI,CAAC,UAAU,GAAG,EAAE,CAAA;QACpB,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE,CAAA;QACxB,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA;QACvB,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,MAAM,CAAA;QAClC,IAAI,CAAC,QAAQ,GAAG,CAAA,CAAE,CAAA;IACpB,CAAC;IAED,cAAA,EAAgB,CAEhB,KAAK,CAAC,iBAAiB,CACrB,GAAW,EACX,OAA+B,EAC/B,OAAe,EAAA;QAEf,MAAM,UAAU,GAAG,IAAI,eAAe,EAAE,CAAA;QACxC,MAAM,EAAE,GAAG,UAAU,CAAC,GAAG,CAAG,CAAD,SAAW,CAAC,KAAK,EAAE,EAAE,OAAO,CAAC,CAAA;QAExD,MAAM,QAAQ,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,GAAG,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACvC,OAAO,GAAA;YACV,MAAM,EAAE,UAAU,CAAC,MAAM;QAAA,GACzB,CAAA;QAEF,YAAY,CAAC,EAAE,CAAC,CAAA;QAEhB,OAAO,QAAQ,CAAA;IACjB,CAAC;IAED,cAAA,EAAgB,CAChB,KAAK,CACH,KAAa,EACb,OAA+B,EAC/B,OAAO,GAAG,IAAI,CAAC,OAAO,EAAA;QAEtB,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,CAAC;YACrB,MAAM,CAAA,eAAA,EAAkB,KAAK,CAAA,MAAA,EAAS,IAAI,CAAC,KAAK,CAAA,+DAAA,CAAiE,CAAA;QACnH,CAAC;QACD,IAAI,SAAS,GAAG,IAAI,gMAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,OAAO,CAAC,CAAA;QACvD,IAAI,IAAI,CAAC,QAAQ,EAAE,EAAE,CAAC;YACpB,SAAS,CAAC,IAAI,EAAE,CAAA;QAClB,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,gBAAgB,CAAC,SAAS,CAAC,CAAA;QAClC,CAAC;QAED,OAAO,SAAS,CAAA;IAClB,CAAC;IAED,cAAA,EAAgB,CAChB,gBAAgB,CAAC,SAAe,EAAA;QAC9B,SAAS,CAAC,YAAY,EAAE,CAAA;QACxB,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,SAAS,CAAC,CAAA;QAE/B,4BAA4B;QAC5B,IAAI,IAAI,CAAC,UAAU,CAAC,MAAM,GAAG,kNAAoB,EAAE,CAAC;YAClD,MAAM,WAAW,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,EAAE,CAAA;YAC3C,IAAI,WAAW,EAAE,CAAC;gBAChB,WAAW,CAAC,OAAO,EAAE,CAAA;gBACrB,IAAI,CAAC,MAAM,CAAC,GAAG,CACb,SAAS,EACT,CAAA,uCAAA,EAA0C,WAAW,CAAC,KAAK,EAAE,EAC7D,WAAW,CAAC,OAAO,CACpB,CAAA;YACH,CAAC;QACH,CAAC;IACH,CAAC;IAED;;;;;;;OAOG,CACH,UAAU,CAAC,MAAc,EAAE,OAAY,EAAE,IAAa,EAAA;QACpD,OAAO,OAAO,CAAA;IAChB,CAAC;IAED,cAAA,EAAgB,CAChB,SAAS,CAAC,KAAa,EAAA;QACrB,OAAO,IAAI,CAAC,KAAK,KAAK,KAAK,CAAA;IAC7B,CAAC;IAED,cAAA,EAAgB,CAChB,QAAQ,GAAA;QACN,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAA;IAC1B,CAAC;IAED,cAAA,EAAgB,CAChB,QAAQ,CAAC,IAAY,EAAE,OAAa,EAAE,GAAY,EAAA;;QAChD,MAAM,SAAS,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAA;QAC1C,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,GAAG,4MAAc,CAAA;QACpD,MAAM,MAAM,GAAa;YAAC,KAAK;YAAE,KAAK;YAAE,KAAK;YAAE,IAAI;SAAC,CAAA;QACpD,IAAI,GAAG,IAAI,MAAM,CAAC,OAAO,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,GAAG,KAAK,IAAI,CAAC,QAAQ,EAAE,EAAE,CAAC;YACrE,OAAM;QACR,CAAC;QACD,IAAI,cAAc,GAAG,IAAI,CAAC,UAAU,CAAC,SAAS,EAAE,OAAO,EAAE,GAAG,CAAC,CAAA;QAC7D,IAAI,OAAO,IAAI,CAAC,cAAc,EAAE,CAAC;YAC/B,MAAM,6EAA6E,CAAA;QACrF,CAAC;QAED,IAAI;YAAC,QAAQ;YAAE,QAAQ;YAAE,QAAQ;SAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;YACvD,CAAA,KAAA,IAAI,CAAC,QAAQ,CAAC,gBAAgB,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAC1B,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE;;gBAChB,OACE,AADK,CACL,CAAA,KAAA,IAAI,CAAC,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,MAAK,GAAG,IAC1B,CAAA,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,iBAAiB,EAAE,MAAK,SAAS,CACtD,CAAA;YACH,CAAC,EACA,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,GAAK,CAAC,QAAQ,CAAC,cAAc,EAAE,GAAG,CAAC,CAAC,CAAA;QACtD,CAAC,MAAM,CAAC;YACN,CAAA,KAAA,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GACpB,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE;;gBAChB,IACE;oBAAC,WAAW;oBAAE,UAAU;oBAAE,kBAAkB;iBAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,EACjE,CAAC;oBACD,IAAI,IAAI,IAAI,IAAI,EAAE,CAAC;wBACjB,MAAM,MAAM,GAAG,IAAI,CAAC,EAAE,CAAA;wBACtB,MAAM,SAAS,GAAG,CAAA,KAAA,IAAI,CAAC,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,CAAA;wBACpC,OAAO,AACL,MAAM,KACN,CAAA,KAAA,OAAO,CAAC,GAAG,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,QAAQ,CAAC,MAAM,CAAC,CAAA,IAC7B,CAAC,SAAS,KAAK,GAAG,IAChB,CAAA,SAAS,KAAA,QAAT,SAAS,KAAA,KAAA,IAAA,KAAA,IAAT,SAAS,CAAE,iBAAiB,EAAE,OAC5B,CAAA,KAAA,OAAO,CAAC,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,IAAI,CAAC,iBAAiB,EAAE,CAAA,CAAC,CAC5C,CAAA;oBACH,CAAC,MAAM,CAAC;wBACN,MAAM,SAAS,GAAG,CAAA,KAAA,CAAA,KAAA,IAAI,KAAA,QAAJ,IAAI,KAAA,KAAA,IAAA,KAAA,IAAJ,IAAI,CAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,iBAAiB,EAAE,CAAA;wBAC1D,OAAO,AACL,SAAS,KAAK,GAAG,IACjB,SAAS,KAAA,CAAK,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,KAAK,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,iBAAiB,EAAE,CAAA,CAClD,CAAA;oBACH,CAAC;gBACH,CAAC,MAAM,CAAC;oBACN,OAAO,IAAI,CAAC,IAAI,CAAC,iBAAiB,EAAE,KAAK,SAAS,CAAA;gBACpD,CAAC;YACH,CAAC,EACA,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE;gBACZ,IAAI,OAAO,cAAc,KAAK,QAAQ,IAAI,KAAK,IAAI,cAAc,EAAE,CAAC;oBAClE,MAAM,eAAe,GAAG,cAAc,CAAC,IAAI,CAAA;oBAC3C,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,gBAAgB,EAAE,IAAI,EAAE,MAAM,EAAE,GACrD,eAAe,CAAA;oBACjB,MAAM,eAAe,GAAG;wBACtB,MAAM,EAAE,MAAM;wBACd,KAAK,EAAE,KAAK;wBACZ,gBAAgB,EAAE,gBAAgB;wBAClC,SAAS,EAAE,IAAI;wBACf,GAAG,EAAE,CAAA,CAAE;wBACP,GAAG,EAAE,CAAA,CAAE;wBACP,MAAM,EAAE,MAAM;qBACf,CAAA;oBACD,cAAc,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACT,eAAe,GACf,IAAI,CAAC,kBAAkB,CAAC,eAAe,CAAC,CAC5C,CAAA;gBACH,CAAC;gBACD,IAAI,CAAC,QAAQ,CAAC,cAAc,EAAE,GAAG,CAAC,CAAA;YACpC,CAAC,CAAC,CAAA;QACN,CAAC;IACH,CAAC;IAED,cAAA,EAAgB,CAChB,SAAS,GAAA;QACP,OAAO,IAAI,CAAC,KAAK,KAAK,4MAAc,CAAC,MAAM,CAAA;IAC7C,CAAC;IAED,cAAA,EAAgB,CAChB,SAAS,GAAA;QACP,OAAO,IAAI,CAAC,KAAK,KAAK,4MAAc,CAAC,MAAM,CAAA;IAC7C,CAAC;IAED,cAAA,EAAgB,CAChB,UAAU,GAAA;QACR,OAAO,IAAI,CAAC,KAAK,KAAK,4MAAc,CAAC,OAAO,CAAA;IAC9C,CAAC;IAED,cAAA,EAAgB,CAChB,UAAU,GAAA;QACR,OAAO,IAAI,CAAC,KAAK,KAAK,4MAAc,CAAC,OAAO,CAAA;IAC9C,CAAC;IAED,cAAA,EAAgB,CAChB,eAAe,CAAC,GAAW,EAAA;QACzB,OAAO,CAAA,WAAA,EAAc,GAAG,EAAE,CAAA;IAC5B,CAAC;IAED,cAAA,EAAgB,CAChB,GAAG,CAAC,IAAY,EAAE,MAA8B,EAAE,QAAkB,EAAA;QAClE,MAAM,SAAS,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAA;QAC1C,MAAM,OAAO,GAAG;YACd,IAAI,EAAE,SAAS;YACf,MAAM,EAAE,MAAM;YACd,QAAQ,EAAE,QAAQ;SACnB,CAAA;QAED,IAAI,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;YAC7B,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC,CAAA;QACxC,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,GAAG;gBAAC,OAAO;aAAC,CAAA;QACtC,CAAC;QAED,OAAO,IAAI,CAAA;IACb,CAAC;IAED,cAAA,EAAgB,CAChB,IAAI,CAAC,IAAY,EAAE,MAA8B,EAAA;QAC/C,MAAM,SAAS,GAAG,IAAI,CAAC,iBAAiB,EAAE,CAAA;QAE1C,IAAI,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;YAC7B,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,EAAE;;gBAClE,OAAO,CAAC,CACN,CAAA,CAAA,KAAA,IAAI,CAAC,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,iBAAiB,EAAE,MAAK,SAAS,IAC5C,eAAe,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,EAAE,MAAM,CAAC,CAC7C,CAAA;YACH,CAAC,CAAC,CAAA;QACJ,CAAC;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IAED,cAAA,EAAgB,CACR,MAAM,CAAC,OAAO,CACpB,IAA+B,EAC/B,IAA+B,EAAA;QAE/B,IAAI,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,MAAM,KAAK,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,MAAM,EAAE,CAAC;YAC1D,OAAO,KAAK,CAAA;QACd,CAAC;QAED,IAAK,MAAM,CAAC,IAAI,IAAI,CAAE,CAAC;YACrB,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC;gBACxB,OAAO,KAAK,CAAA;YACd,CAAC;QACH,CAAC;QAED,OAAO,IAAI,CAAA;IACb,CAAC;IAED,cAAA,EAAgB,CACR,qBAAqB,GAAA;QAC3B,IAAI,CAAC,WAAW,CAAC,eAAe,EAAE,CAAA;QAClC,IAAI,IAAI,CAAC,MAAM,CAAC,WAAW,EAAE,EAAE,CAAC;YAC9B,IAAI,CAAC,OAAO,EAAE,CAAA;QAChB,CAAC;IACH,CAAC;IAED;;;;OAIG,CACK,QAAQ,CAAC,QAAkB,EAAA;QACjC,IAAI,CAAC,GAAG,CAAC,4MAAc,CAAC,KAAK,EAAE,CAAA,CAAE,EAAE,QAAQ,CAAC,CAAA;IAC9C,CAAC;IAED;;;;OAIG,CACK,QAAQ,CAAC,QAAkB,EAAA;QACjC,IAAI,CAAC,GAAG,CAAC,4MAAc,CAAC,KAAK,EAAE,CAAA,CAAE,EAAE,CAAC,MAAc,EAAE,CAAG,CAAD,OAAS,CAAC,MAAM,CAAC,CAAC,CAAA;IAC1E,CAAC;IAED;;;;OAIG,CACK,QAAQ,GAAA;QACd,OAAO,IAAI,CAAC,MAAM,CAAC,WAAW,EAAE,IAAI,IAAI,CAAC,SAAS,EAAE,CAAA;IACtD,CAAC;IAED,cAAA,EAAgB,CACR,OAAO,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,EAAA;QACpC,IAAI,IAAI,CAAC,UAAU,EAAE,EAAE,CAAC;YACtB,OAAM;QACR,CAAC;QACD,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC,IAAI,CAAC,KAAK,CAAC,CAAA;QACvC,IAAI,CAAC,KAAK,GAAG,4MAAc,CAAC,OAAO,CAAA;QACnC,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,OAAO,CAAC,CAAA;IAC/B,CAAC;IAED,cAAA,EAAgB,CACR,kBAAkB,CAAC,OAAY,EAAA;QACrC,MAAM,OAAO,GAAG;YACd,GAAG,EAAE,CAAA,CAAE;YACP,GAAG,EAAE,CAAA,CAAE;SACR,CAAA;QAED,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE,CAAC;YAC3D,OAAO,CAAC,GAAG,GAAG,YAAY,CAAC,qMAAiB,CAC1C,OAAO,CAAC,OAAO,EACf,OAAO,CAAC,MAAM,CACf,CAAA;QACH,CAAC;QAED,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE,CAAC;YAC3D,OAAO,CAAC,GAAG,GAAG,YAAY,CAAC,qMAAiB,CAC1C,OAAO,CAAC,OAAO,EACf,OAAO,CAAC,UAAU,CACnB,CAAA;QACH,CAAC;QAED,OAAO,OAAO,CAAA;IAChB,CAAC;CACF"}},
    {"offset": {"line": 2822, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/RealtimeClient.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/RealtimeClient.ts"],"sourcesContent":["import WebSocketFactory, { WebSocketLike } from './lib/websocket-factory'\n\nimport {\n  CHANNEL_EVENTS,\n  CONNECTION_STATE,\n  DEFAULT_VERSION,\n  DEFAULT_TIMEOUT,\n  SOCKET_STATES,\n  TRANSPORTS,\n  VSN,\n  WS_CLOSE_NORMAL,\n} from './lib/constants'\n\nimport Serializer from './lib/serializer'\nimport Timer from './lib/timer'\n\nimport { httpEndpointURL } from './lib/transformers'\nimport RealtimeChannel from './RealtimeChannel'\nimport type { RealtimeChannelOptions } from './RealtimeChannel'\n\ntype Fetch = typeof fetch\n\nexport type Channel = {\n  name: string\n  inserted_at: string\n  updated_at: string\n  id: number\n}\nexport type LogLevel = 'info' | 'warn' | 'error'\n\nexport type RealtimeMessage = {\n  topic: string\n  event: string\n  payload: any\n  ref: string\n  join_ref?: string\n}\n\nexport type RealtimeRemoveChannelResponse = 'ok' | 'timed out' | 'error'\nexport type HeartbeatStatus =\n  | 'sent'\n  | 'ok'\n  | 'error'\n  | 'timeout'\n  | 'disconnected'\n\nconst noop = () => {}\n\ntype RealtimeClientState =\n  | 'connecting'\n  | 'connected'\n  | 'disconnecting'\n  | 'disconnected'\n\n// Connection-related constants\nconst CONNECTION_TIMEOUTS = {\n  HEARTBEAT_INTERVAL: 25000,\n  RECONNECT_DELAY: 10,\n  HEARTBEAT_TIMEOUT_FALLBACK: 100,\n} as const\n\nconst RECONNECT_INTERVALS = [1000, 2000, 5000, 10000] as const\nconst DEFAULT_RECONNECT_FALLBACK = 10000\n\nexport interface WebSocketLikeConstructor {\n  new (\n    address: string | URL,\n    subprotocols?: string | string[] | undefined\n  ): WebSocketLike\n  // Allow additional properties that may exist on WebSocket constructors\n  [key: string]: any\n}\n\nexport interface WebSocketLikeError {\n  error: any\n  message: string\n  type: string\n}\n\nexport type RealtimeClientOptions = {\n  transport?: WebSocketLikeConstructor\n  timeout?: number\n  heartbeatIntervalMs?: number\n  heartbeatCallback?: (status: HeartbeatStatus) => void\n  logger?: Function\n  encode?: Function\n  decode?: Function\n  reconnectAfterMs?: Function\n  headers?: { [key: string]: string }\n  params?: { [key: string]: any }\n  //Deprecated: Use it in favour of correct casing `logLevel`\n  log_level?: LogLevel\n  logLevel?: LogLevel\n  fetch?: Fetch\n  worker?: boolean\n  workerUrl?: string\n  accessToken?: () => Promise<string | null>\n}\n\nconst WORKER_SCRIPT = `\n  addEventListener(\"message\", (e) => {\n    if (e.data.event === \"start\") {\n      setInterval(() => postMessage({ event: \"keepAlive\" }), e.data.interval);\n    }\n  });`\n\nexport default class RealtimeClient {\n  accessTokenValue: string | null = null\n  apiKey: string | null = null\n  channels: RealtimeChannel[] = new Array()\n  endPoint: string = ''\n  httpEndpoint: string = ''\n  /** @deprecated headers cannot be set on websocket connections */\n  headers?: { [key: string]: string } = {}\n  params?: { [key: string]: string } = {}\n  timeout: number = DEFAULT_TIMEOUT\n  transport: WebSocketLikeConstructor | null = null\n  heartbeatIntervalMs: number = CONNECTION_TIMEOUTS.HEARTBEAT_INTERVAL\n  heartbeatTimer: ReturnType<typeof setInterval> | undefined = undefined\n  pendingHeartbeatRef: string | null = null\n  heartbeatCallback: (status: HeartbeatStatus) => void = noop\n  ref: number = 0\n  reconnectTimer: Timer | null = null\n  logger: Function = noop\n  logLevel?: LogLevel\n  encode!: Function\n  decode!: Function\n  reconnectAfterMs!: Function\n  conn: WebSocketLike | null = null\n  sendBuffer: Function[] = []\n  serializer: Serializer = new Serializer()\n  stateChangeCallbacks: {\n    open: Function[]\n    close: Function[]\n    error: Function[]\n    message: Function[]\n  } = {\n    open: [],\n    close: [],\n    error: [],\n    message: [],\n  }\n  fetch: Fetch\n  accessToken: (() => Promise<string | null>) | null = null\n  worker?: boolean\n  workerUrl?: string\n  workerRef?: Worker\n  private _connectionState: RealtimeClientState = 'disconnected'\n  private _wasManualDisconnect: boolean = false\n  private _authPromise: Promise<void> | null = null\n\n  /**\n   * Initializes the Socket.\n   *\n   * @param endPoint The string WebSocket endpoint, ie, \"ws://example.com/socket\", \"wss://example.com\", \"/socket\" (inherited host & protocol)\n   * @param httpEndpoint The string HTTP endpoint, ie, \"https://example.com\", \"/\" (inherited host & protocol)\n   * @param options.transport The Websocket Transport, for example WebSocket. This can be a custom implementation\n   * @param options.timeout The default timeout in milliseconds to trigger push timeouts.\n   * @param options.params The optional params to pass when connecting.\n   * @param options.headers Deprecated: headers cannot be set on websocket connections and this option will be removed in the future.\n   * @param options.heartbeatIntervalMs The millisec interval to send a heartbeat message.\n   * @param options.heartbeatCallback The optional function to handle heartbeat status.\n   * @param options.logger The optional function for specialized logging, ie: logger: (kind, msg, data) => { console.log(`${kind}: ${msg}`, data) }\n   * @param options.logLevel Sets the log level for Realtime\n   * @param options.encode The function to encode outgoing messages. Defaults to JSON: (payload, callback) => callback(JSON.stringify(payload))\n   * @param options.decode The function to decode incoming messages. Defaults to Serializer's decode.\n   * @param options.reconnectAfterMs he optional function that returns the millsec reconnect interval. Defaults to stepped backoff off.\n   * @param options.worker Use Web Worker to set a side flow. Defaults to false.\n   * @param options.workerUrl The URL of the worker script. Defaults to https://realtime.supabase.com/worker.js that includes a heartbeat event call to keep the connection alive.\n   */\n  constructor(endPoint: string, options?: RealtimeClientOptions) {\n    // Validate required parameters\n    if (!options?.params?.apikey) {\n      throw new Error('API key is required to connect to Realtime')\n    }\n    this.apiKey = options.params.apikey\n\n    // Initialize endpoint URLs\n    this.endPoint = `${endPoint}/${TRANSPORTS.websocket}`\n    this.httpEndpoint = httpEndpointURL(endPoint)\n\n    this._initializeOptions(options)\n    this._setupReconnectionTimer()\n    this.fetch = this._resolveFetch(options?.fetch)\n  }\n\n  /**\n   * Connects the socket, unless already connected.\n   */\n  connect(): void {\n    // Skip if already connecting, disconnecting, or connected\n    if (\n      this.isConnecting() ||\n      this.isDisconnecting() ||\n      (this.conn !== null && this.isConnected())\n    ) {\n      return\n    }\n\n    this._setConnectionState('connecting')\n    this._setAuthSafely('connect')\n\n    // Establish WebSocket connection\n    if (this.transport) {\n      // Use custom transport if provided\n      this.conn = new this.transport(this.endpointURL()) as WebSocketLike\n    } else {\n      // Try to use native WebSocket\n      try {\n        this.conn = WebSocketFactory.createWebSocket(this.endpointURL())\n      } catch (error) {\n        this._setConnectionState('disconnected')\n        const errorMessage = (error as Error).message\n\n        // Provide helpful error message based on environment\n        if (errorMessage.includes('Node.js')) {\n          throw new Error(\n            `${errorMessage}\\n\\n` +\n              'To use Realtime in Node.js, you need to provide a WebSocket implementation:\\n\\n' +\n              'Option 1: Use Node.js 22+ which has native WebSocket support\\n' +\n              'Option 2: Install and provide the \"ws\" package:\\n\\n' +\n              '  npm install ws\\n\\n' +\n              '  import ws from \"ws\"\\n' +\n              '  const client = new RealtimeClient(url, {\\n' +\n              '    ...options,\\n' +\n              '    transport: ws\\n' +\n              '  })'\n          )\n        }\n        throw new Error(`WebSocket not available: ${errorMessage}`)\n      }\n    }\n    this._setupConnectionHandlers()\n  }\n\n  /**\n   * Returns the URL of the websocket.\n   * @returns string The URL of the websocket.\n   */\n  endpointURL(): string {\n    return this._appendParams(\n      this.endPoint,\n      Object.assign({}, this.params, { vsn: VSN })\n    )\n  }\n\n  /**\n   * Disconnects the socket.\n   *\n   * @param code A numeric status code to send on disconnect.\n   * @param reason A custom reason for the disconnect.\n   */\n  disconnect(code?: number, reason?: string): void {\n    if (this.isDisconnecting()) {\n      return\n    }\n\n    this._setConnectionState('disconnecting', true)\n\n    if (this.conn) {\n      // Setup fallback timer to prevent hanging in disconnecting state\n      const fallbackTimer = setTimeout(() => {\n        this._setConnectionState('disconnected')\n      }, 100)\n\n      this.conn.onclose = () => {\n        clearTimeout(fallbackTimer)\n        this._setConnectionState('disconnected')\n      }\n\n      // Close the WebSocket connection\n      if (code) {\n        this.conn.close(code, reason ?? '')\n      } else {\n        this.conn.close()\n      }\n\n      this._teardownConnection()\n    } else {\n      this._setConnectionState('disconnected')\n    }\n  }\n\n  /**\n   * Returns all created channels\n   */\n  getChannels(): RealtimeChannel[] {\n    return this.channels\n  }\n\n  /**\n   * Unsubscribes and removes a single channel\n   * @param channel A RealtimeChannel instance\n   */\n  async removeChannel(\n    channel: RealtimeChannel\n  ): Promise<RealtimeRemoveChannelResponse> {\n    const status = await channel.unsubscribe()\n\n    if (this.channels.length === 0) {\n      this.disconnect()\n    }\n\n    return status\n  }\n\n  /**\n   * Unsubscribes and removes all channels\n   */\n  async removeAllChannels(): Promise<RealtimeRemoveChannelResponse[]> {\n    const values_1 = await Promise.all(\n      this.channels.map((channel) => channel.unsubscribe())\n    )\n    this.channels = []\n    this.disconnect()\n    return values_1\n  }\n\n  /**\n   * Logs the message.\n   *\n   * For customized logging, `this.logger` can be overridden.\n   */\n  log(kind: string, msg: string, data?: any) {\n    this.logger(kind, msg, data)\n  }\n\n  /**\n   * Returns the current state of the socket.\n   */\n  connectionState(): CONNECTION_STATE {\n    switch (this.conn && this.conn.readyState) {\n      case SOCKET_STATES.connecting:\n        return CONNECTION_STATE.Connecting\n      case SOCKET_STATES.open:\n        return CONNECTION_STATE.Open\n      case SOCKET_STATES.closing:\n        return CONNECTION_STATE.Closing\n      default:\n        return CONNECTION_STATE.Closed\n    }\n  }\n\n  /**\n   * Returns `true` is the connection is open.\n   */\n  isConnected(): boolean {\n    return this.connectionState() === CONNECTION_STATE.Open\n  }\n\n  /**\n   * Returns `true` if the connection is currently connecting.\n   */\n  isConnecting(): boolean {\n    return this._connectionState === 'connecting'\n  }\n\n  /**\n   * Returns `true` if the connection is currently disconnecting.\n   */\n  isDisconnecting(): boolean {\n    return this._connectionState === 'disconnecting'\n  }\n\n  channel(\n    topic: string,\n    params: RealtimeChannelOptions = { config: {} }\n  ): RealtimeChannel {\n    const realtimeTopic = `realtime:${topic}`\n    const exists = this.getChannels().find(\n      (c: RealtimeChannel) => c.topic === realtimeTopic\n    )\n\n    if (!exists) {\n      const chan = new RealtimeChannel(`realtime:${topic}`, params, this)\n      this.channels.push(chan)\n\n      return chan\n    } else {\n      return exists\n    }\n  }\n\n  /**\n   * Push out a message if the socket is connected.\n   *\n   * If the socket is not connected, the message gets enqueued within a local buffer, and sent out when a connection is next established.\n   */\n  push(data: RealtimeMessage): void {\n    const { topic, event, payload, ref } = data\n    const callback = () => {\n      this.encode(data, (result: any) => {\n        this.conn?.send(result)\n      })\n    }\n    this.log('push', `${topic} ${event} (${ref})`, payload)\n    if (this.isConnected()) {\n      callback()\n    } else {\n      this.sendBuffer.push(callback)\n    }\n  }\n\n  /**\n   * Sets the JWT access token used for channel subscription authorization and Realtime RLS.\n   *\n   * If param is null it will use the `accessToken` callback function or the token set on the client.\n   *\n   * On callback used, it will set the value of the token internal to the client.\n   *\n   * @param token A JWT string to override the token set on the client.\n   */\n  async setAuth(token: string | null = null): Promise<void> {\n    this._authPromise = this._performAuth(token)\n    try {\n      await this._authPromise\n    } finally {\n      this._authPromise = null\n    }\n  }\n  /**\n   * Sends a heartbeat message if the socket is connected.\n   */\n  async sendHeartbeat() {\n    if (!this.isConnected()) {\n      try {\n        this.heartbeatCallback('disconnected')\n      } catch (e) {\n        this.log('error', 'error in heartbeat callback', e)\n      }\n      return\n    }\n\n    // Handle heartbeat timeout and force reconnection if needed\n    if (this.pendingHeartbeatRef) {\n      this.pendingHeartbeatRef = null\n      this.log(\n        'transport',\n        'heartbeat timeout. Attempting to re-establish connection'\n      )\n      try {\n        this.heartbeatCallback('timeout')\n      } catch (e) {\n        this.log('error', 'error in heartbeat callback', e)\n      }\n\n      // Force reconnection after heartbeat timeout\n      this._wasManualDisconnect = false\n      this.conn?.close(WS_CLOSE_NORMAL, 'heartbeat timeout')\n\n      setTimeout(() => {\n        if (!this.isConnected()) {\n          this.reconnectTimer?.scheduleTimeout()\n        }\n      }, CONNECTION_TIMEOUTS.HEARTBEAT_TIMEOUT_FALLBACK)\n      return\n    }\n\n    // Send heartbeat message to server\n    this.pendingHeartbeatRef = this._makeRef()\n    this.push({\n      topic: 'phoenix',\n      event: 'heartbeat',\n      payload: {},\n      ref: this.pendingHeartbeatRef,\n    })\n    try {\n      this.heartbeatCallback('sent')\n    } catch (e) {\n      this.log('error', 'error in heartbeat callback', e)\n    }\n\n    this._setAuthSafely('heartbeat')\n  }\n\n  onHeartbeat(callback: (status: HeartbeatStatus) => void): void {\n    this.heartbeatCallback = callback\n  }\n  /**\n   * Flushes send buffer\n   */\n  flushSendBuffer() {\n    if (this.isConnected() && this.sendBuffer.length > 0) {\n      this.sendBuffer.forEach((callback) => callback())\n      this.sendBuffer = []\n    }\n  }\n\n  /**\n   * Use either custom fetch, if provided, or default fetch to make HTTP requests\n   *\n   * @internal\n   */\n  _resolveFetch = (customFetch?: Fetch): Fetch => {\n    let _fetch: Fetch\n    if (customFetch) {\n      _fetch = customFetch\n    } else if (typeof fetch === 'undefined') {\n      // Node.js environment without native fetch\n      _fetch = (...args) =>\n        import('@supabase/node-fetch' as any)\n          .then(({ default: fetch }) => fetch(...args))\n          .catch((error) => {\n            throw new Error(\n              `Failed to load @supabase/node-fetch: ${error.message}. ` +\n                `This is required for HTTP requests in Node.js environments without native fetch.`\n            )\n          })\n    } else {\n      _fetch = fetch\n    }\n    return (...args) => _fetch(...args)\n  }\n\n  /**\n   * Return the next message ref, accounting for overflows\n   *\n   * @internal\n   */\n  _makeRef(): string {\n    let newRef = this.ref + 1\n    if (newRef === this.ref) {\n      this.ref = 0\n    } else {\n      this.ref = newRef\n    }\n\n    return this.ref.toString()\n  }\n\n  /**\n   * Unsubscribe from channels with the specified topic.\n   *\n   * @internal\n   */\n  _leaveOpenTopic(topic: string): void {\n    let dupChannel = this.channels.find(\n      (c) => c.topic === topic && (c._isJoined() || c._isJoining())\n    )\n    if (dupChannel) {\n      this.log('transport', `leaving duplicate topic \"${topic}\"`)\n      dupChannel.unsubscribe()\n    }\n  }\n\n  /**\n   * Removes a subscription from the socket.\n   *\n   * @param channel An open subscription.\n   *\n   * @internal\n   */\n  _remove(channel: RealtimeChannel) {\n    this.channels = this.channels.filter((c) => c.topic !== channel.topic)\n  }\n\n  /** @internal */\n  private _onConnMessage(rawMessage: { data: any }) {\n    this.decode(rawMessage.data, (msg: RealtimeMessage) => {\n      // Handle heartbeat responses\n      if (msg.topic === 'phoenix' && msg.event === 'phx_reply') {\n        try {\n          this.heartbeatCallback(msg.payload.status === 'ok' ? 'ok' : 'error')\n        } catch (e) {\n          this.log('error', 'error in heartbeat callback', e)\n        }\n      }\n\n      // Handle pending heartbeat reference cleanup\n      if (msg.ref && msg.ref === this.pendingHeartbeatRef) {\n        this.pendingHeartbeatRef = null\n      }\n\n      // Log incoming message\n      const { topic, event, payload, ref } = msg\n      const refString = ref ? `(${ref})` : ''\n      const status = payload.status || ''\n      this.log(\n        'receive',\n        `${status} ${topic} ${event} ${refString}`.trim(),\n        payload\n      )\n\n      // Route message to appropriate channels\n      this.channels\n        .filter((channel: RealtimeChannel) => channel._isMember(topic))\n        .forEach((channel: RealtimeChannel) =>\n          channel._trigger(event, payload, ref)\n        )\n\n      this._triggerStateCallbacks('message', msg)\n    })\n  }\n\n  /**\n   * Clear specific timer\n   * @internal\n   */\n  private _clearTimer(timer: 'heartbeat' | 'reconnect'): void {\n    if (timer === 'heartbeat' && this.heartbeatTimer) {\n      clearInterval(this.heartbeatTimer)\n      this.heartbeatTimer = undefined\n    } else if (timer === 'reconnect') {\n      this.reconnectTimer?.reset()\n    }\n  }\n\n  /**\n   * Clear all timers\n   * @internal\n   */\n  private _clearAllTimers(): void {\n    this._clearTimer('heartbeat')\n    this._clearTimer('reconnect')\n  }\n\n  /**\n   * Setup connection handlers for WebSocket events\n   * @internal\n   */\n  private _setupConnectionHandlers(): void {\n    if (!this.conn) return\n\n    // Set binary type if supported (browsers and most WebSocket implementations)\n    if ('binaryType' in this.conn) {\n      ;(this.conn as any).binaryType = 'arraybuffer'\n    }\n\n    this.conn.onopen = () => this._onConnOpen()\n    this.conn.onerror = (error: Event) => this._onConnError(error)\n    this.conn.onmessage = (event: any) => this._onConnMessage(event)\n    this.conn.onclose = (event: any) => this._onConnClose(event)\n  }\n\n  /**\n   * Teardown connection and cleanup resources\n   * @internal\n   */\n  private _teardownConnection(): void {\n    if (this.conn) {\n      this.conn.onopen = null\n      this.conn.onerror = null\n      this.conn.onmessage = null\n      this.conn.onclose = null\n      this.conn = null\n    }\n    this._clearAllTimers()\n    this.channels.forEach((channel) => channel.teardown())\n  }\n\n  /** @internal */\n  private _onConnOpen() {\n    this._setConnectionState('connected')\n    this.log('transport', `connected to ${this.endpointURL()}`)\n    this.flushSendBuffer()\n    this._clearTimer('reconnect')\n\n    if (!this.worker) {\n      this._startHeartbeat()\n    } else {\n      if (!this.workerRef) {\n        this._startWorkerHeartbeat()\n      }\n    }\n\n    this._triggerStateCallbacks('open')\n  }\n  /** @internal */\n  private _startHeartbeat() {\n    this.heartbeatTimer && clearInterval(this.heartbeatTimer)\n    this.heartbeatTimer = setInterval(\n      () => this.sendHeartbeat(),\n      this.heartbeatIntervalMs\n    )\n  }\n\n  /** @internal */\n  private _startWorkerHeartbeat() {\n    if (this.workerUrl) {\n      this.log('worker', `starting worker for from ${this.workerUrl}`)\n    } else {\n      this.log('worker', `starting default worker`)\n    }\n    const objectUrl = this._workerObjectUrl(this.workerUrl!)\n    this.workerRef = new Worker(objectUrl)\n    this.workerRef.onerror = (error) => {\n      this.log('worker', 'worker error', (error as ErrorEvent).message)\n      this.workerRef!.terminate()\n    }\n    this.workerRef.onmessage = (event) => {\n      if (event.data.event === 'keepAlive') {\n        this.sendHeartbeat()\n      }\n    }\n    this.workerRef.postMessage({\n      event: 'start',\n      interval: this.heartbeatIntervalMs,\n    })\n  }\n  /** @internal */\n  private _onConnClose(event: any) {\n    this._setConnectionState('disconnected')\n    this.log('transport', 'close', event)\n    this._triggerChanError()\n    this._clearTimer('heartbeat')\n\n    // Only schedule reconnection if it wasn't a manual disconnect\n    if (!this._wasManualDisconnect) {\n      this.reconnectTimer?.scheduleTimeout()\n    }\n\n    this._triggerStateCallbacks('close', event)\n  }\n\n  /** @internal */\n  private _onConnError(error: Event) {\n    this._setConnectionState('disconnected')\n    this.log('transport', `${error}`)\n    this._triggerChanError()\n    this._triggerStateCallbacks('error', error)\n  }\n\n  /** @internal */\n  private _triggerChanError() {\n    this.channels.forEach((channel: RealtimeChannel) =>\n      channel._trigger(CHANNEL_EVENTS.error)\n    )\n  }\n\n  /** @internal */\n  private _appendParams(\n    url: string,\n    params: { [key: string]: string }\n  ): string {\n    if (Object.keys(params).length === 0) {\n      return url\n    }\n    const prefix = url.match(/\\?/) ? '&' : '?'\n    const query = new URLSearchParams(params)\n    return `${url}${prefix}${query}`\n  }\n\n  private _workerObjectUrl(url: string | undefined): string {\n    let result_url: string\n    if (url) {\n      result_url = url\n    } else {\n      const blob = new Blob([WORKER_SCRIPT], { type: 'application/javascript' })\n      result_url = URL.createObjectURL(blob)\n    }\n    return result_url\n  }\n\n  /**\n   * Set connection state with proper state management\n   * @internal\n   */\n  private _setConnectionState(\n    state: RealtimeClientState,\n    manual = false\n  ): void {\n    this._connectionState = state\n\n    if (state === 'connecting') {\n      this._wasManualDisconnect = false\n    } else if (state === 'disconnecting') {\n      this._wasManualDisconnect = manual\n    }\n  }\n\n  /**\n   * Perform the actual auth operation\n   * @internal\n   */\n  private async _performAuth(token: string | null = null): Promise<void> {\n    let tokenToSend: string | null\n\n    if (token) {\n      tokenToSend = token\n    } else if (this.accessToken) {\n      // Always call the accessToken callback to get fresh token\n      tokenToSend = await this.accessToken()\n    } else {\n      tokenToSend = this.accessTokenValue\n    }\n\n    if (this.accessTokenValue != tokenToSend) {\n      this.accessTokenValue = tokenToSend\n      this.channels.forEach((channel) => {\n        const payload = {\n          access_token: tokenToSend,\n          version: DEFAULT_VERSION,\n        }\n\n        tokenToSend && channel.updateJoinPayload(payload)\n\n        if (channel.joinedOnce && channel._isJoined()) {\n          channel._push(CHANNEL_EVENTS.access_token, {\n            access_token: tokenToSend,\n          })\n        }\n      })\n    }\n  }\n\n  /**\n   * Wait for any in-flight auth operations to complete\n   * @internal\n   */\n  private async _waitForAuthIfNeeded(): Promise<void> {\n    if (this._authPromise) {\n      await this._authPromise\n    }\n  }\n\n  /**\n   * Safely call setAuth with standardized error handling\n   * @internal\n   */\n  private _setAuthSafely(context = 'general'): void {\n    this.setAuth().catch((e) => {\n      this.log('error', `error setting auth in ${context}`, e)\n    })\n  }\n\n  /**\n   * Trigger state change callbacks with proper error handling\n   * @internal\n   */\n  private _triggerStateCallbacks(\n    event: keyof typeof this.stateChangeCallbacks,\n    data?: any\n  ): void {\n    try {\n      this.stateChangeCallbacks[event].forEach((callback) => {\n        try {\n          callback(data)\n        } catch (e) {\n          this.log('error', `error in ${event} callback`, e)\n        }\n      })\n    } catch (e) {\n      this.log('error', `error triggering ${event} callbacks`, e)\n    }\n  }\n\n  /**\n   * Setup reconnection timer with proper configuration\n   * @internal\n   */\n  private _setupReconnectionTimer(): void {\n    this.reconnectTimer = new Timer(async () => {\n      setTimeout(async () => {\n        await this._waitForAuthIfNeeded()\n        if (!this.isConnected()) {\n          this.connect()\n        }\n      }, CONNECTION_TIMEOUTS.RECONNECT_DELAY)\n    }, this.reconnectAfterMs)\n  }\n\n  /**\n   * Initialize client options with defaults\n   * @internal\n   */\n  private _initializeOptions(options?: RealtimeClientOptions): void {\n    // Set defaults\n    this.transport = options?.transport ?? null\n    this.timeout = options?.timeout ?? DEFAULT_TIMEOUT\n    this.heartbeatIntervalMs =\n      options?.heartbeatIntervalMs ?? CONNECTION_TIMEOUTS.HEARTBEAT_INTERVAL\n    this.worker = options?.worker ?? false\n    this.accessToken = options?.accessToken ?? null\n    this.heartbeatCallback = options?.heartbeatCallback ?? noop\n    // Handle special cases\n    if (options?.params) this.params = options.params\n    if (options?.logger) this.logger = options.logger\n    if (options?.logLevel || options?.log_level) {\n      this.logLevel = options.logLevel || options.log_level\n      this.params = { ...this.params, log_level: this.logLevel as string }\n    }\n\n    // Set up functions with defaults\n    this.reconnectAfterMs =\n      options?.reconnectAfterMs ??\n      ((tries: number) => {\n        return RECONNECT_INTERVALS[tries - 1] || DEFAULT_RECONNECT_FALLBACK\n      })\n\n    this.encode =\n      options?.encode ??\n      ((payload: JSON, callback: Function) => {\n        return callback(JSON.stringify(payload))\n      })\n\n    this.decode =\n      options?.decode ?? this.serializer.decode.bind(this.serializer)\n\n    // Handle worker setup\n    if (this.worker) {\n      if (typeof window !== 'undefined' && !window.Worker) {\n        throw new Error('Web Worker is not supported')\n      }\n      this.workerUrl = options?.workerUrl\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,gBAAmC,MAAM,yBAAyB,CAAA;AAEzE,OAAO,EACL,cAAc,EACd,gBAAgB,EAChB,eAAe,EACf,eAAe,EACf,aAAa,EACb,UAAU,EACV,GAAG,EACH,eAAe,GAChB,MAAM,iBAAiB,CAAA;AAExB,OAAO,UAAU,MAAM,kBAAkB,CAAA;AACzC,OAAO,KAAK,MAAM,aAAa,CAAA;AAE/B,OAAO,EAAE,eAAe,EAAE,MAAM,oBAAoB,CAAA;AACpD,OAAO,eAAe,MAAM,mBAAmB,CAAA;;;;;;;AA6B/C,MAAM,IAAI,GAAG,GAAG,EAAE,AAAE,CAAC,CAAA;AAQrB,+BAA+B;AAC/B,MAAM,mBAAmB,GAAG;IAC1B,kBAAkB,EAAE,KAAK;IACzB,eAAe,EAAE,EAAE;IACnB,0BAA0B,EAAE,GAAG;CACvB,CAAA;AAEV,MAAM,mBAAmB,GAAG;IAAC,IAAI;IAAE,IAAI;IAAE,IAAI;IAAE,KAAK;CAAU,CAAA;AAC9D,MAAM,0BAA0B,GAAG,KAAK,CAAA;AAqCxC,MAAM,aAAa,GAAG,CAAA;;;;;MAKhB,CAAA;AAEQ,MAAO,cAAc;IA6CjC;;;;;;;;;;;;;;;;;;OAkBG,CACH,YAAY,QAAgB,EAAE,OAA+B,CAAA;;QA/D7D,IAAA,CAAA,gBAAgB,GAAkB,IAAI,CAAA;QACtC,IAAA,CAAA,MAAM,GAAkB,IAAI,CAAA;QAC5B,IAAA,CAAA,QAAQ,GAAsB,IAAI,KAAK,EAAE,CAAA;QACzC,IAAA,CAAA,QAAQ,GAAW,EAAE,CAAA;QACrB,IAAA,CAAA,YAAY,GAAW,EAAE,CAAA;QACzB,+DAAA,EAAiE,CACjE,IAAA,CAAA,OAAO,GAA+B,CAAA,CAAE,CAAA;QACxC,IAAA,CAAA,MAAM,GAA+B,CAAA,CAAE,CAAA;QACvC,IAAA,CAAA,OAAO,GAAW,6MAAe,CAAA;QACjC,IAAA,CAAA,SAAS,GAAoC,IAAI,CAAA;QACjD,IAAA,CAAA,mBAAmB,GAAW,mBAAmB,CAAC,kBAAkB,CAAA;QACpE,IAAA,CAAA,cAAc,GAA+C,SAAS,CAAA;QACtE,IAAA,CAAA,mBAAmB,GAAkB,IAAI,CAAA;QACzC,IAAA,CAAA,iBAAiB,GAAsC,IAAI,CAAA;QAC3D,IAAA,CAAA,GAAG,GAAW,CAAC,CAAA;QACf,IAAA,CAAA,cAAc,GAAiB,IAAI,CAAA;QACnC,IAAA,CAAA,MAAM,GAAa,IAAI,CAAA;QAKvB,IAAA,CAAA,IAAI,GAAyB,IAAI,CAAA;QACjC,IAAA,CAAA,UAAU,GAAe,EAAE,CAAA;QAC3B,IAAA,CAAA,UAAU,GAAe,IAAI,sMAAU,EAAE,CAAA;QACzC,IAAA,CAAA,oBAAoB,GAKhB;YACF,IAAI,EAAE,EAAE;YACR,KAAK,EAAE,EAAE;YACT,KAAK,EAAE,EAAE;YACT,OAAO,EAAE,EAAE;SACZ,CAAA;QAED,IAAA,CAAA,WAAW,GAA0C,IAAI,CAAA;QAIjD,IAAA,CAAA,gBAAgB,GAAwB,cAAc,CAAA;QACtD,IAAA,CAAA,oBAAoB,GAAY,KAAK,CAAA;QACrC,IAAA,CAAA,YAAY,GAAyB,IAAI,CAAA;QAmVjD;;;;WAIG,CACH,IAAA,CAAA,aAAa,GAAG,CAAC,WAAmB,EAAS,EAAE;YAC7C,IAAI,MAAa,CAAA;YACjB,IAAI,WAAW,EAAE,CAAC;gBAChB,MAAM,GAAG,WAAW,CAAA;YACtB,CAAC,MAAM,IAAI,OAAO,KAAK,KAAK,WAAW,EAAE,CAAC;gBACxC,2CAA2C;gBAC3C,MAAM,GAAG,CAAC,GAAG,IAAI,EAAE,CACjB,CADmB,KACb,CAAC,sBAA6B,CAAC,+GAClC,IAAI,CAAC,CAAC,EAAE,OAAO,EAAE,MAAK,EAAE,EAAE,CAAG,CAAD,IAAM,CAAC,IAAG,IAAI,CAAC,CAAC,CAC5C,KAAK,CAAC,CAAC,KAAK,EAAE,EAAE;wBACf,MAAM,IAAI,KAAK,CACb,CAAA,qCAAA,EAAwC,KAAK,CAAC,OAAO,CAAA,EAAA,CAAI,GACvD,CAAA,gFAAA,CAAkF,CACrF,CAAA;oBACH,CAAC,CAAC,CAAA;YACR,CAAC,MAAM,CAAC;gBACN,MAAM,GAAG,KAAK,CAAA;YAChB,CAAC;YACD,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,KAAO,CAAC,GAAG,IAAI,CAAC,CAAA;QACrC,CAAC,CAAA;QArVC,+BAA+B;QAC/B,IAAI,CAAC,CAAA,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,MAAM,CAAA,EAAE,CAAC;YAC7B,MAAM,IAAI,KAAK,CAAC,4CAA4C,CAAC,CAAA;QAC/D,CAAC;QACD,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAC,MAAM,CAAA;QAEnC,2BAA2B;QAC3B,IAAI,CAAC,QAAQ,GAAG,GAAG,QAAQ,CAAA,CAAA,EAAI,wMAAU,CAAC,SAAS,EAAE,CAAA;QACrD,IAAI,CAAC,YAAY,OAAG,gNAAe,EAAC,QAAQ,CAAC,CAAA;QAE7C,IAAI,CAAC,kBAAkB,CAAC,OAAO,CAAC,CAAA;QAChC,IAAI,CAAC,uBAAuB,EAAE,CAAA;QAC9B,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,KAAK,CAAC,CAAA;IACjD,CAAC;IAED;;OAEG,CACH,OAAO,GAAA;QACL,0DAA0D;QAC1D,IACE,IAAI,CAAC,YAAY,EAAE,IACnB,IAAI,CAAC,eAAe,EAAE,IACrB,IAAI,CAAC,IAAI,KAAK,IAAI,IAAI,IAAI,CAAC,WAAW,EAAE,CAAC,CAC1C,CAAC;YACD,OAAM;QACR,CAAC;QAED,IAAI,CAAC,mBAAmB,CAAC,YAAY,CAAC,CAAA;QACtC,IAAI,CAAC,cAAc,CAAC,SAAS,CAAC,CAAA;QAE9B,iCAAiC;QACjC,IAAI,IAAI,CAAC,SAAS,EAAE,CAAC;YACnB,mCAAmC;YACnC,IAAI,CAAC,IAAI,GAAG,IAAI,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,WAAW,EAAE,CAAkB,CAAA;QACrE,CAAC,MAAM,CAAC;YACN,8BAA8B;YAC9B,IAAI,CAAC;gBACH,IAAI,CAAC,IAAI,GAAG,gNAAgB,CAAC,eAAe,CAAC,IAAI,CAAC,WAAW,EAAE,CAAC,CAAA;YAClE,CAAC,CAAC,OAAO,KAAK,EAAE,CAAC;gBACf,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAA;gBACxC,MAAM,YAAY,GAAI,KAAe,CAAC,OAAO,CAAA;gBAE7C,qDAAqD;gBACrD,IAAI,YAAY,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,CAAC;oBACrC,MAAM,IAAI,KAAK,CACb,GAAG,YAAY,CAAA,IAAA,CAAM,GACnB,iFAAiF,GACjF,gEAAgE,GAChE,qDAAqD,GACrD,sBAAsB,GACtB,yBAAyB,GACzB,8CAA8C,GAC9C,mBAAmB,GACnB,qBAAqB,GACrB,MAAM,CACT,CAAA;gBACH,CAAC;gBACD,MAAM,IAAI,KAAK,CAAC,CAAA,yBAAA,EAA4B,YAAY,EAAE,CAAC,CAAA;YAC7D,CAAC;QACH,CAAC;QACD,IAAI,CAAC,wBAAwB,EAAE,CAAA;IACjC,CAAC;IAED;;;OAGG,CACH,WAAW,GAAA;QACT,OAAO,IAAI,CAAC,aAAa,CACvB,IAAI,CAAC,QAAQ,EACb,MAAM,CAAC,MAAM,CAAC,CAAA,CAAE,EAAE,IAAI,CAAC,MAAM,EAAE;YAAE,GAAG,EAAE,iMAAG;QAAA,CAAE,CAAC,CAC7C,CAAA;IACH,CAAC;IAED;;;;;OAKG,CACH,UAAU,CAAC,IAAa,EAAE,MAAe,EAAA;QACvC,IAAI,IAAI,CAAC,eAAe,EAAE,EAAE,CAAC;YAC3B,OAAM;QACR,CAAC;QAED,IAAI,CAAC,mBAAmB,CAAC,eAAe,EAAE,IAAI,CAAC,CAAA;QAE/C,IAAI,IAAI,CAAC,IAAI,EAAE,CAAC;YACd,iEAAiE;YACjE,MAAM,aAAa,GAAG,UAAU,CAAC,GAAG,EAAE;gBACpC,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAA;YAC1C,CAAC,EAAE,GAAG,CAAC,CAAA;YAEP,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,GAAG,EAAE;gBACvB,YAAY,CAAC,aAAa,CAAC,CAAA;gBAC3B,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAA;YAC1C,CAAC,CAAA;YAED,iCAAiC;YACjC,IAAI,IAAI,EAAE,CAAC;gBACT,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,MAAM,KAAA,QAAN,MAAM,KAAA,KAAA,IAAN,MAAM,GAAI,EAAE,CAAC,CAAA;YACrC,CAAC,MAAM,CAAC;gBACN,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE,CAAA;YACnB,CAAC;YAED,IAAI,CAAC,mBAAmB,EAAE,CAAA;QAC5B,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAA;QAC1C,CAAC;IACH,CAAC;IAED;;OAEG,CACH,WAAW,GAAA;QACT,OAAO,IAAI,CAAC,QAAQ,CAAA;IACtB,CAAC;IAED;;;OAGG,CACH,KAAK,CAAC,aAAa,CACjB,OAAwB,EAAA;QAExB,MAAM,MAAM,GAAG,MAAM,OAAO,CAAC,WAAW,EAAE,CAAA;QAE1C,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YAC/B,IAAI,CAAC,UAAU,EAAE,CAAA;QACnB,CAAC;QAED,OAAO,MAAM,CAAA;IACf,CAAC;IAED;;OAEG,CACH,KAAK,CAAC,iBAAiB,GAAA;QACrB,MAAM,QAAQ,GAAG,MAAM,OAAO,CAAC,GAAG,CAChC,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,OAAO,EAAE,CAAG,CAAD,MAAQ,CAAC,WAAW,EAAE,CAAC,CACtD,CAAA;QACD,IAAI,CAAC,QAAQ,GAAG,EAAE,CAAA;QAClB,IAAI,CAAC,UAAU,EAAE,CAAA;QACjB,OAAO,QAAQ,CAAA;IACjB,CAAC;IAED;;;;OAIG,CACH,GAAG,CAAC,IAAY,EAAE,GAAW,EAAE,IAAU,EAAA;QACvC,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,GAAG,EAAE,IAAI,CAAC,CAAA;IAC9B,CAAC;IAED;;OAEG,CACH,eAAe,GAAA;QACb,OAAQ,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,CAAC;YAC1C,KAAK,2MAAa,CAAC,UAAU;gBAC3B,OAAO,8MAAgB,CAAC,UAAU,CAAA;YACpC,KAAK,2MAAa,CAAC,IAAI;gBACrB,OAAO,8MAAgB,CAAC,IAAI,CAAA;YAC9B,KAAK,2MAAa,CAAC,OAAO;gBACxB,OAAO,8MAAgB,CAAC,OAAO,CAAA;YACjC;gBACE,OAAO,8MAAgB,CAAC,MAAM,CAAA;QAClC,CAAC;IACH,CAAC;IAED;;OAEG,CACH,WAAW,GAAA;QACT,OAAO,IAAI,CAAC,eAAe,EAAE,KAAK,8MAAgB,CAAC,IAAI,CAAA;IACzD,CAAC;IAED;;OAEG,CACH,YAAY,GAAA;QACV,OAAO,IAAI,CAAC,gBAAgB,KAAK,YAAY,CAAA;IAC/C,CAAC;IAED;;OAEG,CACH,eAAe,GAAA;QACb,OAAO,IAAI,CAAC,gBAAgB,KAAK,eAAe,CAAA;IAClD,CAAC;IAED,OAAO,CACL,KAAa,EACb,SAAiC;QAAE,MAAM,EAAE,CAAA,CAAE;IAAA,CAAE,EAAA;QAE/C,MAAM,aAAa,GAAG,CAAA,SAAA,EAAY,KAAK,EAAE,CAAA;QACzC,MAAM,MAAM,GAAG,IAAI,CAAC,WAAW,EAAE,CAAC,IAAI,CACpC,CAAC,CAAkB,EAAE,CAAG,CAAC,AAAF,CAAG,KAAK,KAAK,aAAa,CAClD,CAAA;QAED,IAAI,CAAC,MAAM,EAAE,CAAC;YACZ,MAAM,IAAI,GAAG,IAAI,oMAAe,CAAC,CAAA,SAAA,EAAY,KAAK,EAAE,EAAE,MAAM,EAAE,IAAI,CAAC,CAAA;YACnE,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,CAAA;YAExB,OAAO,IAAI,CAAA;QACb,CAAC,MAAM,CAAC;YACN,OAAO,MAAM,CAAA;QACf,CAAC;IACH,CAAC;IAED;;;;OAIG,CACH,IAAI,CAAC,IAAqB,EAAA;QACxB,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE,GAAG,EAAE,GAAG,IAAI,CAAA;QAC3C,MAAM,QAAQ,GAAG,GAAG,EAAE;YACpB,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,MAAW,EAAE,EAAE;;gBAChC,CAAA,KAAA,IAAI,CAAC,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,IAAI,CAAC,MAAM,CAAC,CAAA;YACzB,CAAC,CAAC,CAAA;QACJ,CAAC,CAAA;QACD,IAAI,CAAC,GAAG,CAAC,MAAM,EAAE,GAAG,KAAK,CAAA,CAAA,EAAI,KAAK,CAAA,EAAA,EAAK,GAAG,CAAA,CAAA,CAAG,EAAE,OAAO,CAAC,CAAA;QACvD,IAAI,IAAI,CAAC,WAAW,EAAE,EAAE,CAAC;YACvB,QAAQ,EAAE,CAAA;QACZ,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAA;QAChC,CAAC;IACH,CAAC;IAED;;;;;;;;OAQG,CACH,KAAK,CAAC,OAAO,CAAC,QAAuB,IAAI,EAAA;QACvC,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,CAAA;QAC5C,IAAI,CAAC;YACH,MAAM,IAAI,CAAC,YAAY,CAAA;QACzB,CAAC,QAAS,CAAC;YACT,IAAI,CAAC,YAAY,GAAG,IAAI,CAAA;QAC1B,CAAC;IACH,CAAC;IACD;;OAEG,CACH,KAAK,CAAC,aAAa,GAAA;;QACjB,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE,EAAE,CAAC;YACxB,IAAI,CAAC;gBACH,IAAI,CAAC,iBAAiB,CAAC,cAAc,CAAC,CAAA;YACxC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;gBACX,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,6BAA6B,EAAE,CAAC,CAAC,CAAA;YACrD,CAAC;YACD,OAAM;QACR,CAAC;QAED,4DAA4D;QAC5D,IAAI,IAAI,CAAC,mBAAmB,EAAE,CAAC;YAC7B,IAAI,CAAC,mBAAmB,GAAG,IAAI,CAAA;YAC/B,IAAI,CAAC,GAAG,CACN,WAAW,EACX,0DAA0D,CAC3D,CAAA;YACD,IAAI,CAAC;gBACH,IAAI,CAAC,iBAAiB,CAAC,SAAS,CAAC,CAAA;YACnC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;gBACX,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,6BAA6B,EAAE,CAAC,CAAC,CAAA;YACrD,CAAC;YAED,6CAA6C;YAC7C,IAAI,CAAC,oBAAoB,GAAG,KAAK,CAAA;YACjC,CAAA,KAAA,IAAI,CAAC,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,CAAC,6MAAe,EAAE,mBAAmB,CAAC,CAAA;YAEtD,UAAU,CAAC,GAAG,EAAE;;gBACd,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE,EAAE,CAAC;oBACxB,CAAA,KAAA,IAAI,CAAC,cAAc,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,eAAe,EAAE,CAAA;gBACxC,CAAC;YACH,CAAC,EAAE,mBAAmB,CAAC,0BAA0B,CAAC,CAAA;YAClD,OAAM;QACR,CAAC;QAED,mCAAmC;QACnC,IAAI,CAAC,mBAAmB,GAAG,IAAI,CAAC,QAAQ,EAAE,CAAA;QAC1C,IAAI,CAAC,IAAI,CAAC;YACR,KAAK,EAAE,SAAS;YAChB,KAAK,EAAE,WAAW;YAClB,OAAO,EAAE,CAAA,CAAE;YACX,GAAG,EAAE,IAAI,CAAC,mBAAmB;SAC9B,CAAC,CAAA;QACF,IAAI,CAAC;YACH,IAAI,CAAC,iBAAiB,CAAC,MAAM,CAAC,CAAA;QAChC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;YACX,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,6BAA6B,EAAE,CAAC,CAAC,CAAA;QACrD,CAAC;QAED,IAAI,CAAC,cAAc,CAAC,WAAW,CAAC,CAAA;IAClC,CAAC;IAED,WAAW,CAAC,QAA2C,EAAA;QACrD,IAAI,CAAC,iBAAiB,GAAG,QAAQ,CAAA;IACnC,CAAC;IACD;;OAEG,CACH,eAAe,GAAA;QACb,IAAI,IAAI,CAAC,WAAW,EAAE,IAAI,IAAI,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;YACrD,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,CAAG,CAAD,OAAS,EAAE,CAAC,CAAA;YACjD,IAAI,CAAC,UAAU,GAAG,EAAE,CAAA;QACtB,CAAC;IACH,CAAC;IA4BD;;;;OAIG,CACH,QAAQ,GAAA;QACN,IAAI,MAAM,GAAG,IAAI,CAAC,GAAG,GAAG,CAAC,CAAA;QACzB,IAAI,MAAM,KAAK,IAAI,CAAC,GAAG,EAAE,CAAC;YACxB,IAAI,CAAC,GAAG,GAAG,CAAC,CAAA;QACd,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,GAAG,GAAG,MAAM,CAAA;QACnB,CAAC;QAED,OAAO,IAAI,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAA;IAC5B,CAAC;IAED;;;;OAIG,CACH,eAAe,CAAC,KAAa,EAAA;QAC3B,IAAI,UAAU,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CACjC,CAAC,CAAC,EAAE,CAAG,CAAC,AAAF,CAAG,KAAK,KAAK,KAAK,IAAI,CAAC,CAAC,CAAC,SAAS,EAAE,IAAI,CAAC,CAAC,UAAU,EAAE,CAAC,CAC9D,CAAA;QACD,IAAI,UAAU,EAAE,CAAC;YACf,IAAI,CAAC,GAAG,CAAC,WAAW,EAAE,CAAA,yBAAA,EAA4B,KAAK,CAAA,CAAA,CAAG,CAAC,CAAA;YAC3D,UAAU,CAAC,WAAW,EAAE,CAAA;QAC1B,CAAC;IACH,CAAC;IAED;;;;;;OAMG,CACH,OAAO,CAAC,OAAwB,EAAA;QAC9B,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,KAAK,KAAK,OAAO,CAAC,KAAK,CAAC,CAAA;IACxE,CAAC;IAED,cAAA,EAAgB,CACR,cAAc,CAAC,UAAyB,EAAA;QAC9C,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,EAAE,CAAC,GAAoB,EAAE,EAAE;YACpD,6BAA6B;YAC7B,IAAI,GAAG,CAAC,KAAK,KAAK,SAAS,IAAI,GAAG,CAAC,KAAK,KAAK,WAAW,EAAE,CAAC;gBACzD,IAAI,CAAC;oBACH,IAAI,CAAC,iBAAiB,CAAC,GAAG,CAAC,OAAO,CAAC,MAAM,KAAK,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAA;gBACtE,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;oBACX,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,6BAA6B,EAAE,CAAC,CAAC,CAAA;gBACrD,CAAC;YACH,CAAC;YAED,6CAA6C;YAC7C,IAAI,GAAG,CAAC,GAAG,IAAI,GAAG,CAAC,GAAG,KAAK,IAAI,CAAC,mBAAmB,EAAE,CAAC;gBACpD,IAAI,CAAC,mBAAmB,GAAG,IAAI,CAAA;YACjC,CAAC;YAED,uBAAuB;YACvB,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE,GAAG,EAAE,GAAG,GAAG,CAAA;YAC1C,MAAM,SAAS,GAAG,GAAG,CAAC,CAAC,CAAC,CAAA,CAAA,EAAI,GAAG,CAAA,CAAA,CAAG,CAAC,CAAC,CAAC,EAAE,CAAA;YACvC,MAAM,MAAM,GAAG,OAAO,CAAC,MAAM,IAAI,EAAE,CAAA;YACnC,IAAI,CAAC,GAAG,CACN,SAAS,EACT,GAAG,MAAM,CAAA,CAAA,EAAI,KAAK,CAAA,CAAA,EAAI,KAAK,CAAA,CAAA,EAAI,SAAS,EAAE,CAAC,IAAI,EAAE,EACjD,OAAO,CACR,CAAA;YAED,wCAAwC;YACxC,IAAI,CAAC,QAAQ,CACV,MAAM,CAAC,CAAC,OAAwB,EAAE,CAAG,CAAD,MAAQ,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,CAC9D,OAAO,CAAC,CAAC,OAAwB,EAAE,CAClC,CADoC,MAC7B,CAAC,QAAQ,CAAC,KAAK,EAAE,OAAO,EAAE,GAAG,CAAC,CACtC,CAAA;YAEH,IAAI,CAAC,sBAAsB,CAAC,SAAS,EAAE,GAAG,CAAC,CAAA;QAC7C,CAAC,CAAC,CAAA;IACJ,CAAC;IAED;;;OAGG,CACK,WAAW,CAAC,KAAgC,EAAA;;QAClD,IAAI,KAAK,KAAK,WAAW,IAAI,IAAI,CAAC,cAAc,EAAE,CAAC;YACjD,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAA;YAClC,IAAI,CAAC,cAAc,GAAG,SAAS,CAAA;QACjC,CAAC,MAAM,IAAI,KAAK,KAAK,WAAW,EAAE,CAAC;YACjC,CAAA,KAAA,IAAI,CAAC,cAAc,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,KAAK,EAAE,CAAA;QAC9B,CAAC;IACH,CAAC;IAED;;;OAGG,CACK,eAAe,GAAA;QACrB,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,CAAA;QAC7B,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,CAAA;IAC/B,CAAC;IAED;;;OAGG,CACK,wBAAwB,GAAA;QAC9B,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,OAAM;QAEtB,6EAA6E;QAC7E,IAAI,YAAY,IAAI,IAAI,CAAC,IAAI,EAAE,CAAC;;YAC5B,IAAI,CAAC,IAAY,CAAC,UAAU,GAAG,aAAa,CAAA;QAChD,CAAC;QAED,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,GAAG,CAAG,CAAD,GAAK,CAAC,WAAW,EAAE,CAAA;QAC3C,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,CAAC,KAAY,EAAE,CAAG,CAAD,GAAK,CAAC,YAAY,CAAC,KAAK,CAAC,CAAA;QAC9D,IAAI,CAAC,IAAI,CAAC,SAAS,GAAG,CAAC,KAAU,EAAE,CAAG,CAAD,GAAK,CAAC,cAAc,CAAC,KAAK,CAAC,CAAA;QAChE,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,CAAC,KAAU,EAAE,CAAG,CAAD,GAAK,CAAC,YAAY,CAAC,KAAK,CAAC,CAAA;IAC9D,CAAC;IAED;;;OAGG,CACK,mBAAmB,GAAA;QACzB,IAAI,IAAI,CAAC,IAAI,EAAE,CAAC;YACd,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,IAAI,CAAA;YACvB,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAA;YACxB,IAAI,CAAC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAA;YAC1B,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAA;YACxB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAA;QAClB,CAAC;QACD,IAAI,CAAC,eAAe,EAAE,CAAA;QACtB,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,CAAG,CAAD,MAAQ,CAAC,QAAQ,EAAE,CAAC,CAAA;IACxD,CAAC;IAED,cAAA,EAAgB,CACR,WAAW,GAAA;QACjB,IAAI,CAAC,mBAAmB,CAAC,WAAW,CAAC,CAAA;QACrC,IAAI,CAAC,GAAG,CAAC,WAAW,EAAE,CAAA,aAAA,EAAgB,IAAI,CAAC,WAAW,EAAE,EAAE,CAAC,CAAA;QAC3D,IAAI,CAAC,eAAe,EAAE,CAAA;QACtB,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,CAAA;QAE7B,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE,CAAC;YACjB,IAAI,CAAC,eAAe,EAAE,CAAA;QACxB,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE,CAAC;gBACpB,IAAI,CAAC,qBAAqB,EAAE,CAAA;YAC9B,CAAC;QACH,CAAC;QAED,IAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC,CAAA;IACrC,CAAC;IACD,cAAA,EAAgB,CACR,eAAe,GAAA;QACrB,IAAI,CAAC,cAAc,IAAI,aAAa,CAAC,IAAI,CAAC,cAAc,CAAC,CAAA;QACzD,IAAI,CAAC,cAAc,GAAG,WAAW,CAC/B,GAAG,CAAG,CAAD,GAAK,CAAC,aAAa,EAAE,EAC1B,IAAI,CAAC,mBAAmB,CACzB,CAAA;IACH,CAAC;IAED,cAAA,EAAgB,CACR,qBAAqB,GAAA;QAC3B,IAAI,IAAI,CAAC,SAAS,EAAE,CAAC;YACnB,IAAI,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAA,yBAAA,EAA4B,IAAI,CAAC,SAAS,EAAE,CAAC,CAAA;QAClE,CAAC,MAAM,CAAC;YACN,IAAI,CAAC,GAAG,CAAC,QAAQ,EAAE,CAAA,uBAAA,CAAyB,CAAC,CAAA;QAC/C,CAAC;QACD,MAAM,SAAS,GAAG,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,SAAU,CAAC,CAAA;QACxD,IAAI,CAAC,SAAS,GAAG,IAAI,MAAM,CAAC,SAAS,CAAC,CAAA;QACtC,IAAI,CAAC,SAAS,CAAC,OAAO,GAAG,CAAC,KAAK,EAAE,EAAE;YACjC,IAAI,CAAC,GAAG,CAAC,QAAQ,EAAE,cAAc,EAAG,KAAoB,CAAC,OAAO,CAAC,CAAA;YACjE,IAAI,CAAC,SAAU,CAAC,SAAS,EAAE,CAAA;QAC7B,CAAC,CAAA;QACD,IAAI,CAAC,SAAS,CAAC,SAAS,GAAG,CAAC,KAAK,EAAE,EAAE;YACnC,IAAI,KAAK,CAAC,IAAI,CAAC,KAAK,KAAK,WAAW,EAAE,CAAC;gBACrC,IAAI,CAAC,aAAa,EAAE,CAAA;YACtB,CAAC;QACH,CAAC,CAAA;QACD,IAAI,CAAC,SAAS,CAAC,WAAW,CAAC;YACzB,KAAK,EAAE,OAAO;YACd,QAAQ,EAAE,IAAI,CAAC,mBAAmB;SACnC,CAAC,CAAA;IACJ,CAAC;IACD,cAAA,EAAgB,CACR,YAAY,CAAC,KAAU,EAAA;;QAC7B,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAA;QACxC,IAAI,CAAC,GAAG,CAAC,WAAW,EAAE,OAAO,EAAE,KAAK,CAAC,CAAA;QACrC,IAAI,CAAC,iBAAiB,EAAE,CAAA;QACxB,IAAI,CAAC,WAAW,CAAC,WAAW,CAAC,CAAA;QAE7B,8DAA8D;QAC9D,IAAI,CAAC,IAAI,CAAC,oBAAoB,EAAE,CAAC;YAC/B,CAAA,KAAA,IAAI,CAAC,cAAc,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,eAAe,EAAE,CAAA;QACxC,CAAC;QAED,IAAI,CAAC,sBAAsB,CAAC,OAAO,EAAE,KAAK,CAAC,CAAA;IAC7C,CAAC;IAED,cAAA,EAAgB,CACR,YAAY,CAAC,KAAY,EAAA;QAC/B,IAAI,CAAC,mBAAmB,CAAC,cAAc,CAAC,CAAA;QACxC,IAAI,CAAC,GAAG,CAAC,WAAW,EAAE,GAAG,KAAK,EAAE,CAAC,CAAA;QACjC,IAAI,CAAC,iBAAiB,EAAE,CAAA;QACxB,IAAI,CAAC,sBAAsB,CAAC,OAAO,EAAE,KAAK,CAAC,CAAA;IAC7C,CAAC;IAED,cAAA,EAAgB,CACR,iBAAiB,GAAA;QACvB,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,OAAwB,EAAE,CAC/C,CADiD,MAC1C,CAAC,QAAQ,CAAC,4MAAc,CAAC,KAAK,CAAC,CACvC,CAAA;IACH,CAAC;IAED,cAAA,EAAgB,CACR,aAAa,CACnB,GAAW,EACX,MAAiC,EAAA;QAEjC,IAAI,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE,CAAC;YACrC,OAAO,GAAG,CAAA;QACZ,CAAC;QACD,MAAM,MAAM,GAAG,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,CAAA;QAC1C,MAAM,KAAK,GAAG,IAAI,eAAe,CAAC,MAAM,CAAC,CAAA;QACzC,OAAO,GAAG,GAAG,GAAG,MAAM,GAAG,KAAK,EAAE,CAAA;IAClC,CAAC;IAEO,gBAAgB,CAAC,GAAuB,EAAA;QAC9C,IAAI,UAAkB,CAAA;QACtB,IAAI,GAAG,EAAE,CAAC;YACR,UAAU,GAAG,GAAG,CAAA;QAClB,CAAC,MAAM,CAAC;YACN,MAAM,IAAI,GAAG,IAAI,IAAI,CAAC;gBAAC,aAAa;aAAC,EAAE;gBAAE,IAAI,EAAE,wBAAwB;YAAA,CAAE,CAAC,CAAA;YAC1E,UAAU,GAAG,GAAG,CAAC,eAAe,CAAC,IAAI,CAAC,CAAA;QACxC,CAAC;QACD,OAAO,UAAU,CAAA;IACnB,CAAC;IAED;;;OAGG,CACK,mBAAmB,CACzB,KAA0B,EAC1B,MAAM,GAAG,KAAK,EAAA;QAEd,IAAI,CAAC,gBAAgB,GAAG,KAAK,CAAA;QAE7B,IAAI,KAAK,KAAK,YAAY,EAAE,CAAC;YAC3B,IAAI,CAAC,oBAAoB,GAAG,KAAK,CAAA;QACnC,CAAC,MAAM,IAAI,KAAK,KAAK,eAAe,EAAE,CAAC;YACrC,IAAI,CAAC,oBAAoB,GAAG,MAAM,CAAA;QACpC,CAAC;IACH,CAAC;IAED;;;OAGG,CACK,KAAK,CAAC,YAAY,CAAC,QAAuB,IAAI,EAAA;QACpD,IAAI,WAA0B,CAAA;QAE9B,IAAI,KAAK,EAAE,CAAC;YACV,WAAW,GAAG,KAAK,CAAA;QACrB,CAAC,MAAM,IAAI,IAAI,CAAC,WAAW,EAAE,CAAC;YAC5B,0DAA0D;YAC1D,WAAW,GAAG,MAAM,IAAI,CAAC,WAAW,EAAE,CAAA;QACxC,CAAC,MAAM,CAAC;YACN,WAAW,GAAG,IAAI,CAAC,gBAAgB,CAAA;QACrC,CAAC;QAED,IAAI,IAAI,CAAC,gBAAgB,IAAI,WAAW,EAAE,CAAC;YACzC,IAAI,CAAC,gBAAgB,GAAG,WAAW,CAAA;YACnC,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,EAAE;gBAChC,MAAM,OAAO,GAAG;oBACd,YAAY,EAAE,WAAW;oBACzB,OAAO,EAAE,6MAAe;iBACzB,CAAA;gBAED,WAAW,IAAI,OAAO,CAAC,iBAAiB,CAAC,OAAO,CAAC,CAAA;gBAEjD,IAAI,OAAO,CAAC,UAAU,IAAI,OAAO,CAAC,SAAS,EAAE,EAAE,CAAC;oBAC9C,OAAO,CAAC,KAAK,CAAC,4MAAc,CAAC,YAAY,EAAE;wBACzC,YAAY,EAAE,WAAW;qBAC1B,CAAC,CAAA;gBACJ,CAAC;YACH,CAAC,CAAC,CAAA;QACJ,CAAC;IACH,CAAC;IAED;;;OAGG,CACK,KAAK,CAAC,oBAAoB,GAAA;QAChC,IAAI,IAAI,CAAC,YAAY,EAAE,CAAC;YACtB,MAAM,IAAI,CAAC,YAAY,CAAA;QACzB,CAAC;IACH,CAAC;IAED;;;OAGG,CACK,cAAc,CAAC,OAAO,GAAG,SAAS,EAAA;QACxC,IAAI,CAAC,OAAO,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,EAAE;YACzB,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,CAAA,sBAAA,EAAyB,OAAO,EAAE,EAAE,CAAC,CAAC,CAAA;QAC1D,CAAC,CAAC,CAAA;IACJ,CAAC;IAED;;;OAGG,CACK,sBAAsB,CAC5B,KAA6C,EAC7C,IAAU,EAAA;QAEV,IAAI,CAAC;YACH,IAAI,CAAC,oBAAoB,CAAC,KAAK,CAAC,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,EAAE;gBACpD,IAAI,CAAC;oBACH,QAAQ,CAAC,IAAI,CAAC,CAAA;gBAChB,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;oBACX,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,CAAA,SAAA,EAAY,KAAK,CAAA,SAAA,CAAW,EAAE,CAAC,CAAC,CAAA;gBACpD,CAAC;YACH,CAAC,CAAC,CAAA;QACJ,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;YACX,IAAI,CAAC,GAAG,CAAC,OAAO,EAAE,CAAA,iBAAA,EAAoB,KAAK,CAAA,UAAA,CAAY,EAAE,CAAC,CAAC,CAAA;QAC7D,CAAC;IACH,CAAC;IAED;;;OAGG,CACK,uBAAuB,GAAA;QAC7B,IAAI,CAAC,cAAc,GAAG,IAAI,iMAAK,CAAC,KAAK,IAAI,EAAE;YACzC,UAAU,CAAC,KAAK,IAAI,EAAE;gBACpB,MAAM,IAAI,CAAC,oBAAoB,EAAE,CAAA;gBACjC,IAAI,CAAC,IAAI,CAAC,WAAW,EAAE,EAAE,CAAC;oBACxB,IAAI,CAAC,OAAO,EAAE,CAAA;gBAChB,CAAC;YACH,CAAC,EAAE,mBAAmB,CAAC,eAAe,CAAC,CAAA;QACzC,CAAC,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAA;IAC3B,CAAC;IAED;;;OAGG,CACK,kBAAkB,CAAC,OAA+B,EAAA;;QACxD,eAAe;QACf,IAAI,CAAC,SAAS,GAAG,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,IAAI,CAAA;QAC3C,IAAI,CAAC,OAAO,GAAG,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,6MAAe,CAAA;QAClD,IAAI,CAAC,mBAAmB,GACtB,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,mBAAmB,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,mBAAmB,CAAC,kBAAkB,CAAA;QACxE,IAAI,CAAC,MAAM,GAAG,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,KAAK,CAAA;QACtC,IAAI,CAAC,WAAW,GAAG,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,WAAW,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,IAAI,CAAA;QAC/C,IAAI,CAAC,iBAAiB,GAAG,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,iBAAiB,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,IAAI,CAAA;QAC3D,uBAAuB;QACvB,IAAI,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,EAAE,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAA;QACjD,IAAI,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,EAAE,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAA;QACjD,IAAI,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,QAAQ,KAAA,CAAI,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,CAAA,EAAE,CAAC;YAC5C,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,QAAQ,IAAI,OAAO,CAAC,SAAS,CAAA;YACrD,IAAI,CAAC,MAAM,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,IAAI,CAAC,MAAM,GAAA;gBAAE,SAAS,EAAE,IAAI,CAAC,QAAkB;YAAA,EAAE,CAAA;QACtE,CAAC;QAED,iCAAiC;QACjC,IAAI,CAAC,gBAAgB,GACnB,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,gBAAgB,MAAA,QAAA,OAAA,KAAA,IAAA,KACzB,AAAC,CAAC,KAAa,EAAE,EAAE;YACjB,OAAO,mBAAmB,CAAC,KAAK,GAAG,CAAC,CAAC,IAAI,0BAA0B,CAAA;QACrE,CAAC,CAAC,CAAA;QAEJ,IAAI,CAAC,MAAM,GACT,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KACf,AAAC,CAAC,OAAa,EAAE,QAAkB,EAAE,EAAE;YACrC,OAAO,QAAQ,CAAC,IAAI,CAAC,SAAS,CAAC,OAAO,CAAC,CAAC,CAAA;QAC1C,CAAC,CAAC,CAAA;QAEJ,IAAI,CAAC,MAAM,GACT,CAAA,KAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,CAAA;QAEjE,sBAAsB;QACtB,IAAI,IAAI,CAAC,MAAM,EAAE,CAAC;YAChB,IAAI,OAAO,MAAM,KAAK,WAAW,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,CAAC;;YAGtD,IAAI,CAAC,SAAS,GAAG,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,CAAA;QACrC,CAAC;IACH,CAAC;CACF"}},
    {"offset": {"line": 3484, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/realtime-js/dist/module/index.js","sources":["turbopack:///[project]/node_modules/@supabase/realtime-js/src/index.ts"],"sourcesContent":["import RealtimeClient, {\n  RealtimeClientOptions,\n  RealtimeMessage,\n  RealtimeRemoveChannelResponse,\n  WebSocketLikeConstructor,\n} from './RealtimeClient'\nimport RealtimeChannel, {\n  RealtimeChannelOptions,\n  RealtimeChannelSendResponse,\n  RealtimePostgresChangesFilter,\n  RealtimePostgresChangesPayload,\n  RealtimePostgresInsertPayload,\n  RealtimePostgresUpdatePayload,\n  RealtimePostgresDeletePayload,\n  REALTIME_LISTEN_TYPES,\n  REALTIME_POSTGRES_CHANGES_LISTEN_EVENT,\n  REALTIME_SUBSCRIBE_STATES,\n  REALTIME_CHANNEL_STATES,\n} from './RealtimeChannel'\nimport RealtimePresence, {\n  RealtimePresenceState,\n  RealtimePresenceJoinPayload,\n  RealtimePresenceLeavePayload,\n  REALTIME_PRESENCE_LISTEN_EVENTS,\n} from './RealtimePresence'\nimport WebSocketFactory, { WebSocketLike } from './lib/websocket-factory'\n\nexport {\n  RealtimePresence,\n  RealtimeChannel,\n  RealtimeChannelOptions,\n  RealtimeChannelSendResponse,\n  RealtimeClient,\n  RealtimeClientOptions,\n  RealtimeMessage,\n  RealtimePostgresChangesFilter,\n  RealtimePostgresChangesPayload,\n  RealtimePostgresInsertPayload,\n  RealtimePostgresUpdatePayload,\n  RealtimePostgresDeletePayload,\n  RealtimePresenceJoinPayload,\n  RealtimePresenceLeavePayload,\n  RealtimePresenceState,\n  RealtimeRemoveChannelResponse,\n  REALTIME_LISTEN_TYPES,\n  REALTIME_POSTGRES_CHANGES_LISTEN_EVENT,\n  REALTIME_PRESENCE_LISTEN_EVENTS,\n  REALTIME_SUBSCRIBE_STATES,\n  REALTIME_CHANNEL_STATES,\n  WebSocketFactory,\n  WebSocketLike,\n  WebSocketLikeConstructor,\n}\n"],"names":[],"mappings":";AAAA,OAAO,cAKN,MAAM,kBAAkB,CAAA;AACzB,OAAO,eAAe,EAAE,EAQtB,qBAAqB,EACrB,sCAAsC,EACtC,yBAAyB,EACzB,uBAAuB,GACxB,MAAM,mBAAmB,CAAA;AAC1B,OAAO,gBAAgB,EAAE,EAIvB,+BAA+B,GAChC,MAAM,oBAAoB,CAAA;AAC3B,OAAO,gBAAmC,MAAM,yBAAyB,CAAA"}},
    {"offset": {"line": 3508, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/lib/errors.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/lib/errors.ts"],"sourcesContent":["export class StorageError extends Error {\n  protected __isStorageError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageError'\n  }\n}\n\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\nexport class StorageApiError extends StorageError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAM,MAAO,YAAa,SAAQ,KAAK;IAGrC,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC,OAAO,CAAC,CAAA;QAHN,IAAA,CAAA,gBAAgB,GAAG,IAAI,CAAA;QAI/B,IAAI,CAAC,IAAI,GAAG,cAAc,CAAA;IAC5B,CAAC;CACF;AAEK,SAAU,cAAc,CAAC,KAAc;IAC3C,OAAO,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,KAAK,IAAI,IAAI,kBAAkB,IAAI,KAAK,CAAA;AACnF,CAAC;AAEK,MAAO,eAAgB,SAAQ,YAAY;IAI/C,YAAY,OAAe,EAAE,MAAc,EAAE,UAAkB,CAAA;QAC7D,KAAK,CAAC,OAAO,CAAC,CAAA;QACd,IAAI,CAAC,IAAI,GAAG,iBAAiB,CAAA;QAC7B,IAAI,CAAC,MAAM,GAAG,MAAM,CAAA;QACpB,IAAI,CAAC,UAAU,GAAG,UAAU,CAAA;IAC9B,CAAC;IAED,MAAM,GAAA;QACJ,OAAO;YACL,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,UAAU,EAAE,IAAI,CAAC,UAAU;SAC5B,CAAA;IACH,CAAC;CACF;AAEK,MAAO,mBAAoB,SAAQ,YAAY;IAGnD,YAAY,OAAe,EAAE,aAAsB,CAAA;QACjD,KAAK,CAAC,OAAO,CAAC,CAAA;QACd,IAAI,CAAC,IAAI,GAAG,qBAAqB,CAAA;QACjC,IAAI,CAAC,aAAa,GAAG,aAAa,CAAA;IACpC,CAAC;CACF"}},
    {"offset": {"line": 3555, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/lib/helpers.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/lib/helpers.ts"],"sourcesContent":["type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  let _fetch: Fetch\n  if (customFetch) {\n    _fetch = customFetch\n  } else if (typeof fetch === 'undefined') {\n    _fetch = (...args) =>\n      import('@supabase/node-fetch' as any).then(({ default: fetch }) => fetch(...args))\n  } else {\n    _fetch = fetch\n  }\n  return (...args) => _fetch(...args)\n}\n\nexport const resolveResponse = async (): Promise<typeof Response> => {\n  if (typeof Response === 'undefined') {\n    // @ts-ignore\n    return (await import('@supabase/node-fetch' as any)).Response\n  }\n\n  return Response\n}\n\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n * source: https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEO,MAAM,YAAY,GAAG,CAAC,WAAmB,EAAS,EAAE;IACzD,IAAI,MAAa,CAAA;IACjB,IAAI,WAAW,EAAE;QACf,MAAM,GAAG,WAAW,CAAA;KACrB,MAAM,IAAI,OAAO,KAAK,KAAK,WAAW,EAAE;QACvC,MAAM,GAAG,CAAC,GAAG,IAAI,EAAE,CACjB,CADmB,KACb,CAAC,sBAA6B,CAAC,+GAAC,IAAI,CAAC,CAAC,EAAE,OAAO,EAAE,MAAK,EAAE,EAAE,CAAG,CAAD,IAAM,CAAC,IAAG,IAAI,CAAC,CAAC,CAAA;KACrF,MAAM;QACL,MAAM,GAAG,KAAK,CAAA;KACf;IACD,OAAO,CAAC,GAAG,IAAI,EAAE,CAAG,CAAD,KAAO,CAAC,GAAG,IAAI,CAAC,CAAA;AACrC,CAAC,CAAA;AAEM,MAAM,eAAe,GAAG,GAAmC,CAAE,CAAA,SAAA,KAAA,GAAA,KAAA,GAAA,KAAA,GAAA;QAClE,IAAI,OAAO,QAAQ,KAAK,WAAW,EAAE;YACnC,aAAa;YACb,OAAO,CAAC,MAAM,MAAM,CAAC,sBAA6B,+GAAC,CAAC,CAAC,QAAQ,CAAA;SAC9D;QAED,OAAO,QAAQ,CAAA;IACjB,CAAC,CAAA,CAAA;AAEM,MAAM,gBAAgB,GAAG,CAAC,IAAyB,EAAW,EAAE;IACrE,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;QACvB,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,EAAE,CAAG,CAAD,eAAiB,CAAC,EAAE,CAAC,CAAC,CAAA;KAC9C,MAAM,IAAI,OAAO,IAAI,KAAK,UAAU,IAAI,IAAI,KAAK,MAAM,CAAC,IAAI,CAAC,EAAE;QAC9D,OAAO,IAAI,CAAA;KACZ;IAED,MAAM,MAAM,GAAwB,CAAA,CAAE,CAAA;IACtC,MAAM,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,EAAE,KAAK,CAAC,EAAE,EAAE;QAC5C,MAAM,MAAM,GAAG,GAAG,CAAC,OAAO,CAAC,eAAe,EAAE,CAAC,CAAC,EAAE,CAAG,CAAD,AAAE,CAAC,WAAW,EAAE,CAAC,OAAO,CAAC,OAAO,EAAE,EAAE,CAAC,CAAC,CAAA;QACxF,MAAM,CAAC,MAAM,CAAC,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAA;IAC1C,CAAC,CAAC,CAAA;IAEF,OAAO,MAAM,CAAA;AACf,CAAC,CAAA;AAOM,MAAM,aAAa,GAAG,CAAC,KAAa,EAAW,EAAE;IACtD,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,KAAK,IAAI,EAAE;QAC/C,OAAO,KAAK,CAAA;KACb;IAED,MAAM,SAAS,GAAG,MAAM,CAAC,cAAc,CAAC,KAAK,CAAC,CAAA;IAC9C,OAAO,AACL,CAAC,SAAS,KAAK,IAAI,IACjB,SAAS,KAAK,MAAM,CAAC,SAAS,IAC9B,MAAM,CAAC,cAAc,CAAC,SAAS,CAAC,KAAK,IAAI,CAAC,IAC5C,CAAC,CAAC,MAAM,CAAC,WAAW,IAAI,KAAK,CAAC,IAC9B,CAAC,CAAC,MAAM,CAAC,QAAQ,IAAI,KAAK,CAAC,CAC5B,CAAA;AACH,CAAC,CAAA"}},
    {"offset": {"line": 3634, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/lib/fetch.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/lib/fetch.ts"],"sourcesContent":["import { StorageApiError, StorageUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\nconst _getErrorMessage = (err: any): string =>\n  err.msg || err.message || err.error_description || err.error || JSON.stringify(err)\n\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  const Res = await resolveResponse()\n\n  if (error instanceof Res && !options?.noResolveJson) {\n    error\n      .json()\n      .then((err) => {\n        const status = error.status || 500\n        const statusCode = err?.statusCode || status + ''\n        reject(new StorageApiError(_getErrorMessage(err), status, statusCode))\n      })\n      .catch((err) => {\n        reject(new StorageUnknownError(_getErrorMessage(err), err))\n      })\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error))\n  }\n}\n\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\nexport async function head(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(\n    fetcher,\n    'HEAD',\n    url,\n    {\n      ...options,\n      noResolveJson: true,\n    },\n    parameters\n  )\n}\n\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA,OAAO,EAAE,eAAe,EAAE,mBAAmB,EAAE,MAAM,UAAU,CAAA;AAC/D,OAAO,EAAE,aAAa,EAAE,eAAe,EAAE,MAAM,WAAW,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAe1D,MAAM,gBAAgB,GAAG,CAAC,GAAQ,EAAU,CAC1C,CAD4C,EACzC,CAAC,GAAG,IAAI,GAAG,CAAC,OAAO,IAAI,GAAG,CAAC,iBAAiB,IAAI,GAAG,CAAC,KAAK,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,CAAA;AAErF,MAAM,WAAW,GAAG,CAClB,KAAc,EACd,MAA8B,EAC9B,OAAsB,EACtB,CAAE,CAAA,SAAA,KAAA,GAAA,KAAA,GAAA,KAAA,GAAA;QACF,MAAM,GAAG,GAAG,MAAM,eAAe,EAAE,CAAA;QAEnC,IAAI,KAAK,YAAY,GAAG,IAAI,CAAC,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,aAAa,CAAA,EAAE;YACnD,KAAK,CACF,IAAI,EAAE,CACN,IAAI,CAAC,CAAC,GAAG,EAAE,EAAE;gBACZ,MAAM,MAAM,GAAG,KAAK,CAAC,MAAM,IAAI,GAAG,CAAA;gBAClC,MAAM,UAAU,GAAG,CAAA,GAAG,KAAA,QAAH,GAAG,KAAA,KAAA,IAAA,KAAA,IAAH,GAAG,CAAE,UAAU,KAAI,MAAM,GAAG,EAAE,CAAA;gBACjD,MAAM,CAAC,IAAI,yMAAe,CAAC,gBAAgB,CAAC,GAAG,CAAC,EAAE,MAAM,EAAE,UAAU,CAAC,CAAC,CAAA;YACxE,CAAC,CAAC,CACD,KAAK,CAAC,CAAC,GAAG,EAAE,EAAE;gBACb,MAAM,CAAC,IAAI,6MAAmB,CAAC,gBAAgB,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,CAAA;YAC7D,CAAC,CAAC,CAAA;SACL,MAAM;YACL,MAAM,CAAC,IAAI,6MAAmB,CAAC,gBAAgB,CAAC,KAAK,CAAC,EAAE,KAAK,CAAC,CAAC,CAAA;SAChE;IACH,CAAC,CAAA,CAAA;AAED,MAAM,iBAAiB,GAAG,CACxB,MAAyB,EACzB,OAAsB,EACtB,UAA4B,EAC5B,IAAa,EACb,EAAE;IACF,MAAM,MAAM,GAAyB;QAAE,MAAM;QAAE,OAAO,EAAE,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,OAAO,KAAI,CAAA,CAAE;IAAA,CAAE,CAAA;IAEhF,IAAI,MAAM,KAAK,KAAK,IAAI,CAAC,IAAI,EAAE;QAC7B,OAAO,MAAM,CAAA;KACd;IAED,QAAI,wMAAa,EAAC,IAAI,CAAC,EAAE;QACvB,MAAM,CAAC,OAAO,GAAA,OAAA,MAAA,CAAA;YAAK,cAAc,EAAE,kBAAkB;QAAA,GAAK,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,OAAO,CAAE,CAAA;QAC5E,MAAM,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAA;KACnC,MAAM;QACL,MAAM,CAAC,IAAI,GAAG,IAAI,CAAA;KACnB;IAED,IAAI,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,EAAE;QACnB,MAAM,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,CAAA;KAC/B;IAED,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAY,MAAM,GAAK,UAAU,EAAE;AACrC,CAAC,CAAA;AAED,SAAe,cAAc,CAC3B,OAAc,EACd,MAAyB,EACzB,GAAW,EACX,OAAsB,EACtB,UAA4B,EAC5B,IAAa;;QAEb,OAAO,IAAI,OAAO,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACrC,OAAO,CAAC,GAAG,EAAE,iBAAiB,CAAC,MAAM,EAAE,OAAO,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC,CAC/D,IAAI,CAAC,CAAC,MAAM,EAAE,EAAE;gBACf,IAAI,CAAC,MAAM,CAAC,EAAE,EAAE,MAAM,MAAM,CAAA;gBAC5B,IAAI,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,aAAa,EAAE,OAAO,MAAM,CAAA;gBACzC,OAAO,MAAM,CAAC,IAAI,EAAE,CAAA;YACtB,CAAC,CAAC,CACD,IAAI,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,MAAQ,CAAC,IAAI,CAAC,CAAC,CAC7B,KAAK,CAAC,CAAC,KAAK,EAAE,CAAG,CAAD,UAAY,CAAC,KAAK,EAAE,MAAM,EAAE,OAAO,CAAC,CAAC,CAAA;QAC1D,CAAC,CAAC,CAAA;IACJ,CAAC;CAAA;AAEK,SAAgB,GAAG,CACvB,OAAc,EACd,GAAW,EACX,OAAsB,EACtB,UAA4B;;QAE5B,OAAO,cAAc,CAAC,OAAO,EAAE,KAAK,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,CAAC,CAAA;IACjE,CAAC;CAAA;AAEK,SAAgB,IAAI,CACxB,OAAc,EACd,GAAW,EACX,IAAY,EACZ,OAAsB,EACtB,UAA4B;;QAE5B,OAAO,cAAc,CAAC,OAAO,EAAE,MAAM,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE,IAAI,CAAC,CAAA;IACxE,CAAC;CAAA;AAEK,SAAgB,GAAG,CACvB,OAAc,EACd,GAAW,EACX,IAAY,EACZ,OAAsB,EACtB,UAA4B;;QAE5B,OAAO,cAAc,CAAC,OAAO,EAAE,KAAK,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE,IAAI,CAAC,CAAA;IACvE,CAAC;CAAA;AAEK,SAAgB,IAAI,CACxB,OAAc,EACd,GAAW,EACX,OAAsB,EACtB,UAA4B;;QAE5B,OAAO,cAAc,CACnB,OAAO,EACP,MAAM,EACN,GAAG,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAEE,OAAO,GAAA;YACV,aAAa,EAAE,IAAI;QAAA,IAErB,UAAU,CACX,CAAA;IACH,CAAC;CAAA;AAEK,SAAgB,MAAM,CAC1B,OAAc,EACd,GAAW,EACX,IAAY,EACZ,OAAsB,EACtB,UAA4B;;QAE5B,OAAO,cAAc,CAAC,OAAO,EAAE,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE,IAAI,CAAC,CAAA;IAC1E,CAAC;CAAA"}},
    {"offset": {"line": 3755, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/packages/StreamDownloadBuilder.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/packages/StreamDownloadBuilder.ts"],"sourcesContent":["import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(private downloadFn: () => Promise<Response>, private shouldThrowOnError: boolean) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,cAAc,EAAE,MAAM,eAAe,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAGhC,MAAO,qBAAqB;IACxC,YAAoB,UAAmC,EAAU,kBAA2B,CAAA;QAAxE,IAAA,CAAA,UAAU,GAAV,UAAU,CAAyB;QAAU,IAAA,CAAA,kBAAkB,GAAlB,kBAAkB,CAAS;IAAG,CAAC;IAEhG,IAAI,CACF,WAEQ,EACR,UAAuE,EAAA;QAEvE,OAAO,IAAI,CAAC,OAAO,EAAE,CAAC,IAAI,CAAC,WAAW,EAAE,UAAU,CAAC,CAAA;IACrD,CAAC;IAEa,OAAO,GAAA;;YACnB,IAAI;gBACF,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,UAAU,EAAE,CAAA;gBAEtC,OAAO;oBACL,IAAI,EAAE,MAAM,CAAC,IAAsB;oBACnC,KAAK,EAAE,IAAI;iBACZ,CAAA;aACF,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBAED,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;CACF"}},
    {"offset": {"line": 3823, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/packages/BlobDownloadBuilder.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/packages/BlobDownloadBuilder.ts"],"sourcesContent":["import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements PromiseLike<DownloadResult<Blob>> {\n  constructor(private downloadFn: () => Promise<Response>, private shouldThrowOnError: boolean) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,cAAc,EAAE,MAAM,eAAe,CAAA;AAE9C,OAAO,qBAAqB,MAAM,yBAAyB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAE7C,MAAO,mBAAmB;IACtC,YAAoB,UAAmC,EAAU,kBAA2B,CAAA;QAAxE,IAAA,CAAA,UAAU,GAAV,UAAU,CAAyB;QAAU,IAAA,CAAA,kBAAkB,GAAlB,kBAAkB,CAAS;IAAG,CAAC;IAEhG,QAAQ,GAAA;QACN,OAAO,IAAI,qNAAqB,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,kBAAkB,CAAC,CAAA;IAC5E,CAAC;IAED,IAAI,CACF,WAAwF,EACxF,UAAuE,EAAA;QAEvE,OAAO,IAAI,CAAC,OAAO,EAAE,CAAC,IAAI,CAAC,WAAW,EAAE,UAAU,CAAC,CAAA;IACrD,CAAC;IAEa,OAAO,GAAA;;YACnB,IAAI;gBACF,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,UAAU,EAAE,CAAA;gBAEtC,OAAO;oBACL,IAAI,EAAE,MAAM,MAAM,CAAC,IAAI,EAAE;oBACzB,KAAK,EAAE,IAAI;iBACZ,CAAA;aACF,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBAED,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;CACF"}},
    {"offset": {"line": 3896, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/packages/StorageFileApi.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/packages/StorageFileApi.ts"],"sourcesContent":["import { isStorageError, StorageError, StorageUnknownError } from '../lib/errors'\nimport { Fetch, get, head, post, put, remove } from '../lib/fetch'\nimport { recursiveToCamel, resolveFetch } from '../lib/helpers'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected bucketId?: string\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    this.url = url\n    this.headers = headers\n    this.bucketId = bucketId\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return {\n        data: { path: cleanPath, id: data.Id, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    try {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return {\n        data: { path: cleanPath, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { data: { signedUrl: url.toString(), path, token }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data: { path: data.Key }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      data = { signedUrl }\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return {\n        data: data.map((datum: { signedURL: string }) => ({\n          ...datum,\n          signedUrl: datum.signedURL\n            ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n            : null,\n        })),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n        headers: this.headers,\n        noResolveJson: true,\n      })\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   * @param path\n   */\n  async info(\n    path: string\n  ): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: recursiveToCamel(data) as Camelize<FileObjectV2>, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Checks the existence of a file.\n   * @param path\n   */\n  async exists(\n    path: string\n  ): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = (error.originalError as unknown) as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   */\n  async remove(\n    paths: string[]\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...options }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n"],"names":[],"mappings":";;;;AA60Be;AA70Bf,OAAO,EAAE,cAAc,EAAE,YAAY,EAAE,mBAAmB,EAAE,MAAM,eAAe,CAAA;AACjF,OAAO,EAAS,GAAG,EAAE,IAAI,EAAE,IAAI,EAAE,GAAG,EAAE,MAAM,EAAE,MAAM,cAAc,CAAA;AAClE,OAAO,EAAE,gBAAgB,EAAE,YAAY,EAAE,MAAM,gBAAgB,CAAA;AAa/D,OAAO,mBAAmB,MAAM,uBAAuB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEvD,MAAM,sBAAsB,GAAG;IAC7B,KAAK,EAAE,GAAG;IACV,MAAM,EAAE,CAAC;IACT,MAAM,EAAE;QACN,MAAM,EAAE,MAAM;QACd,KAAK,EAAE,KAAK;KACb;CACF,CAAA;AAED,MAAM,oBAAoB,GAAgB;IACxC,YAAY,EAAE,MAAM;IACpB,WAAW,EAAE,0BAA0B;IACvC,MAAM,EAAE,KAAK;CACd,CAAA;AAca,MAAO,cAAc;IAOjC,YACE,GAAW,EACX,UAAqC,CAAA,CAAE,EACvC,QAAiB,EACjB,KAAa,CAAA;QANL,IAAA,CAAA,kBAAkB,GAAG,KAAK,CAAA;QAQlC,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;QACd,IAAI,CAAC,OAAO,GAAG,OAAO,CAAA;QACtB,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAA;QACxB,IAAI,CAAC,KAAK,OAAG,uMAAY,EAAC,KAAK,CAAC,CAAA;IAClC,CAAC;IAED;;OAEG,CACI,YAAY,GAAA;QACjB,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAA;QAC9B,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;;;;;OAMG,CACW,cAAc,CAC1B,MAAsB,EACtB,IAAY,EACZ,QAAkB,EAClB,WAAyB,EAAA;;YAWzB,IAAI;gBACF,IAAI,IAAI,CAAA;gBACR,MAAM,OAAO,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,oBAAoB,GAAK,WAAW,CAAE,CAAA;gBAC3D,IAAI,OAAO,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACN,IAAI,CAAC,OAAO,GACZ,AAAC,MAAM,KAAK,MAAM,IAAI;oBAAE,UAAU,EAAE,MAAM,CAAC,OAAO,CAAC,MAAiB,CAAC;gBAAA,CAAE,CAAC,CAC5E,CAAA;gBAED,MAAM,QAAQ,GAAG,OAAO,CAAC,QAAQ,CAAA;gBAEjC,IAAI,OAAO,IAAI,KAAK,WAAW,IAAI,QAAQ,YAAY,IAAI,EAAE;oBAC3D,IAAI,GAAG,IAAI,QAAQ,EAAE,CAAA;oBACrB,IAAI,CAAC,MAAM,CAAC,cAAc,EAAE,OAAO,CAAC,YAAsB,CAAC,CAAA;oBAC3D,IAAI,QAAQ,EAAE;wBACZ,IAAI,CAAC,MAAM,CAAC,UAAU,EAAE,IAAI,CAAC,cAAc,CAAC,QAAQ,CAAC,CAAC,CAAA;qBACvD;oBACD,IAAI,CAAC,MAAM,CAAC,EAAE,EAAE,QAAQ,CAAC,CAAA;iBAC1B,MAAM,IAAI,OAAO,QAAQ,KAAK,WAAW,IAAI,QAAQ,YAAY,QAAQ,EAAE;oBAC1E,IAAI,GAAG,QAAQ,CAAA;oBACf,IAAI,CAAC,MAAM,CAAC,cAAc,EAAE,OAAO,CAAC,YAAsB,CAAC,CAAA;oBAC3D,IAAI,QAAQ,EAAE;wBACZ,IAAI,CAAC,MAAM,CAAC,UAAU,EAAE,IAAI,CAAC,cAAc,CAAC,QAAQ,CAAC,CAAC,CAAA;qBACvD;iBACF,MAAM;oBACL,IAAI,GAAG,QAAQ,CAAA;oBACf,OAAO,CAAC,eAAe,CAAC,GAAG,CAAA,QAAA,EAAW,OAAO,CAAC,YAAY,EAAE,CAAA;oBAC5D,OAAO,CAAC,cAAc,CAAC,GAAG,OAAO,CAAC,WAAqB,CAAA;oBAEvD,IAAI,QAAQ,EAAE;wBACZ,OAAO,CAAC,YAAY,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,cAAc,CAAC,QAAQ,CAAC,CAAC,CAAA;qBACrE;iBACF;gBAED,IAAI,WAAW,KAAA,QAAX,WAAW,KAAA,KAAA,IAAA,KAAA,IAAX,WAAW,CAAE,OAAO,EAAE;oBACxB,OAAO,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,OAAO,GAAK,WAAW,CAAC,OAAO,CAAE,CAAA;iBACjD;gBAED,MAAM,SAAS,GAAG,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC,CAAA;gBAChD,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,SAAS,CAAC,CAAA;gBAC3C,MAAM,IAAI,GAAG,MAAM,CAAC,MAAM,IAAI,KAAK,CAAC,CAAC,CAAC,4LAAG,CAAC,CAAC,CAAC,6LAAI,CAAC,CAC/C,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,KAAK,EAAE,EAC7B,IAAc,EAAA,OAAA,MAAA,CAAA;oBACZ,OAAO;gBAAA,GAAK,AAAC,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,EAAC,CAAC,CAAC;oBAAE,MAAM,EAAE,OAAO,CAAC,MAAM;gBAAA,CAAE,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,EAClE,CAAA;gBAED,OAAO;oBACL,IAAI,EAAE;wBAAE,IAAI,EAAE,SAAS;wBAAE,EAAE,EAAE,IAAI,CAAC,EAAE;wBAAE,QAAQ,EAAE,IAAI,CAAC,GAAG;oBAAA,CAAE;oBAC1D,KAAK,EAAE,IAAI;iBACZ,CAAA;aACF,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;OAKG,CACG,MAAM,CACV,IAAY,EACZ,QAAkB,EAClB,WAAyB,EAAA;;YAWzB,OAAO,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,IAAI,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAA;QACjE,CAAC;KAAA;IAED;;;;;OAKG,CACG,iBAAiB,CACrB,IAAY,EACZ,KAAa,EACb,QAAkB,EAClB,WAAyB,EAAA;;YAEzB,MAAM,SAAS,GAAG,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC,CAAA;YAChD,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,SAAS,CAAC,CAAA;YAE3C,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,IAAI,CAAC,GAAG,GAAG,CAAA,oBAAA,EAAuB,KAAK,EAAE,CAAC,CAAA;YAC9D,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,OAAO,EAAE,KAAK,CAAC,CAAA;YAEpC,IAAI;gBACF,IAAI,IAAI,CAAA;gBACR,MAAM,OAAO,GAAA,OAAA,MAAA,CAAA;oBAAK,MAAM,EAAE,oBAAoB,CAAC,MAAM;gBAAA,GAAK,WAAW,CAAE,CAAA;gBACvE,MAAM,OAAO,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACR,IAAI,CAAC,OAAO,GACZ;oBAAE,UAAU,EAAE,MAAM,CAAC,OAAO,CAAC,MAAiB,CAAC;gBAAA,CAAE,CACrD,CAAA;gBAED,IAAI,OAAO,IAAI,KAAK,WAAW,IAAI,QAAQ,YAAY,IAAI,EAAE;oBAC3D,IAAI,GAAG,IAAI,QAAQ,EAAE,CAAA;oBACrB,IAAI,CAAC,MAAM,CAAC,cAAc,EAAE,OAAO,CAAC,YAAsB,CAAC,CAAA;oBAC3D,IAAI,CAAC,MAAM,CAAC,EAAE,EAAE,QAAQ,CAAC,CAAA;iBAC1B,MAAM,IAAI,OAAO,QAAQ,KAAK,WAAW,IAAI,QAAQ,YAAY,QAAQ,EAAE;oBAC1E,IAAI,GAAG,QAAQ,CAAA;oBACf,IAAI,CAAC,MAAM,CAAC,cAAc,EAAE,OAAO,CAAC,YAAsB,CAAC,CAAA;iBAC5D,MAAM;oBACL,IAAI,GAAG,QAAQ,CAAA;oBACf,OAAO,CAAC,eAAe,CAAC,GAAG,CAAA,QAAA,EAAW,OAAO,CAAC,YAAY,EAAE,CAAA;oBAC5D,OAAO,CAAC,cAAc,CAAC,GAAG,OAAO,CAAC,WAAqB,CAAA;iBACxD;gBAED,MAAM,IAAI,GAAG,MAAM,GAAG,+LAAC,IAAI,CAAC,KAAK,EAAE,GAAG,CAAC,QAAQ,EAAE,EAAE,IAAc,EAAE;oBAAE,OAAO;gBAAA,CAAE,CAAC,CAAA;gBAE/E,OAAO;oBACL,IAAI,EAAE;wBAAE,IAAI,EAAE,SAAS;wBAAE,QAAQ,EAAE,IAAI,CAAC,GAAG;oBAAA,CAAE;oBAC7C,KAAK,EAAE,IAAI;iBACZ,CAAA;aACF,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;OAMG,CACG,qBAAqB,CACzB,IAAY,EACZ,OAA6B,EAAA;;YAW7B,IAAI;gBACF,IAAI,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAA;gBAEpC,MAAM,OAAO,GAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,IAAI,CAAC,OAAO,CAAE,CAAA;gBAEnC,IAAI,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM,EAAE;oBACnB,OAAO,CAAC,UAAU,CAAC,GAAG,MAAM,CAAA;iBAC7B;gBAED,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,oBAAA,EAAuB,KAAK,EAAE,EACzC,CAAA,CAAE,EACF;oBAAE,OAAO;gBAAA,CAAE,CACZ,CAAA;gBAED,MAAM,GAAG,GAAG,IAAI,GAAG,CAAC,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,GAAG,CAAC,CAAA;gBAExC,MAAM,KAAK,GAAG,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,OAAO,CAAC,CAAA;gBAE3C,IAAI,CAAC,KAAK,EAAE;oBACV,MAAM,IAAI,sMAAY,CAAC,0BAA0B,CAAC,CAAA;iBACnD;gBAED,OAAO;oBAAE,IAAI,EAAE;wBAAE,SAAS,EAAE,GAAG,CAAC,QAAQ,EAAE;wBAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aACzE,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;OAKG,CACG,MAAM,CACV,IAAY,EACZ,QAUU,EACV,WAAyB,EAAA;;YAWzB,OAAO,IAAI,CAAC,cAAc,CAAC,KAAK,EAAE,IAAI,EAAE,QAAQ,EAAE,WAAW,CAAC,CAAA;QAChE,CAAC;KAAA;IAED;;;;;;OAMG,CACG,IAAI,CACR,QAAgB,EAChB,MAAc,EACd,OAA4B,EAAA;;YAW5B,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,YAAA,CAAc,EACzB;oBACE,QAAQ,EAAE,IAAI,CAAC,QAAQ;oBACvB,SAAS,EAAE,QAAQ;oBACnB,cAAc,EAAE,MAAM;oBACtB,iBAAiB,EAAE,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,iBAAiB;iBAC9C,EACD;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;OAMG,CACG,IAAI,CACR,QAAgB,EAChB,MAAc,EACd,OAA4B,EAAA;;YAW5B,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,YAAA,CAAc,EACzB;oBACE,QAAQ,EAAE,IAAI,CAAC,QAAQ;oBACvB,SAAS,EAAE,QAAQ;oBACnB,cAAc,EAAE,MAAM;oBACtB,iBAAiB,EAAE,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,iBAAiB;iBAC9C,EACD;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI,EAAE;wBAAE,IAAI,EAAE,IAAI,CAAC,GAAG;oBAAA,CAAE;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aACjD,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;;OAOG,CACG,eAAe,CACnB,IAAY,EACZ,SAAiB,EACjB,OAAuE,EAAA;;YAWvE,IAAI;gBACF,IAAI,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAA;gBAEpC,IAAI,IAAI,GAAG,MAAM,IAAI,+LACnB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,aAAA,EAAgB,KAAK,EAAE,EAAA,OAAA,MAAA,CAAA;oBAChC,SAAS;gBAAA,GAAK,AAAC,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,EAAC,CAAC,CAAC;oBAAE,SAAS,EAAE,OAAO,CAAC,SAAS;gBAAA,CAAE,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,EAC5E;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,MAAM,kBAAkB,GAAG,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,QAAQ,IACxC,CAAA,UAAA,EAAa,OAAO,CAAC,QAAQ,KAAK,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,QAAQ,EAAE,GAChE,EAAE,CAAA;gBACN,MAAM,SAAS,GAAG,SAAS,CAAC,GAAG,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,SAAS,GAAG,kBAAkB,EAAE,CAAC,CAAA;gBAChF,IAAI,GAAG;oBAAE,SAAS;gBAAA,CAAE,CAAA;gBACpB,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;OAMG,CACG,gBAAgB,CACpB,KAAe,EACf,SAAiB,EACjB,OAAwC,EAAA;;YAWxC,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,aAAA,EAAgB,IAAI,CAAC,QAAQ,EAAE,EAC1C;oBAAE,SAAS;oBAAE,KAAK;gBAAA,CAAE,EACpB;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBAED,MAAM,kBAAkB,GAAG,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,QAAQ,IACxC,CAAA,UAAA,EAAa,OAAO,CAAC,QAAQ,KAAK,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,QAAQ,EAAE,GAChE,EAAE,CAAA;gBACN,OAAO;oBACL,IAAI,EAAE,IAAI,CAAC,GAAG,CAAC,CAAC,KAA4B,EAAE,CAAG,CAAD,CAAC,KAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAC5C,KAAK,GAAA;4BACR,SAAS,EAAE,KAAK,CAAC,SAAS,GACtB,SAAS,CAAC,GAAG,IAAI,CAAC,GAAG,GAAG,KAAK,CAAC,SAAS,GAAG,kBAAkB,EAAE,CAAC,GAC/D,IAAI;wBAAA,GACR,CAAC;oBACH,KAAK,EAAE,IAAI;iBACZ,CAAA;aACF,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;OAKG,CACH,QAAQ,CACN,IAAY,EACZ,OAAiB,EAAA;QAEjB,MAAM,mBAAmB,GAAG,OAAO,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,CAAA,KAAK,WAAW,CAAA;QACrE,MAAM,UAAU,GAAG,mBAAmB,CAAC,CAAC,CAAC,4BAA4B,CAAC,CAAC,CAAC,QAAQ,CAAA;QAChF,MAAM,mBAAmB,GAAG,IAAI,CAAC,0BAA0B,CAAC,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,KAAI,CAAA,CAAE,CAAC,CAAA;QACrF,MAAM,WAAW,GAAG,mBAAmB,CAAC,CAAC,CAAC,CAAA,CAAA,EAAI,mBAAmB,EAAE,CAAC,CAAC,CAAC,EAAE,CAAA;QACxE,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAA;QACtC,MAAM,UAAU,GAAG,GAAG,EAAE,GACtB,4LAAG,EAAC,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,GAAG,CAAA,CAAA,EAAI,UAAU,CAAA,CAAA,EAAI,KAAK,GAAG,WAAW,EAAE,EAAE;gBAClE,OAAO,EAAE,IAAI,CAAC,OAAO;gBACrB,aAAa,EAAE,IAAI;aACpB,CAAC,CAAA;QACJ,OAAO,IAAI,mNAAmB,CAAC,UAAU,EAAE,IAAI,CAAC,kBAAkB,CAAC,CAAA;IACrE,CAAC;IAED;;;OAGG,CACG,IAAI,CACR,IAAY,EAAA;;YAWZ,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAA;YAEtC,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,GAAG,+LAAC,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,GAAG,CAAA,aAAA,EAAgB,KAAK,EAAE,EAAE;oBACrE,OAAO,EAAE,IAAI,CAAC,OAAO;iBACtB,CAAC,CAAA;gBAEF,OAAO;oBAAE,IAAI,EAAE,gBAAgB,iMAAC,IAAI,CAA2B;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC/E,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;OAGG,CACG,MAAM,CACV,IAAY,EAAA;;YAWZ,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAA;YAEtC,IAAI;gBACF,MAAM,IAAI,+LAAC,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,KAAK,EAAE,EAAE;oBACpD,OAAO,EAAE,IAAI,CAAC,OAAO;iBACtB,CAAC,CAAA;gBAEF,OAAO;oBAAE,IAAI,EAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aACnC,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,IAAI,KAAK,YAAY,6MAAmB,EAAE;oBACjE,MAAM,aAAa,GAAI,KAAK,CAAC,aAA+C,CAAA;oBAE5E,IAAI;wBAAC,GAAG;wBAAE,GAAG;qBAAC,CAAC,QAAQ,CAAC,aAAa,KAAA,QAAb,aAAa,KAAA,KAAA,IAAA,KAAA,IAAb,aAAa,CAAE,MAAM,CAAC,EAAE;wBAC9C,OAAO;4BAAE,IAAI,EAAE,KAAK;4BAAE,KAAK;wBAAA,CAAE,CAAA;qBAC9B;iBACF;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;;OAOG,CACH,YAAY,CACV,IAAY,EACZ,OAAuE,EAAA;QAEvE,MAAM,KAAK,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,CAAA;QACtC,MAAM,YAAY,GAAG,EAAE,CAAA;QAEvB,MAAM,kBAAkB,GAAG,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,QAAQ,IACxC,CAAA,SAAA,EAAY,OAAO,CAAC,QAAQ,KAAK,IAAI,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,OAAO,CAAC,QAAQ,EAAE,GAC/D,EAAE,CAAA;QAEN,IAAI,kBAAkB,KAAK,EAAE,EAAE;YAC7B,YAAY,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAA;SACtC;QAED,MAAM,mBAAmB,GAAG,OAAO,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,CAAA,KAAK,WAAW,CAAA;QACrE,MAAM,UAAU,GAAG,mBAAmB,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC,QAAQ,CAAA;QAClE,MAAM,mBAAmB,GAAG,IAAI,CAAC,0BAA0B,CAAC,CAAA,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,SAAS,KAAI,CAAA,CAAE,CAAC,CAAA;QAErF,IAAI,mBAAmB,KAAK,EAAE,EAAE;YAC9B,YAAY,CAAC,IAAI,CAAC,mBAAmB,CAAC,CAAA;SACvC;QAED,IAAI,WAAW,GAAG,YAAY,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA;QACxC,IAAI,WAAW,KAAK,EAAE,EAAE;YACtB,WAAW,GAAG,CAAA,CAAA,EAAI,WAAW,EAAE,CAAA;SAChC;QAED,OAAO;YACL,IAAI,EAAE;gBAAE,SAAS,EAAE,SAAS,CAAC,GAAG,IAAI,CAAC,GAAG,CAAA,CAAA,EAAI,UAAU,CAAA,QAAA,EAAW,KAAK,GAAG,WAAW,EAAE,CAAC;YAAA,CAAE;SAC1F,CAAA;IACH,CAAC;IAED;;;;OAIG,CACG,MAAM,CACV,KAAe,EAAA;;YAWf,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,MAAM,+LACvB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,IAAI,CAAC,QAAQ,EAAE,EACrC;oBAAE,QAAQ,EAAE,KAAK;gBAAA,CAAE,EACnB;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;OAGG,CACH,qBAAqB;IACrB,eAAe;IACf,cAAc;IACd,QAAQ;IACR,uBAAuB;IACvB,oBAAoB;IACpB,QAAQ;IACR,QAAQ;IACR,mBAAmB;IACnB,4BAA4B;IAC5B,QAAQ;IACR,MAAM;IACN,UAAU;IACV,kGAAkG;IAClG,mCAAmC;IACnC,sBAAsB;IACtB,mCAAmC;IACnC,qCAAqC;IACrC,QAAQ;IAER,kBAAkB;IAClB,MAAM;IACN,IAAI;IAEJ;;;;OAIG,CACH,wBAAwB;IACxB,gBAAgB;IAChB,mBAAmB;IACnB,cAAc;IACd,QAAQ;IACR,uBAAuB;IACvB,oBAAoB;IACpB,QAAQ;IACR,QAAQ;IACR,mBAAmB;IACnB,4BAA4B;IAC5B,QAAQ;IACR,MAAM;IACN,UAAU;IACV,+BAA+B;IAC/B,oBAAoB;IACpB,sCAAsC;IACtC,qBAAqB;IACrB,kCAAkC;IAClC,QAAQ;IACR,mCAAmC;IACnC,sBAAsB;IACtB,mCAAmC;IACnC,qCAAqC;IACrC,QAAQ;IAER,kBAAkB;IAClB,MAAM;IACN,IAAI;IAEJ;;;;OAIG,CACG,IAAI,CACR,IAAa,EACb,OAAuB,EACvB,UAA4B,EAAA;;YAW5B,IAAI;gBACF,MAAM,IAAI,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,sBAAsB,GAAK,OAAO,GAAA;oBAAE,MAAM,EAAE,IAAI,IAAI,EAAE;gBAAA,EAAE,CAAA;gBAC1E,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,aAAA,EAAgB,IAAI,CAAC,QAAQ,EAAE,EAC1C,IAAI,EACJ;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,EACzB,UAAU,CACX,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;OAIG,CACG,MAAM,CACV,OAAyB,EACzB,UAA4B,EAAA;;YAW5B,IAAI;gBACF,MAAM,IAAI,GAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,OAAO,CAAE,CAAA;gBAC3B,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,gBAAA,EAAmB,IAAI,CAAC,QAAQ,EAAE,EAC7C,IAAI,EACJ;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,EACzB,UAAU,CACX,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAES,cAAc,CAAC,QAA6B,EAAA;QACpD,OAAO,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,CAAA;IACjC,CAAC;IAED,QAAQ,CAAC,IAAY,EAAA;QACnB,IAAI,sIAAa,KAAK,WAAW,EAAE;YACjC,OAAO,+HAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,QAAQ,CAAC,QAAQ,CAAC,CAAA;SAC5C;QACD,OAAO,IAAI,CAAC,IAAI,CAAC,CAAA;IACnB,CAAC;IAEO,aAAa,CAAC,IAAY,EAAA;QAChC,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAA,CAAA,EAAI,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE,CAAA;IACvD,CAAC;IAEO,mBAAmB,CAAC,IAAY,EAAA;QACtC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,EAAE,EAAE,CAAC,CAAC,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAA;IAC1D,CAAC;IAEO,0BAA0B,CAAC,SAA2B,EAAA;QAC5D,MAAM,MAAM,GAAG,EAAE,CAAA;QACjB,IAAI,SAAS,CAAC,KAAK,EAAE;YACnB,MAAM,CAAC,IAAI,CAAC,CAAA,MAAA,EAAS,SAAS,CAAC,KAAK,EAAE,CAAC,CAAA;SACxC;QAED,IAAI,SAAS,CAAC,MAAM,EAAE;YACpB,MAAM,CAAC,IAAI,CAAC,CAAA,OAAA,EAAU,SAAS,CAAC,MAAM,EAAE,CAAC,CAAA;SAC1C;QAED,IAAI,SAAS,CAAC,MAAM,EAAE;YACpB,MAAM,CAAC,IAAI,CAAC,CAAA,OAAA,EAAU,SAAS,CAAC,MAAM,EAAE,CAAC,CAAA;SAC1C;QAED,IAAI,SAAS,CAAC,MAAM,EAAE;YACpB,MAAM,CAAC,IAAI,CAAC,CAAA,OAAA,EAAU,SAAS,CAAC,MAAM,EAAE,CAAC,CAAA;SAC1C;QAED,IAAI,SAAS,CAAC,OAAO,EAAE;YACrB,MAAM,CAAC,IAAI,CAAC,CAAA,QAAA,EAAW,SAAS,CAAC,OAAO,EAAE,CAAC,CAAA;SAC5C;QAED,OAAO,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAA;IACzB,CAAC;CACF"}},
    {"offset": {"line": 4594, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/lib/version.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/lib/version.ts"],"sourcesContent":["// generated by genversion\nexport const version = '2.12.2'\n"],"names":[],"mappings":"AAAA,0BAA0B;;;;;AACnB,MAAM,OAAO,GAAG,OAAO,CAAA"}},
    {"offset": {"line": 4604, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/lib/constants.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/lib/constants.ts"],"sourcesContent":["import { version } from './version'\nexport const DEFAULT_HEADERS = { 'X-Client-Info': `storage-js/${version}` }\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAA;;AAC5B,MAAM,eAAe,GAAG;IAAE,eAAe,EAAE,CAAA,WAAA,EAAc,kMAAO,EAAE;AAAA,CAAE,CAAA"}},
    {"offset": {"line": 4617, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/packages/StorageBucketApi.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/packages/StorageBucketApi.ts"],"sourcesContent":["import { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, put, remove } from '../lib/fetch'\nimport { resolveFetch } from '../lib/helpers'\nimport { Bucket, BucketType } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    this.url = baseUrl.href\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   */\n  async listBuckets(): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await get(this.fetch, `${this.url}/bucket`, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   */\n  async getBucket(\n    id: string\n  ): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns newly created bucket id\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @param id The unique identifier of the bucket you would like to empty.\n   */\n  async emptyBucket(\n    id: string\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket/${id}/empty`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @param id The unique identifier of the bucket you would like to delete.\n   */\n  async deleteBucket(\n    id: string\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,eAAe,EAAE,MAAM,kBAAkB,CAAA;AAClD,OAAO,EAAE,cAAc,EAAgB,MAAM,eAAe,CAAA;AAC5D,OAAO,EAAS,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,MAAM,EAAE,MAAM,cAAc,CAAA;AAC5D,OAAO,EAAE,YAAY,EAAE,MAAM,gBAAgB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAI/B,MAAO,gBAAgB;IAMnC,YACE,GAAW,EACX,UAAqC,CAAA,CAAE,EACvC,KAAa,EACb,IAA2B,CAAA;QANnB,IAAA,CAAA,kBAAkB,GAAG,KAAK,CAAA;QAQlC,MAAM,OAAO,GAAG,IAAI,GAAG,CAAC,GAAG,CAAC,CAAA;QAE5B,4GAA4G;QAC5G,sEAAsE;QACtE,IAAI,IAAI,KAAA,QAAJ,IAAI,KAAA,KAAA,IAAA,KAAA,IAAJ,IAAI,CAAE,cAAc,EAAE;YACxB,MAAM,cAAc,GAAG,wBAAwB,CAAC,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAA;YACtE,IAAI,cAAc,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,QAAQ,CAAC,mBAAmB,CAAC,EAAE;gBACrE,OAAO,CAAC,QAAQ,GAAG,OAAO,CAAC,QAAQ,CAAC,OAAO,CAAC,WAAW,EAAE,mBAAmB,CAAC,CAAA;aAC9E;SACF;QAED,IAAI,CAAC,GAAG,GAAG,OAAO,CAAC,IAAI,CAAA;QACvB,IAAI,CAAC,OAAO,GAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAQ,4MAAe,GAAK,OAAO,CAAE,CAAA;QACjD,IAAI,CAAC,KAAK,OAAG,uMAAY,EAAC,KAAK,CAAC,CAAA;IAClC,CAAC;IAED;;OAEG,CACI,YAAY,GAAA;QACjB,IAAI,CAAC,kBAAkB,GAAG,IAAI,CAAA;QAC9B,OAAO,IAAI,CAAA;IACb,CAAC;IAED;;OAEG,CACG,WAAW,GAAA;;YAUf,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,GAAG,+LAAC,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,GAAG,CAAA,OAAA,CAAS,EAAE;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAAC,CAAA;gBACnF,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;OAIG,CACG,SAAS,CACb,EAAU,EAAA;;YAWV,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,GAAG,+LAAC,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,EAAE,EAAE,EAAE;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAAC,CAAA;gBACzF,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;;;;;;;;;OAcG,CACG,YAAY,CAChB,EAAU,EACV,UAKI;QACF,MAAM,EAAE,KAAK;KACd,EAAA;;YAWD,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,OAAA,CAAS,EACpB;oBACE,EAAE;oBACF,IAAI,EAAE,EAAE;oBACR,IAAI,EAAE,OAAO,CAAC,IAAI;oBAClB,MAAM,EAAE,OAAO,CAAC,MAAM;oBACtB,eAAe,EAAE,OAAO,CAAC,aAAa;oBACtC,kBAAkB,EAAE,OAAO,CAAC,gBAAgB;iBAC7C,EACD;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;;;;;;;OAWG,CACG,YAAY,CAChB,EAAU,EACV,OAIC,EAAA;;YAWD,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,GAAG,+LACpB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,EAAE,EAAE,EAC1B;oBACE,EAAE;oBACF,IAAI,EAAE,EAAE;oBACR,MAAM,EAAE,OAAO,CAAC,MAAM;oBACtB,eAAe,EAAE,OAAO,CAAC,aAAa;oBACtC,kBAAkB,EAAE,OAAO,CAAC,gBAAgB;iBAC7C,EACD;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;OAIG,CACG,WAAW,CACf,EAAU,EAAA;;YAWV,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,IAAI,+LACrB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,EAAE,CAAA,MAAA,CAAQ,EAChC,CAAA,CAAE,EACF;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;IAED;;;;;OAKG,CACG,YAAY,CAChB,EAAU,EAAA;;YAWV,IAAI;gBACF,MAAM,IAAI,GAAG,MAAM,MAAM,+LACvB,IAAI,CAAC,KAAK,EACV,GAAG,IAAI,CAAC,GAAG,CAAA,QAAA,EAAW,EAAE,EAAE,EAC1B,CAAA,CAAE,EACF;oBAAE,OAAO,EAAE,IAAI,CAAC,OAAO;gBAAA,CAAE,CAC1B,CAAA;gBACD,OAAO;oBAAE,IAAI;oBAAE,KAAK,EAAE,IAAI;gBAAA,CAAE,CAAA;aAC7B,CAAC,OAAO,KAAK,EAAE;gBACd,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,MAAM,KAAK,CAAA;iBACZ;gBACD,IAAI,cAAc,gMAAC,KAAK,CAAC,EAAE;oBACzB,OAAO;wBAAE,IAAI,EAAE,IAAI;wBAAE,KAAK;oBAAA,CAAE,CAAA;iBAC7B;gBAED,MAAM,KAAK,CAAA;aACZ;QACH,CAAC;KAAA;CACF"}},
    {"offset": {"line": 4882, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/storage-js/dist/module/StorageClient.js","sources":["turbopack:///[project]/node_modules/@supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport { Fetch } from './lib/fetch'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @param id The bucket id to operate on.\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,cAAc,MAAM,2BAA2B,CAAA;AACtD,OAAO,gBAAgB,MAAM,6BAA6B,CAAA;;;AAOpD,MAAO,aAAc,SAAQ,gNAAgB;IACjD,YACE,GAAW,EACX,UAAqC,CAAA,CAAE,EACvC,KAAa,EACb,IAA2B,CAAA;QAE3B,KAAK,CAAC,GAAG,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,CAAA;IAClC,CAAC;IAED;;;;OAIG,CACH,IAAI,CAAC,EAAU,EAAA;QACb,OAAO,IAAI,8MAAc,CAAC,IAAI,CAAC,GAAG,EAAE,IAAI,CAAC,OAAO,EAAE,EAAE,EAAE,IAAI,CAAC,KAAK,CAAC,CAAA;IACnE,CAAC;CACF"}},
    {"offset": {"line": 4906, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/lib/version.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/lib/version.ts"],"sourcesContent":["export const version = '2.58.0'\n"],"names":[],"mappings":";;;;AAAO,MAAM,OAAO,GAAG,iBAAiB,CAAA"}},
    {"offset": {"line": 4915, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/lib/constants.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/lib/constants.ts"],"sourcesContent":["// constants.ts\nimport { RealtimeClientOptions } from '@supabase/realtime-js'\nimport { SupabaseAuthClientOptions } from './types'\nimport { version } from './version'\n\nlet JS_ENV = ''\n// @ts-ignore\nif (typeof Deno !== 'undefined') {\n  JS_ENV = 'deno'\n} else if (typeof document !== 'undefined') {\n  JS_ENV = 'web'\n} else if (typeof navigator !== 'undefined' && navigator.product === 'ReactNative') {\n  JS_ENV = 'react-native'\n} else {\n  JS_ENV = 'node'\n}\n\nexport const DEFAULT_HEADERS = { 'X-Client-Info': `supabase-js-${JS_ENV}/${version}` }\n\nexport const DEFAULT_GLOBAL_OPTIONS = {\n  headers: DEFAULT_HEADERS,\n}\n\nexport const DEFAULT_DB_OPTIONS = {\n  schema: 'public',\n}\n\nexport const DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions = {\n  autoRefreshToken: true,\n  persistSession: true,\n  detectSessionInUrl: true,\n  flowType: 'implicit',\n}\n\nexport const DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions = {}\n"],"names":[],"mappings":";;;;;;;;;;;;AAGA,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAA;;AAEnC,IAAI,MAAM,GAAG,EAAE,CAAA;AACf,aAAa;AACb,IAAI,OAAO,IAAI,KAAK,WAAW,EAAE;IAC/B,MAAM,GAAG,MAAM,CAAA;CAChB,MAAM,IAAI,OAAO,QAAQ,KAAK,WAAW,EAAE;IAC1C,MAAM,GAAG,KAAK,CAAA;CACf,MAAM,IAAI,OAAO,SAAS,KAAK,WAAW,IAAI,SAAS,CAAC,OAAO,KAAK,aAAa,EAAE;IAClF,MAAM,GAAG,cAAc,CAAA;CACxB,MAAM;IACL,MAAM,GAAG,MAAM,CAAA;CAChB;AAEM,MAAM,eAAe,GAAG;IAAE,eAAe,EAAE,CAAA,YAAA,EAAe,MAAM,CAAA,CAAA,EAAI,mMAAO,EAAE;AAAA,CAAE,CAAA;AAE/E,MAAM,sBAAsB,GAAG;IACpC,OAAO,EAAE,eAAe;CACzB,CAAA;AAEM,MAAM,kBAAkB,GAAG;IAChC,MAAM,EAAE,QAAQ;CACjB,CAAA;AAEM,MAAM,oBAAoB,GAA8B;IAC7D,gBAAgB,EAAE,IAAI;IACtB,cAAc,EAAE,IAAI;IACpB,kBAAkB,EAAE,IAAI;IACxB,QAAQ,EAAE,UAAU;CACrB,CAAA;AAEM,MAAM,wBAAwB,GAA0B,CAAA,CAAE,CAAA"}},
    {"offset": {"line": 4960, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/lib/fetch.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/lib/fetch.ts"],"sourcesContent":["// @ts-ignore\nimport nodeFetch, { Headers as NodeFetchHeaders } from '@supabase/node-fetch'\n\ntype Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  let _fetch: Fetch\n  if (customFetch) {\n    _fetch = customFetch\n  } else if (typeof fetch === 'undefined') {\n    _fetch = nodeFetch as unknown as Fetch\n  } else {\n    _fetch = fetch\n  }\n  return (...args: Parameters<Fetch>) => _fetch(...args)\n}\n\nexport const resolveHeadersConstructor = () => {\n  if (typeof Headers === 'undefined') {\n    return NodeFetchHeaders\n  }\n\n  return Headers\n}\n\nexport const fetchWithAuth = (\n  supabaseKey: string,\n  getAccessToken: () => Promise<string | null>,\n  customFetch?: Fetch\n): Fetch => {\n  const fetch = resolveFetch(customFetch)\n  const HeadersConstructor = resolveHeadersConstructor()\n\n  return async (input, init) => {\n    const accessToken = (await getAccessToken()) ?? supabaseKey\n    let headers = new HeadersConstructor(init?.headers)\n\n    if (!headers.has('apikey')) {\n      headers.set('apikey', supabaseKey)\n    }\n\n    if (!headers.has('Authorization')) {\n      headers.set('Authorization', `Bearer ${accessToken}`)\n    }\n\n    return fetch(input, { ...init, headers })\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA,aAAa;AACb,OAAO,SAAS,EAAE,EAAE,OAAO,IAAI,gBAAgB,EAAE,MAAM,sBAAsB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAItE,MAAM,YAAY,GAAG,CAAC,WAAmB,EAAS,EAAE;IACzD,IAAI,MAAa,CAAA;IACjB,IAAI,WAAW,EAAE;QACf,MAAM,GAAG,WAAW,CAAA;KACrB,MAAM,IAAI,OAAO,KAAK,KAAK,WAAW,EAAE;QACvC,MAAM,GAAG,yKAA6B,CAAA;KACvC,MAAM;QACL,MAAM,GAAG,KAAK,CAAA;KACf;IACD,OAAO,CAAC,GAAG,IAAuB,EAAE,CAAG,CAAD,KAAO,CAAC,GAAG,IAAI,CAAC,CAAA;AACxD,CAAC,CAAA;AAEM,MAAM,yBAAyB,GAAG,GAAG,EAAE;IAC5C,IAAI,OAAO,OAAO,KAAK,WAAW,EAAE;QAClC,OAAO,yKAAgB,CAAA;KACxB;IAED,OAAO,OAAO,CAAA;AAChB,CAAC,CAAA;AAEM,MAAM,aAAa,GAAG,CAC3B,WAAmB,EACnB,cAA4C,EAC5C,WAAmB,EACZ,EAAE;IACT,MAAM,KAAK,IAAG,YAAY,CAAC,WAAW,CAAC,CAAA;IACvC,MAAM,kBAAkB,GAAG,yBAAyB,EAAE,CAAA;IAEtD,OAAO,CAAO,KAAK,EAAE,IAAI,EAAE,CAAE,CAAA,SAAA,KAAA,GAAA,KAAA,GAAA,KAAA,GAAA;;YAC3B,MAAM,WAAW,GAAG,CAAA,KAAA,AAAC,MAAM,cAAc,EAAE,AAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,WAAW,CAAA;YAC3D,IAAI,OAAO,GAAG,IAAI,kBAAkB,CAAC,IAAI,KAAA,QAAJ,IAAI,KAAA,KAAA,IAAA,KAAA,IAAJ,IAAI,CAAE,OAAO,CAAC,CAAA;YAEnD,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE;gBAC1B,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAA;aACnC;YAED,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,eAAe,CAAC,EAAE;gBACjC,OAAO,CAAC,GAAG,CAAC,eAAe,EAAE,CAAA,OAAA,EAAU,WAAW,EAAE,CAAC,CAAA;aACtD;YAED,OAAO,KAAK,EAAC,KAAK,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,IAAI,GAAA;gBAAE,OAAO;YAAA,GAAG,CAAA;QAC3C,CAAC,CAAA,CAAA;AACH,CAAC,CAAA"}},
    {"offset": {"line": 5037, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/lib/helpers.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/lib/helpers.ts"],"sourcesContent":["// helpers.ts\nimport { SupabaseClientOptions } from './types'\n\nexport function uuid() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n    var r = (Math.random() * 16) | 0,\n      v = c == 'x' ? r : (r & 0x3) | 0x8\n    return v.toString(16)\n  })\n}\n\nexport function ensureTrailingSlash(url: string): string {\n  return url.endsWith('/') ? url : url + '/'\n}\n\nexport const isBrowser = () => typeof window !== 'undefined'\n\nexport function applySettingDefaults<\n  Database = any,\n  SchemaName extends string & keyof Database = 'public' extends keyof Database\n    ? 'public'\n    : string & keyof Database\n>(\n  options: SupabaseClientOptions<SchemaName>,\n  defaults: SupabaseClientOptions<any>\n): Required<SupabaseClientOptions<SchemaName>> {\n  const {\n    db: dbOptions,\n    auth: authOptions,\n    realtime: realtimeOptions,\n    global: globalOptions,\n  } = options\n  const {\n    db: DEFAULT_DB_OPTIONS,\n    auth: DEFAULT_AUTH_OPTIONS,\n    realtime: DEFAULT_REALTIME_OPTIONS,\n    global: DEFAULT_GLOBAL_OPTIONS,\n  } = defaults\n\n  const result: Required<SupabaseClientOptions<SchemaName>> = {\n    db: {\n      ...DEFAULT_DB_OPTIONS,\n      ...dbOptions,\n    },\n    auth: {\n      ...DEFAULT_AUTH_OPTIONS,\n      ...authOptions,\n    },\n    realtime: {\n      ...DEFAULT_REALTIME_OPTIONS,\n      ...realtimeOptions,\n    },\n    storage: {},\n    global: {\n      ...DEFAULT_GLOBAL_OPTIONS,\n      ...globalOptions,\n      headers: {\n        ...(DEFAULT_GLOBAL_OPTIONS?.headers ?? {}),\n        ...(globalOptions?.headers ?? {}),\n      },\n    },\n    accessToken: async () => '',\n  }\n\n  if (options.accessToken) {\n    result.accessToken = options.accessToken\n  } else {\n    // hack around Required<>\n    delete (result as any).accessToken\n  }\n\n  return result\n}\n\n/**\n * Validates a Supabase client URL\n *\n * @param {string} supabaseUrl - The Supabase client URL string.\n * @returns {URL} - The validated base URL.\n * @throws {Error}\n */\nexport function validateSupabaseUrl(supabaseUrl: string): URL {\n  const trimmedUrl = supabaseUrl?.trim()\n\n  if (!trimmedUrl) {\n    throw new Error('supabaseUrl is required.')\n  }\n\n  if (!trimmedUrl.match(/^https?:\\/\\//i)) {\n    throw new Error('Invalid supabaseUrl: Must be a valid HTTP or HTTPS URL.')\n  }\n\n  try {\n    return new URL(ensureTrailingSlash(trimmedUrl))\n  } catch {\n    throw Error('Invalid supabaseUrl: Provided URL is malformed.')\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAGM,SAAU,IAAI;IAClB,OAAO,sCAAsC,CAAC,OAAO,CAAC,OAAO,EAAE,SAAU,CAAC;QACxE,IAAI,CAAC,GAAG,AAAC,IAAI,CAAC,MAAM,EAAE,GAAG,EAAE,CAAC,EAAG,CAAC,EAC9B,CAAC,GAAG,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,AAAC,CAAC,GAAG,GAAG,CAAC,EAAG,GAAG,CAAA;QACpC,OAAO,CAAC,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAA;IACvB,CAAC,CAAC,CAAA;AACJ,CAAC;AAEK,SAAU,mBAAmB,CAAC,GAAW;IAC7C,OAAO,GAAG,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,GAAG,GAAG,CAAA;AAC5C,CAAC;AAEM,MAAM,SAAS,GAAG,GAAG,CAAG,CAAD,MAAQ,MAAM,qCAAK,WAAW,CAAA;AAEtD,SAAU,oBAAoB,CAMlC,OAA0C,EAC1C,QAAoC;;IAEpC,MAAM,EACJ,EAAE,EAAE,SAAS,EACb,IAAI,EAAE,WAAW,EACjB,QAAQ,EAAE,eAAe,EACzB,MAAM,EAAE,aAAa,EACtB,GAAG,OAAO,CAAA;IACX,MAAM,EACJ,EAAE,EAAE,kBAAkB,EACtB,IAAI,EAAE,oBAAoB,EAC1B,QAAQ,EAAE,wBAAwB,EAClC,MAAM,EAAE,sBAAsB,EAC/B,GAAG,QAAQ,CAAA;IAEZ,MAAM,MAAM,GAAgD;QAC1D,EAAE,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACG,kBAAkB,GAClB,SAAS,CACb;QACD,IAAI,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACC,oBAAoB,GACpB,WAAW,CACf;QACD,QAAQ,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACH,wBAAwB,GACxB,eAAe,CACnB;QACD,OAAO,EAAE,CAAA,CAAE;QACX,MAAM,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACD,sBAAsB,GACtB,aAAa,GAAA;YAChB,OAAO,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GACD,AAAD,CAAC,KAAA,sBAAsB,KAAA,QAAtB,sBAAsB,KAAA,KAAA,IAAA,KAAA,IAAtB,sBAAsB,CAAE,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAA,CAAE,CAAC,EACtC,CAAD,AAAC,KAAA,aAAa,KAAA,QAAb,aAAa,KAAA,KAAA,IAAA,KAAA,IAAb,aAAa,CAAE,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAA,CAAE,CAAC;QAAA,EAEpC;QACD,WAAW,EAAE,GAAS,CAAE,CAAA,SAAA,IAAA,EAAA,KAAA,GAAA,KAAA,GAAA;gBAAC,OAAA,EAAE,CAAA;YAAA,EAAA;KAC5B,CAAA;IAED,IAAI,OAAO,CAAC,WAAW,EAAE;QACvB,MAAM,CAAC,WAAW,GAAG,OAAO,CAAC,WAAW,CAAA;KACzC,MAAM;QACL,yBAAyB;QACzB,OAAQ,MAAc,CAAC,WAAW,CAAA;KACnC;IAED,OAAO,MAAM,CAAA;AACf,CAAC;AASK,SAAU,mBAAmB,CAAC,WAAmB;IACrD,MAAM,UAAU,GAAG,WAAW,KAAA,QAAX,WAAW,KAAA,KAAA,IAAA,KAAA,IAAX,WAAW,CAAE,IAAI,EAAE,CAAA;IAEtC,IAAI,CAAC,UAAU,EAAE;QACf,MAAM,IAAI,KAAK,CAAC,0BAA0B,CAAC,CAAA;KAC5C;IAED,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,eAAe,CAAC,EAAE;QACtC,MAAM,IAAI,KAAK,CAAC,yDAAyD,CAAC,CAAA;KAC3E;IAED,IAAI;QACF,OAAO,IAAI,GAAG,CAAC,mBAAmB,CAAC,UAAU,CAAC,CAAC,CAAA;KAChD,CAAC,OAAA,IAAM;QACN,MAAM,KAAK,CAAC,iDAAiD,CAAC,CAAA;KAC/D;AACH,CAAC"}},
    {"offset": {"line": 5128, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/lib/SupabaseAuthClient.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/lib/SupabaseAuthClient.ts"],"sourcesContent":["import { AuthClient } from '@supabase/auth-js'\nimport { SupabaseAuthClientOptions } from './types'\n\nexport class SupabaseAuthClient extends AuthClient {\n  constructor(options: SupabaseAuthClientOptions) {\n    super(options)\n  }\n}\n"],"names":[],"mappings":";;;;;AAAA,OAAO,EAAE,UAAU,EAAE,MAAM,mBAAmB,CAAA;;AAGxC,MAAO,kBAAmB,SAAQ,uOAAU;IAChD,YAAY,OAAkC,CAAA;QAC5C,KAAK,CAAC,OAAO,CAAC,CAAA;IAChB,CAAC;CACF"}},
    {"offset": {"line": 5144, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/SupabaseClient.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/SupabaseClient.ts"],"sourcesContent":["import { FunctionsClient } from '@supabase/functions-js'\nimport { AuthChangeEvent } from '@supabase/auth-js'\nimport {\n  PostgrestClient,\n  PostgrestFilterBuilder,\n  PostgrestQueryBuilder,\n} from '@supabase/postgrest-js'\nimport {\n  RealtimeChannel,\n  RealtimeChannelOptions,\n  RealtimeClient,\n  RealtimeClientOptions,\n} from '@supabase/realtime-js'\nimport { StorageClient as SupabaseStorageClient } from '@supabase/storage-js'\nimport {\n  DEFAULT_GLOBAL_OPTIONS,\n  DEFAULT_DB_OPTIONS,\n  DEFAULT_AUTH_OPTIONS,\n  DEFAULT_REALTIME_OPTIONS,\n} from './lib/constants'\nimport { fetchWithAuth } from './lib/fetch'\nimport { applySettingDefaults, validateSupabaseUrl } from './lib/helpers'\nimport { SupabaseAuthClient } from './lib/SupabaseAuthClient'\nimport { Fetch, GenericSchema, SupabaseClientOptions, SupabaseAuthClientOptions } from './lib/types'\n\n/**\n * Supabase Client.\n *\n * An isomorphic Javascript client for interacting with Postgres.\n */\nexport default class SupabaseClient<\n  Database = any,\n  // The second type parameter is also used for specifying db_schema, so we\n  // support both cases.\n  // TODO: Allow setting db_schema from ClientOptions.\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n  Schema extends Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never = Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never,\n  ClientOptions extends { PostgrestVersion: string } = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? // If the version isn't explicitly set, look for it in the __InternalSupabase object to infer the right version\n      Database extends { __InternalSupabase: { PostgrestVersion: string } }\n      ? Database['__InternalSupabase']\n      : // otherwise default to 12\n        { PostgrestVersion: '12' }\n    : SchemaNameOrClientOptions extends { PostgrestVersion: string }\n    ? SchemaNameOrClientOptions\n    : never\n> {\n  /**\n   * Supabase Auth allows you to create and manage user sessions for access to data that is secured by access policies.\n   */\n  auth: SupabaseAuthClient\n  realtime: RealtimeClient\n  /**\n   * Supabase Storage allows you to manage user-generated content, such as photos or videos.\n   */\n  storage: SupabaseStorageClient\n\n  protected realtimeUrl: URL\n  protected authUrl: URL\n  protected storageUrl: URL\n  protected functionsUrl: URL\n  protected rest: PostgrestClient<Database, ClientOptions, SchemaName>\n  protected storageKey: string\n  protected fetch?: Fetch\n  protected changedAccessToken?: string\n  protected accessToken?: () => Promise<string | null>\n\n  protected headers: Record<string, string>\n\n  /**\n   * Create a new client for use in the browser.\n   * @param supabaseUrl The unique Supabase URL which is supplied when you create a new project in your project dashboard.\n   * @param supabaseKey The unique Supabase Key which is supplied when you create a new project in your project dashboard.\n   * @param options.db.schema You can switch in between schemas. The schema needs to be on the list of exposed schemas inside Supabase.\n   * @param options.auth.autoRefreshToken Set to \"true\" if you want to automatically refresh the token before expiring.\n   * @param options.auth.persistSession Set to \"true\" if you want to automatically save the user session into local storage.\n   * @param options.auth.detectSessionInUrl Set to \"true\" if you want to automatically detects OAuth grants in the URL and signs in the user.\n   * @param options.realtime Options passed along to realtime-js constructor.\n   * @param options.storage Options passed along to the storage-js constructor.\n   * @param options.global.fetch A custom fetch implementation.\n   * @param options.global.headers Any additional headers to send with each network request.\n   */\n  constructor(\n    protected supabaseUrl: string,\n    protected supabaseKey: string,\n    options?: SupabaseClientOptions<SchemaName>\n  ) {\n    const baseUrl = validateSupabaseUrl(supabaseUrl)\n    if (!supabaseKey) throw new Error('supabaseKey is required.')\n\n    this.realtimeUrl = new URL('realtime/v1', baseUrl)\n    this.realtimeUrl.protocol = this.realtimeUrl.protocol.replace('http', 'ws')\n    this.authUrl = new URL('auth/v1', baseUrl)\n    this.storageUrl = new URL('storage/v1', baseUrl)\n    this.functionsUrl = new URL('functions/v1', baseUrl)\n\n    // default storage key uses the supabase project ref as a namespace\n    const defaultStorageKey = `sb-${baseUrl.hostname.split('.')[0]}-auth-token`\n    const DEFAULTS = {\n      db: DEFAULT_DB_OPTIONS,\n      realtime: DEFAULT_REALTIME_OPTIONS,\n      auth: { ...DEFAULT_AUTH_OPTIONS, storageKey: defaultStorageKey },\n      global: DEFAULT_GLOBAL_OPTIONS,\n    }\n\n    const settings = applySettingDefaults(options ?? {}, DEFAULTS)\n\n    this.storageKey = settings.auth.storageKey ?? ''\n    this.headers = settings.global.headers ?? {}\n\n    if (!settings.accessToken) {\n      this.auth = this._initSupabaseAuthClient(\n        settings.auth ?? {},\n        this.headers,\n        settings.global.fetch\n      )\n    } else {\n      this.accessToken = settings.accessToken\n\n      this.auth = new Proxy<SupabaseAuthClient>({} as any, {\n        get: (_, prop) => {\n          throw new Error(\n            `@supabase/supabase-js: Supabase Client is configured with the accessToken option, accessing supabase.auth.${String(\n              prop\n            )} is not possible`\n          )\n        },\n      })\n    }\n\n    this.fetch = fetchWithAuth(supabaseKey, this._getAccessToken.bind(this), settings.global.fetch)\n    this.realtime = this._initRealtimeClient({\n      headers: this.headers,\n      accessToken: this._getAccessToken.bind(this),\n      ...settings.realtime,\n    })\n    this.rest = new PostgrestClient(new URL('rest/v1', baseUrl).href, {\n      headers: this.headers,\n      schema: settings.db.schema,\n      fetch: this.fetch,\n    })\n\n    this.storage = new SupabaseStorageClient(\n      this.storageUrl.href,\n      this.headers,\n      this.fetch,\n      options?.storage\n    )\n\n    if (!settings.accessToken) {\n      this._listenForAuthEvents()\n    }\n  }\n\n  /**\n   * Supabase Functions allows you to deploy and invoke edge functions.\n   */\n  get functions(): FunctionsClient {\n    return new FunctionsClient(this.functionsUrl.href, {\n      headers: this.headers,\n      customFetch: this.fetch,\n    })\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.from\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName]\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any> {\n    return this.rest.from(relation)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.schema\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return this.rest.schema<DynamicSchema>(schema)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.rpc\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  rpc<FnName extends string & keyof Schema['Functions'], Fn extends Schema['Functions'][FnName]>(\n    fn: FnName,\n    args: Fn['Args'] = {},\n    options: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Fn['Returns'] extends any[]\n      ? Fn['Returns'][number] extends Record<string, unknown>\n        ? Fn['Returns'][number]\n        : never\n      : never,\n    Fn['Returns'],\n    FnName,\n    null,\n    'RPC'\n  > {\n    return this.rest.rpc(fn, args, options)\n  }\n\n  /**\n   * Creates a Realtime channel with Broadcast, Presence, and Postgres Changes.\n   *\n   * @param {string} name - The name of the Realtime channel.\n   * @param {Object} opts - The options to pass to the Realtime channel.\n   *\n   */\n  channel(name: string, opts: RealtimeChannelOptions = { config: {} }): RealtimeChannel {\n    return this.realtime.channel(name, opts)\n  }\n\n  /**\n   * Returns all Realtime channels.\n   */\n  getChannels(): RealtimeChannel[] {\n    return this.realtime.getChannels()\n  }\n\n  /**\n   * Unsubscribes and removes Realtime channel from Realtime client.\n   *\n   * @param {RealtimeChannel} channel - The name of the Realtime channel.\n   *\n   */\n  removeChannel(channel: RealtimeChannel): Promise<'ok' | 'timed out' | 'error'> {\n    return this.realtime.removeChannel(channel)\n  }\n\n  /**\n   * Unsubscribes and removes all Realtime channels from Realtime client.\n   */\n  removeAllChannels(): Promise<('ok' | 'timed out' | 'error')[]> {\n    return this.realtime.removeAllChannels()\n  }\n\n  private async _getAccessToken() {\n    if (this.accessToken) {\n      return await this.accessToken()\n    }\n\n    const { data } = await this.auth.getSession()\n\n    return data.session?.access_token ?? this.supabaseKey\n  }\n\n  private _initSupabaseAuthClient(\n    {\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      storageKey,\n      flowType,\n      lock,\n      debug,\n    }: SupabaseAuthClientOptions,\n    headers?: Record<string, string>,\n    fetch?: Fetch\n  ) {\n    const authHeaders = {\n      Authorization: `Bearer ${this.supabaseKey}`,\n      apikey: `${this.supabaseKey}`,\n    }\n    return new SupabaseAuthClient({\n      url: this.authUrl.href,\n      headers: { ...authHeaders, ...headers },\n      storageKey: storageKey,\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      flowType,\n      lock,\n      debug,\n      fetch,\n      // auth checks if there is a custom authorizaiton header using this flag\n      // so it knows whether to return an error when getUser is called with no session\n      hasCustomAuthorizationHeader: Object.keys(this.headers).some(\n        (key) => key.toLowerCase() === 'authorization'\n      ),\n    })\n  }\n\n  private _initRealtimeClient(options: RealtimeClientOptions) {\n    return new RealtimeClient(this.realtimeUrl.href, {\n      ...options,\n      params: { ...{ apikey: this.supabaseKey }, ...options?.params },\n    })\n  }\n\n  private _listenForAuthEvents() {\n    let data = this.auth.onAuthStateChange((event, session) => {\n      this._handleTokenChanged(event, 'CLIENT', session?.access_token)\n    })\n    return data\n  }\n\n  private _handleTokenChanged(\n    event: AuthChangeEvent,\n    source: 'CLIENT' | 'STORAGE',\n    token?: string\n  ) {\n    if (\n      (event === 'TOKEN_REFRESHED' || event === 'SIGNED_IN') &&\n      this.changedAccessToken !== token\n    ) {\n      this.changedAccessToken = token\n      this.realtime.setAuth(token)\n    } else if (event === 'SIGNED_OUT') {\n      this.realtime.setAuth()\n      if (source == 'STORAGE') this.auth.signOut()\n      this.changedAccessToken = undefined\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAAE,eAAe,EAAE,MAAM,wBAAwB,CAAA;AAExD,OAAO,EACL,eAAe,GAGhB,MAAM,wBAAwB,CAAA;AAC/B,OAAO,EAGL,cAAc,GAEf,MAAM,uBAAuB,CAAA;;AAC9B,OAAO,EAAE,aAAa,IAAI,qBAAqB,EAAE,MAAM,sBAAsB,CAAA;AAC7E,OAAO,EACL,sBAAsB,EACtB,kBAAkB,EAClB,oBAAoB,EACpB,wBAAwB,GACzB,MAAM,iBAAiB,CAAA;AACxB,OAAO,EAAE,aAAa,EAAE,MAAM,aAAa,CAAA;AAC3C,OAAO,EAAE,oBAAoB,EAAE,mBAAmB,EAAE,MAAM,eAAe,CAAA;AACzE,OAAO,EAAE,kBAAkB,EAAE,MAAM,0BAA0B,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAQ/C,MAAO,cAAc;IAuDjC;;;;;;;;;;;;OAYG,CACH,YACY,WAAmB,EACnB,WAAmB,EAC7B,OAA2C,CAAA;;QAFjC,IAAA,CAAA,WAAW,GAAX,WAAW,CAAQ;QACnB,IAAA,CAAA,WAAW,GAAX,WAAW,CAAQ;QAG7B,MAAM,OAAO,GAAG,mNAAmB,EAAC,WAAW,CAAC,CAAA;QAChD,IAAI,CAAC,WAAW,EAAE,MAAM,IAAI,KAAK,CAAC,0BAA0B,CAAC,CAAA;QAE7D,IAAI,CAAC,WAAW,GAAG,IAAI,GAAG,CAAC,aAAa,EAAE,OAAO,CAAC,CAAA;QAClD,IAAI,CAAC,WAAW,CAAC,QAAQ,GAAG,IAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CAAA;QAC3E,IAAI,CAAC,OAAO,GAAG,IAAI,GAAG,CAAC,SAAS,EAAE,OAAO,CAAC,CAAA;QAC1C,IAAI,CAAC,UAAU,GAAG,IAAI,GAAG,CAAC,YAAY,EAAE,OAAO,CAAC,CAAA;QAChD,IAAI,CAAC,YAAY,GAAG,IAAI,GAAG,CAAC,cAAc,EAAE,OAAO,CAAC,CAAA;QAEpD,mEAAmE;QACnE,MAAM,iBAAiB,GAAG,CAAA,GAAA,EAAM,OAAO,CAAC,QAAQ,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,CAAA,WAAA,CAAa,CAAA;QAC3E,MAAM,QAAQ,GAAG;YACf,EAAE,EAAE,gNAAkB;YACtB,QAAQ,EAAE,sNAAwB;YAClC,IAAI,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,kNAAoB,GAAA;gBAAE,UAAU,EAAE,iBAAiB;YAAA,EAAE;YAChE,MAAM,EAAE,oNAAsB;SAC/B,CAAA;QAED,MAAM,QAAQ,OAAG,gNAAoB,EAAC,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAP,OAAO,GAAI,CAAA,CAAE,EAAE,QAAQ,CAAC,CAAA;QAE9D,IAAI,CAAC,UAAU,GAAG,CAAA,KAAA,QAAQ,CAAC,IAAI,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,EAAE,CAAA;QAChD,IAAI,CAAC,OAAO,GAAG,CAAA,KAAA,QAAQ,CAAC,MAAM,CAAC,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAA,CAAE,CAAA;QAE5C,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE;YACzB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,uBAAuB,CACtC,CAAA,KAAA,QAAQ,CAAC,IAAI,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,CAAA,CAAE,EACnB,IAAI,CAAC,OAAO,EACZ,QAAQ,CAAC,MAAM,CAAC,KAAK,CACtB,CAAA;SACF,MAAM;YACL,IAAI,CAAC,WAAW,GAAG,QAAQ,CAAC,WAAW,CAAA;YAEvC,IAAI,CAAC,IAAI,GAAG,IAAI,KAAK,CAAqB,CAAA,CAAS,EAAE;gBACnD,GAAG,EAAE,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE;oBACf,MAAM,IAAI,KAAK,CACb,CAAA,0GAAA,EAA6G,MAAM,CACjH,IAAI,CACL,CAAA,gBAAA,CAAkB,CACpB,CAAA;gBACH,CAAC;aACF,CAAC,CAAA;SACH;QAED,IAAI,CAAC,KAAK,GAAG,2MAAa,EAAC,WAAW,EAAE,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,QAAQ,CAAC,MAAM,CAAC,KAAK,CAAC,CAAA;QAC/F,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,mBAAmB,CAAA,OAAA,MAAA,CAAA;YACtC,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,WAAW,EAAE,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC;QAAA,GACzC,QAAQ,CAAC,QAAQ,EACpB,CAAA;QACF,IAAI,CAAC,IAAI,GAAG,IAAI,mMAAe,CAAC,IAAI,GAAG,CAAC,SAAS,EAAE,OAAO,CAAC,CAAC,IAAI,EAAE;YAChE,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,QAAQ,CAAC,EAAE,CAAC,MAAM;YAC1B,KAAK,EAAE,IAAI,CAAC,KAAK;SAClB,CAAC,CAAA;QAEF,IAAI,CAAC,OAAO,GAAG,IAAI,uMAAqB,CACtC,IAAI,CAAC,UAAU,CAAC,IAAI,EACpB,IAAI,CAAC,OAAO,EACZ,IAAI,CAAC,KAAK,EACV,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,OAAO,CACjB,CAAA;QAED,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE;YACzB,IAAI,CAAC,oBAAoB,EAAE,CAAA;SAC5B;IACH,CAAC;IAED;;OAEG,CACH,IAAI,SAAS,GAAA;QACX,OAAO,IAAI,6MAAe,CAAC,IAAI,CAAC,YAAY,CAAC,IAAI,EAAE;YACjD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,WAAW,EAAE,IAAI,CAAC,KAAK;SACxB,CAAC,CAAA;IACJ,CAAC;IAUD;;;;OAIG,CACH,IAAI,CAAC,QAAgB,EAAA;QACnB,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAA;IACjC,CAAC;IAED,oEAAoE;IACpE;;;;;;OAMG,CACH,MAAM,CACJ,MAAqB,EAAA;QAOrB,OAAO,IAAI,CAAC,IAAI,CAAC,MAAM,CAAgB,MAAM,CAAC,CAAA;IAChD,CAAC;IAED,iEAAiE;IACjE;;;;;;;;;;;;;;;;;;;;;;OAsBG,CACH,GAAG,CACD,EAAU,EACV,OAAmB,CAAA,CAAE,EACrB,UAII,CAAA,CAAE,EAAA;QAcN,OAAO,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,EAAE,EAAE,IAAI,EAAE,OAAO,CAAC,CAAA;IACzC,CAAC;IAED;;;;;;OAMG,CACH,OAAO,CAAC,IAAY,EAAE,OAA+B;QAAE,MAAM,EAAE,CAAA,CAAE;IAAA,CAAE,EAAA;QACjE,OAAO,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,CAAA;IAC1C,CAAC;IAED;;OAEG,CACH,WAAW,GAAA;QACT,OAAO,IAAI,CAAC,QAAQ,CAAC,WAAW,EAAE,CAAA;IACpC,CAAC;IAED;;;;;OAKG,CACH,aAAa,CAAC,OAAwB,EAAA;QACpC,OAAO,IAAI,CAAC,QAAQ,CAAC,aAAa,CAAC,OAAO,CAAC,CAAA;IAC7C,CAAC;IAED;;OAEG,CACH,iBAAiB,GAAA;QACf,OAAO,IAAI,CAAC,QAAQ,CAAC,iBAAiB,EAAE,CAAA;IAC1C,CAAC;IAEa,eAAe,GAAA;;;YAC3B,IAAI,IAAI,CAAC,WAAW,EAAE;gBACpB,OAAO,MAAM,IAAI,CAAC,WAAW,EAAE,CAAA;aAChC;YAED,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,CAAA;YAE7C,OAAO,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,YAAY,MAAA,QAAA,OAAA,KAAA,IAAA,KAAI,IAAI,CAAC,WAAW,CAAA;;KACtD;IAEO,uBAAuB,CAC7B,EACE,gBAAgB,EAChB,cAAc,EACd,kBAAkB,EAClB,OAAO,EACP,WAAW,EACX,UAAU,EACV,QAAQ,EACR,IAAI,EACJ,KAAK,EACqB,EAC5B,OAAgC,EAChC,KAAa,EAAA;QAEb,MAAM,WAAW,GAAG;YAClB,aAAa,EAAE,CAAA,OAAA,EAAU,IAAI,CAAC,WAAW,EAAE;YAC3C,MAAM,EAAE,GAAG,IAAI,CAAC,WAAW,EAAE;SAC9B,CAAA;QACD,OAAO,IAAI,yNAAkB,CAAC;YAC5B,GAAG,EAAE,IAAI,CAAC,OAAO,CAAC,IAAI;YACtB,OAAO,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAO,WAAW,GAAK,OAAO,CAAE;YACvC,UAAU,EAAE,UAAU;YACtB,gBAAgB;YAChB,cAAc;YACd,kBAAkB;YAClB,OAAO;YACP,WAAW;YACX,QAAQ;YACR,IAAI;YACJ,KAAK;YACL,KAAK;YACL,wEAAwE;YACxE,gFAAgF;YAChF,4BAA4B,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,IAAI,CAC1D,CAAC,GAAG,EAAE,CAAG,CAAD,EAAI,CAAC,WAAW,EAAE,KAAK,eAAe,CAC/C;SACF,CAAC,CAAA;IACJ,CAAC;IAEO,mBAAmB,CAAC,OAA8B,EAAA;QACxD,OAAO,IAAI,uPAAc,CAAC,IAAI,CAAC,WAAW,CAAC,IAAI,EAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAC1C,OAAO,GAAA;YACV,MAAM,EAAA,OAAA,MAAA,CAAO;gBAAE,MAAM,EAAE,IAAI,CAAC,WAAW;YAAA,CAAE,EAAK,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,MAAM;QAAA,GAC7D,CAAA;IACJ,CAAC;IAEO,oBAAoB,GAAA;QAC1B,IAAI,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC,KAAK,EAAE,OAAO,EAAE,EAAE;YACxD,IAAI,CAAC,mBAAmB,CAAC,KAAK,EAAE,QAAQ,EAAE,OAAO,KAAA,QAAP,OAAO,KAAA,KAAA,IAAA,KAAA,IAAP,OAAO,CAAE,YAAY,CAAC,CAAA;QAClE,CAAC,CAAC,CAAA;QACF,OAAO,IAAI,CAAA;IACb,CAAC;IAEO,mBAAmB,CACzB,KAAsB,EACtB,MAA4B,EAC5B,KAAc,EAAA;QAEd,IACE,CAAC,KAAK,KAAK,iBAAiB,IAAI,KAAK,KAAK,WAAW,CAAC,IACtD,IAAI,CAAC,kBAAkB,KAAK,KAAK,EACjC;YACA,IAAI,CAAC,kBAAkB,GAAG,KAAK,CAAA;YAC/B,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,KAAK,CAAC,CAAA;SAC7B,MAAM,IAAI,KAAK,KAAK,YAAY,EAAE;YACjC,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA;YACvB,IAAI,MAAM,IAAI,SAAS,EAAE,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CAAA;YAC5C,IAAI,CAAC,kBAAkB,GAAG,SAAS,CAAA;SACpC;IACH,CAAC;CACF"}},
    {"offset": {"line": 5395, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/supabase-js/dist/module/index.js","sources":["turbopack:///[project]/node_modules/@supabase/supabase-js/src/index.ts"],"sourcesContent":["import SupabaseClient from './SupabaseClient'\nimport type { SupabaseClientOptions } from './lib/types'\n\nexport * from '@supabase/auth-js'\nexport type { User as AuthUser, Session as AuthSession } from '@supabase/auth-js'\nexport {\n  type PostgrestResponse,\n  type PostgrestSingleResponse,\n  type PostgrestMaybeSingleResponse,\n  PostgrestError,\n} from '@supabase/postgrest-js'\nexport {\n  FunctionsHttpError,\n  FunctionsFetchError,\n  FunctionsRelayError,\n  FunctionsError,\n  type FunctionInvokeOptions,\n  FunctionRegion,\n} from '@supabase/functions-js'\nexport * from '@supabase/realtime-js'\nexport { default as SupabaseClient } from './SupabaseClient'\nexport type { SupabaseClientOptions, QueryResult, QueryData, QueryError } from './lib/types'\n\n/**\n * Creates a new Supabase Client.\n */\nexport const createClient = <\n  Database = any,\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName>\n): SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName> => {\n  return new SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName>(\n    supabaseUrl,\n    supabaseKey,\n    options\n  )\n}\n\n// Check for Node.js <= 18 deprecation\nfunction shouldShowDeprecationWarning(): boolean {\n  // Skip in browser environments\n  if (typeof window !== 'undefined') {\n    return false\n  }\n\n  // Skip if process is not available (e.g., Edge Runtime)\n  if (typeof process === 'undefined') {\n    return false\n  }\n\n  // Use dynamic property access to avoid Next.js Edge Runtime static analysis warnings\n  const processVersion = (process as any)['version']\n  if (processVersion === undefined || processVersion === null) {\n    return false\n  }\n\n  const versionMatch = processVersion.match(/^v(\\d+)\\./)\n  if (!versionMatch) {\n    return false\n  }\n\n  const majorVersion = parseInt(versionMatch[1], 10)\n  return majorVersion <= 18\n}\n\nif (shouldShowDeprecationWarning()) {\n  console.warn(\n    `  Node.js 18 and below are deprecated and will no longer be supported in future versions of @supabase/supabase-js. ` +\n      `Please upgrade to Node.js 20 or later. ` +\n      `For more information, visit: https://github.com/orgs/supabase/discussions/37217`\n  )\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,cAAc,MAAM,kBAAkB,CAAA;AAG7C,cAAc,mBAAmB,CAAA;AAEjC,OAAO,EAIL,cAAc,GACf,MAAM,wBAAwB,CAAA;AAS/B,cAAc,uBAAuB,CAAA;;;;;;;AAO9B,MAAM,YAAY,GAAG,CAe1B,WAAmB,EACnB,WAAmB,EACnB,OAA2C,EACsB,EAAE;IACnE,OAAO,IAAI,mMAAc,CACvB,WAAW,EACX,WAAW,EACX,OAAO,CACR,CAAA;AACH,CAAC,CAAA;AAED,sCAAsC;AACtC,SAAS,4BAA4B;IACnC,+BAA+B;IAC/B,IAAI,OAAO,MAAM,KAAK,WAAW,EAAE;;IAInC,wDAAwD;IACxD,IAAI,OAAO,OAAO,KAAK,WAAW,EAAE;QAClC,OAAO,KAAK,CAAA;KACb;IAED,qFAAqF;IACrF,MAAM,cAAc,GAAI,OAAe,CAAC,SAAS,CAAC,CAAA;IAClD,IAAI,cAAc,KAAK,SAAS,IAAI,cAAc,KAAK,IAAI,EAAE;QAC3D,OAAO,KAAK,CAAA;KACb;IAED,MAAM,YAAY,GAAG,cAAc,CAAC,KAAK,CAAC,WAAW,CAAC,CAAA;IACtD,IAAI,CAAC,YAAY,EAAE;QACjB,OAAO,KAAK,CAAA;KACb;IAED,MAAM,YAAY,GAAG,QAAQ,CAAC,YAAY,CAAC,CAAC,CAAC,EAAE,EAAE,CAAC,CAAA;IAClD,OAAO,YAAY,IAAI,EAAE,CAAA;AAC3B,CAAC;AAED,IAAI,4BAA4B,EAAE,EAAE;IAClC,OAAO,CAAC,IAAI,CACV,CAAA,qHAAA,CAAuH,GACrH,CAAA,uCAAA,CAAyC,GACzC,CAAA,+EAAA,CAAiF,CACpF,CAAA;CACF"}},
    {"offset": {"line": 5440, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/version.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/version.ts"],"sourcesContent":["export const VERSION = '0.7.0';\n"],"names":[],"mappings":";;;;AAAO,MAAM,OAAO,GAAG,OAAO,CAAC"}},
    {"offset": {"line": 5449, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/utils/helpers.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/utils/helpers.ts"],"sourcesContent":["import type { SerializeOptions } from \"cookie\";\nimport { parse as cookieParse, serialize as cookieSerialize } from \"cookie\";\n\n/**\n * @deprecated Since v0.4.0: Please use {@link parseCookieHeader}. `parse` will\n * not be available for import starting v1.0.0 of `@supabase/ssr`.\n */\nexport const parse = cookieParse;\n\n/**\n * @deprecated Since v0.4.0: Please use {@link serializeCookieHeader}.\n * `serialize` will not be available for import starting v1.0.0 of\n * `@supabase/ssr`.\n */\nexport const serialize = cookieSerialize;\n\n/**\n * Parses the `Cookie` HTTP header into an array of cookie name-value objects.\n *\n * @param header The `Cookie` HTTP header. Decodes cookie names and values from\n * URI encoding first.\n */\nexport function parseCookieHeader(\n  header: string,\n): { name: string; value?: string }[] {\n  const parsed = cookieParse(header);\n\n  return Object.keys(parsed ?? {}).map((name) => ({\n    name,\n    value: parsed[name],\n  }));\n}\n\n/**\n * Converts the arguments to a valid `Set-Cookie` header. Non US-ASCII chars\n * and other forbidden cookie chars will be URI encoded.\n *\n * @param name Name of cookie.\n * @param value Value of cookie.\n */\nexport function serializeCookieHeader(\n  name: string,\n  value: string,\n  options: SerializeOptions,\n): string {\n  return cookieSerialize(name, value, options);\n}\n\nexport function isBrowser() {\n  return (\n    typeof window !== \"undefined\" && typeof window.document !== \"undefined\"\n  );\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AACA,OAAO,EAAE,KAAK,IAAI,WAAW,EAAE,SAAS,IAAI,eAAe,EAAE,MAAM,QAAQ,CAAC;;AAMrE,MAAM,KAAK,GAAG,wJAAW,CAAC;AAO1B,MAAM,SAAS,GAAG,4JAAe,CAAC;AAQnC,SAAU,iBAAiB,CAC/B,MAAc;IAEd,MAAM,MAAM,OAAG,wJAAW,EAAC,MAAM,CAAC,CAAC;IAEnC,OAAO,MAAM,CAAC,IAAI,CAAC,MAAM,IAAI,CAAA,CAAE,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;YAC9C,IAAI;YACJ,KAAK,EAAE,MAAM,CAAC,IAAI,CAAC;SACpB,CAAC,CAAC,CAAC;AACN,CAAC;AASK,SAAU,qBAAqB,CACnC,IAAY,EACZ,KAAa,EACb,OAAyB;IAEzB,WAAO,4JAAe,EAAC,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;AAC/C,CAAC;AAEK,SAAU,SAAS;IACvB,OAAO,AACL,OAAO,MAAM,qCAAK,WAAW,IAAI,OAAO,MAAM,CAAC,QAAQ,KAAK,WAAW,CACxE,CAAC;AACJ,CAAC"}},
    {"offset": {"line": 5482, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/utils/constants.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/utils/constants.ts"],"sourcesContent":["import { CookieOptions } from \"../types\";\n\nexport const DEFAULT_COOKIE_OPTIONS: CookieOptions = {\n  path: \"/\",\n  sameSite: \"lax\",\n  httpOnly: false,\n  // https://developer.chrome.com/blog/cookie-max-age-expires\n  // https://httpwg.org/http-extensions/draft-ietf-httpbis-rfc6265bis.html#name-cookie-lifetime-limits\n  maxAge: 400 * 24 * 60 * 60,\n};\n"],"names":[],"mappings":";;;;AAEO,MAAM,sBAAsB,GAAkB;IACnD,IAAI,EAAE,GAAG;IACT,QAAQ,EAAE,KAAK;IACf,QAAQ,EAAE,KAAK;IACf,2DAA2D;IAC3D,oGAAoG;IACpG,MAAM,EAAE,GAAG,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE;CAC3B,CAAC"}},
    {"offset": {"line": 5498, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/utils/chunker.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/utils/chunker.ts"],"sourcesContent":["interface Chunk {\n  name: string;\n  value: string;\n}\n\nexport const MAX_CHUNK_SIZE = 3180;\n\nconst CHUNK_LIKE_REGEX = /^(.*)[.](0|[1-9][0-9]*)$/;\nexport function isChunkLike(cookieName: string, key: string) {\n  if (cookieName === key) {\n    return true;\n  }\n\n  const chunkLike = cookieName.match(CHUNK_LIKE_REGEX);\n  if (chunkLike && chunkLike[1] === key) {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * create chunks from a string and return an array of object\n */\nexport function createChunks(\n  key: string,\n  value: string,\n  chunkSize?: number,\n): Chunk[] {\n  const resolvedChunkSize = chunkSize ?? MAX_CHUNK_SIZE;\n\n  let encodedValue = encodeURIComponent(value);\n\n  if (encodedValue.length <= resolvedChunkSize) {\n    return [{ name: key, value }];\n  }\n\n  const chunks: string[] = [];\n\n  while (encodedValue.length > 0) {\n    let encodedChunkHead = encodedValue.slice(0, resolvedChunkSize);\n\n    const lastEscapePos = encodedChunkHead.lastIndexOf(\"%\");\n\n    // Check if the last escaped character is truncated.\n    if (lastEscapePos > resolvedChunkSize - 3) {\n      // If so, reslice the string to exclude the whole escape sequence.\n      // We only reduce the size of the string as the chunk must\n      // be smaller than the chunk size.\n      encodedChunkHead = encodedChunkHead.slice(0, lastEscapePos);\n    }\n\n    let valueHead: string = \"\";\n\n    // Check if the chunk was split along a valid unicode boundary.\n    while (encodedChunkHead.length > 0) {\n      try {\n        // Try to decode the chunk back and see if it is valid.\n        // Stop when the chunk is valid.\n        valueHead = decodeURIComponent(encodedChunkHead);\n        break;\n      } catch (error) {\n        if (\n          error instanceof URIError &&\n          encodedChunkHead.at(-3) === \"%\" &&\n          encodedChunkHead.length > 3\n        ) {\n          encodedChunkHead = encodedChunkHead.slice(\n            0,\n            encodedChunkHead.length - 3,\n          );\n        } else {\n          throw error;\n        }\n      }\n    }\n\n    chunks.push(valueHead);\n    encodedValue = encodedValue.slice(encodedChunkHead.length);\n  }\n\n  return chunks.map((value, i) => ({ name: `${key}.${i}`, value }));\n}\n\n// Get fully constructed chunks\nexport async function combineChunks(\n  key: string,\n  retrieveChunk: (\n    name: string,\n  ) => Promise<string | null | undefined> | string | null | undefined,\n) {\n  const value = await retrieveChunk(key);\n\n  if (value) {\n    return value;\n  }\n\n  let values: string[] = [];\n\n  for (let i = 0; ; i++) {\n    const chunkName = `${key}.${i}`;\n    const chunk = await retrieveChunk(chunkName);\n\n    if (!chunk) {\n      break;\n    }\n\n    values.push(chunk);\n  }\n\n  if (values.length > 0) {\n    return values.join(\"\");\n  }\n\n  return null;\n}\n\nexport async function deleteChunks(\n  key: string,\n  retrieveChunk: (\n    name: string,\n  ) => Promise<string | null | undefined> | string | null | undefined,\n  removeChunk: (name: string) => Promise<void> | void,\n) {\n  const value = await retrieveChunk(key);\n\n  if (value) {\n    await removeChunk(key);\n  }\n\n  for (let i = 0; ; i++) {\n    const chunkName = `${key}.${i}`;\n    const chunk = await retrieveChunk(chunkName);\n\n    if (!chunk) {\n      break;\n    }\n\n    await removeChunk(chunkName);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAKO,MAAM,cAAc,GAAG,IAAI,CAAC;AAEnC,MAAM,gBAAgB,GAAG,0BAA0B,CAAC;AAC9C,SAAU,WAAW,CAAC,UAAkB,EAAE,GAAW;IACzD,IAAI,UAAU,KAAK,GAAG,EAAE,CAAC;QACvB,OAAO,IAAI,CAAC;IACd,CAAC;IAED,MAAM,SAAS,GAAG,UAAU,CAAC,KAAK,CAAC,gBAAgB,CAAC,CAAC;IACrD,IAAI,SAAS,IAAI,SAAS,CAAC,CAAC,CAAC,KAAK,GAAG,EAAE,CAAC;QACtC,OAAO,IAAI,CAAC;IACd,CAAC;IAED,OAAO,KAAK,CAAC;AACf,CAAC;AAKK,SAAU,YAAY,CAC1B,GAAW,EACX,KAAa,EACb,SAAkB;IAElB,MAAM,iBAAiB,GAAG,SAAS,IAAI,cAAc,CAAC;IAEtD,IAAI,YAAY,GAAG,kBAAkB,CAAC,KAAK,CAAC,CAAC;IAE7C,IAAI,YAAY,CAAC,MAAM,IAAI,iBAAiB,EAAE,CAAC;QAC7C,OAAO;YAAC;gBAAE,IAAI,EAAE,GAAG;gBAAE,KAAK;YAAA,CAAE;SAAC,CAAC;IAChC,CAAC;IAED,MAAM,MAAM,GAAa,EAAE,CAAC;IAE5B,MAAO,YAAY,CAAC,MAAM,GAAG,CAAC,CAAE,CAAC;QAC/B,IAAI,gBAAgB,GAAG,YAAY,CAAC,KAAK,CAAC,CAAC,EAAE,iBAAiB,CAAC,CAAC;QAEhE,MAAM,aAAa,GAAG,gBAAgB,CAAC,WAAW,CAAC,GAAG,CAAC,CAAC;QAExD,oDAAoD;QACpD,IAAI,aAAa,GAAG,iBAAiB,GAAG,CAAC,EAAE,CAAC;YAC1C,kEAAkE;YAClE,0DAA0D;YAC1D,kCAAkC;YAClC,gBAAgB,GAAG,gBAAgB,CAAC,KAAK,CAAC,CAAC,EAAE,aAAa,CAAC,CAAC;QAC9D,CAAC;QAED,IAAI,SAAS,GAAW,EAAE,CAAC;QAE3B,+DAA+D;QAC/D,MAAO,gBAAgB,CAAC,MAAM,GAAG,CAAC,CAAE,CAAC;YACnC,IAAI,CAAC;gBACH,uDAAuD;gBACvD,gCAAgC;gBAChC,SAAS,GAAG,kBAAkB,CAAC,gBAAgB,CAAC,CAAC;gBACjD,MAAM;YACR,CAAC,CAAC,OAAO,KAAK,EAAE,CAAC;gBACf,IACE,KAAK,YAAY,QAAQ,IACzB,gBAAgB,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,KAAK,GAAG,IAC/B,gBAAgB,CAAC,MAAM,GAAG,CAAC,EAC3B,CAAC;oBACD,gBAAgB,GAAG,gBAAgB,CAAC,KAAK,CACvC,CAAC,EACD,gBAAgB,CAAC,MAAM,GAAG,CAAC,CAC5B,CAAC;gBACJ,CAAC,MAAM,CAAC;oBACN,MAAM,KAAK,CAAC;gBACd,CAAC;YACH,CAAC;QACH,CAAC;QAED,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QACvB,YAAY,GAAG,YAAY,CAAC,KAAK,CAAC,gBAAgB,CAAC,MAAM,CAAC,CAAC;IAC7D,CAAC;IAED,OAAO,MAAM,CAAC,GAAG,CAAC,CAAC,KAAK,EAAE,CAAC,EAAE,CAAG,CAAD,AAAE;YAAE,IAAI,EAAE,GAAG,GAAG,CAAA,CAAA,EAAI,CAAC,EAAE;YAAE,KAAK;QAAA,CAAE,CAAC,CAAC,CAAC;AACpE,CAAC;AAGM,KAAK,UAAU,aAAa,CACjC,GAAW,EACX,aAEmE;IAEnE,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,CAAC;IAEvC,IAAI,KAAK,EAAE,CAAC;QACV,OAAO,KAAK,CAAC;IACf,CAAC;IAED,IAAI,MAAM,GAAa,EAAE,CAAC;IAE1B,IAAK,IAAI,CAAC,GAAG,CAAC,GAAI,CAAC,EAAE,CAAE,CAAC;QACtB,MAAM,SAAS,GAAG,GAAG,GAAG,CAAA,CAAA,EAAI,CAAC,EAAE,CAAC;QAChC,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,SAAS,CAAC,CAAC;QAE7C,IAAI,CAAC,KAAK,EAAE,CAAC;YACX,MAAM;QACR,CAAC;QAED,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;IACrB,CAAC;IAED,IAAI,MAAM,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;QACtB,OAAO,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;IACzB,CAAC;IAED,OAAO,IAAI,CAAC;AACd,CAAC;AAEM,KAAK,UAAU,YAAY,CAChC,GAAW,EACX,aAEmE,EACnE,WAAmD;IAEnD,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,GAAG,CAAC,CAAC;IAEvC,IAAI,KAAK,EAAE,CAAC;QACV,MAAM,WAAW,CAAC,GAAG,CAAC,CAAC;IACzB,CAAC;IAED,IAAK,IAAI,CAAC,GAAG,CAAC,GAAI,CAAC,EAAE,CAAE,CAAC;QACtB,MAAM,SAAS,GAAG,GAAG,GAAG,CAAA,CAAA,EAAI,CAAC,EAAE,CAAC;QAChC,MAAM,KAAK,GAAG,MAAM,aAAa,CAAC,SAAS,CAAC,CAAC;QAE7C,IAAI,CAAC,KAAK,EAAE,CAAC;YACX,MAAM;QACR,CAAC;QAED,MAAM,WAAW,CAAC,SAAS,CAAC,CAAC;IAC/B,CAAC;AACH,CAAC"}},
    {"offset": {"line": 5605, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/utils/base64url.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/utils/base64url.ts"],"sourcesContent":["/**\n * Avoid modifying this file. It's part of\n * https://github.com/supabase-community/base64url-js.  Submit all fixes on\n * that repo!\n */\n\n/**\n * An array of characters that encode 6 bits into a Base64-URL alphabet\n * character.\n */\nconst TO_BASE64URL =\n  \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_\".split(\"\");\n\n/**\n * An array of characters that can appear in a Base64-URL encoded string but\n * should be ignored.\n */\nconst IGNORE_BASE64URL = \" \\t\\n\\r=\".split(\"\");\n\n/**\n * An array of 128 numbers that map a Base64-URL character to 6 bits, or if -2\n * used to skip the character, or if -1 used to error out.\n */\nconst FROM_BASE64URL = (() => {\n  const charMap: number[] = new Array(128);\n\n  for (let i = 0; i < charMap.length; i += 1) {\n    charMap[i] = -1;\n  }\n\n  for (let i = 0; i < IGNORE_BASE64URL.length; i += 1) {\n    charMap[IGNORE_BASE64URL[i].charCodeAt(0)] = -2;\n  }\n\n  for (let i = 0; i < TO_BASE64URL.length; i += 1) {\n    charMap[TO_BASE64URL[i].charCodeAt(0)] = i;\n  }\n\n  return charMap;\n})();\n\n/**\n * Converts a JavaScript string (which may include any valid character) into a\n * Base64-URL encoded string. The string is first encoded in UTF-8 which is\n * then encoded as Base64-URL.\n *\n * @param str The string to convert.\n */\nexport function stringToBase64URL(str: string) {\n  const base64: string[] = [];\n\n  let queue = 0;\n  let queuedBits = 0;\n\n  const emitter = (byte: number) => {\n    queue = (queue << 8) | byte;\n    queuedBits += 8;\n\n    while (queuedBits >= 6) {\n      const pos = (queue >> (queuedBits - 6)) & 63;\n      base64.push(TO_BASE64URL[pos]);\n      queuedBits -= 6;\n    }\n  };\n\n  stringToUTF8(str, emitter);\n\n  if (queuedBits > 0) {\n    queue = queue << (6 - queuedBits);\n    queuedBits = 6;\n\n    while (queuedBits >= 6) {\n      const pos = (queue >> (queuedBits - 6)) & 63;\n      base64.push(TO_BASE64URL[pos]);\n      queuedBits -= 6;\n    }\n  }\n\n  return base64.join(\"\");\n}\n\n/**\n * Converts a Base64-URL encoded string into a JavaScript string. It is assumed\n * that the underlying string has been encoded as UTF-8.\n *\n * @param str The Base64-URL encoded string.\n */\nexport function stringFromBase64URL(str: string) {\n  const conv: string[] = [];\n\n  const emit = (codepoint: number) => {\n    conv.push(String.fromCodePoint(codepoint));\n  };\n\n  const state = {\n    utf8seq: 0,\n    codepoint: 0,\n  };\n\n  let queue = 0;\n  let queuedBits = 0;\n\n  for (let i = 0; i < str.length; i += 1) {\n    const codepoint = str.charCodeAt(i);\n    const bits = FROM_BASE64URL[codepoint];\n\n    if (bits > -1) {\n      // valid Base64-URL character\n      queue = (queue << 6) | bits;\n      queuedBits += 6;\n\n      while (queuedBits >= 8) {\n        stringFromUTF8((queue >> (queuedBits - 8)) & 0xff, state, emit);\n        queuedBits -= 8;\n      }\n    } else if (bits === -2) {\n      // ignore spaces, tabs, newlines, =\n      continue;\n    } else {\n      throw new Error(\n        `Invalid Base64-URL character \"${str.at(i)}\" at position ${i}`,\n      );\n    }\n  }\n\n  return conv.join(\"\");\n}\n\n/**\n * Converts a Unicode codepoint to a multi-byte UTF-8 sequence.\n *\n * @param codepoint The Unicode codepoint.\n * @param emit      Function which will be called for each UTF-8 byte that represents the codepoint.\n */\nexport function codepointToUTF8(\n  codepoint: number,\n  emit: (byte: number) => void,\n) {\n  if (codepoint <= 0x7f) {\n    emit(codepoint);\n    return;\n  } else if (codepoint <= 0x7ff) {\n    emit(0xc0 | (codepoint >> 6));\n    emit(0x80 | (codepoint & 0x3f));\n    return;\n  } else if (codepoint <= 0xffff) {\n    emit(0xe0 | (codepoint >> 12));\n    emit(0x80 | ((codepoint >> 6) & 0x3f));\n    emit(0x80 | (codepoint & 0x3f));\n    return;\n  } else if (codepoint <= 0x10ffff) {\n    emit(0xf0 | (codepoint >> 18));\n    emit(0x80 | ((codepoint >> 12) & 0x3f));\n    emit(0x80 | ((codepoint >> 6) & 0x3f));\n    emit(0x80 | (codepoint & 0x3f));\n    return;\n  }\n\n  throw new Error(`Unrecognized Unicode codepoint: ${codepoint.toString(16)}`);\n}\n\n/**\n * Converts a JavaScript string to a sequence of UTF-8 bytes.\n *\n * @param str  The string to convert to UTF-8.\n * @param emit Function which will be called for each UTF-8 byte of the string.\n */\nexport function stringToUTF8(str: string, emit: (byte: number) => void) {\n  for (let i = 0; i < str.length; i += 1) {\n    let codepoint = str.charCodeAt(i);\n\n    if (codepoint > 0xd7ff && codepoint <= 0xdbff) {\n      // most UTF-16 codepoints are Unicode codepoints, except values in this\n      // range where the next UTF-16 codepoint needs to be combined with the\n      // current one to get the Unicode codepoint\n      const highSurrogate = ((codepoint - 0xd800) * 0x400) & 0xffff;\n      const lowSurrogate = (str.charCodeAt(i + 1) - 0xdc00) & 0xffff;\n      codepoint = (lowSurrogate | highSurrogate) + 0x10000;\n      i += 1;\n    }\n\n    codepointToUTF8(codepoint, emit);\n  }\n}\n\n/**\n * Converts a UTF-8 byte to a Unicode codepoint.\n *\n * @param byte  The UTF-8 byte next in the sequence.\n * @param state The shared state between consecutive UTF-8 bytes in the\n *              sequence, an object with the shape `{ utf8seq: 0, codepoint: 0 }`.\n * @param emit  Function which will be called for each codepoint.\n */\nexport function stringFromUTF8(\n  byte: number,\n  state: { utf8seq: number; codepoint: number },\n  emit: (codepoint: number) => void,\n) {\n  if (state.utf8seq === 0) {\n    if (byte <= 0x7f) {\n      emit(byte);\n      return;\n    }\n\n    // count the number of 1 leading bits until you reach 0\n    for (let leadingBit = 1; leadingBit < 6; leadingBit += 1) {\n      if (((byte >> (7 - leadingBit)) & 1) === 0) {\n        state.utf8seq = leadingBit;\n        break;\n      }\n    }\n\n    if (state.utf8seq === 2) {\n      state.codepoint = byte & 31;\n    } else if (state.utf8seq === 3) {\n      state.codepoint = byte & 15;\n    } else if (state.utf8seq === 4) {\n      state.codepoint = byte & 7;\n    } else {\n      throw new Error(\"Invalid UTF-8 sequence\");\n    }\n\n    state.utf8seq -= 1;\n  } else if (state.utf8seq > 0) {\n    if (byte <= 0x7f) {\n      throw new Error(\"Invalid UTF-8 sequence\");\n    }\n\n    state.codepoint = (state.codepoint << 6) | (byte & 63);\n    state.utf8seq -= 1;\n\n    if (state.utf8seq === 0) {\n      emit(state.codepoint);\n    }\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;GAIG,CAEH;;;GAGG;;;;;;;;;;;;AACH,MAAM,YAAY,GAChB,kEAAkE,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;AAE/E;;;GAGG,CACH,MAAM,gBAAgB,GAAG,UAAU,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC;AAE9C;;;GAGG,CACH,MAAM,cAAc,GAAG,CAAC,GAAG,EAAE;IAC3B,MAAM,OAAO,GAAa,IAAI,KAAK,CAAC,GAAG,CAAC,CAAC;IAEzC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QAC3C,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAClB,CAAC;IAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,gBAAgB,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QACpD,OAAO,CAAC,gBAAgB,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;IAClD,CAAC;IAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,YAAY,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QAChD,OAAO,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;IAC7C,CAAC;IAED,OAAO,OAAO,CAAC;AACjB,CAAC,CAAC,EAAE,CAAC;AASC,SAAU,iBAAiB,CAAC,GAAW;IAC3C,MAAM,MAAM,GAAa,EAAE,CAAC;IAE5B,IAAI,KAAK,GAAG,CAAC,CAAC;IACd,IAAI,UAAU,GAAG,CAAC,CAAC;IAEnB,MAAM,OAAO,GAAG,CAAC,IAAY,EAAE,EAAE;QAC/B,KAAK,GAAG,AAAC,KAAK,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC;QAC5B,UAAU,IAAI,CAAC,CAAC;QAEhB,MAAO,UAAU,IAAI,CAAC,CAAE,CAAC;YACvB,MAAM,GAAG,GAAG,AAAC,KAAK,IAAI,AAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAG,EAAE,CAAC;YAC7C,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC;YAC/B,UAAU,IAAI,CAAC,CAAC;QAClB,CAAC;IACH,CAAC,CAAC;IAEF,YAAY,CAAC,GAAG,EAAE,OAAO,CAAC,CAAC;IAE3B,IAAI,UAAU,GAAG,CAAC,EAAE,CAAC;QACnB,KAAK,GAAG,KAAK,IAAI,AAAC,CAAC,GAAG,UAAU,CAAC,CAAC;QAClC,UAAU,GAAG,CAAC,CAAC;QAEf,MAAO,UAAU,IAAI,CAAC,CAAE,CAAC;YACvB,MAAM,GAAG,GAAG,AAAC,KAAK,IAAI,AAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAG,EAAE,CAAC;YAC7C,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,CAAC;YAC/B,UAAU,IAAI,CAAC,CAAC;QAClB,CAAC;IACH,CAAC;IAED,OAAO,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACzB,CAAC;AAQK,SAAU,mBAAmB,CAAC,GAAW;IAC7C,MAAM,IAAI,GAAa,EAAE,CAAC;IAE1B,MAAM,IAAI,GAAG,CAAC,SAAiB,EAAE,EAAE;QACjC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC,CAAC;IAC7C,CAAC,CAAC;IAEF,MAAM,KAAK,GAAG;QACZ,OAAO,EAAE,CAAC;QACV,SAAS,EAAE,CAAC;KACb,CAAC;IAEF,IAAI,KAAK,GAAG,CAAC,CAAC;IACd,IAAI,UAAU,GAAG,CAAC,CAAC;IAEnB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QACvC,MAAM,SAAS,GAAG,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACpC,MAAM,IAAI,GAAG,cAAc,CAAC,SAAS,CAAC,CAAC;QAEvC,IAAI,IAAI,GAAG,CAAC,CAAC,EAAE,CAAC;YACd,6BAA6B;YAC7B,KAAK,GAAG,AAAC,KAAK,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC;YAC5B,UAAU,IAAI,CAAC,CAAC;YAEhB,MAAO,UAAU,IAAI,CAAC,CAAE,CAAC;gBACvB,cAAc,CAAC,AAAC,KAAK,IAAI,AAAC,UAAU,GAAG,CAAC,CAAC,CAAC,CAAG,IAAI,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;gBAChE,UAAU,IAAI,CAAC,CAAC;YAClB,CAAC;QACH,CAAC,MAAM,IAAI,IAAI,KAAK,CAAC,CAAC,EAAE,CAAC;YAEvB,SAAS;QACX,CAAC,MAAM,CAAC;YACN,MAAM,IAAI,KAAK,CACb,CAAA,8BAAA,EAAiC,GAAG,CAAC,EAAE,CAAC,CAAC,CAAC,CAAA,cAAA,EAAiB,CAAC,EAAE,CAC/D,CAAC;QACJ,CAAC;IACH,CAAC;IAED,OAAO,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACvB,CAAC;AAQK,SAAU,eAAe,CAC7B,SAAiB,EACjB,IAA4B;IAE5B,IAAI,SAAS,IAAI,IAAI,EAAE,CAAC;QACtB,IAAI,CAAC,SAAS,CAAC,CAAC;QAChB,OAAO;IACT,CAAC,MAAM,IAAI,SAAS,IAAI,KAAK,EAAE,CAAC;QAC9B,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,IAAI,CAAC,CAAC,CAAC,CAAC;QAC9B,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC;QAChC,OAAO;IACT,CAAC,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,CAAC;QAC/B,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,IAAI,EAAE,CAAC,CAAC,CAAC;QAC/B,IAAI,CAAC,IAAI,GAAK,AAAD,AAAD,SAAW,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC;QAChC,OAAO;IACT,CAAC,MAAM,IAAI,SAAS,IAAI,QAAQ,EAAE,CAAC;QACjC,IAAI,CAAC,IAAI,GAAG,AAAC,SAAS,IAAI,EAAE,CAAC,CAAC,CAAC;QAC/B,IAAI,CAAC,IAAI,GAAG,AAAC,AAAC,SAAS,IAAI,EAAE,CAAC,EAAG,IAAI,CAAC,CAAC,CAAC;QACxC,IAAI,CAAC,IAAI,GAAK,AAAF,AAAC,SAAU,IAAI,CAAC,CAAC,EAAG,IAAI,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,IAAI,GAAI,AAAD,SAAU,GAAG,IAAI,CAAC,CAAC,CAAC;QAChC,OAAO;IACT,CAAC;IAED,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EAAmC,SAAS,CAAC,QAAQ,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;AAC/E,CAAC;AAQK,SAAU,YAAY,CAAC,GAAW,EAAE,IAA4B;IACpE,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;QACvC,IAAI,SAAS,GAAG,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QAElC,IAAI,SAAS,GAAG,MAAM,IAAI,SAAS,IAAI,MAAM,EAAE,CAAC;YAC9C,uEAAuE;YACvE,sEAAsE;YACtE,2CAA2C;YAC3C,MAAM,aAAa,GAAG,AAAC,CAAC,SAAS,GAAG,MAAM,CAAC,GAAG,KAAK,CAAC,EAAG,MAAM,CAAC;YAC9D,MAAM,YAAY,GAAG,AAAC,GAAG,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,CAAC,EAAG,MAAM,CAAC;YAC/D,SAAS,GAAG,CAAC,YAAY,GAAG,aAAa,CAAC,GAAG,OAAO,CAAC;YACrD,CAAC,IAAI,CAAC,CAAC;QACT,CAAC;QAED,eAAe,CAAC,SAAS,EAAE,IAAI,CAAC,CAAC;IACnC,CAAC;AACH,CAAC;AAUK,SAAU,cAAc,CAC5B,IAAY,EACZ,KAA6C,EAC7C,IAAiC;IAEjC,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;QACxB,IAAI,IAAI,IAAI,IAAI,EAAE,CAAC;YACjB,IAAI,CAAC,IAAI,CAAC,CAAC;YACX,OAAO;QACT,CAAC;QAED,uDAAuD;QACvD,IAAK,IAAI,UAAU,GAAG,CAAC,EAAE,UAAU,GAAG,CAAC,EAAE,UAAU,IAAI,CAAC,CAAE,CAAC;YACzD,IAAI,CAAC,AAAC,IAAI,IAAI,AAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAG,CAAC,CAAC,KAAK,CAAC,EAAE,CAAC;gBAC3C,KAAK,CAAC,OAAO,GAAG,UAAU,CAAC;gBAC3B,MAAM;YACR,CAAC;QACH,CAAC;QAED,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YACxB,KAAK,CAAC,SAAS,GAAG,IAAI,GAAG,EAAE,CAAC;QAC9B,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YAC/B,KAAK,CAAC,SAAS,GAAG,IAAI,GAAG,EAAE,CAAC;QAC9B,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YAC/B,KAAK,CAAC,SAAS,GAAG,IAAI,GAAG,CAAC,CAAC;QAC7B,CAAC,MAAM,CAAC;YACN,MAAM,IAAI,KAAK,CAAC,wBAAwB,CAAC,CAAC;QAC5C,CAAC;QAED,KAAK,CAAC,OAAO,IAAI,CAAC,CAAC;IACrB,CAAC,MAAM,IAAI,KAAK,CAAC,OAAO,GAAG,CAAC,EAAE,CAAC;QAC7B,IAAI,IAAI,IAAI,IAAI,EAAE,CAAC;YACjB,MAAM,IAAI,KAAK,CAAC,wBAAwB,CAAC,CAAC;QAC5C,CAAC;QAED,KAAK,CAAC,SAAS,GAAG,AAAC,KAAK,CAAC,SAAS,IAAI,CAAC,CAAC,EAAI,CAAD,GAAK,GAAG,EAAE,CAAC,CAAC;QACvD,KAAK,CAAC,OAAO,IAAI,CAAC,CAAC;QAEnB,IAAI,KAAK,CAAC,OAAO,KAAK,CAAC,EAAE,CAAC;YACxB,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC;QACxB,CAAC;IACH,CAAC;AACH,CAAC"}},
    {"offset": {"line": 5775, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/utils/index.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/utils/index.ts"],"sourcesContent":["export * from \"./helpers\";\nexport * from \"./constants\";\nexport * from \"./chunker\";\nexport * from \"./base64url\";\n"],"names":[],"mappings":";AAAA,cAAc,WAAW,CAAC;AAC1B,cAAc,aAAa,CAAC;AAC5B,cAAc,WAAW,CAAC;AAC1B,cAAc,aAAa,CAAC"}},
    {"offset": {"line": 5788, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/cookies.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/cookies.ts"],"sourcesContent":["import { parse, serialize } from \"cookie\";\n\nimport {\n  DEFAULT_COOKIE_OPTIONS,\n  combineChunks,\n  createChunks,\n  isBrowser,\n  isChunkLike,\n  stringFromBase64URL,\n  stringToBase64URL,\n} from \"./utils\";\n\nimport type {\n  CookieMethodsServer,\n  CookieMethodsServerDeprecated,\n  CookieMethodsBrowser,\n  CookieMethodsBrowserDeprecated,\n  CookieOptions,\n  CookieOptionsWithName,\n  GetAllCookies,\n  SetAllCookies,\n} from \"./types\";\n\nconst BASE64_PREFIX = \"base64-\";\n\n/**\n * Creates a storage client that handles cookies correctly for browser and\n * server clients with or without properly provided cookie methods.\n *\n * @param options The options passed to createBrowserClient or createServer client.\n *\n * @param isServerClient Whether it's called from createServerClient.\n */\nexport function createStorageFromOptions(\n  options: {\n    cookieEncoding: \"raw\" | \"base64url\";\n    cookies?:\n      | CookieMethodsBrowser\n      | CookieMethodsBrowserDeprecated\n      | CookieMethodsServer\n      | CookieMethodsServerDeprecated;\n    cookieOptions?: CookieOptionsWithName;\n  },\n  isServerClient: boolean,\n) {\n  const cookies = options.cookies ?? null;\n  const cookieEncoding = options.cookieEncoding;\n\n  const setItems: { [key: string]: string } = {};\n  const removedItems: { [key: string]: boolean } = {};\n\n  let getAll: (keyHints: string[]) => ReturnType<GetAllCookies>;\n  let setAll: SetAllCookies;\n\n  if (cookies) {\n    if (\"get\" in cookies) {\n      // Just get is not enough, because the client needs to see what cookies\n      // are already set and unset them if necessary. To attempt to fix this\n      // behavior for most use cases, we pass \"hints\" which is the keys of the\n      // storage items. They are then converted to their corresponding cookie\n      // chunk names and are fetched with get. Only 5 chunks are fetched, which\n      // should be enough for the majority of use cases, but does not solve\n      // those with very large sessions.\n\n      const getWithHints = async (keyHints: string[]) => {\n        // optimistically find the first 5 potential chunks for the specified key\n        const chunkNames = keyHints.flatMap((keyHint) => [\n          keyHint,\n          ...Array.from({ length: 5 }).map((_, i) => `${keyHint}.${i}`),\n        ]);\n\n        const chunks: ReturnType<GetAllCookies> = [];\n\n        for (let i = 0; i < chunkNames.length; i += 1) {\n          const value = await cookies.get(chunkNames[i]);\n\n          if (!value && typeof value !== \"string\") {\n            continue;\n          }\n\n          chunks.push({ name: chunkNames[i], value });\n        }\n\n        // TODO: detect and log stale chunks error\n\n        return chunks;\n      };\n\n      getAll = async (keyHints: string[]) => await getWithHints(keyHints);\n\n      if (\"set\" in cookies && \"remove\" in cookies) {\n        setAll = async (setCookies) => {\n          for (let i = 0; i < setCookies.length; i += 1) {\n            const { name, value, options } = setCookies[i];\n\n            if (value) {\n              await cookies.set!(name, value, options);\n            } else {\n              await cookies.remove!(name, options);\n            }\n          }\n        };\n      } else if (isServerClient) {\n        setAll = async () => {\n          console.warn(\n            \"@supabase/ssr: createServerClient was configured without set and remove cookie methods, but the client needs to set cookies. This can lead to issues such as random logouts, early session termination or increased token refresh requests. If in NextJS, check your middleware.ts file, route handlers and server actions for correctness. Consider switching to the getAll and setAll cookie methods instead of get, set and remove which are deprecated and can be difficult to use correctly.\",\n          );\n        };\n      } else {\n        throw new Error(\n          \"@supabase/ssr: createBrowserClient requires configuring a getAll and setAll cookie method (deprecated: alternatively both get, set and remove can be used)\",\n        );\n      }\n    } else if (\"getAll\" in cookies) {\n      getAll = async () => await cookies.getAll!();\n\n      if (\"setAll\" in cookies) {\n        setAll = cookies.setAll!;\n      } else if (isServerClient) {\n        setAll = async () => {\n          console.warn(\n            \"@supabase/ssr: createServerClient was configured without the setAll cookie method, but the client needs to set cookies. This can lead to issues such as random logouts, early session termination or increased token refresh requests. If in NextJS, check your middleware.ts file, route handlers and server actions for correctness.\",\n          );\n        };\n      } else {\n        throw new Error(\n          \"@supabase/ssr: createBrowserClient requires configuring both getAll and setAll cookie methods (deprecated: alternatively both get, set and remove can be used)\",\n        );\n      }\n    } else {\n      // neither get nor getAll is present on cookies, only will occur if pure JavaScript is used, but cookies is an object\n      throw new Error(\n        `@supabase/ssr: ${isServerClient ? \"createServerClient\" : \"createBrowserClient\"} requires configuring getAll and setAll cookie methods (deprecated: alternatively use get, set and remove).${isBrowser() ? \" As this is called in a browser runtime, consider removing the cookies option object to use the document.cookie API automatically.\" : \"\"}`,\n      );\n    }\n  } else if (!isServerClient && isBrowser()) {\n    // The environment is browser, so use the document.cookie API to implement getAll and setAll.\n\n    const noHintGetAll = () => {\n      const parsed = parse(document.cookie);\n\n      return Object.keys(parsed).map((name) => ({\n        name,\n        value: parsed[name] ?? \"\",\n      }));\n    };\n\n    getAll = () => noHintGetAll();\n\n    setAll = (setCookies) => {\n      setCookies.forEach(({ name, value, options }) => {\n        document.cookie = serialize(name, value, options);\n      });\n    };\n  } else if (isServerClient) {\n    throw new Error(\n      \"@supabase/ssr: createServerClient must be initialized with cookie options that specify getAll and setAll functions (deprecated, not recommended: alternatively use get, set and remove)\",\n    );\n  } else {\n    // getting cookies when there's no window but we're in browser mode can be OK, because the developer probably is not using auth functions\n    getAll = () => {\n      return [];\n    };\n\n    // this is NOT OK because the developer is using auth functions that require setting some state, so that must error out\n    setAll = () => {\n      throw new Error(\n        \"@supabase/ssr: createBrowserClient in non-browser runtimes (including Next.js pre-rendering mode) was not initialized cookie options that specify getAll and setAll functions (deprecated: alternatively use get, set and remove), but they were needed\",\n      );\n    };\n  }\n\n  if (!isServerClient) {\n    // This is the storage client to be used in browsers. It only\n    // works on the cookies abstraction, unlike the server client\n    // which only uses cookies to read the initial state. When an\n    // item is set, cookies are both cleared and set to values so\n    // that stale chunks are not left remaining.\n    return {\n      getAll, // for type consistency\n      setAll, // for type consistency\n      setItems, // for type consistency\n      removedItems, // for type consistency\n      storage: {\n        isServer: false,\n        getItem: async (key: string) => {\n          const allCookies = await getAll([key]);\n          const chunkedCookie = await combineChunks(\n            key,\n            async (chunkName: string) => {\n              const cookie =\n                allCookies?.find(({ name }) => name === chunkName) || null;\n\n              if (!cookie) {\n                return null;\n              }\n\n              return cookie.value;\n            },\n          );\n\n          if (!chunkedCookie) {\n            return null;\n          }\n\n          let decoded = chunkedCookie;\n\n          if (chunkedCookie.startsWith(BASE64_PREFIX)) {\n            decoded = stringFromBase64URL(\n              chunkedCookie.substring(BASE64_PREFIX.length),\n            );\n          }\n\n          return decoded;\n        },\n        setItem: async (key: string, value: string) => {\n          const allCookies = await getAll([key]);\n          const cookieNames = allCookies?.map(({ name }) => name) || [];\n\n          const removeCookies = new Set(\n            cookieNames.filter((name) => isChunkLike(name, key)),\n          );\n\n          let encoded = value;\n\n          if (cookieEncoding === \"base64url\") {\n            encoded = BASE64_PREFIX + stringToBase64URL(value);\n          }\n\n          const setCookies = createChunks(key, encoded);\n\n          setCookies.forEach(({ name }) => {\n            removeCookies.delete(name);\n          });\n\n          const removeCookieOptions = {\n            ...DEFAULT_COOKIE_OPTIONS,\n            ...options?.cookieOptions,\n            maxAge: 0,\n          };\n          const setCookieOptions = {\n            ...DEFAULT_COOKIE_OPTIONS,\n            ...options?.cookieOptions,\n            maxAge: DEFAULT_COOKIE_OPTIONS.maxAge,\n          };\n\n          // the NextJS cookieStore API can get confused if the `name` from\n          // options.cookieOptions leaks\n          delete removeCookieOptions.name;\n          delete setCookieOptions.name;\n\n          const allToSet = [\n            ...[...removeCookies].map((name) => ({\n              name,\n              value: \"\",\n              options: removeCookieOptions,\n            })),\n            ...setCookies.map(({ name, value }) => ({\n              name,\n              value,\n              options: setCookieOptions,\n            })),\n          ];\n\n          if (allToSet.length > 0) {\n            await setAll(allToSet);\n          }\n        },\n        removeItem: async (key: string) => {\n          const allCookies = await getAll([key]);\n          const cookieNames = allCookies?.map(({ name }) => name) || [];\n          const removeCookies = cookieNames.filter((name) =>\n            isChunkLike(name, key),\n          );\n\n          const removeCookieOptions = {\n            ...DEFAULT_COOKIE_OPTIONS,\n            ...options?.cookieOptions,\n            maxAge: 0,\n          };\n\n          // the NextJS cookieStore API can get confused if the `name` from\n          // options.cookieOptions leaks\n          delete removeCookieOptions.name;\n\n          if (removeCookies.length > 0) {\n            await setAll(\n              removeCookies.map((name) => ({\n                name,\n                value: \"\",\n                options: removeCookieOptions,\n              })),\n            );\n          }\n        },\n      },\n    };\n  }\n\n  // This is the server client. It only uses getAll to read the initial\n  // state. Any subsequent changes to the items is persisted in the\n  // setItems and removedItems objects. createServerClient *must* use\n  // getAll, setAll and the values in setItems and removedItems to\n  // persist the changes *at once* when appropriate (usually only when\n  // the TOKEN_REFRESHED, USER_UPDATED or SIGNED_OUT events are fired by\n  // the Supabase Auth client).\n  return {\n    getAll,\n    setAll,\n    setItems,\n    removedItems,\n    storage: {\n      // to signal to the libraries that these cookies are\n      // coming from a server environment and their value\n      // should not be trusted\n      isServer: true,\n      getItem: async (key: string) => {\n        if (typeof setItems[key] === \"string\") {\n          return setItems[key];\n        }\n\n        if (removedItems[key]) {\n          return null;\n        }\n\n        const allCookies = await getAll([key]);\n        const chunkedCookie = await combineChunks(\n          key,\n          async (chunkName: string) => {\n            const cookie =\n              allCookies?.find(({ name }) => name === chunkName) || null;\n\n            if (!cookie) {\n              return null;\n            }\n\n            return cookie.value;\n          },\n        );\n\n        if (!chunkedCookie) {\n          return null;\n        }\n\n        let decoded = chunkedCookie;\n\n        if (\n          typeof chunkedCookie === \"string\" &&\n          chunkedCookie.startsWith(BASE64_PREFIX)\n        ) {\n          decoded = stringFromBase64URL(\n            chunkedCookie.substring(BASE64_PREFIX.length),\n          );\n        }\n\n        return decoded;\n      },\n      setItem: async (key: string, value: string) => {\n        // We don't have an `onAuthStateChange` event that can let us know that\n        // the PKCE code verifier is being set. Therefore, if we see it being\n        // set, we need to apply the storage (call `setAll` so the cookie is\n        // set properly).\n        if (key.endsWith(\"-code-verifier\")) {\n          await applyServerStorage(\n            {\n              getAll,\n              setAll,\n              // pretend only that the code verifier was set\n              setItems: { [key]: value },\n              // pretend that nothing was removed\n              removedItems: {},\n            },\n            {\n              cookieOptions: options?.cookieOptions ?? null,\n              cookieEncoding,\n            },\n          );\n        }\n\n        setItems[key] = value;\n        delete removedItems[key];\n      },\n      removeItem: async (key: string) => {\n        // Intentionally not applying the storage when the key is the PKCE code\n        // verifier, as usually right after it's removed other items are set,\n        // so application of the storage will be handled by the\n        // `onAuthStateChange` callback that follows removal -- usually as part\n        // of the `exchangeCodeForSession` call.\n        delete setItems[key];\n        removedItems[key] = true;\n      },\n    },\n  };\n}\n\n/**\n * When createServerClient needs to apply the created storage to cookies, it\n * should call this function which handles correcly setting cookies for stored\n * and removed items in the storage.\n */\nexport async function applyServerStorage(\n  {\n    getAll,\n    setAll,\n    setItems,\n    removedItems,\n  }: {\n    getAll: (keyHints: string[]) => ReturnType<GetAllCookies>;\n    setAll: SetAllCookies;\n    setItems: { [name: string]: string };\n    removedItems: { [name: string]: boolean };\n  },\n  options: {\n    cookieEncoding: \"raw\" | \"base64url\";\n    cookieOptions?: CookieOptions | null;\n  },\n) {\n  const cookieEncoding = options.cookieEncoding;\n  const cookieOptions = options.cookieOptions ?? null;\n\n  const allCookies = await getAll([\n    ...(setItems ? (Object.keys(setItems) as string[]) : []),\n    ...(removedItems ? (Object.keys(removedItems) as string[]) : []),\n  ]);\n  const cookieNames = allCookies?.map(({ name }) => name) || [];\n\n  const removeCookies: string[] = Object.keys(removedItems).flatMap(\n    (itemName) => {\n      return cookieNames.filter((name) => isChunkLike(name, itemName));\n    },\n  );\n\n  const setCookies = Object.keys(setItems).flatMap((itemName) => {\n    const removeExistingCookiesForItem = new Set(\n      cookieNames.filter((name) => isChunkLike(name, itemName)),\n    );\n\n    let encoded = setItems[itemName];\n\n    if (cookieEncoding === \"base64url\") {\n      encoded = BASE64_PREFIX + stringToBase64URL(encoded);\n    }\n\n    const chunks = createChunks(itemName, encoded);\n\n    chunks.forEach((chunk) => {\n      removeExistingCookiesForItem.delete(chunk.name);\n    });\n\n    removeCookies.push(...removeExistingCookiesForItem);\n\n    return chunks;\n  });\n\n  const removeCookieOptions = {\n    ...DEFAULT_COOKIE_OPTIONS,\n    ...cookieOptions,\n    maxAge: 0,\n  };\n  const setCookieOptions = {\n    ...DEFAULT_COOKIE_OPTIONS,\n    ...cookieOptions,\n    maxAge: DEFAULT_COOKIE_OPTIONS.maxAge,\n  };\n\n  // the NextJS cookieStore API can get confused if the `name` from\n  // options.cookieOptions leaks\n  delete (removeCookieOptions as any).name;\n  delete (setCookieOptions as any).name;\n\n  await setAll([\n    ...removeCookies.map((name) => ({\n      name,\n      value: \"\",\n      options: removeCookieOptions,\n    })),\n    ...setCookies.map(({ name, value }) => ({\n      name,\n      value,\n      options: setCookieOptions,\n    })),\n  ]);\n}\n"],"names":[],"mappings":";;;;;;AAAA,OAAO,EAAE,KAAK,EAAE,SAAS,EAAE,MAAM,QAAQ,CAAC;;;;;AAE1C,OAAO,EACL,sBAAsB,EACtB,aAAa,EACb,YAAY,EACZ,SAAS,EACT,WAAW,EACX,mBAAmB,EACnB,iBAAiB,GAClB,MAAM,SAAS,CAAC;;;AAajB,MAAM,aAAa,GAAG,SAAS,CAAC;AAU1B,SAAU,wBAAwB,CACtC,OAQC,EACD,cAAuB;IAEvB,MAAM,OAAO,GAAG,OAAO,CAAC,OAAO,IAAI,IAAI,CAAC;IACxC,MAAM,cAAc,GAAG,OAAO,CAAC,cAAc,CAAC;IAE9C,MAAM,QAAQ,GAA8B,CAAA,CAAE,CAAC;IAC/C,MAAM,YAAY,GAA+B,CAAA,CAAE,CAAC;IAEpD,IAAI,MAAyD,CAAC;IAC9D,IAAI,MAAqB,CAAC;IAE1B,IAAI,OAAO,EAAE,CAAC;QACZ,IAAI,KAAK,IAAI,OAAO,EAAE,CAAC;YACrB,uEAAuE;YACvE,sEAAsE;YACtE,wEAAwE;YACxE,uEAAuE;YACvE,yEAAyE;YACzE,qEAAqE;YACrE,kCAAkC;YAElC,MAAM,YAAY,GAAG,KAAK,EAAE,QAAkB,EAAE,EAAE;gBAChD,yEAAyE;gBACzE,MAAM,UAAU,GAAG,QAAQ,CAAC,OAAO,CAAC,CAAC,OAAO,EAAE,CAAG,CAAD;wBAC9C,OAAO;2BACJ,KAAK,CAAC,IAAI,CAAC;4BAAE,MAAM,EAAE,CAAC;wBAAA,CAAE,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAG,CAAD,EAAI,OAAO,CAAA,CAAA,EAAI,CAAC,EAAE,CAAC;qBAC9D,CAAC,CAAC;gBAEH,MAAM,MAAM,GAA8B,EAAE,CAAC;gBAE7C,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;oBAC9C,MAAM,KAAK,GAAG,MAAM,OAAO,CAAC,GAAG,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;oBAE/C,IAAI,CAAC,KAAK,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,CAAC;wBACxC,SAAS;oBACX,CAAC;oBAED,MAAM,CAAC,IAAI,CAAC;wBAAE,IAAI,EAAE,UAAU,CAAC,CAAC,CAAC;wBAAE,KAAK;oBAAA,CAAE,CAAC,CAAC;gBAC9C,CAAC;gBAED,0CAA0C;gBAE1C,OAAO,MAAM,CAAC;YAChB,CAAC,CAAC;YAEF,MAAM,GAAG,KAAK,EAAE,QAAkB,EAAE,CAAG,CAAD,KAAO,YAAY,CAAC,QAAQ,CAAC,CAAC;YAEpE,IAAI,KAAK,IAAI,OAAO,IAAI,QAAQ,IAAI,OAAO,EAAE,CAAC;gBAC5C,MAAM,GAAG,KAAK,EAAE,UAAU,EAAE,EAAE;oBAC5B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,CAAE,CAAC;wBAC9C,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;wBAE/C,IAAI,KAAK,EAAE,CAAC;4BACV,MAAM,OAAO,CAAC,GAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;wBAC3C,CAAC,MAAM,CAAC;4BACN,MAAM,OAAO,CAAC,MAAO,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;wBACvC,CAAC;oBACH,CAAC;gBACH,CAAC,CAAC;YACJ,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;gBAC1B,MAAM,GAAG,KAAK,IAAI,EAAE;oBAClB,OAAO,CAAC,IAAI,CACV,meAAme,CACpe,CAAC;gBACJ,CAAC,CAAC;YACJ,CAAC,MAAM,CAAC;gBACN,MAAM,IAAI,KAAK,CACb,4JAA4J,CAC7J,CAAC;YACJ,CAAC;QACH,CAAC,MAAM,IAAI,QAAQ,IAAI,OAAO,EAAE,CAAC;YAC/B,MAAM,GAAG,KAAK,IAAI,CAAG,CAAD,KAAO,OAAO,CAAC,MAAO,EAAE,CAAC;YAE7C,IAAI,QAAQ,IAAI,OAAO,EAAE,CAAC;gBACxB,MAAM,GAAG,OAAO,CAAC,MAAO,CAAC;YAC3B,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;gBAC1B,MAAM,GAAG,KAAK,IAAI,EAAE;oBAClB,OAAO,CAAC,IAAI,CACV,wUAAwU,CACzU,CAAC;gBACJ,CAAC,CAAC;YACJ,CAAC,MAAM,CAAC;gBACN,MAAM,IAAI,KAAK,CACb,gKAAgK,CACjK,CAAC;YACJ,CAAC;QACH,CAAC,MAAM,CAAC;YACN,qHAAqH;YACrH,MAAM,IAAI,KAAK,CACb,CAAA,eAAA,EAAkB,cAAc,CAAC,CAAC,CAAC,oBAAoB,CAAC,CAAC,CAAC,qBAAqB,CAAA,2GAAA,MAA8G,4LAAS,EAAE,CAAC,CAAC,EAAC,oIAAoI,CAAC,CAAC,CAAC,EAAE,EAAE,CACvV,CAAC;QACJ,CAAC;IACH,CAAC,MAAM,IAAI,CAAC,cAAc,QAAI,4LAAS,EAAE,GAAE,CAAC;QAC1C,6FAA6F;QAE7F,MAAM,YAAY,GAAG,GAAG,EAAE;YACxB,MAAM,MAAM,OAAG,wJAAK,EAAC,QAAQ,CAAC,MAAM,CAAC,CAAC;YAEtC,OAAO,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;oBACxC,IAAI;oBACJ,KAAK,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE;iBAC1B,CAAC,CAAC,CAAC;QACN,CAAC,CAAC;QAEF,MAAM,GAAG,GAAG,CAAG,CAAD,WAAa,EAAE,CAAC;QAE9B,MAAM,GAAG,CAAC,UAAU,EAAE,EAAE;YACtB,UAAU,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,EAAE,EAAE;gBAC9C,QAAQ,CAAC,MAAM,OAAG,4JAAS,EAAC,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;YACpD,CAAC,CAAC,CAAC;QACL,CAAC,CAAC;IACJ,CAAC,MAAM,IAAI,cAAc,EAAE,CAAC;QAC1B,MAAM,IAAI,KAAK,CACb,yLAAyL,CAC1L,CAAC;IACJ,CAAC,MAAM,CAAC;QACN,yIAAyI;QACzI,MAAM,GAAG,GAAG,EAAE;YACZ,OAAO,EAAE,CAAC;QACZ,CAAC,CAAC;QAEF,uHAAuH;QACvH,MAAM,GAAG,GAAG,EAAE;YACZ,MAAM,IAAI,KAAK,CACb,yPAAyP,CAC1P,CAAC;QACJ,CAAC,CAAC;IACJ,CAAC;IAED,IAAI,CAAC,cAAc,EAAE,CAAC;QACpB,6DAA6D;QAC7D,6DAA6D;QAC7D,6DAA6D;QAC7D,6DAA6D;QAC7D,4CAA4C;QAC5C,OAAO;YACL,MAAM,EAAE,uBAAuB;YAC/B,MAAM,EAAE,uBAAuB;YAC/B,QAAQ,EAAE,uBAAuB;YACjC,YAAY,EAAE,uBAAuB;YACrC,OAAO,EAAE;gBACP,QAAQ,EAAE,KAAK;gBACf,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;oBAC7B,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;wBAAC,GAAG;qBAAC,CAAC,CAAC;oBACvC,MAAM,aAAa,GAAG,UAAM,gMAAa,EACvC,GAAG,EACH,KAAK,EAAE,SAAiB,EAAE,EAAE;wBAC1B,MAAM,MAAM,GACV,UAAU,EAAE,IAAI,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,KAAK,SAAS,CAAC,IAAI,IAAI,CAAC;wBAE7D,IAAI,CAAC,MAAM,EAAE,CAAC;4BACZ,OAAO,IAAI,CAAC;wBACd,CAAC;wBAED,OAAO,MAAM,CAAC,KAAK,CAAC;oBACtB,CAAC,CACF,CAAC;oBAEF,IAAI,CAAC,aAAa,EAAE,CAAC;wBACnB,OAAO,IAAI,CAAC;oBACd,CAAC;oBAED,IAAI,OAAO,GAAG,aAAa,CAAC;oBAE5B,IAAI,aAAa,CAAC,UAAU,CAAC,aAAa,CAAC,EAAE,CAAC;wBAC5C,OAAO,OAAG,wMAAmB,EAC3B,aAAa,CAAC,SAAS,CAAC,aAAa,CAAC,MAAM,CAAC,CAC9C,CAAC;oBACJ,CAAC;oBAED,OAAO,OAAO,CAAC;gBACjB,CAAC;gBACD,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,KAAa,EAAE,EAAE;oBAC5C,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;wBAAC,GAAG;qBAAC,CAAC,CAAC;oBACvC,MAAM,WAAW,GAAG,UAAU,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,EAAE,CAAC;oBAE9D,MAAM,aAAa,GAAG,IAAI,GAAG,CAC3B,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,UAAY,yLAAC,IAAI,EAAE,GAAG,CAAC,CAAC,CACrD,CAAC;oBAEF,IAAI,OAAO,GAAG,KAAK,CAAC;oBAEpB,IAAI,cAAc,KAAK,WAAW,EAAE,CAAC;wBACnC,OAAO,GAAG,aAAa,OAAG,sMAAiB,EAAC,KAAK,CAAC,CAAC;oBACrD,CAAC;oBAED,MAAM,UAAU,OAAG,+LAAY,EAAC,GAAG,EAAE,OAAO,CAAC,CAAC;oBAE9C,UAAU,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE;wBAC9B,aAAa,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;oBAC7B,CAAC,CAAC,CAAC;oBAEH,MAAM,mBAAmB,GAAG;wBAC1B,GAAG,2MAAsB;wBACzB,GAAG,OAAO,EAAE,aAAa;wBACzB,MAAM,EAAE,CAAC;qBACV,CAAC;oBACF,MAAM,gBAAgB,GAAG;wBACvB,GAAG,2MAAsB;wBACzB,GAAG,OAAO,EAAE,aAAa;wBACzB,MAAM,EAAE,2MAAsB,CAAC,MAAM;qBACtC,CAAC;oBAEF,iEAAiE;oBACjE,8BAA8B;oBAC9B,OAAO,mBAAmB,CAAC,IAAI,CAAC;oBAChC,OAAO,gBAAgB,CAAC,IAAI,CAAC;oBAE7B,MAAM,QAAQ,GAAG;2BACZ,CAAC;+BAAG,aAAa;yBAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;gCACnC,IAAI;gCACJ,KAAK,EAAE,EAAE;gCACT,OAAO,EAAE,mBAAmB;6BAC7B,CAAC,CAAC;2BACA,UAAU,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,EAAE,CAAG,CAAD,AAAE;gCACtC,IAAI;gCACJ,KAAK;gCACL,OAAO,EAAE,gBAAgB;6BAC1B,CAAC,CAAC;qBACJ,CAAC;oBAEF,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;wBACxB,MAAM,MAAM,CAAC,QAAQ,CAAC,CAAC;oBACzB,CAAC;gBACH,CAAC;gBACD,UAAU,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;oBAChC,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;wBAAC,GAAG;qBAAC,CAAC,CAAC;oBACvC,MAAM,WAAW,GAAG,UAAU,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,EAAE,CAAC;oBAC9D,MAAM,aAAa,GAAG,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAC9C,CADgD,UACrC,yLAAC,IAAI,EAAE,GAAG,CAAC,CACvB,CAAC;oBAEF,MAAM,mBAAmB,GAAG;wBAC1B,GAAG,2MAAsB;wBACzB,GAAG,OAAO,EAAE,aAAa;wBACzB,MAAM,EAAE,CAAC;qBACV,CAAC;oBAEF,iEAAiE;oBACjE,8BAA8B;oBAC9B,OAAO,mBAAmB,CAAC,IAAI,CAAC;oBAEhC,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC;wBAC7B,MAAM,MAAM,CACV,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;gCAC3B,IAAI;gCACJ,KAAK,EAAE,EAAE;gCACT,OAAO,EAAE,mBAAmB;6BAC7B,CAAC,CAAC,CACJ,CAAC;oBACJ,CAAC;gBACH,CAAC;aACF;SACF,CAAC;IACJ,CAAC;IAED,qEAAqE;IACrE,iEAAiE;IACjE,mEAAmE;IACnE,gEAAgE;IAChE,oEAAoE;IACpE,sEAAsE;IACtE,6BAA6B;IAC7B,OAAO;QACL,MAAM;QACN,MAAM;QACN,QAAQ;QACR,YAAY;QACZ,OAAO,EAAE;YACP,oDAAoD;YACpD,mDAAmD;YACnD,wBAAwB;YACxB,QAAQ,EAAE,IAAI;YACd,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;gBAC7B,IAAI,OAAO,QAAQ,CAAC,GAAG,CAAC,KAAK,QAAQ,EAAE,CAAC;oBACtC,OAAO,QAAQ,CAAC,GAAG,CAAC,CAAC;gBACvB,CAAC;gBAED,IAAI,YAAY,CAAC,GAAG,CAAC,EAAE,CAAC;oBACtB,OAAO,IAAI,CAAC;gBACd,CAAC;gBAED,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;oBAAC,GAAG;iBAAC,CAAC,CAAC;gBACvC,MAAM,aAAa,GAAG,UAAM,gMAAa,EACvC,GAAG,EACH,KAAK,EAAE,SAAiB,EAAE,EAAE;oBAC1B,MAAM,MAAM,GACV,UAAU,EAAE,IAAI,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,KAAK,SAAS,CAAC,IAAI,IAAI,CAAC;oBAE7D,IAAI,CAAC,MAAM,EAAE,CAAC;wBACZ,OAAO,IAAI,CAAC;oBACd,CAAC;oBAED,OAAO,MAAM,CAAC,KAAK,CAAC;gBACtB,CAAC,CACF,CAAC;gBAEF,IAAI,CAAC,aAAa,EAAE,CAAC;oBACnB,OAAO,IAAI,CAAC;gBACd,CAAC;gBAED,IAAI,OAAO,GAAG,aAAa,CAAC;gBAE5B,IACE,OAAO,aAAa,KAAK,QAAQ,IACjC,aAAa,CAAC,UAAU,CAAC,aAAa,CAAC,EACvC,CAAC;oBACD,OAAO,OAAG,wMAAmB,EAC3B,aAAa,CAAC,SAAS,CAAC,aAAa,CAAC,MAAM,CAAC,CAC9C,CAAC;gBACJ,CAAC;gBAED,OAAO,OAAO,CAAC;YACjB,CAAC;YACD,OAAO,EAAE,KAAK,EAAE,GAAW,EAAE,KAAa,EAAE,EAAE;gBAC5C,uEAAuE;gBACvE,qEAAqE;gBACrE,oEAAoE;gBACpE,iBAAiB;gBACjB,IAAI,GAAG,CAAC,QAAQ,CAAC,gBAAgB,CAAC,EAAE,CAAC;oBACnC,MAAM,kBAAkB,CACtB;wBACE,MAAM;wBACN,MAAM;wBACN,8CAA8C;wBAC9C,QAAQ,EAAE;4BAAE,CAAC,GAAG,CAAC,EAAE,KAAK;wBAAA,CAAE;wBAC1B,mCAAmC;wBACnC,YAAY,EAAE,CAAA,CAAE;qBACjB,EACD;wBACE,aAAa,EAAE,OAAO,EAAE,aAAa,IAAI,IAAI;wBAC7C,cAAc;qBACf,CACF,CAAC;gBACJ,CAAC;gBAED,QAAQ,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC;gBACtB,OAAO,YAAY,CAAC,GAAG,CAAC,CAAC;YAC3B,CAAC;YACD,UAAU,EAAE,KAAK,EAAE,GAAW,EAAE,EAAE;gBAChC,uEAAuE;gBACvE,qEAAqE;gBACrE,uDAAuD;gBACvD,uEAAuE;gBACvE,wCAAwC;gBACxC,OAAO,QAAQ,CAAC,GAAG,CAAC,CAAC;gBACrB,YAAY,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC;YAC3B,CAAC;SACF;KACF,CAAC;AACJ,CAAC;AAOM,KAAK,UAAU,kBAAkB,CACtC,EACE,MAAM,EACN,MAAM,EACN,QAAQ,EACR,YAAY,EAMb,EACD,OAGC;IAED,MAAM,cAAc,GAAG,OAAO,CAAC,cAAc,CAAC;IAC9C,MAAM,aAAa,GAAG,OAAO,CAAC,aAAa,IAAI,IAAI,CAAC;IAEpD,MAAM,UAAU,GAAG,MAAM,MAAM,CAAC;WAC1B,QAAQ,CAAC,CAAC,CAAE,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAc,CAAC,CAAC,CAAC,EAAE,CAAC;WACpD,YAAY,CAAC,CAAC,CAAE,MAAM,CAAC,IAAI,CAAC,YAAY,CAAc,CAAC,CAAC,CAAC,EAAE,CAAC;KACjE,CAAC,CAAC;IACH,MAAM,WAAW,GAAG,UAAU,EAAE,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,EAAE,CAAC;IAE9D,MAAM,aAAa,GAAa,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,OAAO,CAC/D,CAAC,QAAQ,EAAE,EAAE;QACX,OAAO,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,UAAY,yLAAC,IAAI,EAAE,QAAQ,CAAC,CAAC,CAAC;IACnE,CAAC,CACF,CAAC;IAEF,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,OAAO,CAAC,CAAC,QAAQ,EAAE,EAAE;QAC5D,MAAM,4BAA4B,GAAG,IAAI,GAAG,CAC1C,WAAW,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,UAAY,yLAAC,IAAI,EAAE,QAAQ,CAAC,CAAC,CAC1D,CAAC;QAEF,IAAI,OAAO,GAAG,QAAQ,CAAC,QAAQ,CAAC,CAAC;QAEjC,IAAI,cAAc,KAAK,WAAW,EAAE,CAAC;YACnC,OAAO,GAAG,aAAa,OAAG,sMAAiB,EAAC,OAAO,CAAC,CAAC;QACvD,CAAC;QAED,MAAM,MAAM,OAAG,+LAAY,EAAC,QAAQ,EAAE,OAAO,CAAC,CAAC;QAE/C,MAAM,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE,EAAE;YACvB,4BAA4B,CAAC,MAAM,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;QAClD,CAAC,CAAC,CAAC;QAEH,aAAa,CAAC,IAAI,CAAC,GAAG,4BAA4B,CAAC,CAAC;QAEpD,OAAO,MAAM,CAAC;IAChB,CAAC,CAAC,CAAC;IAEH,MAAM,mBAAmB,GAAG;QAC1B,GAAG,2MAAsB;QACzB,GAAG,aAAa;QAChB,MAAM,EAAE,CAAC;KACV,CAAC;IACF,MAAM,gBAAgB,GAAG;QACvB,GAAG,2MAAsB;QACzB,GAAG,aAAa;QAChB,MAAM,EAAE,2MAAsB,CAAC,MAAM;KACtC,CAAC;IAEF,iEAAiE;IACjE,8BAA8B;IAC9B,OAAQ,mBAA2B,CAAC,IAAI,CAAC;IACzC,OAAQ,gBAAwB,CAAC,IAAI,CAAC;IAEtC,MAAM,MAAM,CAAC;WACR,aAAa,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,AAAE;gBAC9B,IAAI;gBACJ,KAAK,EAAE,EAAE;gBACT,OAAO,EAAE,mBAAmB;aAC7B,CAAC,CAAC;WACA,UAAU,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,EAAE,KAAK,EAAE,EAAE,CAAG,CAAD,AAAE;gBACtC,IAAI;gBACJ,KAAK;gBACL,OAAO,EAAE,gBAAgB;aAC1B,CAAC,CAAC;KACJ,CAAC,CAAC;AACL,CAAC"}},
    {"offset": {"line": 6139, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/createBrowserClient.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/createBrowserClient.ts"],"sourcesContent":["import {\n  createClient,\n  SupabaseClient,\n  SupabaseClientOptions,\n} from \"@supabase/supabase-js\";\n\nimport { VERSION } from \"./version\";\nimport { isBrowser } from \"./utils\";\n\nimport type {\n  CookieMethodsBrowser,\n  CookieMethodsBrowserDeprecated,\n  CookieOptionsWithName,\n} from \"./types\";\n\nimport { createStorageFromOptions } from \"./cookies\";\n\nlet cachedBrowserClient: SupabaseClient<any, any, any> | undefined;\n\n/**\n * Creates a Supabase Client for use in a browser environment.\n *\n * In most cases you should not configure the `options.cookies` object, as this\n * is automatically handled for you. If you do customize this, prefer using the\n * `getAll` and `setAll` functions over `get`, `set` and `remove`. The latter\n * are deprecated due to being difficult to correctly implement and not\n * supporting some edge-cases. Both `getAll` and `setAll` (or both `get`, `set`\n * and `remove`) must be provided. Failing to provide the methods for setting\n * will throw an exception, and in previous versions of the library will result\n * in difficult to debug authentication issues such as random logouts, early\n * session termination or problems with inconsistent state.\n *\n * @param supabaseUrl The URL of the Supabase project.\n * @param supabaseKey The `anon` API key of the Supabase project.\n * @param options Various configuration options.\n */\nexport function createBrowserClient<\n  Database = any,\n  SchemaName extends string &\n    keyof Omit<Database, \"__InternalSupabase\"> = \"public\" extends keyof Omit<\n    Database,\n    \"__InternalSupabase\"\n  >\n    ? \"public\"\n    : string & keyof Omit<Database, \"__InternalSupabase\">,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName> & {\n    cookies?: CookieMethodsBrowser;\n    cookieOptions?: CookieOptionsWithName;\n    cookieEncoding?: \"raw\" | \"base64url\";\n    isSingleton?: boolean;\n  },\n): SupabaseClient<Database, SchemaName>;\n\n/**\n * @deprecated Please specify `getAll` and `setAll` cookie methods instead of\n * the `get`, `set` and `remove`. These will not be supported in the next major\n * version.\n */\nexport function createBrowserClient<\n  Database = any,\n  SchemaName extends string &\n    keyof Omit<Database, \"__InternalSupabase\"> = \"public\" extends keyof Omit<\n    Database,\n    \"__InternalSupabase\"\n  >\n    ? \"public\"\n    : string & keyof Omit<Database, \"__InternalSupabase\">,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName> & {\n    cookies: CookieMethodsBrowserDeprecated;\n    cookieOptions?: CookieOptionsWithName;\n    cookieEncoding?: \"raw\" | \"base64url\";\n    isSingleton?: boolean;\n  },\n): SupabaseClient<Database, SchemaName>;\n\nexport function createBrowserClient<\n  Database = any,\n  SchemaName extends string &\n    keyof Omit<Database, \"__InternalSupabase\"> = \"public\" extends keyof Omit<\n    Database,\n    \"__InternalSupabase\"\n  >\n    ? \"public\"\n    : string & keyof Omit<Database, \"__InternalSupabase\">,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName> & {\n    cookies?: CookieMethodsBrowser | CookieMethodsBrowserDeprecated;\n    cookieOptions?: CookieOptionsWithName;\n    cookieEncoding?: \"raw\" | \"base64url\";\n    isSingleton?: boolean;\n  },\n): SupabaseClient<Database, SchemaName> {\n  // singleton client is created only if isSingleton is set to true, or if isSingleton is not defined and we detect a browser\n  const shouldUseSingleton =\n    options?.isSingleton === true ||\n    ((!options || !(\"isSingleton\" in options)) && isBrowser());\n\n  if (shouldUseSingleton && cachedBrowserClient) {\n    return cachedBrowserClient;\n  }\n\n  if (!supabaseUrl || !supabaseKey) {\n    throw new Error(\n      `@supabase/ssr: Your project's URL and API key are required to create a Supabase client!\\n\\nCheck your Supabase project's API settings to find these values\\n\\nhttps://supabase.com/dashboard/project/_/settings/api`,\n    );\n  }\n\n  const { storage } = createStorageFromOptions(\n    {\n      ...options,\n      cookieEncoding: options?.cookieEncoding ?? \"base64url\",\n    },\n    false,\n  );\n\n  const client = createClient<Database, SchemaName>(supabaseUrl, supabaseKey, {\n    // TODO: resolve type error\n    ...(options as any),\n    global: {\n      ...options?.global,\n      headers: {\n        ...options?.global?.headers,\n        \"X-Client-Info\": `supabase-ssr/${VERSION} createBrowserClient`,\n      },\n    },\n    auth: {\n      ...options?.auth,\n      ...(options?.cookieOptions?.name\n        ? { storageKey: options.cookieOptions.name }\n        : null),\n      flowType: \"pkce\",\n      autoRefreshToken: isBrowser(),\n      detectSessionInUrl: isBrowser(),\n      persistSession: true,\n      storage,\n    },\n  });\n\n  if (shouldUseSingleton) {\n    cachedBrowserClient = client;\n  }\n\n  return client;\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EACL,YAAY,GAGb,MAAM,uBAAuB,CAAC;AAE/B,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAC;;AACpC,OAAO,EAAE,SAAS,EAAE,MAAM,SAAS,CAAC;AAQpC,OAAO,EAAE,wBAAwB,EAAE,MAAM,WAAW,CAAC;;;;;AAErD,IAAI,mBAA8D,CAAC;AAgE7D,SAAU,mBAAmB,CAUjC,WAAmB,EACnB,WAAmB,EACnB,OAKC;IAED,2HAA2H;IAC3H,MAAM,kBAAkB,GACtB,OAAO,EAAE,WAAW,KAAK,IAAI,IAC5B,CAAC,CAAC,OAAO,IAAI,CAAC,CAAC,aAAa,IAAI,OAAO,CAAC,CAAC,QAAI,4LAAS,EAAE,CAAC,CAAC;IAE7D,IAAI,kBAAkB,IAAI,mBAAmB,EAAE,CAAC;QAC9C,OAAO,mBAAmB,CAAC;IAC7B,CAAC;IAED,IAAI,CAAC,WAAW,IAAI,CAAC,WAAW,EAAE,CAAC;QACjC,MAAM,IAAI,KAAK,CACb,CAAA,mNAAA,CAAqN,CACtN,CAAC;IACJ,CAAC;IAED,MAAM,EAAE,OAAO,EAAE,OAAG,kMAAwB,EAC1C;QACE,GAAG,OAAO;QACV,cAAc,EAAE,OAAO,EAAE,cAAc,IAAI,WAAW;KACvD,EACD,KAAK,CACN,CAAC;IAEF,MAAM,MAAM,OAAG,+MAAY,EAAuB,WAAW,EAAE,WAAW,EAAE;QAC1E,2BAA2B;QAC3B,GAAI,OAAe;QACnB,MAAM,EAAE;YACN,GAAG,OAAO,EAAE,MAAM;YAClB,OAAO,EAAE;gBACP,GAAG,OAAO,EAAE,MAAM,EAAE,OAAO;gBAC3B,eAAe,EAAE,CAAA,aAAA,EAAgB,iLAAO,CAAA,oBAAA,CAAsB;aAC/D;SACF;QACD,IAAI,EAAE;YACJ,GAAG,OAAO,EAAE,IAAI;YAChB,GAAG,AAAC,OAAO,EAAE,aAAa,EAAE,IAAI,GAC5B;gBAAE,UAAU,EAAE,OAAO,CAAC,aAAa,CAAC,IAAI;YAAA,CAAE,GAC1C,IAAI,CAAC;YACT,QAAQ,EAAE,MAAM;YAChB,gBAAgB,MAAE,4LAAS,EAAE;YAC7B,kBAAkB,MAAE,4LAAS,EAAE;YAC/B,cAAc,EAAE,IAAI;YACpB,OAAO;SACR;KACF,CAAC,CAAC;IAEH,IAAI,kBAAkB,EAAE,CAAC;QACvB,mBAAmB,GAAG,MAAM,CAAC;IAC/B,CAAC;IAED,OAAO,MAAM,CAAC;AAChB,CAAC"}},
    {"offset": {"line": 6197, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/createServerClient.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/createServerClient.ts"],"sourcesContent":["import {\n  AuthChangeEvent,\n  createClient,\n  SupabaseClient,\n  SupabaseClientOptions,\n} from \"@supabase/supabase-js\";\n\nimport { VERSION } from \"./version\";\nimport { createStorageFromOptions, applyServerStorage } from \"./cookies\";\nimport type {\n  CookieOptionsWithName,\n  CookieMethodsServer,\n  CookieMethodsServerDeprecated,\n} from \"./types\";\n\n/**\n * @deprecated Please specify `getAll` and `setAll` cookie methods instead of\n * the `get`, `set` and `remove`. These will not be supported in the next major\n * version.\n */\nexport function createServerClient<\n  Database = any,\n  SchemaName extends string &\n    keyof Omit<Database, \"__InternalSupabase\"> = \"public\" extends keyof Omit<\n    Database,\n    \"__InternalSupabase\"\n  >\n    ? \"public\"\n    : string & keyof Omit<Database, \"__InternalSupabase\">,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options: SupabaseClientOptions<SchemaName> & {\n    cookieOptions?: CookieOptionsWithName;\n    cookies: CookieMethodsServerDeprecated;\n    cookieEncoding?: \"raw\" | \"base64url\";\n  },\n): SupabaseClient<Database, SchemaName>;\n\n/**\n * Creates a Supabase Client for use on the server-side of a server-side\n * rendering (SSR) framework.\n *\n * There are two categories of uses for this function: use in middlewares and\n * use in pages, components or routes.\n *\n * **Use in middlewares.**\n *\n * Middlewares are functions that run before any rendering logic is executed on\n * the server-side. They typically have access to request headers (cookies) and\n * can modify both the request and response headers.\n *\n * In most SSR frameworks, to use Supabase correctly you *must set up a\n * middleware* and use this function in it.\n *\n * When using this in a middleware, the `cookie` option must be configured to\n * use both `getAll` and `setAll`. Alternatively you can use the `get`, `set`\n * and `remove` functions. The latter are deprecated **and not recommended**\n * for most use cases due to being difficult to use properly and they do not\n * cover important edge cases. In future major versions of the library, the\n * option to configure `get`, `set` and `remove` will be removed.\n *\n * **IMPORTANT:** Failing to implement `getAll` and `setAll` correctly (or the\n * deprecated `get`, `set` and `remove`) including omitting them **will cause\n * significant and difficult to debug authentication issues**. They will\n * manifest as: random logouts, early session termination, JSON parsing errors,\n * increased number of refresh token requests, or relying on garbage state.\n *\n * **Use in pages, components or routes.**\n *\n * To use Supabase features server-side rendered in pages, components or routes\n * (a.k.a. actions / APIs) you must create a client with this function. Not all\n * frameworks allow the ability to set cookies or response headers when pages\n * or components are rendered. In those cases you _can omit `setAll` (or the\n * deprecated `set`, `remove`) cookie option methods_. **It is strongly\n * recommended that if the ability to set cookies and response headers is\n * present, you should configure the `setAll` (or the deprecated `set` and\n * `remove`) cookie access methods.**\n *\n * **IMPORTANT:** If the ability to set cookies or response headers is not\n * available **middleware or an equivalent must be used.** Failing to do this\n * will cause significant and difficult to debug authentication issues.\n *\n * When `setAll` (or the deprecated `set`, `remove`) cookie methods are not\n * configured, the Supabase Client will emit a warning if it is used in a way\n * that requires setting cookies. If you see this warning, it usually means\n * that you are using the Supabase Client in a wrong way:\n *\n * - You should have, but did not configure a middleware client.\n * - There is a bug in your middleware function.\n * - You are using features of the Supabase Client that change the User, e.g.\n *   by calling `supabase.auth.updateUser()` on the server.\n *\n * Please consult the latest Supabase guides for advice on how to avoid common\n * pitfalls depending on SSR framework.\n *\n * @param supabaseUrl The URL of the Supabase project.\n * @param supabaseKey The `anon` API key of the Supabase project.\n * @param options Various configuration options.\n */\nexport function createServerClient<\n  Database = any,\n  SchemaName extends string &\n    keyof Omit<Database, \"__InternalSupabase\"> = \"public\" extends keyof Omit<\n    Database,\n    \"__InternalSupabase\"\n  >\n    ? \"public\"\n    : string & keyof Omit<Database, \"__InternalSupabase\">,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options: SupabaseClientOptions<SchemaName> & {\n    cookieOptions?: CookieOptionsWithName;\n    cookies: CookieMethodsServer;\n    cookieEncoding?: \"raw\" | \"base64url\";\n  },\n): SupabaseClient<Database, SchemaName>;\n\nexport function createServerClient<\n  Database = any,\n  SchemaName extends string &\n    keyof Omit<Database, \"__InternalSupabase\"> = \"public\" extends keyof Omit<\n    Database,\n    \"__InternalSupabase\"\n  >\n    ? \"public\"\n    : string & keyof Omit<Database, \"__InternalSupabase\">,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options: SupabaseClientOptions<SchemaName> & {\n    cookieOptions?: CookieOptionsWithName;\n    cookies: CookieMethodsServer | CookieMethodsServerDeprecated;\n    cookieEncoding?: \"raw\" | \"base64url\";\n  },\n): SupabaseClient<Database, SchemaName> {\n  if (!supabaseUrl || !supabaseKey) {\n    throw new Error(\n      `Your project's URL and Key are required to create a Supabase client!\\n\\nCheck your Supabase project's API settings to find these values\\n\\nhttps://supabase.com/dashboard/project/_/settings/api`,\n    );\n  }\n\n  const { storage, getAll, setAll, setItems, removedItems } =\n    createStorageFromOptions(\n      {\n        ...options,\n        cookieEncoding: options?.cookieEncoding ?? \"base64url\",\n      },\n      true,\n    );\n\n  const client = createClient<Database, SchemaName>(supabaseUrl, supabaseKey, {\n    // TODO: resolve type error\n    ...(options as any),\n    global: {\n      ...options?.global,\n      headers: {\n        ...options?.global?.headers,\n        \"X-Client-Info\": `supabase-ssr/${VERSION} createServerClient`,\n      },\n    },\n    auth: {\n      ...(options?.cookieOptions?.name\n        ? { storageKey: options.cookieOptions.name }\n        : null),\n      ...options?.auth,\n      flowType: \"pkce\",\n      autoRefreshToken: false,\n      detectSessionInUrl: false,\n      persistSession: true,\n      storage,\n    },\n  });\n\n  client.auth.onAuthStateChange(async (event: AuthChangeEvent) => {\n    // The SIGNED_IN event is fired very often, but we don't need to\n    // apply the storage each time it fires, only if there are changes\n    // that need to be set -- which is if setItems / removeItems have\n    // data.\n    const hasStorageChanges =\n      Object.keys(setItems).length > 0 || Object.keys(removedItems).length > 0;\n\n    if (\n      hasStorageChanges &&\n      (event === \"SIGNED_IN\" ||\n        event === \"TOKEN_REFRESHED\" ||\n        event === \"USER_UPDATED\" ||\n        event === \"PASSWORD_RECOVERY\" ||\n        event === \"SIGNED_OUT\" ||\n        event === \"MFA_CHALLENGE_VERIFIED\")\n    ) {\n      await applyServerStorage(\n        { getAll, setAll, setItems, removedItems },\n        {\n          cookieOptions: options?.cookieOptions ?? null,\n          cookieEncoding: options?.cookieEncoding ?? \"base64url\",\n        },\n      );\n    }\n  });\n\n  return client;\n}\n"],"names":[],"mappings":";;;;AAAA,OAAO,EAEL,YAAY,GAGb,MAAM,uBAAuB,CAAC;AAE/B,OAAO,EAAE,OAAO,EAAE,MAAM,WAAW,CAAC;AACpC,OAAO,EAAE,wBAAwB,EAAE,kBAAkB,EAAE,MAAM,WAAW,CAAC;;;;AA+GnE,SAAU,kBAAkB,CAUhC,WAAmB,EACnB,WAAmB,EACnB,OAIC;IAED,IAAI,CAAC,WAAW,IAAI,CAAC,WAAW,EAAE,CAAC;QACjC,MAAM,IAAI,KAAK,CACb,CAAA,gMAAA,CAAkM,CACnM,CAAC;IACJ,CAAC;IAED,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,MAAM,EAAE,QAAQ,EAAE,YAAY,EAAE,OACvD,kMAAwB,EACtB;QACE,GAAG,OAAO;QACV,cAAc,EAAE,OAAO,EAAE,cAAc,IAAI,WAAW;KACvD,EACD,IAAI,CACL,CAAC;IAEJ,MAAM,MAAM,OAAG,+MAAY,EAAuB,WAAW,EAAE,WAAW,EAAE;QAC1E,2BAA2B;QAC3B,GAAI,OAAe;QACnB,MAAM,EAAE;YACN,GAAG,OAAO,EAAE,MAAM;YAClB,OAAO,EAAE;gBACP,GAAG,OAAO,EAAE,MAAM,EAAE,OAAO;gBAC3B,eAAe,EAAE,CAAA,aAAA,EAAgB,iLAAO,CAAA,mBAAA,CAAqB;aAC9D;SACF;QACD,IAAI,EAAE;YACJ,GAAG,AAAC,OAAO,EAAE,aAAa,EAAE,IAAI,GAC5B;gBAAE,UAAU,EAAE,OAAO,CAAC,aAAa,CAAC,IAAI;YAAA,CAAE,GAC1C,IAAI,CAAC;YACT,GAAG,OAAO,EAAE,IAAI;YAChB,QAAQ,EAAE,MAAM;YAChB,gBAAgB,EAAE,KAAK;YACvB,kBAAkB,EAAE,KAAK;YACzB,cAAc,EAAE,IAAI;YACpB,OAAO;SACR;KACF,CAAC,CAAC;IAEH,MAAM,CAAC,IAAI,CAAC,iBAAiB,CAAC,KAAK,EAAE,KAAsB,EAAE,EAAE;QAC7D,gEAAgE;QAChE,kEAAkE;QAClE,iEAAiE;QACjE,QAAQ;QACR,MAAM,iBAAiB,GACrB,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,MAAM,GAAG,CAAC,IAAI,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC;QAE3E,IACE,iBAAiB,IACjB,CAAC,KAAK,KAAK,WAAW,IACpB,KAAK,KAAK,iBAAiB,IAC3B,KAAK,KAAK,cAAc,IACxB,KAAK,KAAK,mBAAmB,IAC7B,KAAK,KAAK,YAAY,IACtB,KAAK,KAAK,wBAAwB,CAAC,EACrC,CAAC;YACD,UAAM,4LAAkB,EACtB;gBAAE,MAAM;gBAAE,MAAM;gBAAE,QAAQ;gBAAE,YAAY;YAAA,CAAE,EAC1C;gBACE,aAAa,EAAE,OAAO,EAAE,aAAa,IAAI,IAAI;gBAC7C,cAAc,EAAE,OAAO,EAAE,cAAc,IAAI,WAAW;aACvD,CACF,CAAC;QACJ,CAAC;IACH,CAAC,CAAC,CAAC;IAEH,OAAO,MAAM,CAAC;AAChB,CAAC"}},
    {"offset": {"line": 6260, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/@supabase/ssr/dist/module/types.js"],"sourcesContent":["//# sourceMappingURL=types.js.map"],"names":[],"mappings":"AAAA,iCAAiC","ignoreList":[0]}},
    {"offset": {"line": 6265, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@supabase/ssr/dist/module/index.js","sources":["turbopack:///[project]/node_modules/@supabase/ssr/src/index.ts"],"sourcesContent":["export * from \"./createBrowserClient\";\nexport * from \"./createServerClient\";\nexport * from \"./types\";\nexport * from \"./utils\";\n"],"names":[],"mappings":";AAAA,cAAc,uBAAuB,CAAC;AACtC,cAAc,sBAAsB,CAAC;AACrC,cAAc,SAAS,CAAC;AACxB,cAAc,SAAS,CAAC"}},
    {"offset": {"line": 6278, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/cookie/dist/index.js","sources":["turbopack:///[project]/node_modules/cookie/src/index.ts"],"sourcesContent":["/**\n * RegExp to match cookie-name in RFC 6265 sec 4.1.1\n * This refers out to the obsoleted definition of token in RFC 2616 sec 2.2\n * which has been replaced by the token definition in RFC 7230 appendix B.\n *\n * cookie-name       = token\n * token             = 1*tchar\n * tchar             = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" /\n *                     \"*\" / \"+\" / \"-\" / \".\" / \"^\" / \"_\" /\n *                     \"`\" / \"|\" / \"~\" / DIGIT / ALPHA\n *\n * Note: Allowing more characters - https://github.com/jshttp/cookie/issues/191\n * Allow same range as cookie value, except `=`, which delimits end of name.\n */\nconst cookieNameRegExp = /^[\\u0021-\\u003A\\u003C\\u003E-\\u007E]+$/;\n\n/**\n * RegExp to match cookie-value in RFC 6265 sec 4.1.1\n *\n * cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )\n * cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E\n *                     ; US-ASCII characters excluding CTLs,\n *                     ; whitespace DQUOTE, comma, semicolon,\n *                     ; and backslash\n *\n * Allowing more characters: https://github.com/jshttp/cookie/issues/191\n * Comma, backslash, and DQUOTE are not part of the parsing algorithm.\n */\nconst cookieValueRegExp = /^[\\u0021-\\u003A\\u003C-\\u007E]*$/;\n\n/**\n * RegExp to match domain-value in RFC 6265 sec 4.1.1\n *\n * domain-value      = <subdomain>\n *                     ; defined in [RFC1034], Section 3.5, as\n *                     ; enhanced by [RFC1123], Section 2.1\n * <subdomain>       = <label> | <subdomain> \".\" <label>\n * <label>           = <let-dig> [ [ <ldh-str> ] <let-dig> ]\n *                     Labels must be 63 characters or less.\n *                     'let-dig' not 'letter' in the first char, per RFC1123\n * <ldh-str>         = <let-dig-hyp> | <let-dig-hyp> <ldh-str>\n * <let-dig-hyp>     = <let-dig> | \"-\"\n * <let-dig>         = <letter> | <digit>\n * <letter>          = any one of the 52 alphabetic characters A through Z in\n *                     upper case and a through z in lower case\n * <digit>           = any one of the ten digits 0 through 9\n *\n * Keep support for leading dot: https://github.com/jshttp/cookie/issues/173\n *\n * > (Note that a leading %x2E (\".\"), if present, is ignored even though that\n * character is not permitted, but a trailing %x2E (\".\"), if present, will\n * cause the user agent to ignore the attribute.)\n */\nconst domainValueRegExp =\n  /^([.]?[a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?)([.][a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?)*$/i;\n\n/**\n * RegExp to match path-value in RFC 6265 sec 4.1.1\n *\n * path-value        = <any CHAR except CTLs or \";\">\n * CHAR              = %x01-7F\n *                     ; defined in RFC 5234 appendix B.1\n */\nconst pathValueRegExp = /^[\\u0020-\\u003A\\u003D-\\u007E]*$/;\n\nconst __toString = Object.prototype.toString;\n\nconst NullObject = /* @__PURE__ */ (() => {\n  const C = function () {};\n  C.prototype = Object.create(null);\n  return C;\n})() as unknown as { new (): any };\n\n/**\n * Parse options.\n */\nexport interface ParseOptions {\n  /**\n   * Specifies a function that will be used to decode a [cookie-value](https://datatracker.ietf.org/doc/html/rfc6265#section-4.1.1).\n   * Since the value of a cookie has a limited character set (and must be a simple string), this function can be used to decode\n   * a previously-encoded cookie value into a JavaScript string.\n   *\n   * The default function is the global `decodeURIComponent`, wrapped in a `try..catch`. If an error\n   * is thrown it will return the cookie's original value. If you provide your own encode/decode\n   * scheme you must ensure errors are appropriately handled.\n   *\n   * @default decode\n   */\n  decode?: (str: string) => string | undefined;\n}\n\n/**\n * Parse a cookie header.\n *\n * Parse the given cookie header string into an object\n * The object has the various cookies as keys(names) => values\n */\nexport function parse(\n  str: string,\n  options?: ParseOptions,\n): Record<string, string | undefined> {\n  const obj: Record<string, string | undefined> = new NullObject();\n  const len = str.length;\n  // RFC 6265 sec 4.1.1, RFC 2616 2.2 defines a cookie name consists of one char minimum, plus '='.\n  if (len < 2) return obj;\n\n  const dec = options?.decode || decode;\n  let index = 0;\n\n  do {\n    const eqIdx = str.indexOf(\"=\", index);\n    if (eqIdx === -1) break; // No more cookie pairs.\n\n    const colonIdx = str.indexOf(\";\", index);\n    const endIdx = colonIdx === -1 ? len : colonIdx;\n\n    if (eqIdx > endIdx) {\n      // backtrack on prior semicolon\n      index = str.lastIndexOf(\";\", eqIdx - 1) + 1;\n      continue;\n    }\n\n    const keyStartIdx = startIndex(str, index, eqIdx);\n    const keyEndIdx = endIndex(str, eqIdx, keyStartIdx);\n    const key = str.slice(keyStartIdx, keyEndIdx);\n\n    // only assign once\n    if (obj[key] === undefined) {\n      let valStartIdx = startIndex(str, eqIdx + 1, endIdx);\n      let valEndIdx = endIndex(str, endIdx, valStartIdx);\n\n      const value = dec(str.slice(valStartIdx, valEndIdx));\n      obj[key] = value;\n    }\n\n    index = endIdx + 1;\n  } while (index < len);\n\n  return obj;\n}\n\nfunction startIndex(str: string, index: number, max: number) {\n  do {\n    const code = str.charCodeAt(index);\n    if (code !== 0x20 /*   */ && code !== 0x09 /* \\t */) return index;\n  } while (++index < max);\n  return max;\n}\n\nfunction endIndex(str: string, index: number, min: number) {\n  while (index > min) {\n    const code = str.charCodeAt(--index);\n    if (code !== 0x20 /*   */ && code !== 0x09 /* \\t */) return index + 1;\n  }\n  return min;\n}\n\n/**\n * Serialize options.\n */\nexport interface SerializeOptions {\n  /**\n   * Specifies a function that will be used to encode a [cookie-value](https://datatracker.ietf.org/doc/html/rfc6265#section-4.1.1).\n   * Since value of a cookie has a limited character set (and must be a simple string), this function can be used to encode\n   * a value into a string suited for a cookie's value, and should mirror `decode` when parsing.\n   *\n   * @default encodeURIComponent\n   */\n  encode?: (str: string) => string;\n  /**\n   * Specifies the `number` (in seconds) to be the value for the [`Max-Age` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.2).\n   *\n   * The [cookie storage model specification](https://tools.ietf.org/html/rfc6265#section-5.3) states that if both `expires` and\n   * `maxAge` are set, then `maxAge` takes precedence, but it is possible not all clients by obey this,\n   * so if both are set, they should point to the same date and time.\n   */\n  maxAge?: number;\n  /**\n   * Specifies the `Date` object to be the value for the [`Expires` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.1).\n   * When no expiration is set clients consider this a \"non-persistent cookie\" and delete it the current session is over.\n   *\n   * The [cookie storage model specification](https://tools.ietf.org/html/rfc6265#section-5.3) states that if both `expires` and\n   * `maxAge` are set, then `maxAge` takes precedence, but it is possible not all clients by obey this,\n   * so if both are set, they should point to the same date and time.\n   */\n  expires?: Date;\n  /**\n   * Specifies the value for the [`Domain` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.3).\n   * When no domain is set clients consider the cookie to apply to the current domain only.\n   */\n  domain?: string;\n  /**\n   * Specifies the value for the [`Path` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.4).\n   * When no path is set, the path is considered the [\"default path\"](https://tools.ietf.org/html/rfc6265#section-5.1.4).\n   */\n  path?: string;\n  /**\n   * Enables the [`HttpOnly` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.6).\n   * When enabled, clients will not allow client-side JavaScript to see the cookie in `document.cookie`.\n   */\n  httpOnly?: boolean;\n  /**\n   * Enables the [`Secure` `Set-Cookie` attribute](https://tools.ietf.org/html/rfc6265#section-5.2.5).\n   * When enabled, clients will only send the cookie back if the browser has a HTTPS connection.\n   */\n  secure?: boolean;\n  /**\n   * Enables the [`Partitioned` `Set-Cookie` attribute](https://tools.ietf.org/html/draft-cutler-httpbis-partitioned-cookies/).\n   * When enabled, clients will only send the cookie back when the current domain _and_ top-level domain matches.\n   *\n   * This is an attribute that has not yet been fully standardized, and may change in the future.\n   * This also means clients may ignore this attribute until they understand it. More information\n   * about can be found in [the proposal](https://github.com/privacycg/CHIPS).\n   */\n  partitioned?: boolean;\n  /**\n   * Specifies the value for the [`Priority` `Set-Cookie` attribute](https://tools.ietf.org/html/draft-west-cookie-priority-00#section-4.1).\n   *\n   * - `'low'` will set the `Priority` attribute to `Low`.\n   * - `'medium'` will set the `Priority` attribute to `Medium`, the default priority when not set.\n   * - `'high'` will set the `Priority` attribute to `High`.\n   *\n   * More information about priority levels can be found in [the specification](https://tools.ietf.org/html/draft-west-cookie-priority-00#section-4.1).\n   */\n  priority?: \"low\" | \"medium\" | \"high\";\n  /**\n   * Specifies the value for the [`SameSite` `Set-Cookie` attribute](https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-09#section-5.4.7).\n   *\n   * - `true` will set the `SameSite` attribute to `Strict` for strict same site enforcement.\n   * - `'lax'` will set the `SameSite` attribute to `Lax` for lax same site enforcement.\n   * - `'none'` will set the `SameSite` attribute to `None` for an explicit cross-site cookie.\n   * - `'strict'` will set the `SameSite` attribute to `Strict` for strict same site enforcement.\n   *\n   * More information about enforcement levels can be found in [the specification](https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-09#section-5.4.7).\n   */\n  sameSite?: boolean | \"lax\" | \"strict\" | \"none\";\n}\n\n/**\n * Serialize data into a cookie header.\n *\n * Serialize a name value pair into a cookie string suitable for\n * http headers. An optional options object specifies cookie parameters.\n *\n * serialize('foo', 'bar', { httpOnly: true })\n *   => \"foo=bar; httpOnly\"\n */\nexport function serialize(\n  name: string,\n  val: string,\n  options?: SerializeOptions,\n): string {\n  const enc = options?.encode || encodeURIComponent;\n\n  if (!cookieNameRegExp.test(name)) {\n    throw new TypeError(`argument name is invalid: ${name}`);\n  }\n\n  const value = enc(val);\n\n  if (!cookieValueRegExp.test(value)) {\n    throw new TypeError(`argument val is invalid: ${val}`);\n  }\n\n  let str = name + \"=\" + value;\n  if (!options) return str;\n\n  if (options.maxAge !== undefined) {\n    if (!Number.isInteger(options.maxAge)) {\n      throw new TypeError(`option maxAge is invalid: ${options.maxAge}`);\n    }\n\n    str += \"; Max-Age=\" + options.maxAge;\n  }\n\n  if (options.domain) {\n    if (!domainValueRegExp.test(options.domain)) {\n      throw new TypeError(`option domain is invalid: ${options.domain}`);\n    }\n\n    str += \"; Domain=\" + options.domain;\n  }\n\n  if (options.path) {\n    if (!pathValueRegExp.test(options.path)) {\n      throw new TypeError(`option path is invalid: ${options.path}`);\n    }\n\n    str += \"; Path=\" + options.path;\n  }\n\n  if (options.expires) {\n    if (\n      !isDate(options.expires) ||\n      !Number.isFinite(options.expires.valueOf())\n    ) {\n      throw new TypeError(`option expires is invalid: ${options.expires}`);\n    }\n\n    str += \"; Expires=\" + options.expires.toUTCString();\n  }\n\n  if (options.httpOnly) {\n    str += \"; HttpOnly\";\n  }\n\n  if (options.secure) {\n    str += \"; Secure\";\n  }\n\n  if (options.partitioned) {\n    str += \"; Partitioned\";\n  }\n\n  if (options.priority) {\n    const priority =\n      typeof options.priority === \"string\"\n        ? options.priority.toLowerCase()\n        : undefined;\n    switch (priority) {\n      case \"low\":\n        str += \"; Priority=Low\";\n        break;\n      case \"medium\":\n        str += \"; Priority=Medium\";\n        break;\n      case \"high\":\n        str += \"; Priority=High\";\n        break;\n      default:\n        throw new TypeError(`option priority is invalid: ${options.priority}`);\n    }\n  }\n\n  if (options.sameSite) {\n    const sameSite =\n      typeof options.sameSite === \"string\"\n        ? options.sameSite.toLowerCase()\n        : options.sameSite;\n    switch (sameSite) {\n      case true:\n      case \"strict\":\n        str += \"; SameSite=Strict\";\n        break;\n      case \"lax\":\n        str += \"; SameSite=Lax\";\n        break;\n      case \"none\":\n        str += \"; SameSite=None\";\n        break;\n      default:\n        throw new TypeError(`option sameSite is invalid: ${options.sameSite}`);\n    }\n  }\n\n  return str;\n}\n\n/**\n * URL-decode string value. Optimized to skip native call when no %.\n */\nfunction decode(str: string): string {\n  if (str.indexOf(\"%\") === -1) return str;\n\n  try {\n    return decodeURIComponent(str);\n  } catch (e) {\n    return str;\n  }\n}\n\n/**\n * Determine if value is a Date.\n */\nfunction isDate(val: any): val is Date {\n  return __toString.call(val) === \"[object Date]\";\n}\n"],"names":[],"mappings":";;;AAiGA,QAAA,KAAA,GAAA,MA0CC;AA4GD,QAAA,SAAA,GAAA,UA6GC;AApWD;;;;;;;;;;;;;GAaG,CACH,MAAM,gBAAgB,GAAG,uCAAuC,CAAC;AAEjE;;;;;;;;;;;GAWG,CACH,MAAM,iBAAiB,GAAG,iCAAiC,CAAC;AAE5D;;;;;;;;;;;;;;;;;;;;;;GAsBG,CACH,MAAM,iBAAiB,GACrB,qFAAqF,CAAC;AAExF;;;;;;GAMG,CACH,MAAM,eAAe,GAAG,iCAAiC,CAAC;AAE1D,MAAM,UAAU,GAAG,MAAM,CAAC,SAAS,CAAC,QAAQ,CAAC;AAE7C,MAAM,UAAU,GAAG,aAAA,EAAe,CAAC,CAAC,GAAG,EAAE;IACvC,MAAM,CAAC,GAAG,YAAa,CAAC,CAAC;IACzB,CAAC,CAAC,SAAS,GAAG,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC;IAClC,OAAO,CAAC,CAAC;AACX,CAAC,CAAC,EAAgC,CAAC;AAoBnC;;;;;GAKG,CACH,SAAgB,KAAK,CACnB,GAAW,EACX,OAAsB;IAEtB,MAAM,GAAG,GAAuC,IAAI,UAAU,EAAE,CAAC;IACjE,MAAM,GAAG,GAAG,GAAG,CAAC,MAAM,CAAC;IACvB,iGAAiG;IACjG,IAAI,GAAG,GAAG,CAAC,EAAE,OAAO,GAAG,CAAC;IAExB,MAAM,GAAG,GAAG,OAAO,EAAE,MAAM,IAAI,MAAM,CAAC;IACtC,IAAI,KAAK,GAAG,CAAC,CAAC;IAEd,GAAG,CAAC;QACF,MAAM,KAAK,GAAG,GAAG,CAAC,OAAO,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;QACtC,IAAI,KAAK,KAAK,CAAC,CAAC,EAAE,MAAM,CAAC,wBAAwB;QAEjD,MAAM,QAAQ,GAAG,GAAG,CAAC,OAAO,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;QACzC,MAAM,MAAM,GAAG,QAAQ,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,QAAQ,CAAC;QAEhD,IAAI,KAAK,GAAG,MAAM,EAAE,CAAC;YACnB,+BAA+B;YAC/B,KAAK,GAAG,GAAG,CAAC,WAAW,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;YAC5C,SAAS;QACX,CAAC;QAED,MAAM,WAAW,GAAG,UAAU,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,CAAC,CAAC;QAClD,MAAM,SAAS,GAAG,QAAQ,CAAC,GAAG,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;QACpD,MAAM,GAAG,GAAG,GAAG,CAAC,KAAK,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC;QAE9C,mBAAmB;QACnB,IAAI,GAAG,CAAC,GAAG,CAAC,KAAK,SAAS,EAAE,CAAC;YAC3B,IAAI,WAAW,GAAG,UAAU,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC,EAAE,MAAM,CAAC,CAAC;YACrD,IAAI,SAAS,GAAG,QAAQ,CAAC,GAAG,EAAE,MAAM,EAAE,WAAW,CAAC,CAAC;YAEnD,MAAM,KAAK,GAAG,GAAG,CAAC,GAAG,CAAC,KAAK,CAAC,WAAW,EAAE,SAAS,CAAC,CAAC,CAAC;YACrD,GAAG,CAAC,GAAG,CAAC,GAAG,KAAK,CAAC;QACnB,CAAC;QAED,KAAK,GAAG,MAAM,GAAG,CAAC,CAAC;IACrB,CAAC,OAAQ,KAAK,GAAG,GAAG,CAAE;IAEtB,OAAO,GAAG,CAAC;AACb,CAAC;AAED,SAAS,UAAU,CAAC,GAAW,EAAE,KAAa,EAAE,GAAW;IACzD,GAAG,CAAC;QACF,MAAM,IAAI,GAAG,GAAG,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;QACnC,IAAI,IAAI,KAAK,IAAI,CAAC,KAAA,EAAO,KAAI,IAAI,KAAK,IAAI,CAAC,MAAA,EAAQ,GAAE,OAAO,KAAK,CAAC;IACpE,CAAC,OAAQ,EAAE,KAAK,GAAG,GAAG,CAAE;IACxB,OAAO,GAAG,CAAC;AACb,CAAC;AAED,SAAS,QAAQ,CAAC,GAAW,EAAE,KAAa,EAAE,GAAW;IACvD,MAAO,KAAK,GAAG,GAAG,CAAE,CAAC;QACnB,MAAM,IAAI,GAAG,GAAG,CAAC,UAAU,CAAC,EAAE,KAAK,CAAC,CAAC;QACrC,IAAI,IAAI,KAAK,IAAI,CAAC,KAAA,EAAO,KAAI,IAAI,KAAK,IAAI,CAAC,MAAA,EAAQ,GAAE,OAAO,KAAK,GAAG,CAAC,CAAC;IACxE,CAAC;IACD,OAAO,GAAG,CAAC;AACb,CAAC;AAmFD;;;;;;;;GAQG,CACH,SAAgB,SAAS,CACvB,IAAY,EACZ,GAAW,EACX,OAA0B;IAE1B,MAAM,GAAG,GAAG,OAAO,EAAE,MAAM,IAAI,kBAAkB,CAAC;IAElD,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;QACjC,MAAM,IAAI,SAAS,CAAC,CAAA,0BAAA,EAA6B,IAAI,EAAE,CAAC,CAAC;IAC3D,CAAC;IAED,MAAM,KAAK,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC;IAEvB,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC;QACnC,MAAM,IAAI,SAAS,CAAC,CAAA,yBAAA,EAA4B,GAAG,EAAE,CAAC,CAAC;IACzD,CAAC;IAED,IAAI,GAAG,GAAG,IAAI,GAAG,GAAG,GAAG,KAAK,CAAC;IAC7B,IAAI,CAAC,OAAO,EAAE,OAAO,GAAG,CAAC;IAEzB,IAAI,OAAO,CAAC,MAAM,KAAK,SAAS,EAAE,CAAC;QACjC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,CAAC;YACtC,MAAM,IAAI,SAAS,CAAC,CAAA,0BAAA,EAA6B,OAAO,CAAC,MAAM,EAAE,CAAC,CAAC;QACrE,CAAC;QAED,GAAG,IAAI,YAAY,GAAG,OAAO,CAAC,MAAM,CAAC;IACvC,CAAC;IAED,IAAI,OAAO,CAAC,MAAM,EAAE,CAAC;QACnB,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE,CAAC;YAC5C,MAAM,IAAI,SAAS,CAAC,CAAA,0BAAA,EAA6B,OAAO,CAAC,MAAM,EAAE,CAAC,CAAC;QACrE,CAAC;QAED,GAAG,IAAI,WAAW,GAAG,OAAO,CAAC,MAAM,CAAC;IACtC,CAAC;IAED,IAAI,OAAO,CAAC,IAAI,EAAE,CAAC;QACjB,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE,CAAC;YACxC,MAAM,IAAI,SAAS,CAAC,CAAA,wBAAA,EAA2B,OAAO,CAAC,IAAI,EAAE,CAAC,CAAC;QACjE,CAAC;QAED,GAAG,IAAI,SAAS,GAAG,OAAO,CAAC,IAAI,CAAC;IAClC,CAAC;IAED,IAAI,OAAO,CAAC,OAAO,EAAE,CAAC;QACpB,IACE,CAAC,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,IACxB,CAAC,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,OAAO,CAAC,OAAO,EAAE,CAAC,EAC3C,CAAC;YACD,MAAM,IAAI,SAAS,CAAC,CAAA,2BAAA,EAA8B,OAAO,CAAC,OAAO,EAAE,CAAC,CAAC;QACvE,CAAC;QAED,GAAG,IAAI,YAAY,GAAG,OAAO,CAAC,OAAO,CAAC,WAAW,EAAE,CAAC;IACtD,CAAC;IAED,IAAI,OAAO,CAAC,QAAQ,EAAE,CAAC;QACrB,GAAG,IAAI,YAAY,CAAC;IACtB,CAAC;IAED,IAAI,OAAO,CAAC,MAAM,EAAE,CAAC;QACnB,GAAG,IAAI,UAAU,CAAC;IACpB,CAAC;IAED,IAAI,OAAO,CAAC,WAAW,EAAE,CAAC;QACxB,GAAG,IAAI,eAAe,CAAC;IACzB,CAAC;IAED,IAAI,OAAO,CAAC,QAAQ,EAAE,CAAC;QACrB,MAAM,QAAQ,GACZ,OAAO,OAAO,CAAC,QAAQ,KAAK,QAAQ,GAChC,OAAO,CAAC,QAAQ,CAAC,WAAW,EAAE,GAC9B,SAAS,CAAC;QAChB,OAAQ,QAAQ,EAAE,CAAC;YACjB,KAAK,KAAK;gBACR,GAAG,IAAI,gBAAgB,CAAC;gBACxB,MAAM;YACR,KAAK,QAAQ;gBACX,GAAG,IAAI,mBAAmB,CAAC;gBAC3B,MAAM;YACR,KAAK,MAAM;gBACT,GAAG,IAAI,iBAAiB,CAAC;gBACzB,MAAM;YACR;gBACE,MAAM,IAAI,SAAS,CAAC,CAAA,4BAAA,EAA+B,OAAO,CAAC,QAAQ,EAAE,CAAC,CAAC;QAC3E,CAAC;IACH,CAAC;IAED,IAAI,OAAO,CAAC,QAAQ,EAAE,CAAC;QACrB,MAAM,QAAQ,GACZ,OAAO,OAAO,CAAC,QAAQ,KAAK,QAAQ,GAChC,OAAO,CAAC,QAAQ,CAAC,WAAW,EAAE,GAC9B,OAAO,CAAC,QAAQ,CAAC;QACvB,OAAQ,QAAQ,EAAE,CAAC;YACjB,KAAK,IAAI,CAAC;YACV,KAAK,QAAQ;gBACX,GAAG,IAAI,mBAAmB,CAAC;gBAC3B,MAAM;YACR,KAAK,KAAK;gBACR,GAAG,IAAI,gBAAgB,CAAC;gBACxB,MAAM;YACR,KAAK,MAAM;gBACT,GAAG,IAAI,iBAAiB,CAAC;gBACzB,MAAM;YACR;gBACE,MAAM,IAAI,SAAS,CAAC,CAAA,4BAAA,EAA+B,OAAO,CAAC,QAAQ,EAAE,CAAC,CAAC;QAC3E,CAAC;IACH,CAAC;IAED,OAAO,GAAG,CAAC;AACb,CAAC;AAED;;GAEG,CACH,SAAS,MAAM,CAAC,GAAW;IACzB,IAAI,GAAG,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC,EAAE,OAAO,GAAG,CAAC;IAExC,IAAI,CAAC;QACH,OAAO,kBAAkB,CAAC,GAAG,CAAC,CAAC;IACjC,CAAC,CAAC,OAAO,CAAC,EAAE,CAAC;QACX,OAAO,GAAG,CAAC;IACb,CAAC;AACH,CAAC;AAED;;GAEG,CACH,SAAS,MAAM,CAAC,GAAQ;IACtB,OAAO,UAAU,CAAC,IAAI,CAAC,GAAG,CAAC,KAAK,eAAe,CAAC;AAClD,CAAC"}},
    {"offset": {"line": 6501, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/semantic-conventions/build/esm/stable_attributes.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/semantic-conventions/src/stable_attributes.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n//----------------------------------------------------------------------------------------------------------\n// DO NOT EDIT, this is an Auto-generated file from scripts/semconv/templates/registry/stable/attributes.ts.j2\n//----------------------------------------------------------------------------------------------------------\n\n/**\n * ASP.NET Core exception middleware handling result.\n *\n * @example handled\n * @example unhandled\n */\nexport const ATTR_ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT = 'aspnetcore.diagnostics.exception.result' as const;\n\n/**\n * Enum value \"aborted\" for attribute {@link ATTR_ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT}.\n *\n * Exception handling didn't run because the request was aborted.\n */\nexport const ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT_VALUE_ABORTED = \"aborted\" as const;\n\n/**\n * Enum value \"handled\" for attribute {@link ATTR_ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT}.\n *\n * Exception was handled by the exception handling middleware.\n */\nexport const ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT_VALUE_HANDLED = \"handled\" as const;\n\n/**\n * Enum value \"skipped\" for attribute {@link ATTR_ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT}.\n *\n * Exception handling was skipped because the response had started.\n */\nexport const ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT_VALUE_SKIPPED = \"skipped\" as const;\n\n/**\n * Enum value \"unhandled\" for attribute {@link ATTR_ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT}.\n *\n * Exception was not handled by the exception handling middleware.\n */\nexport const ASPNETCORE_DIAGNOSTICS_EXCEPTION_RESULT_VALUE_UNHANDLED = \"unhandled\" as const;\n\n/**\n * Full type name of the [`IExceptionHandler`](https://learn.microsoft.com/dotnet/api/microsoft.aspnetcore.diagnostics.iexceptionhandler) implementation that handled the exception.\n *\n * @example Contoso.MyHandler\n */\nexport const ATTR_ASPNETCORE_DIAGNOSTICS_HANDLER_TYPE = 'aspnetcore.diagnostics.handler.type' as const;\n\n/**\n * Rate limiting policy name.\n *\n * @example fixed\n * @example sliding\n * @example token\n */\nexport const ATTR_ASPNETCORE_RATE_LIMITING_POLICY = 'aspnetcore.rate_limiting.policy' as const;\n\n/**\n * Rate-limiting result, shows whether the lease was acquired or contains a rejection reason\n *\n * @example acquired\n * @example request_canceled\n */\nexport const ATTR_ASPNETCORE_RATE_LIMITING_RESULT = 'aspnetcore.rate_limiting.result' as const;\n\n/**\n * Enum value \"acquired\" for attribute {@link ATTR_ASPNETCORE_RATE_LIMITING_RESULT}.\n *\n * Lease was acquired\n */\nexport const ASPNETCORE_RATE_LIMITING_RESULT_VALUE_ACQUIRED = \"acquired\" as const;\n\n/**\n * Enum value \"endpoint_limiter\" for attribute {@link ATTR_ASPNETCORE_RATE_LIMITING_RESULT}.\n *\n * Lease request was rejected by the endpoint limiter\n */\nexport const ASPNETCORE_RATE_LIMITING_RESULT_VALUE_ENDPOINT_LIMITER = \"endpoint_limiter\" as const;\n\n/**\n * Enum value \"global_limiter\" for attribute {@link ATTR_ASPNETCORE_RATE_LIMITING_RESULT}.\n *\n * Lease request was rejected by the global limiter\n */\nexport const ASPNETCORE_RATE_LIMITING_RESULT_VALUE_GLOBAL_LIMITER = \"global_limiter\" as const;\n\n/**\n * Enum value \"request_canceled\" for attribute {@link ATTR_ASPNETCORE_RATE_LIMITING_RESULT}.\n *\n * Lease request was canceled\n */\nexport const ASPNETCORE_RATE_LIMITING_RESULT_VALUE_REQUEST_CANCELED = \"request_canceled\" as const;\n\n/**\n * Flag indicating if request was handled by the application pipeline.\n *\n * @example true\n */\nexport const ATTR_ASPNETCORE_REQUEST_IS_UNHANDLED = 'aspnetcore.request.is_unhandled' as const;\n\n/**\n * A value that indicates whether the matched route is a fallback route.\n *\n * @example true\n */\nexport const ATTR_ASPNETCORE_ROUTING_IS_FALLBACK = 'aspnetcore.routing.is_fallback' as const;\n\n/**\n * Match result - success or failure\n *\n * @example success\n * @example failure\n */\nexport const ATTR_ASPNETCORE_ROUTING_MATCH_STATUS = 'aspnetcore.routing.match_status' as const;\n\n/**\n * Enum value \"failure\" for attribute {@link ATTR_ASPNETCORE_ROUTING_MATCH_STATUS}.\n *\n * Match failed\n */\nexport const ASPNETCORE_ROUTING_MATCH_STATUS_VALUE_FAILURE = \"failure\" as const;\n\n/**\n * Enum value \"success\" for attribute {@link ATTR_ASPNETCORE_ROUTING_MATCH_STATUS}.\n *\n * Match succeeded\n */\nexport const ASPNETCORE_ROUTING_MATCH_STATUS_VALUE_SUCCESS = \"success\" as const;\n\n/**\n * A value that indicates whether the user is authenticated.\n *\n * @example true\n */\nexport const ATTR_ASPNETCORE_USER_IS_AUTHENTICATED = 'aspnetcore.user.is_authenticated' as const;\n\n/**\n * Client address - domain name if available without reverse DNS lookup; otherwise, IP address or Unix domain socket name.\n *\n * @example client.example.com\n * @example 10.1.2.80\n * @example /tmp/my.sock\n *\n * @note When observed from the server side, and when communicating through an intermediary, `client.address` **SHOULD** represent the client address behind any intermediaries,  for example proxies, if it's available.\n */\nexport const ATTR_CLIENT_ADDRESS = 'client.address' as const;\n\n/**\n * Client port number.\n *\n * @example 65123\n *\n * @note When observed from the server side, and when communicating through an intermediary, `client.port` **SHOULD** represent the client port behind any intermediaries,  for example proxies, if it's available.\n */\nexport const ATTR_CLIENT_PORT = 'client.port' as const;\n\n/**\n * The column number in `code.file.path` best representing the operation. It **SHOULD** point within the code unit named in `code.function.name`. This attribute **MUST NOT** be used on the Profile signal since the data is already captured in 'message Line'. This constraint is imposed to prevent redundancy and maintain data integrity.\n *\n * @example 16\n */\nexport const ATTR_CODE_COLUMN_NUMBER = 'code.column.number' as const;\n\n/**\n * The source code file name that identifies the code unit as uniquely as possible (preferably an absolute file path). This attribute **MUST NOT** be used on the Profile signal since the data is already captured in 'message Function'. This constraint is imposed to prevent redundancy and maintain data integrity.\n *\n * @example \"/usr/local/MyApplication/content_root/app/index.php\"\n */\nexport const ATTR_CODE_FILE_PATH = 'code.file.path' as const;\n\n/**\n * The method or function fully-qualified name without arguments. The value should fit the natural representation of the language runtime, which is also likely the same used within `code.stacktrace` attribute value. This attribute **MUST NOT** be used on the Profile signal since the data is already captured in 'message Function'. This constraint is imposed to prevent redundancy and maintain data integrity.\n *\n * @example com.example.MyHttpService.serveRequest\n * @example GuzzleHttp\\\\Client::transfer\n * @example fopen\n *\n * @note Values and format depends on each language runtime, thus it is impossible to provide an exhaustive list of examples.\n * The values are usually the same (or prefixes of) the ones found in native stack trace representation stored in\n * `code.stacktrace` without information on arguments.\n *\n * Examples:\n *\n *   - Java method: `com.example.MyHttpService.serveRequest`\n *   - Java anonymous class method: `com.mycompany.Main$1.myMethod`\n *   - Java lambda method: `com.mycompany.Main$$Lambda/0x0000748ae4149c00.myMethod`\n *   - PHP function: `GuzzleHttp\\Client::transfer`\n *   - Go function: `github.com/my/repo/pkg.foo.func5`\n *   - Elixir: `OpenTelemetry.Ctx.new`\n *   - Erlang: `opentelemetry_ctx:new`\n *   - Rust: `playground::my_module::my_cool_func`\n *   - C function: `fopen`\n */\nexport const ATTR_CODE_FUNCTION_NAME = 'code.function.name' as const;\n\n/**\n * The line number in `code.file.path` best representing the operation. It **SHOULD** point within the code unit named in `code.function.name`. This attribute **MUST NOT** be used on the Profile signal since the data is already captured in 'message Line'. This constraint is imposed to prevent redundancy and maintain data integrity.\n *\n * @example 42\n */\nexport const ATTR_CODE_LINE_NUMBER = 'code.line.number' as const;\n\n/**\n * A stacktrace as a string in the natural representation for the language runtime. The representation is identical to [`exception.stacktrace`](/docs/exceptions/exceptions-spans.md#stacktrace-representation). This attribute **MUST NOT** be used on the Profile signal since the data is already captured in 'message Location'. This constraint is imposed to prevent redundancy and maintain data integrity.\n *\n * @example \"at com.example.GenerateTrace.methodB(GenerateTrace.java:13)\\\\n at com.example.GenerateTrace.methodA(GenerateTrace.java:9)\\\\n at com.example.GenerateTrace.main(GenerateTrace.java:5)\\\\n\"\n */\nexport const ATTR_CODE_STACKTRACE = 'code.stacktrace' as const;\n\n/**\n * The name of a collection (table, container) within the database.\n *\n * @example public.users\n * @example customers\n *\n * @note It is **RECOMMENDED** to capture the value as provided by the application\n * without attempting to do any case normalization.\n *\n * The collection name **SHOULD NOT** be extracted from `db.query.text`,\n * when the database system supports query text with multiple collections\n * in non-batch operations.\n *\n * For batch operations, if the individual operations are known to have the same\n * collection name then that collection name **SHOULD** be used.\n */\nexport const ATTR_DB_COLLECTION_NAME = 'db.collection.name' as const;\n\n/**\n * The name of the database, fully qualified within the server address and port.\n *\n * @example customers\n * @example test.users\n *\n * @note If a database system has multiple namespace components, they **SHOULD** be concatenated from the most general to the most specific namespace component, using `|` as a separator between the components. Any missing components (and their associated separators) **SHOULD** be omitted.\n * Semantic conventions for individual database systems **SHOULD** document what `db.namespace` means in the context of that system.\n * It is **RECOMMENDED** to capture the value as provided by the application without attempting to do any case normalization.\n */\nexport const ATTR_DB_NAMESPACE = 'db.namespace' as const;\n\n/**\n * The number of queries included in a batch operation.\n *\n * @example 2\n * @example 3\n * @example 4\n *\n * @note Operations are only considered batches when they contain two or more operations, and so `db.operation.batch.size` **SHOULD** never be `1`.\n */\nexport const ATTR_DB_OPERATION_BATCH_SIZE = 'db.operation.batch.size' as const;\n\n/**\n * The name of the operation or command being executed.\n *\n * @example findAndModify\n * @example HMSET\n * @example SELECT\n *\n * @note It is **RECOMMENDED** to capture the value as provided by the application\n * without attempting to do any case normalization.\n *\n * The operation name **SHOULD NOT** be extracted from `db.query.text`,\n * when the database system supports query text with multiple operations\n * in non-batch operations.\n *\n * If spaces can occur in the operation name, multiple consecutive spaces\n * **SHOULD** be normalized to a single space.\n *\n * For batch operations, if the individual operations are known to have the same operation name\n * then that operation name **SHOULD** be used prepended by `BATCH `,\n * otherwise `db.operation.name` **SHOULD** be `BATCH` or some other database\n * system specific term if more applicable.\n */\nexport const ATTR_DB_OPERATION_NAME = 'db.operation.name' as const;\n\n/**\n * Low cardinality summary of a database query.\n *\n * @example SELECT wuser_table\n * @example INSERT shipping_details SELECT orders\n * @example get user by id\n *\n * @note The query summary describes a class of database queries and is useful\n * as a grouping key, especially when analyzing telemetry for database\n * calls involving complex queries.\n *\n * Summary may be available to the instrumentation through\n * instrumentation hooks or other means. If it is not available, instrumentations\n * that support query parsing **SHOULD** generate a summary following\n * [Generating query summary](/docs/database/database-spans.md#generating-a-summary-of-the-query)\n * section.\n */\nexport const ATTR_DB_QUERY_SUMMARY = 'db.query.summary' as const;\n\n/**\n * The database query being executed.\n *\n * @example SELECT * FROM wuser_table where username = ?\n * @example SET mykey ?\n *\n * @note For sanitization see [Sanitization of `db.query.text`](/docs/database/database-spans.md#sanitization-of-dbquerytext).\n * For batch operations, if the individual operations are known to have the same query text then that query text **SHOULD** be used, otherwise all of the individual query texts **SHOULD** be concatenated with separator `; ` or some other database system specific separator if more applicable.\n * Parameterized query text **SHOULD NOT** be sanitized. Even though parameterized query text can potentially have sensitive data, by using a parameterized query the user is giving a strong signal that any sensitive data will be passed as parameter values, and the benefit to observability of capturing the static part of the query text by default outweighs the risk.\n */\nexport const ATTR_DB_QUERY_TEXT = 'db.query.text' as const;\n\n/**\n * Database response status code.\n *\n * @example 102\n * @example ORA-17002\n * @example 08P01\n * @example 404\n *\n * @note The status code returned by the database. Usually it represents an error code, but may also represent partial success, warning, or differentiate between various types of successful outcomes.\n * Semantic conventions for individual database systems **SHOULD** document what `db.response.status_code` means in the context of that system.\n */\nexport const ATTR_DB_RESPONSE_STATUS_CODE = 'db.response.status_code' as const;\n\n/**\n * The name of a stored procedure within the database.\n *\n * @example GetCustomer\n *\n * @note It is **RECOMMENDED** to capture the value as provided by the application\n * without attempting to do any case normalization.\n *\n * For batch operations, if the individual operations are known to have the same\n * stored procedure name then that stored procedure name **SHOULD** be used.\n */\nexport const ATTR_DB_STORED_PROCEDURE_NAME = 'db.stored_procedure.name' as const;\n\n/**\n * The database management system (DBMS) product as identified by the client instrumentation.\n *\n * @note The actual DBMS may differ from the one identified by the client. For example, when using PostgreSQL client libraries to connect to a CockroachDB, the `db.system.name` is set to `postgresql` based on the instrumentation's best knowledge.\n */\nexport const ATTR_DB_SYSTEM_NAME = 'db.system.name' as const;\n\n/**\n * Enum value \"mariadb\" for attribute {@link ATTR_DB_SYSTEM_NAME}.\n *\n * [MariaDB](https://mariadb.org/)\n */\nexport const DB_SYSTEM_NAME_VALUE_MARIADB = \"mariadb\" as const;\n\n/**\n * Enum value \"microsoft.sql_server\" for attribute {@link ATTR_DB_SYSTEM_NAME}.\n *\n * [Microsoft SQL Server](https://www.microsoft.com/sql-server)\n */\nexport const DB_SYSTEM_NAME_VALUE_MICROSOFT_SQL_SERVER = \"microsoft.sql_server\" as const;\n\n/**\n * Enum value \"mysql\" for attribute {@link ATTR_DB_SYSTEM_NAME}.\n *\n * [MySQL](https://www.mysql.com/)\n */\nexport const DB_SYSTEM_NAME_VALUE_MYSQL = \"mysql\" as const;\n\n/**\n * Enum value \"postgresql\" for attribute {@link ATTR_DB_SYSTEM_NAME}.\n *\n * [PostgreSQL](https://www.postgresql.org/)\n */\nexport const DB_SYSTEM_NAME_VALUE_POSTGRESQL = \"postgresql\" as const;\n\n/**\n * Name of the garbage collector managed heap generation.\n *\n * @example gen0\n * @example gen1\n * @example gen2\n */\nexport const ATTR_DOTNET_GC_HEAP_GENERATION = 'dotnet.gc.heap.generation' as const;\n\n/**\n * Enum value \"gen0\" for attribute {@link ATTR_DOTNET_GC_HEAP_GENERATION}.\n *\n * Generation 0\n */\nexport const DOTNET_GC_HEAP_GENERATION_VALUE_GEN0 = \"gen0\" as const;\n\n/**\n * Enum value \"gen1\" for attribute {@link ATTR_DOTNET_GC_HEAP_GENERATION}.\n *\n * Generation 1\n */\nexport const DOTNET_GC_HEAP_GENERATION_VALUE_GEN1 = \"gen1\" as const;\n\n/**\n * Enum value \"gen2\" for attribute {@link ATTR_DOTNET_GC_HEAP_GENERATION}.\n *\n * Generation 2\n */\nexport const DOTNET_GC_HEAP_GENERATION_VALUE_GEN2 = \"gen2\" as const;\n\n/**\n * Enum value \"loh\" for attribute {@link ATTR_DOTNET_GC_HEAP_GENERATION}.\n *\n * Large Object Heap\n */\nexport const DOTNET_GC_HEAP_GENERATION_VALUE_LOH = \"loh\" as const;\n\n/**\n * Enum value \"poh\" for attribute {@link ATTR_DOTNET_GC_HEAP_GENERATION}.\n *\n * Pinned Object Heap\n */\nexport const DOTNET_GC_HEAP_GENERATION_VALUE_POH = \"poh\" as const;\n\n/**\n * Describes a class of error the operation ended with.\n *\n * @example timeout\n * @example java.net.UnknownHostException\n * @example server_certificate_invalid\n * @example 500\n *\n * @note The `error.type` **SHOULD** be predictable, and **SHOULD** have low cardinality.\n *\n * When `error.type` is set to a type (e.g., an exception type), its\n * canonical class name identifying the type within the artifact **SHOULD** be used.\n *\n * Instrumentations **SHOULD** document the list of errors they report.\n *\n * The cardinality of `error.type` within one instrumentation library **SHOULD** be low.\n * Telemetry consumers that aggregate data from multiple instrumentation libraries and applications\n * should be prepared for `error.type` to have high cardinality at query time when no\n * additional filters are applied.\n *\n * If the operation has completed successfully, instrumentations **SHOULD NOT** set `error.type`.\n *\n * If a specific domain defines its own set of error identifiers (such as HTTP or gRPC status codes),\n * it's **RECOMMENDED** to:\n *\n *   - Use a domain-specific attribute\n *   - Set `error.type` to capture all errors, regardless of whether they are defined within the domain-specific set or not.\n */\nexport const ATTR_ERROR_TYPE = 'error.type' as const;\n\n/**\n * Enum value \"_OTHER\" for attribute {@link ATTR_ERROR_TYPE}.\n *\n * A fallback error value to be used when the instrumentation doesn't define a custom value.\n */\nexport const ERROR_TYPE_VALUE_OTHER = \"_OTHER\" as const;\n\n/**\n * Indicates that the exception is escaping the scope of the span.\n *\n * @deprecated It's no longer recommended to record exceptions that are handled and do not escape the scope of a span.\n */\nexport const ATTR_EXCEPTION_ESCAPED = 'exception.escaped' as const;\n\n/**\n * The exception message.\n *\n * @example Division by zero\n * @example Can't convert 'int' object to str implicitly\n */\nexport const ATTR_EXCEPTION_MESSAGE = 'exception.message' as const;\n\n/**\n * A stacktrace as a string in the natural representation for the language runtime. The representation is to be determined and documented by each language SIG.\n *\n * @example \"Exception in thread \"main\" java.lang.RuntimeException: Test exception\\\\n at com.example.GenerateTrace.methodB(GenerateTrace.java:13)\\\\n at com.example.GenerateTrace.methodA(GenerateTrace.java:9)\\\\n at com.example.GenerateTrace.main(GenerateTrace.java:5)\\\\n\"\n */\nexport const ATTR_EXCEPTION_STACKTRACE = 'exception.stacktrace' as const;\n\n/**\n * The type of the exception (its fully-qualified class name, if applicable). The dynamic type of the exception should be preferred over the static type in languages that support it.\n *\n * @example java.net.ConnectException\n * @example OSError\n */\nexport const ATTR_EXCEPTION_TYPE = 'exception.type' as const;\n\n/**\n * HTTP request headers, `<key>` being the normalized HTTP Header name (lowercase), the value being the header values.\n *\n * @example [\"application/json\"]\n * @example [\"1.2.3.4\", \"1.2.3.5\"]\n *\n * @note Instrumentations **SHOULD** require an explicit configuration of which headers are to be captured.\n * Including all request headers can be a security risk - explicit configuration helps avoid leaking sensitive information.\n *\n * The `User-Agent` header is already captured in the `user_agent.original` attribute.\n * Users **MAY** explicitly configure instrumentations to capture them even though it is not recommended.\n *\n * The attribute value **MUST** consist of either multiple header values as an array of strings\n * or a single-item array containing a possibly comma-concatenated string, depending on the way\n * the HTTP library provides access to headers.\n *\n * Examples:\n *\n *   - A header `Content-Type: application/json` **SHOULD** be recorded as the `http.request.header.content-type`\n *     attribute with value `[\"application/json\"]`.\n *   - A header `X-Forwarded-For: 1.2.3.4, 1.2.3.5` **SHOULD** be recorded as the `http.request.header.x-forwarded-for`\n *     attribute with value `[\"1.2.3.4\", \"1.2.3.5\"]` or `[\"1.2.3.4, 1.2.3.5\"]` depending on the HTTP library.\n */\nexport const ATTR_HTTP_REQUEST_HEADER = (key: string) => `http.request.header.${key}`;\n\n/**\n * HTTP request method.\n *\n * @example GET\n * @example POST\n * @example HEAD\n *\n * @note HTTP request method value **SHOULD** be \"known\" to the instrumentation.\n * By default, this convention defines \"known\" methods as the ones listed in [RFC9110](https://www.rfc-editor.org/rfc/rfc9110.html#name-methods),\n * the PATCH method defined in [RFC5789](https://www.rfc-editor.org/rfc/rfc5789.html)\n * and the QUERY method defined in [httpbis-safe-method-w-body](https://datatracker.ietf.org/doc/draft-ietf-httpbis-safe-method-w-body/?include_text=1).\n *\n * If the HTTP request method is not known to instrumentation, it **MUST** set the `http.request.method` attribute to `_OTHER`.\n *\n * If the HTTP instrumentation could end up converting valid HTTP request methods to `_OTHER`, then it **MUST** provide a way to override\n * the list of known HTTP methods. If this override is done via environment variable, then the environment variable **MUST** be named\n * OTEL_INSTRUMENTATION_HTTP_KNOWN_METHODS and support a comma-separated list of case-sensitive known HTTP methods\n * (this list **MUST** be a full override of the default known method, it is not a list of known methods in addition to the defaults).\n *\n * HTTP method names are case-sensitive and `http.request.method` attribute value **MUST** match a known HTTP method name exactly.\n * Instrumentations for specific web frameworks that consider HTTP methods to be case insensitive, **SHOULD** populate a canonical equivalent.\n * Tracing instrumentations that do so, **MUST** also set `http.request.method_original` to the original value.\n */\nexport const ATTR_HTTP_REQUEST_METHOD = 'http.request.method' as const;\n\n/**\n * Enum value \"_OTHER\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * Any HTTP method that the instrumentation has no prior knowledge of.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_OTHER = \"_OTHER\" as const;\n\n/**\n * Enum value \"CONNECT\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * CONNECT method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_CONNECT = \"CONNECT\" as const;\n\n/**\n * Enum value \"DELETE\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * DELETE method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_DELETE = \"DELETE\" as const;\n\n/**\n * Enum value \"GET\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * GET method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_GET = \"GET\" as const;\n\n/**\n * Enum value \"HEAD\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * HEAD method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_HEAD = \"HEAD\" as const;\n\n/**\n * Enum value \"OPTIONS\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * OPTIONS method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_OPTIONS = \"OPTIONS\" as const;\n\n/**\n * Enum value \"PATCH\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * PATCH method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_PATCH = \"PATCH\" as const;\n\n/**\n * Enum value \"POST\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * POST method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_POST = \"POST\" as const;\n\n/**\n * Enum value \"PUT\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * PUT method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_PUT = \"PUT\" as const;\n\n/**\n * Enum value \"TRACE\" for attribute {@link ATTR_HTTP_REQUEST_METHOD}.\n *\n * TRACE method.\n */\nexport const HTTP_REQUEST_METHOD_VALUE_TRACE = \"TRACE\" as const;\n\n/**\n * Original HTTP method sent by the client in the request line.\n *\n * @example GeT\n * @example ACL\n * @example foo\n */\nexport const ATTR_HTTP_REQUEST_METHOD_ORIGINAL = 'http.request.method_original' as const;\n\n/**\n * The ordinal number of request resending attempt (for any reason, including redirects).\n *\n * @example 3\n *\n * @note The resend count **SHOULD** be updated each time an HTTP request gets resent by the client, regardless of what was the cause of the resending (e.g. redirection, authorization failure, 503 Server Unavailable, network issues, or any other).\n */\nexport const ATTR_HTTP_REQUEST_RESEND_COUNT = 'http.request.resend_count' as const;\n\n/**\n * HTTP response headers, `<key>` being the normalized HTTP Header name (lowercase), the value being the header values.\n *\n * @example [\"application/json\"]\n * @example [\"abc\", \"def\"]\n *\n * @note Instrumentations **SHOULD** require an explicit configuration of which headers are to be captured.\n * Including all response headers can be a security risk - explicit configuration helps avoid leaking sensitive information.\n *\n * Users **MAY** explicitly configure instrumentations to capture them even though it is not recommended.\n *\n * The attribute value **MUST** consist of either multiple header values as an array of strings\n * or a single-item array containing a possibly comma-concatenated string, depending on the way\n * the HTTP library provides access to headers.\n *\n * Examples:\n *\n *   - A header `Content-Type: application/json` header **SHOULD** be recorded as the `http.request.response.content-type`\n *     attribute with value `[\"application/json\"]`.\n *   - A header `My-custom-header: abc, def` header **SHOULD** be recorded as the `http.response.header.my-custom-header`\n *     attribute with value `[\"abc\", \"def\"]` or `[\"abc, def\"]` depending on the HTTP library.\n */\nexport const ATTR_HTTP_RESPONSE_HEADER = (key: string) => `http.response.header.${key}`;\n\n/**\n * [HTTP response status code](https://tools.ietf.org/html/rfc7231#section-6).\n *\n * @example 200\n */\nexport const ATTR_HTTP_RESPONSE_STATUS_CODE = 'http.response.status_code' as const;\n\n/**\n * The matched route template for the request. This **MUST** be low-cardinality and include all static path segments, with dynamic path segments represented with placeholders.\n *\n * @example /users/:userID?\n * @example my-controller/my-action/{id?}\n *\n * @note **MUST NOT** be populated when this is not supported by the HTTP server framework as the route attribute should have low-cardinality and the URI path can NOT substitute it.\n * **SHOULD** include the [application root](/docs/http/http-spans.md#http-server-definitions) if there is one.\n *\n * A static path segment is a part of the route template with a fixed, low-cardinality value. This includes literal strings like `/users/` and placeholders that\n * are constrained to a finite, predefined set of values, e.g. `{controller}` or `{action}`.\n *\n * A dynamic path segment is a placeholder for a value that can have high cardinality and is not constrained to a predefined list like static path segments.\n *\n * Instrumentations **SHOULD** use routing information provided by the corresponding web framework. They **SHOULD** pick the most precise source of routing information and **MAY**\n * support custom route formatting. Instrumentations **SHOULD** document the format and the API used to obtain the route string.\n */\nexport const ATTR_HTTP_ROUTE = 'http.route' as const;\n\n/**\n * Name of the garbage collector action.\n *\n * @example end of minor GC\n * @example end of major GC\n *\n * @note Garbage collector action is generally obtained via [GarbageCollectionNotificationInfo#getGcAction()](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.management/com/sun/management/GarbageCollectionNotificationInfo.html#getGcAction()).\n */\nexport const ATTR_JVM_GC_ACTION = 'jvm.gc.action' as const;\n\n/**\n * Name of the garbage collector.\n *\n * @example G1 Young Generation\n * @example G1 Old Generation\n *\n * @note Garbage collector name is generally obtained via [GarbageCollectionNotificationInfo#getGcName()](https://docs.oracle.com/en/java/javase/11/docs/api/jdk.management/com/sun/management/GarbageCollectionNotificationInfo.html#getGcName()).\n */\nexport const ATTR_JVM_GC_NAME = 'jvm.gc.name' as const;\n\n/**\n * Name of the memory pool.\n *\n * @example G1 Old Gen\n * @example G1 Eden space\n * @example G1 Survivor Space\n *\n * @note Pool names are generally obtained via [MemoryPoolMXBean#getName()](https://docs.oracle.com/en/java/javase/11/docs/api/java.management/java/lang/management/MemoryPoolMXBean.html#getName()).\n */\nexport const ATTR_JVM_MEMORY_POOL_NAME = 'jvm.memory.pool.name' as const;\n\n/**\n * The type of memory.\n *\n * @example heap\n * @example non_heap\n */\nexport const ATTR_JVM_MEMORY_TYPE = 'jvm.memory.type' as const;\n\n/**\n * Enum value \"heap\" for attribute {@link ATTR_JVM_MEMORY_TYPE}.\n *\n * Heap memory.\n */\nexport const JVM_MEMORY_TYPE_VALUE_HEAP = \"heap\" as const;\n\n/**\n * Enum value \"non_heap\" for attribute {@link ATTR_JVM_MEMORY_TYPE}.\n *\n * Non-heap memory\n */\nexport const JVM_MEMORY_TYPE_VALUE_NON_HEAP = \"non_heap\" as const;\n\n/**\n * Whether the thread is daemon or not.\n */\nexport const ATTR_JVM_THREAD_DAEMON = 'jvm.thread.daemon' as const;\n\n/**\n * State of the thread.\n *\n * @example runnable\n * @example blocked\n */\nexport const ATTR_JVM_THREAD_STATE = 'jvm.thread.state' as const;\n\n/**\n * Enum value \"blocked\" for attribute {@link ATTR_JVM_THREAD_STATE}.\n *\n * A thread that is blocked waiting for a monitor lock is in this state.\n */\nexport const JVM_THREAD_STATE_VALUE_BLOCKED = \"blocked\" as const;\n\n/**\n * Enum value \"new\" for attribute {@link ATTR_JVM_THREAD_STATE}.\n *\n * A thread that has not yet started is in this state.\n */\nexport const JVM_THREAD_STATE_VALUE_NEW = \"new\" as const;\n\n/**\n * Enum value \"runnable\" for attribute {@link ATTR_JVM_THREAD_STATE}.\n *\n * A thread executing in the Java virtual machine is in this state.\n */\nexport const JVM_THREAD_STATE_VALUE_RUNNABLE = \"runnable\" as const;\n\n/**\n * Enum value \"terminated\" for attribute {@link ATTR_JVM_THREAD_STATE}.\n *\n * A thread that has exited is in this state.\n */\nexport const JVM_THREAD_STATE_VALUE_TERMINATED = \"terminated\" as const;\n\n/**\n * Enum value \"timed_waiting\" for attribute {@link ATTR_JVM_THREAD_STATE}.\n *\n * A thread that is waiting for another thread to perform an action for up to a specified waiting time is in this state.\n */\nexport const JVM_THREAD_STATE_VALUE_TIMED_WAITING = \"timed_waiting\" as const;\n\n/**\n * Enum value \"waiting\" for attribute {@link ATTR_JVM_THREAD_STATE}.\n *\n * A thread that is waiting indefinitely for another thread to perform a particular action is in this state.\n */\nexport const JVM_THREAD_STATE_VALUE_WAITING = \"waiting\" as const;\n\n/**\n * Local address of the network connection - IP address or Unix domain socket name.\n *\n * @example 10.1.2.80\n * @example /tmp/my.sock\n */\nexport const ATTR_NETWORK_LOCAL_ADDRESS = 'network.local.address' as const;\n\n/**\n * Local port number of the network connection.\n *\n * @example 65123\n */\nexport const ATTR_NETWORK_LOCAL_PORT = 'network.local.port' as const;\n\n/**\n * Peer address of the network connection - IP address or Unix domain socket name.\n *\n * @example 10.1.2.80\n * @example /tmp/my.sock\n */\nexport const ATTR_NETWORK_PEER_ADDRESS = 'network.peer.address' as const;\n\n/**\n * Peer port number of the network connection.\n *\n * @example 65123\n */\nexport const ATTR_NETWORK_PEER_PORT = 'network.peer.port' as const;\n\n/**\n * [OSI application layer](https://wikipedia.org/wiki/Application_layer) or non-OSI equivalent.\n *\n * @example amqp\n * @example http\n * @example mqtt\n *\n * @note The value **SHOULD** be normalized to lowercase.\n */\nexport const ATTR_NETWORK_PROTOCOL_NAME = 'network.protocol.name' as const;\n\n/**\n * The actual version of the protocol used for network communication.\n *\n * @example 1.1\n * @example 2\n *\n * @note If protocol version is subject to negotiation (for example using [ALPN](https://www.rfc-editor.org/rfc/rfc7301.html)), this attribute **SHOULD** be set to the negotiated version. If the actual protocol version is not known, this attribute **SHOULD NOT** be set.\n */\nexport const ATTR_NETWORK_PROTOCOL_VERSION = 'network.protocol.version' as const;\n\n/**\n * [OSI transport layer](https://wikipedia.org/wiki/Transport_layer) or [inter-process communication method](https://wikipedia.org/wiki/Inter-process_communication).\n *\n * @example tcp\n * @example udp\n *\n * @note The value **SHOULD** be normalized to lowercase.\n *\n * Consider always setting the transport when setting a port number, since\n * a port number is ambiguous without knowing the transport. For example\n * different processes could be listening on TCP port 12345 and UDP port 12345.\n */\nexport const ATTR_NETWORK_TRANSPORT = 'network.transport' as const;\n\n/**\n * Enum value \"pipe\" for attribute {@link ATTR_NETWORK_TRANSPORT}.\n *\n * Named or anonymous pipe.\n */\nexport const NETWORK_TRANSPORT_VALUE_PIPE = \"pipe\" as const;\n\n/**\n * Enum value \"quic\" for attribute {@link ATTR_NETWORK_TRANSPORT}.\n *\n * QUIC\n */\nexport const NETWORK_TRANSPORT_VALUE_QUIC = \"quic\" as const;\n\n/**\n * Enum value \"tcp\" for attribute {@link ATTR_NETWORK_TRANSPORT}.\n *\n * TCP\n */\nexport const NETWORK_TRANSPORT_VALUE_TCP = \"tcp\" as const;\n\n/**\n * Enum value \"udp\" for attribute {@link ATTR_NETWORK_TRANSPORT}.\n *\n * UDP\n */\nexport const NETWORK_TRANSPORT_VALUE_UDP = \"udp\" as const;\n\n/**\n * Enum value \"unix\" for attribute {@link ATTR_NETWORK_TRANSPORT}.\n *\n * Unix domain socket\n */\nexport const NETWORK_TRANSPORT_VALUE_UNIX = \"unix\" as const;\n\n/**\n * [OSI network layer](https://wikipedia.org/wiki/Network_layer) or non-OSI equivalent.\n *\n * @example ipv4\n * @example ipv6\n *\n * @note The value **SHOULD** be normalized to lowercase.\n */\nexport const ATTR_NETWORK_TYPE = 'network.type' as const;\n\n/**\n * Enum value \"ipv4\" for attribute {@link ATTR_NETWORK_TYPE}.\n *\n * IPv4\n */\nexport const NETWORK_TYPE_VALUE_IPV4 = \"ipv4\" as const;\n\n/**\n * Enum value \"ipv6\" for attribute {@link ATTR_NETWORK_TYPE}.\n *\n * IPv6\n */\nexport const NETWORK_TYPE_VALUE_IPV6 = \"ipv6\" as const;\n\n/**\n * The name of the instrumentation scope - (`InstrumentationScope.Name` in OTLP).\n *\n * @example io.opentelemetry.contrib.mongodb\n */\nexport const ATTR_OTEL_SCOPE_NAME = 'otel.scope.name' as const;\n\n/**\n * The version of the instrumentation scope - (`InstrumentationScope.Version` in OTLP).\n *\n * @example 1.0.0\n */\nexport const ATTR_OTEL_SCOPE_VERSION = 'otel.scope.version' as const;\n\n/**\n * Name of the code, either \"OK\" or \"ERROR\". **MUST NOT** be set if the status code is UNSET.\n */\nexport const ATTR_OTEL_STATUS_CODE = 'otel.status_code' as const;\n\n/**\n * Enum value \"ERROR\" for attribute {@link ATTR_OTEL_STATUS_CODE}.\n *\n * The operation contains an error.\n */\nexport const OTEL_STATUS_CODE_VALUE_ERROR = \"ERROR\" as const;\n\n/**\n * Enum value \"OK\" for attribute {@link ATTR_OTEL_STATUS_CODE}.\n *\n * The operation has been validated by an Application developer or Operator to have completed successfully.\n */\nexport const OTEL_STATUS_CODE_VALUE_OK = \"OK\" as const;\n\n/**\n * Description of the Status if it has a value, otherwise not set.\n *\n * @example resource not found\n */\nexport const ATTR_OTEL_STATUS_DESCRIPTION = 'otel.status_description' as const;\n\n/**\n * Server domain name if available without reverse DNS lookup; otherwise, IP address or Unix domain socket name.\n *\n * @example example.com\n * @example 10.1.2.80\n * @example /tmp/my.sock\n *\n * @note When observed from the client side, and when communicating through an intermediary, `server.address` **SHOULD** represent the server address behind any intermediaries, for example proxies, if it's available.\n */\nexport const ATTR_SERVER_ADDRESS = 'server.address' as const;\n\n/**\n * Server port number.\n *\n * @example 80\n * @example 8080\n * @example 443\n *\n * @note When observed from the client side, and when communicating through an intermediary, `server.port` **SHOULD** represent the server port behind any intermediaries, for example proxies, if it's available.\n */\nexport const ATTR_SERVER_PORT = 'server.port' as const;\n\n/**\n * Logical name of the service.\n *\n * @example shoppingcart\n *\n * @note **MUST** be the same for all instances of horizontally scaled services. If the value was not specified, SDKs **MUST** fallback to `unknown_service:` concatenated with [`process.executable.name`](process.md), e.g. `unknown_service:bash`. If `process.executable.name` is not available, the value **MUST** be set to `unknown_service`.\n */\nexport const ATTR_SERVICE_NAME = 'service.name' as const;\n\n/**\n * The version string of the service API or implementation. The format is not defined by these conventions.\n *\n * @example 2.0.0\n * @example a01dbef8a\n */\nexport const ATTR_SERVICE_VERSION = 'service.version' as const;\n\n/**\n * SignalR HTTP connection closure status.\n *\n * @example app_shutdown\n * @example timeout\n */\nexport const ATTR_SIGNALR_CONNECTION_STATUS = 'signalr.connection.status' as const;\n\n/**\n * Enum value \"app_shutdown\" for attribute {@link ATTR_SIGNALR_CONNECTION_STATUS}.\n *\n * The connection was closed because the app is shutting down.\n */\nexport const SIGNALR_CONNECTION_STATUS_VALUE_APP_SHUTDOWN = \"app_shutdown\" as const;\n\n/**\n * Enum value \"normal_closure\" for attribute {@link ATTR_SIGNALR_CONNECTION_STATUS}.\n *\n * The connection was closed normally.\n */\nexport const SIGNALR_CONNECTION_STATUS_VALUE_NORMAL_CLOSURE = \"normal_closure\" as const;\n\n/**\n * Enum value \"timeout\" for attribute {@link ATTR_SIGNALR_CONNECTION_STATUS}.\n *\n * The connection was closed due to a timeout.\n */\nexport const SIGNALR_CONNECTION_STATUS_VALUE_TIMEOUT = \"timeout\" as const;\n\n/**\n * [SignalR transport type](https://github.com/dotnet/aspnetcore/blob/main/src/SignalR/docs/specs/TransportProtocols.md)\n *\n * @example web_sockets\n * @example long_polling\n */\nexport const ATTR_SIGNALR_TRANSPORT = 'signalr.transport' as const;\n\n/**\n * Enum value \"long_polling\" for attribute {@link ATTR_SIGNALR_TRANSPORT}.\n *\n * LongPolling protocol\n */\nexport const SIGNALR_TRANSPORT_VALUE_LONG_POLLING = \"long_polling\" as const;\n\n/**\n * Enum value \"server_sent_events\" for attribute {@link ATTR_SIGNALR_TRANSPORT}.\n *\n * ServerSentEvents protocol\n */\nexport const SIGNALR_TRANSPORT_VALUE_SERVER_SENT_EVENTS = \"server_sent_events\" as const;\n\n/**\n * Enum value \"web_sockets\" for attribute {@link ATTR_SIGNALR_TRANSPORT}.\n *\n * WebSockets protocol\n */\nexport const SIGNALR_TRANSPORT_VALUE_WEB_SOCKETS = \"web_sockets\" as const;\n\n/**\n * The language of the telemetry SDK.\n */\nexport const ATTR_TELEMETRY_SDK_LANGUAGE = 'telemetry.sdk.language' as const;\n\n/**\n * Enum value \"cpp\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_CPP = \"cpp\" as const;\n\n/**\n * Enum value \"dotnet\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_DOTNET = \"dotnet\" as const;\n\n/**\n * Enum value \"erlang\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_ERLANG = \"erlang\" as const;\n\n/**\n * Enum value \"go\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_GO = \"go\" as const;\n\n/**\n * Enum value \"java\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_JAVA = \"java\" as const;\n\n/**\n * Enum value \"nodejs\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_NODEJS = \"nodejs\" as const;\n\n/**\n * Enum value \"php\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_PHP = \"php\" as const;\n\n/**\n * Enum value \"python\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_PYTHON = \"python\" as const;\n\n/**\n * Enum value \"ruby\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_RUBY = \"ruby\" as const;\n\n/**\n * Enum value \"rust\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_RUST = \"rust\" as const;\n\n/**\n * Enum value \"swift\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_SWIFT = \"swift\" as const;\n\n/**\n * Enum value \"webjs\" for attribute {@link ATTR_TELEMETRY_SDK_LANGUAGE}.\n */\nexport const TELEMETRY_SDK_LANGUAGE_VALUE_WEBJS = \"webjs\" as const;\n\n/**\n * The name of the telemetry SDK as defined above.\n *\n * @example opentelemetry\n *\n * @note The OpenTelemetry SDK **MUST** set the `telemetry.sdk.name` attribute to `opentelemetry`.\n * If another SDK, like a fork or a vendor-provided implementation, is used, this SDK **MUST** set the\n * `telemetry.sdk.name` attribute to the fully-qualified class or module name of this SDK's main entry point\n * or another suitable identifier depending on the language.\n * The identifier `opentelemetry` is reserved and **MUST NOT** be used in this case.\n * All custom identifiers **SHOULD** be stable across different versions of an implementation.\n */\nexport const ATTR_TELEMETRY_SDK_NAME = 'telemetry.sdk.name' as const;\n\n/**\n * The version string of the telemetry SDK.\n *\n * @example 1.2.3\n */\nexport const ATTR_TELEMETRY_SDK_VERSION = 'telemetry.sdk.version' as const;\n\n/**\n * The [URI fragment](https://www.rfc-editor.org/rfc/rfc3986#section-3.5) component\n *\n * @example SemConv\n */\nexport const ATTR_URL_FRAGMENT = 'url.fragment' as const;\n\n/**\n * Absolute URL describing a network resource according to [RFC3986](https://www.rfc-editor.org/rfc/rfc3986)\n *\n * @example https://www.foo.bar/search?q=OpenTelemetry#SemConv\n * @example //localhost\n *\n * @note For network calls, URL usually has `scheme://host[:port][path][?query][#fragment]` format, where the fragment\n * is not transmitted over HTTP, but if it is known, it **SHOULD** be included nevertheless.\n *\n * `url.full` **MUST NOT** contain credentials passed via URL in form of `https://username:password@www.example.com/`.\n * In such case username and password **SHOULD** be redacted and attribute's value **SHOULD** be `https://REDACTED:REDACTED@www.example.com/`.\n *\n * `url.full` **SHOULD** capture the absolute URL when it is available (or can be reconstructed).\n *\n * Sensitive content provided in `url.full` **SHOULD** be scrubbed when instrumentations can identify it.\n *\n *\n * Query string values for the following keys **SHOULD** be redacted by default and replaced by the\n * value `REDACTED`:\n *\n *   - [`AWSAccessKeyId`](https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html#RESTAuthenticationQueryStringAuth)\n *   - [`Signature`](https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html#RESTAuthenticationQueryStringAuth)\n *   - [`sig`](https://learn.microsoft.com/azure/storage/common/storage-sas-overview#sas-token)\n *   - [`X-Goog-Signature`](https://cloud.google.com/storage/docs/access-control/signed-urls)\n *\n * This list is subject to change over time.\n *\n * When a query string value is redacted, the query string key **SHOULD** still be preserved, e.g.\n * `https://www.example.com/path?color=blue&sig=REDACTED`.\n */\nexport const ATTR_URL_FULL = 'url.full' as const;\n\n/**\n * The [URI path](https://www.rfc-editor.org/rfc/rfc3986#section-3.3) component\n *\n * @example /search\n *\n * @note Sensitive content provided in `url.path` **SHOULD** be scrubbed when instrumentations can identify it.\n */\nexport const ATTR_URL_PATH = 'url.path' as const;\n\n/**\n * The [URI query](https://www.rfc-editor.org/rfc/rfc3986#section-3.4) component\n *\n * @example q=OpenTelemetry\n *\n * @note Sensitive content provided in `url.query` **SHOULD** be scrubbed when instrumentations can identify it.\n *\n *\n * Query string values for the following keys **SHOULD** be redacted by default and replaced by the value `REDACTED`:\n *\n *   - [`AWSAccessKeyId`](https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html#RESTAuthenticationQueryStringAuth)\n *   - [`Signature`](https://docs.aws.amazon.com/AmazonS3/latest/userguide/RESTAuthentication.html#RESTAuthenticationQueryStringAuth)\n *   - [`sig`](https://learn.microsoft.com/azure/storage/common/storage-sas-overview#sas-token)\n *   - [`X-Goog-Signature`](https://cloud.google.com/storage/docs/access-control/signed-urls)\n *\n * This list is subject to change over time.\n *\n * When a query string value is redacted, the query string key **SHOULD** still be preserved, e.g.\n * `q=OpenTelemetry&sig=REDACTED`.\n */\nexport const ATTR_URL_QUERY = 'url.query' as const;\n\n/**\n * The [URI scheme](https://www.rfc-editor.org/rfc/rfc3986#section-3.1) component identifying the used protocol.\n *\n * @example https\n * @example ftp\n * @example telnet\n */\nexport const ATTR_URL_SCHEME = 'url.scheme' as const;\n\n/**\n * Value of the [HTTP User-Agent](https://www.rfc-editor.org/rfc/rfc9110.html#field.user-agent) header sent by the client.\n *\n * @example CERN-LineMode/2.15 libwww/2.17b3\n * @example Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.2 Mobile/15E148 Safari/604.1\n * @example YourApp/1.0.0 grpc-java-okhttp/1.27.2\n */\nexport const ATTR_USER_AGENT_ORIGINAL = 'user_agent.original' as const;\n\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG,CAEH,4GAA4G;AAC5G,8GAA8G;AAC9G,4GAA4G;AAE5G;;;;;GAKG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AACI,MAAM,4CAA4C,GAAG,yCAAkD,CAAC;AAOxG,MAAM,qDAAqD,GAAG,SAAkB,CAAC;AAOjF,MAAM,qDAAqD,GAAG,SAAkB,CAAC;AAOjF,MAAM,qDAAqD,GAAG,SAAkB,CAAC;AAOjF,MAAM,uDAAuD,GAAG,WAAoB,CAAC;AAOrF,MAAM,wCAAwC,GAAG,qCAA8C,CAAC;AAShG,MAAM,oCAAoC,GAAG,iCAA0C,CAAC;AAQxF,MAAM,oCAAoC,GAAG,iCAA0C,CAAC;AAOxF,MAAM,8CAA8C,GAAG,UAAmB,CAAC;AAO3E,MAAM,sDAAsD,GAAG,kBAA2B,CAAC;AAO3F,MAAM,oDAAoD,GAAG,gBAAyB,CAAC;AAOvF,MAAM,sDAAsD,GAAG,kBAA2B,CAAC;AAO3F,MAAM,oCAAoC,GAAG,iCAA0C,CAAC;AAOxF,MAAM,mCAAmC,GAAG,gCAAyC,CAAC;AAQtF,MAAM,oCAAoC,GAAG,iCAA0C,CAAC;AAOxF,MAAM,6CAA6C,GAAG,SAAkB,CAAC;AAOzE,MAAM,6CAA6C,GAAG,SAAkB,CAAC;AAOzE,MAAM,qCAAqC,GAAG,kCAA2C,CAAC;AAW1F,MAAM,mBAAmB,GAAG,gBAAyB,CAAC;AAStD,MAAM,gBAAgB,GAAG,aAAsB,CAAC;AAOhD,MAAM,uBAAuB,GAAG,oBAA6B,CAAC;AAO9D,MAAM,mBAAmB,GAAG,gBAAyB,CAAC;AAyBtD,MAAM,uBAAuB,GAAG,oBAA6B,CAAC;AAO9D,MAAM,qBAAqB,GAAG,kBAA2B,CAAC;AAO1D,MAAM,oBAAoB,GAAG,iBAA0B,CAAC;AAkBxD,MAAM,uBAAuB,GAAG,oBAA6B,CAAC;AAY9D,MAAM,iBAAiB,GAAG,cAAuB,CAAC;AAWlD,MAAM,4BAA4B,GAAG,yBAAkC,CAAC;AAwBxE,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAmB5D,MAAM,qBAAqB,GAAG,kBAA2B,CAAC;AAY1D,MAAM,kBAAkB,GAAG,eAAwB,CAAC;AAapD,MAAM,4BAA4B,GAAG,yBAAkC,CAAC;AAaxE,MAAM,6BAA6B,GAAG,0BAAmC,CAAC;AAO1E,MAAM,mBAAmB,GAAG,gBAAyB,CAAC;AAOtD,MAAM,4BAA4B,GAAG,SAAkB,CAAC;AAOxD,MAAM,yCAAyC,GAAG,sBAA+B,CAAC;AAOlF,MAAM,0BAA0B,GAAG,OAAgB,CAAC;AAOpD,MAAM,+BAA+B,GAAG,YAAqB,CAAC;AAS9D,MAAM,8BAA8B,GAAG,2BAAoC,CAAC;AAO5E,MAAM,oCAAoC,GAAG,MAAe,CAAC;AAO7D,MAAM,oCAAoC,GAAG,MAAe,CAAC;AAO7D,MAAM,oCAAoC,GAAG,MAAe,CAAC;AAO7D,MAAM,mCAAmC,GAAG,KAAc,CAAC;AAO3D,MAAM,mCAAmC,GAAG,KAAc,CAAC;AA8B3D,MAAM,eAAe,GAAG,YAAqB,CAAC;AAO9C,MAAM,sBAAsB,GAAG,QAAiB,CAAC;AAOjD,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAQ5D,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAO5D,MAAM,yBAAyB,GAAG,sBAA+B,CAAC;AAQlE,MAAM,mBAAmB,GAAG,gBAAyB,CAAC;AAyBtD,MAAM,wBAAwB,GAAG,CAAC,GAAW,EAAE,CAAG,CAAD,AAAC,oBAAA,EAAuB,GAAG,EAAE,CAAC;AAyB/E,MAAM,wBAAwB,GAAG,qBAA8B,CAAC;AAOhE,MAAM,+BAA+B,GAAG,QAAiB,CAAC;AAO1D,MAAM,iCAAiC,GAAG,SAAkB,CAAC;AAO7D,MAAM,gCAAgC,GAAG,QAAiB,CAAC;AAO3D,MAAM,6BAA6B,GAAG,KAAc,CAAC;AAOrD,MAAM,8BAA8B,GAAG,MAAe,CAAC;AAOvD,MAAM,iCAAiC,GAAG,SAAkB,CAAC;AAO7D,MAAM,+BAA+B,GAAG,OAAgB,CAAC;AAOzD,MAAM,8BAA8B,GAAG,MAAe,CAAC;AAOvD,MAAM,6BAA6B,GAAG,KAAc,CAAC;AAOrD,MAAM,+BAA+B,GAAG,OAAgB,CAAC;AASzD,MAAM,iCAAiC,GAAG,8BAAuC,CAAC;AASlF,MAAM,8BAA8B,GAAG,2BAAoC,CAAC;AAwB5E,MAAM,yBAAyB,GAAG,CAAC,GAAW,EAAE,CAAG,CAAD,AAAC,qBAAA,EAAwB,GAAG,EAAE,CAAC;AAOjF,MAAM,8BAA8B,GAAG,2BAAoC,CAAC;AAmB5E,MAAM,eAAe,GAAG,YAAqB,CAAC;AAU9C,MAAM,kBAAkB,GAAG,eAAwB,CAAC;AAUpD,MAAM,gBAAgB,GAAG,aAAsB,CAAC;AAWhD,MAAM,yBAAyB,GAAG,sBAA+B,CAAC;AAQlE,MAAM,oBAAoB,GAAG,iBAA0B,CAAC;AAOxD,MAAM,0BAA0B,GAAG,MAAe,CAAC;AAOnD,MAAM,8BAA8B,GAAG,UAAmB,CAAC;AAK3D,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAQ5D,MAAM,qBAAqB,GAAG,kBAA2B,CAAC;AAO1D,MAAM,8BAA8B,GAAG,SAAkB,CAAC;AAO1D,MAAM,0BAA0B,GAAG,KAAc,CAAC;AAOlD,MAAM,+BAA+B,GAAG,UAAmB,CAAC;AAO5D,MAAM,iCAAiC,GAAG,YAAqB,CAAC;AAOhE,MAAM,oCAAoC,GAAG,eAAwB,CAAC;AAOtE,MAAM,8BAA8B,GAAG,SAAkB,CAAC;AAQ1D,MAAM,0BAA0B,GAAG,uBAAgC,CAAC;AAOpE,MAAM,uBAAuB,GAAG,oBAA6B,CAAC;AAQ9D,MAAM,yBAAyB,GAAG,sBAA+B,CAAC;AAOlE,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAW5D,MAAM,0BAA0B,GAAG,uBAAgC,CAAC;AAUpE,MAAM,6BAA6B,GAAG,0BAAmC,CAAC;AAc1E,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAO5D,MAAM,4BAA4B,GAAG,MAAe,CAAC;AAOrD,MAAM,4BAA4B,GAAG,MAAe,CAAC;AAOrD,MAAM,2BAA2B,GAAG,KAAc,CAAC;AAOnD,MAAM,2BAA2B,GAAG,KAAc,CAAC;AAOnD,MAAM,4BAA4B,GAAG,MAAe,CAAC;AAUrD,MAAM,iBAAiB,GAAG,cAAuB,CAAC;AAOlD,MAAM,uBAAuB,GAAG,MAAe,CAAC;AAOhD,MAAM,uBAAuB,GAAG,MAAe,CAAC;AAOhD,MAAM,oBAAoB,GAAG,iBAA0B,CAAC;AAOxD,MAAM,uBAAuB,GAAG,oBAA6B,CAAC;AAK9D,MAAM,qBAAqB,GAAG,kBAA2B,CAAC;AAO1D,MAAM,4BAA4B,GAAG,OAAgB,CAAC;AAOtD,MAAM,yBAAyB,GAAG,IAAa,CAAC;AAOhD,MAAM,4BAA4B,GAAG,yBAAkC,CAAC;AAWxE,MAAM,mBAAmB,GAAG,gBAAyB,CAAC;AAWtD,MAAM,gBAAgB,GAAG,aAAsB,CAAC;AAShD,MAAM,iBAAiB,GAAG,cAAuB,CAAC;AAQlD,MAAM,oBAAoB,GAAG,iBAA0B,CAAC;AAQxD,MAAM,8BAA8B,GAAG,2BAAoC,CAAC;AAO5E,MAAM,4CAA4C,GAAG,cAAuB,CAAC;AAO7E,MAAM,8CAA8C,GAAG,gBAAyB,CAAC;AAOjF,MAAM,uCAAuC,GAAG,SAAkB,CAAC;AAQnE,MAAM,sBAAsB,GAAG,mBAA4B,CAAC;AAO5D,MAAM,oCAAoC,GAAG,cAAuB,CAAC;AAOrE,MAAM,0CAA0C,GAAG,oBAA6B,CAAC;AAOjF,MAAM,mCAAmC,GAAG,aAAsB,CAAC;AAKnE,MAAM,2BAA2B,GAAG,wBAAiC,CAAC;AAKtE,MAAM,gCAAgC,GAAG,KAAc,CAAC;AAKxD,MAAM,mCAAmC,GAAG,QAAiB,CAAC;AAK9D,MAAM,mCAAmC,GAAG,QAAiB,CAAC;AAK9D,MAAM,+BAA+B,GAAG,IAAa,CAAC;AAKtD,MAAM,iCAAiC,GAAG,MAAe,CAAC;AAK1D,MAAM,mCAAmC,GAAG,QAAiB,CAAC;AAK9D,MAAM,gCAAgC,GAAG,KAAc,CAAC;AAKxD,MAAM,mCAAmC,GAAG,QAAiB,CAAC;AAK9D,MAAM,iCAAiC,GAAG,MAAe,CAAC;AAK1D,MAAM,iCAAiC,GAAG,MAAe,CAAC;AAK1D,MAAM,kCAAkC,GAAG,OAAgB,CAAC;AAK5D,MAAM,kCAAkC,GAAG,OAAgB,CAAC;AAc5D,MAAM,uBAAuB,GAAG,oBAA6B,CAAC;AAO9D,MAAM,0BAA0B,GAAG,uBAAgC,CAAC;AAOpE,MAAM,iBAAiB,GAAG,cAAuB,CAAC;AAgClD,MAAM,aAAa,GAAG,UAAmB,CAAC;AAS1C,MAAM,aAAa,GAAG,UAAmB,CAAC;AAsB1C,MAAM,cAAc,GAAG,WAAoB,CAAC;AAS5C,MAAM,eAAe,GAAG,YAAqB,CAAC;AAS9C,MAAM,wBAAwB,GAAG,qBAA8B,CAAC"}},
    {"offset": {"line": 6934, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/semantic-conventions/build/esm/internal/utils.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/semantic-conventions/src/internal/utils.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Creates a const map from the given values\n * @param values - An array of values to be used as keys and values in the map.\n * @returns A populated version of the map with the values and keys derived from the values.\n */\n/*#__NO_SIDE_EFFECTS__*/\nexport function createConstMap<T>(values: Array<T[keyof T]>): T {\n  // eslint-disable-next-line prefer-const, @typescript-eslint/no-explicit-any\n  let res: any = {};\n  const len = values.length;\n  for (let lp = 0; lp < len; lp++) {\n    const val = values[lp];\n    if (val) {\n      res[String(val).toUpperCase().replace(/[-.]/g, '_')] = val;\n    }\n  }\n\n  return res as T;\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG,CAEH;;;;GAIG,CACH,sBAAA,EAAwB;;;;AAClB,SAAU,cAAc,CAAI,MAAyB;IACzD,4EAA4E;IAC5E,IAAI,GAAG,GAAQ,CAAA,CAAE,CAAC;IAClB,MAAM,GAAG,GAAG,MAAM,CAAC,MAAM,CAAC;IAC1B,IAAK,IAAI,EAAE,GAAG,CAAC,EAAE,EAAE,GAAG,GAAG,EAAE,EAAE,EAAE,CAAE;QAC/B,MAAM,GAAG,GAAG,MAAM,CAAC,EAAE,CAAC,CAAC;QACvB,IAAI,GAAG,EAAE;YACP,GAAG,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,WAAW,EAAE,CAAC,OAAO,CAAC,OAAO,EAAE,GAAG,CAAC,CAAC,GAAG,GAAG,CAAC;SAC5D;KACF;IAED,OAAO,GAAQ,CAAC;AAClB,CAAC"}},
    {"offset": {"line": 6972, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/semantic-conventions/build/esm/trace/SemanticAttributes.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/semantic-conventions/src/trace/SemanticAttributes.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { createConstMap } from '../internal/utils';\n\n//----------------------------------------------------------------------------------------------------------\n// DO NOT EDIT, this is an Auto-generated file from scripts/semconv/templates//templates/SemanticAttributes.ts.j2\n//----------------------------------------------------------------------------------------------------------\n\n//----------------------------------------------------------------------------------------------------------\n// Constant values for SemanticAttributes\n//----------------------------------------------------------------------------------------------------------\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_AWS_LAMBDA_INVOKED_ARN = 'aws.lambda.invoked_arn';\nconst TMP_DB_SYSTEM = 'db.system';\nconst TMP_DB_CONNECTION_STRING = 'db.connection_string';\nconst TMP_DB_USER = 'db.user';\nconst TMP_DB_JDBC_DRIVER_CLASSNAME = 'db.jdbc.driver_classname';\nconst TMP_DB_NAME = 'db.name';\nconst TMP_DB_STATEMENT = 'db.statement';\nconst TMP_DB_OPERATION = 'db.operation';\nconst TMP_DB_MSSQL_INSTANCE_NAME = 'db.mssql.instance_name';\nconst TMP_DB_CASSANDRA_KEYSPACE = 'db.cassandra.keyspace';\nconst TMP_DB_CASSANDRA_PAGE_SIZE = 'db.cassandra.page_size';\nconst TMP_DB_CASSANDRA_CONSISTENCY_LEVEL = 'db.cassandra.consistency_level';\nconst TMP_DB_CASSANDRA_TABLE = 'db.cassandra.table';\nconst TMP_DB_CASSANDRA_IDEMPOTENCE = 'db.cassandra.idempotence';\nconst TMP_DB_CASSANDRA_SPECULATIVE_EXECUTION_COUNT =\n  'db.cassandra.speculative_execution_count';\nconst TMP_DB_CASSANDRA_COORDINATOR_ID = 'db.cassandra.coordinator.id';\nconst TMP_DB_CASSANDRA_COORDINATOR_DC = 'db.cassandra.coordinator.dc';\nconst TMP_DB_HBASE_NAMESPACE = 'db.hbase.namespace';\nconst TMP_DB_REDIS_DATABASE_INDEX = 'db.redis.database_index';\nconst TMP_DB_MONGODB_COLLECTION = 'db.mongodb.collection';\nconst TMP_DB_SQL_TABLE = 'db.sql.table';\nconst TMP_EXCEPTION_TYPE = 'exception.type';\nconst TMP_EXCEPTION_MESSAGE = 'exception.message';\nconst TMP_EXCEPTION_STACKTRACE = 'exception.stacktrace';\nconst TMP_EXCEPTION_ESCAPED = 'exception.escaped';\nconst TMP_FAAS_TRIGGER = 'faas.trigger';\nconst TMP_FAAS_EXECUTION = 'faas.execution';\nconst TMP_FAAS_DOCUMENT_COLLECTION = 'faas.document.collection';\nconst TMP_FAAS_DOCUMENT_OPERATION = 'faas.document.operation';\nconst TMP_FAAS_DOCUMENT_TIME = 'faas.document.time';\nconst TMP_FAAS_DOCUMENT_NAME = 'faas.document.name';\nconst TMP_FAAS_TIME = 'faas.time';\nconst TMP_FAAS_CRON = 'faas.cron';\nconst TMP_FAAS_COLDSTART = 'faas.coldstart';\nconst TMP_FAAS_INVOKED_NAME = 'faas.invoked_name';\nconst TMP_FAAS_INVOKED_PROVIDER = 'faas.invoked_provider';\nconst TMP_FAAS_INVOKED_REGION = 'faas.invoked_region';\nconst TMP_NET_TRANSPORT = 'net.transport';\nconst TMP_NET_PEER_IP = 'net.peer.ip';\nconst TMP_NET_PEER_PORT = 'net.peer.port';\nconst TMP_NET_PEER_NAME = 'net.peer.name';\nconst TMP_NET_HOST_IP = 'net.host.ip';\nconst TMP_NET_HOST_PORT = 'net.host.port';\nconst TMP_NET_HOST_NAME = 'net.host.name';\nconst TMP_NET_HOST_CONNECTION_TYPE = 'net.host.connection.type';\nconst TMP_NET_HOST_CONNECTION_SUBTYPE = 'net.host.connection.subtype';\nconst TMP_NET_HOST_CARRIER_NAME = 'net.host.carrier.name';\nconst TMP_NET_HOST_CARRIER_MCC = 'net.host.carrier.mcc';\nconst TMP_NET_HOST_CARRIER_MNC = 'net.host.carrier.mnc';\nconst TMP_NET_HOST_CARRIER_ICC = 'net.host.carrier.icc';\nconst TMP_PEER_SERVICE = 'peer.service';\nconst TMP_ENDUSER_ID = 'enduser.id';\nconst TMP_ENDUSER_ROLE = 'enduser.role';\nconst TMP_ENDUSER_SCOPE = 'enduser.scope';\nconst TMP_THREAD_ID = 'thread.id';\nconst TMP_THREAD_NAME = 'thread.name';\nconst TMP_CODE_FUNCTION = 'code.function';\nconst TMP_CODE_NAMESPACE = 'code.namespace';\nconst TMP_CODE_FILEPATH = 'code.filepath';\nconst TMP_CODE_LINENO = 'code.lineno';\nconst TMP_HTTP_METHOD = 'http.method';\nconst TMP_HTTP_URL = 'http.url';\nconst TMP_HTTP_TARGET = 'http.target';\nconst TMP_HTTP_HOST = 'http.host';\nconst TMP_HTTP_SCHEME = 'http.scheme';\nconst TMP_HTTP_STATUS_CODE = 'http.status_code';\nconst TMP_HTTP_FLAVOR = 'http.flavor';\nconst TMP_HTTP_USER_AGENT = 'http.user_agent';\nconst TMP_HTTP_REQUEST_CONTENT_LENGTH = 'http.request_content_length';\nconst TMP_HTTP_REQUEST_CONTENT_LENGTH_UNCOMPRESSED =\n  'http.request_content_length_uncompressed';\nconst TMP_HTTP_RESPONSE_CONTENT_LENGTH = 'http.response_content_length';\nconst TMP_HTTP_RESPONSE_CONTENT_LENGTH_UNCOMPRESSED =\n  'http.response_content_length_uncompressed';\nconst TMP_HTTP_SERVER_NAME = 'http.server_name';\nconst TMP_HTTP_ROUTE = 'http.route';\nconst TMP_HTTP_CLIENT_IP = 'http.client_ip';\nconst TMP_AWS_DYNAMODB_TABLE_NAMES = 'aws.dynamodb.table_names';\nconst TMP_AWS_DYNAMODB_CONSUMED_CAPACITY = 'aws.dynamodb.consumed_capacity';\nconst TMP_AWS_DYNAMODB_ITEM_COLLECTION_METRICS =\n  'aws.dynamodb.item_collection_metrics';\nconst TMP_AWS_DYNAMODB_PROVISIONED_READ_CAPACITY =\n  'aws.dynamodb.provisioned_read_capacity';\nconst TMP_AWS_DYNAMODB_PROVISIONED_WRITE_CAPACITY =\n  'aws.dynamodb.provisioned_write_capacity';\nconst TMP_AWS_DYNAMODB_CONSISTENT_READ = 'aws.dynamodb.consistent_read';\nconst TMP_AWS_DYNAMODB_PROJECTION = 'aws.dynamodb.projection';\nconst TMP_AWS_DYNAMODB_LIMIT = 'aws.dynamodb.limit';\nconst TMP_AWS_DYNAMODB_ATTRIBUTES_TO_GET = 'aws.dynamodb.attributes_to_get';\nconst TMP_AWS_DYNAMODB_INDEX_NAME = 'aws.dynamodb.index_name';\nconst TMP_AWS_DYNAMODB_SELECT = 'aws.dynamodb.select';\nconst TMP_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEXES =\n  'aws.dynamodb.global_secondary_indexes';\nconst TMP_AWS_DYNAMODB_LOCAL_SECONDARY_INDEXES =\n  'aws.dynamodb.local_secondary_indexes';\nconst TMP_AWS_DYNAMODB_EXCLUSIVE_START_TABLE =\n  'aws.dynamodb.exclusive_start_table';\nconst TMP_AWS_DYNAMODB_TABLE_COUNT = 'aws.dynamodb.table_count';\nconst TMP_AWS_DYNAMODB_SCAN_FORWARD = 'aws.dynamodb.scan_forward';\nconst TMP_AWS_DYNAMODB_SEGMENT = 'aws.dynamodb.segment';\nconst TMP_AWS_DYNAMODB_TOTAL_SEGMENTS = 'aws.dynamodb.total_segments';\nconst TMP_AWS_DYNAMODB_COUNT = 'aws.dynamodb.count';\nconst TMP_AWS_DYNAMODB_SCANNED_COUNT = 'aws.dynamodb.scanned_count';\nconst TMP_AWS_DYNAMODB_ATTRIBUTE_DEFINITIONS =\n  'aws.dynamodb.attribute_definitions';\nconst TMP_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEX_UPDATES =\n  'aws.dynamodb.global_secondary_index_updates';\nconst TMP_MESSAGING_SYSTEM = 'messaging.system';\nconst TMP_MESSAGING_DESTINATION = 'messaging.destination';\nconst TMP_MESSAGING_DESTINATION_KIND = 'messaging.destination_kind';\nconst TMP_MESSAGING_TEMP_DESTINATION = 'messaging.temp_destination';\nconst TMP_MESSAGING_PROTOCOL = 'messaging.protocol';\nconst TMP_MESSAGING_PROTOCOL_VERSION = 'messaging.protocol_version';\nconst TMP_MESSAGING_URL = 'messaging.url';\nconst TMP_MESSAGING_MESSAGE_ID = 'messaging.message_id';\nconst TMP_MESSAGING_CONVERSATION_ID = 'messaging.conversation_id';\nconst TMP_MESSAGING_MESSAGE_PAYLOAD_SIZE_BYTES =\n  'messaging.message_payload_size_bytes';\nconst TMP_MESSAGING_MESSAGE_PAYLOAD_COMPRESSED_SIZE_BYTES =\n  'messaging.message_payload_compressed_size_bytes';\nconst TMP_MESSAGING_OPERATION = 'messaging.operation';\nconst TMP_MESSAGING_CONSUMER_ID = 'messaging.consumer_id';\nconst TMP_MESSAGING_RABBITMQ_ROUTING_KEY = 'messaging.rabbitmq.routing_key';\nconst TMP_MESSAGING_KAFKA_MESSAGE_KEY = 'messaging.kafka.message_key';\nconst TMP_MESSAGING_KAFKA_CONSUMER_GROUP = 'messaging.kafka.consumer_group';\nconst TMP_MESSAGING_KAFKA_CLIENT_ID = 'messaging.kafka.client_id';\nconst TMP_MESSAGING_KAFKA_PARTITION = 'messaging.kafka.partition';\nconst TMP_MESSAGING_KAFKA_TOMBSTONE = 'messaging.kafka.tombstone';\nconst TMP_RPC_SYSTEM = 'rpc.system';\nconst TMP_RPC_SERVICE = 'rpc.service';\nconst TMP_RPC_METHOD = 'rpc.method';\nconst TMP_RPC_GRPC_STATUS_CODE = 'rpc.grpc.status_code';\nconst TMP_RPC_JSONRPC_VERSION = 'rpc.jsonrpc.version';\nconst TMP_RPC_JSONRPC_REQUEST_ID = 'rpc.jsonrpc.request_id';\nconst TMP_RPC_JSONRPC_ERROR_CODE = 'rpc.jsonrpc.error_code';\nconst TMP_RPC_JSONRPC_ERROR_MESSAGE = 'rpc.jsonrpc.error_message';\nconst TMP_MESSAGE_TYPE = 'message.type';\nconst TMP_MESSAGE_ID = 'message.id';\nconst TMP_MESSAGE_COMPRESSED_SIZE = 'message.compressed_size';\nconst TMP_MESSAGE_UNCOMPRESSED_SIZE = 'message.uncompressed_size';\n\n/**\n * The full invoked ARN as provided on the `Context` passed to the function (`Lambda-Runtime-Invoked-Function-Arn` header on the `/runtime/invocation/next` applicable).\n *\n * Note: This may be different from `faas.id` if an alias is involved.\n *\n * @deprecated Use ATTR_AWS_LAMBDA_INVOKED_ARN in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_LAMBDA_INVOKED_ARN = TMP_AWS_LAMBDA_INVOKED_ARN;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use ATTR_DB_SYSTEM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_SYSTEM = TMP_DB_SYSTEM;\n\n/**\n * The connection string used to connect to the database. It is recommended to remove embedded credentials.\n *\n * @deprecated Use ATTR_DB_CONNECTION_STRING in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CONNECTION_STRING = TMP_DB_CONNECTION_STRING;\n\n/**\n * Username for accessing the database.\n *\n * @deprecated Use ATTR_DB_USER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_USER = TMP_DB_USER;\n\n/**\n * The fully-qualified class name of the [Java Database Connectivity (JDBC)](https://docs.oracle.com/javase/8/docs/technotes/guides/jdbc/) driver used to connect.\n *\n * @deprecated Use ATTR_DB_JDBC_DRIVER_CLASSNAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_JDBC_DRIVER_CLASSNAME = TMP_DB_JDBC_DRIVER_CLASSNAME;\n\n/**\n * If no [tech-specific attribute](#call-level-attributes-for-specific-technologies) is defined, this attribute is used to report the name of the database being accessed. For commands that switch the database, this should be set to the target database (even if the command fails).\n *\n * Note: In some SQL databases, the database name to be used is called &#34;schema name&#34;.\n *\n * @deprecated Use ATTR_DB_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_NAME = TMP_DB_NAME;\n\n/**\n * The database statement being executed.\n *\n * Note: The value may be sanitized to exclude sensitive information.\n *\n * @deprecated Use ATTR_DB_STATEMENT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_STATEMENT = TMP_DB_STATEMENT;\n\n/**\n * The name of the operation being executed, e.g. the [MongoDB command name](https://docs.mongodb.com/manual/reference/command/#database-operations) such as `findAndModify`, or the SQL keyword.\n *\n * Note: When setting this to an SQL keyword, it is not recommended to attempt any client-side parsing of `db.statement` just to get this property, but it should be set if the operation name is provided by the library being instrumented. If the SQL statement has an ambiguous operation, or performs more than one operation, this value may be omitted.\n *\n * @deprecated Use ATTR_DB_OPERATION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_OPERATION = TMP_DB_OPERATION;\n\n/**\n * The Microsoft SQL Server [instance name](https://docs.microsoft.com/en-us/sql/connect/jdbc/building-the-connection-url?view=sql-server-ver15) connecting to. This name is used to determine the port of a named instance.\n *\n * Note: If setting a `db.mssql.instance_name`, `net.peer.port` is no longer required (but still recommended if non-standard).\n *\n * @deprecated Use ATTR_DB_MSSQL_INSTANCE_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_MSSQL_INSTANCE_NAME = TMP_DB_MSSQL_INSTANCE_NAME;\n\n/**\n * The name of the keyspace being accessed. To be used instead of the generic `db.name` attribute.\n *\n * @deprecated Use ATTR_DB_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_KEYSPACE = TMP_DB_CASSANDRA_KEYSPACE;\n\n/**\n * The fetch size used for paging, i.e. how many rows will be returned at once.\n *\n * @deprecated Use ATTR_DB_CASSANDRA_PAGE_SIZE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_PAGE_SIZE = TMP_DB_CASSANDRA_PAGE_SIZE;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use ATTR_DB_CASSANDRA_CONSISTENCY_LEVEL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_CONSISTENCY_LEVEL =\n  TMP_DB_CASSANDRA_CONSISTENCY_LEVEL;\n\n/**\n * The name of the primary table that the operation is acting upon, including the schema name (if applicable).\n *\n * Note: This mirrors the db.sql.table attribute but references cassandra rather than sql. It is not recommended to attempt any client-side parsing of `db.statement` just to get this property, but it should be set if it is provided by the library being instrumented. If the operation is acting upon an anonymous table, or more than one table, this value MUST NOT be set.\n *\n * @deprecated Use ATTR_DB_CASSANDRA_TABLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_TABLE = TMP_DB_CASSANDRA_TABLE;\n\n/**\n * Whether or not the query is idempotent.\n *\n * @deprecated Use ATTR_DB_CASSANDRA_IDEMPOTENCE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_IDEMPOTENCE = TMP_DB_CASSANDRA_IDEMPOTENCE;\n\n/**\n * The number of times a query was speculatively executed. Not set or `0` if the query was not executed speculatively.\n *\n * @deprecated Use ATTR_DB_CASSANDRA_SPECULATIVE_EXECUTION_COUNT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_SPECULATIVE_EXECUTION_COUNT =\n  TMP_DB_CASSANDRA_SPECULATIVE_EXECUTION_COUNT;\n\n/**\n * The ID of the coordinating node for a query.\n *\n * @deprecated Use ATTR_DB_CASSANDRA_COORDINATOR_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_COORDINATOR_ID =\n  TMP_DB_CASSANDRA_COORDINATOR_ID;\n\n/**\n * The data center of the coordinating node for a query.\n *\n * @deprecated Use ATTR_DB_CASSANDRA_COORDINATOR_DC in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_CASSANDRA_COORDINATOR_DC =\n  TMP_DB_CASSANDRA_COORDINATOR_DC;\n\n/**\n * The [HBase namespace](https://hbase.apache.org/book.html#_namespace) being accessed. To be used instead of the generic `db.name` attribute.\n *\n * @deprecated Use ATTR_DB_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_HBASE_NAMESPACE = TMP_DB_HBASE_NAMESPACE;\n\n/**\n * The index of the database being accessed as used in the [`SELECT` command](https://redis.io/commands/select), provided as an integer. To be used instead of the generic `db.name` attribute.\n *\n * @deprecated Use ATTR_DB_REDIS_DATABASE_INDEX in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_REDIS_DATABASE_INDEX = TMP_DB_REDIS_DATABASE_INDEX;\n\n/**\n * The collection being accessed within the database stated in `db.name`.\n *\n * @deprecated Use ATTR_DB_MONGODB_COLLECTION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_MONGODB_COLLECTION = TMP_DB_MONGODB_COLLECTION;\n\n/**\n * The name of the primary table that the operation is acting upon, including the schema name (if applicable).\n *\n * Note: It is not recommended to attempt any client-side parsing of `db.statement` just to get this property, but it should be set if it is provided by the library being instrumented. If the operation is acting upon an anonymous table, or more than one table, this value MUST NOT be set.\n *\n * @deprecated Use ATTR_DB_SQL_TABLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_DB_SQL_TABLE = TMP_DB_SQL_TABLE;\n\n/**\n * The type of the exception (its fully-qualified class name, if applicable). The dynamic type of the exception should be preferred over the static type in languages that support it.\n *\n * @deprecated Use ATTR_EXCEPTION_TYPE.\n */\nexport const SEMATTRS_EXCEPTION_TYPE = TMP_EXCEPTION_TYPE;\n\n/**\n * The exception message.\n *\n * @deprecated Use ATTR_EXCEPTION_MESSAGE.\n */\nexport const SEMATTRS_EXCEPTION_MESSAGE = TMP_EXCEPTION_MESSAGE;\n\n/**\n * A stacktrace as a string in the natural representation for the language runtime. The representation is to be determined and documented by each language SIG.\n *\n * @deprecated Use ATTR_EXCEPTION_STACKTRACE.\n */\nexport const SEMATTRS_EXCEPTION_STACKTRACE = TMP_EXCEPTION_STACKTRACE;\n\n/**\n* SHOULD be set to true if the exception event is recorded at a point where it is known that the exception is escaping the scope of the span.\n*\n* Note: An exception is considered to have escaped (or left) the scope of a span,\nif that span is ended while the exception is still logically &#34;in flight&#34;.\nThis may be actually &#34;in flight&#34; in some languages (e.g. if the exception\nis passed to a Context manager&#39;s `__exit__` method in Python) but will\nusually be caught at the point of recording the exception in most languages.\n\nIt is usually not possible to determine at the point where an exception is thrown\nwhether it will escape the scope of a span.\nHowever, it is trivial to know that an exception\nwill escape, if one checks for an active exception just before ending the span,\nas done in the [example above](#exception-end-example).\n\nIt follows that an exception may still escape the scope of the span\neven if the `exception.escaped` attribute was not set or set to false,\nsince the event might have been recorded at a time where it was not\nclear whether the exception will escape.\n*\n* @deprecated Use ATTR_EXCEPTION_ESCAPED.\n*/\nexport const SEMATTRS_EXCEPTION_ESCAPED = TMP_EXCEPTION_ESCAPED;\n\n/**\n * Type of the trigger on which the function is executed.\n *\n * @deprecated Use ATTR_FAAS_TRIGGER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_TRIGGER = TMP_FAAS_TRIGGER;\n\n/**\n * The execution ID of the current function execution.\n *\n * @deprecated Use ATTR_FAAS_INVOCATION_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_EXECUTION = TMP_FAAS_EXECUTION;\n\n/**\n * The name of the source on which the triggering operation was performed. For example, in Cloud Storage or S3 corresponds to the bucket name, and in Cosmos DB to the database name.\n *\n * @deprecated Use ATTR_FAAS_DOCUMENT_COLLECTION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_DOCUMENT_COLLECTION = TMP_FAAS_DOCUMENT_COLLECTION;\n\n/**\n * Describes the type of the operation that was performed on the data.\n *\n * @deprecated Use ATTR_FAAS_DOCUMENT_OPERATION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_DOCUMENT_OPERATION = TMP_FAAS_DOCUMENT_OPERATION;\n\n/**\n * A string containing the time when the data was accessed in the [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html) format expressed in [UTC](https://www.w3.org/TR/NOTE-datetime).\n *\n * @deprecated Use ATTR_FAAS_DOCUMENT_TIME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_DOCUMENT_TIME = TMP_FAAS_DOCUMENT_TIME;\n\n/**\n * The document name/table subjected to the operation. For example, in Cloud Storage or S3 is the name of the file, and in Cosmos DB the table name.\n *\n * @deprecated Use ATTR_FAAS_DOCUMENT_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_DOCUMENT_NAME = TMP_FAAS_DOCUMENT_NAME;\n\n/**\n * A string containing the function invocation time in the [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html) format expressed in [UTC](https://www.w3.org/TR/NOTE-datetime).\n *\n * @deprecated Use ATTR_FAAS_TIME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_TIME = TMP_FAAS_TIME;\n\n/**\n * A string containing the schedule period as [Cron Expression](https://docs.oracle.com/cd/E12058_01/doc/doc.1014/e12030/cron_expressions.htm).\n *\n * @deprecated Use ATTR_FAAS_CRON in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_CRON = TMP_FAAS_CRON;\n\n/**\n * A boolean that is true if the serverless function is executed for the first time (aka cold-start).\n *\n * @deprecated Use ATTR_FAAS_COLDSTART in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_COLDSTART = TMP_FAAS_COLDSTART;\n\n/**\n * The name of the invoked function.\n *\n * Note: SHOULD be equal to the `faas.name` resource attribute of the invoked function.\n *\n * @deprecated Use ATTR_FAAS_INVOKED_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_INVOKED_NAME = TMP_FAAS_INVOKED_NAME;\n\n/**\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n *\n * @deprecated Use ATTR_FAAS_INVOKED_PROVIDER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_INVOKED_PROVIDER = TMP_FAAS_INVOKED_PROVIDER;\n\n/**\n * The cloud region of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.region` resource attribute of the invoked function.\n *\n * @deprecated Use ATTR_FAAS_INVOKED_REGION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_FAAS_INVOKED_REGION = TMP_FAAS_INVOKED_REGION;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Use ATTR_NET_TRANSPORT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_TRANSPORT = TMP_NET_TRANSPORT;\n\n/**\n * Remote address of the peer (dotted decimal for IPv4 or [RFC5952](https://tools.ietf.org/html/rfc5952) for IPv6).\n *\n * @deprecated Use ATTR_NET_PEER_IP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_PEER_IP = TMP_NET_PEER_IP;\n\n/**\n * Remote port number.\n *\n * @deprecated Use ATTR_NET_PEER_PORT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_PEER_PORT = TMP_NET_PEER_PORT;\n\n/**\n * Remote hostname or similar, see note below.\n *\n * @deprecated Use ATTR_NET_PEER_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_PEER_NAME = TMP_NET_PEER_NAME;\n\n/**\n * Like `net.peer.ip` but for the host IP. Useful in case of a multi-IP host.\n *\n * @deprecated Use ATTR_NET_HOST_IP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_IP = TMP_NET_HOST_IP;\n\n/**\n * Like `net.peer.port` but for the host port.\n *\n * @deprecated Use ATTR_NET_HOST_PORT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_PORT = TMP_NET_HOST_PORT;\n\n/**\n * Local hostname or similar, see note below.\n *\n * @deprecated Use ATTR_NET_HOST_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_NAME = TMP_NET_HOST_NAME;\n\n/**\n * The internet connection type currently being used by the host.\n *\n * @deprecated Use ATTR_NETWORK_CONNECTION_TYPE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_CONNECTION_TYPE = TMP_NET_HOST_CONNECTION_TYPE;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use ATTR_NETWORK_CONNECTION_SUBTYPE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_CONNECTION_SUBTYPE =\n  TMP_NET_HOST_CONNECTION_SUBTYPE;\n\n/**\n * The name of the mobile carrier.\n *\n * @deprecated Use ATTR_NETWORK_CARRIER_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_CARRIER_NAME = TMP_NET_HOST_CARRIER_NAME;\n\n/**\n * The mobile carrier country code.\n *\n * @deprecated Use ATTR_NETWORK_CARRIER_MCC in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_CARRIER_MCC = TMP_NET_HOST_CARRIER_MCC;\n\n/**\n * The mobile carrier network code.\n *\n * @deprecated Use ATTR_NETWORK_CARRIER_MNC in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_CARRIER_MNC = TMP_NET_HOST_CARRIER_MNC;\n\n/**\n * The ISO 3166-1 alpha-2 2-character country code associated with the mobile carrier network.\n *\n * @deprecated Use ATTR_NETWORK_CARRIER_ICC in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_NET_HOST_CARRIER_ICC = TMP_NET_HOST_CARRIER_ICC;\n\n/**\n * The [`service.name`](../../resource/semantic_conventions/README.md#service) of the remote service. SHOULD be equal to the actual `service.name` resource attribute of the remote service if any.\n *\n * @deprecated Use ATTR_PEER_SERVICE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_PEER_SERVICE = TMP_PEER_SERVICE;\n\n/**\n * Username or client_id extracted from the access token or [Authorization](https://tools.ietf.org/html/rfc7235#section-4.2) header in the inbound request from outside the system.\n *\n * @deprecated Use ATTR_ENDUSER_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_ENDUSER_ID = TMP_ENDUSER_ID;\n\n/**\n * Actual/assumed role the client is making the request under extracted from token or application security context.\n *\n * @deprecated Use ATTR_ENDUSER_ROLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_ENDUSER_ROLE = TMP_ENDUSER_ROLE;\n\n/**\n * Scopes or granted authorities the client currently possesses extracted from token or application security context. The value would come from the scope associated with an [OAuth 2.0 Access Token](https://tools.ietf.org/html/rfc6749#section-3.3) or an attribute value in a [SAML 2.0 Assertion](http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html).\n *\n * @deprecated Use ATTR_ENDUSER_SCOPE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_ENDUSER_SCOPE = TMP_ENDUSER_SCOPE;\n\n/**\n * Current &#34;managed&#34; thread ID (as opposed to OS thread ID).\n *\n * @deprecated Use ATTR_THREAD_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_THREAD_ID = TMP_THREAD_ID;\n\n/**\n * Current thread name.\n *\n * @deprecated Use ATTR_THREAD_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_THREAD_NAME = TMP_THREAD_NAME;\n\n/**\n * The method or function name, or equivalent (usually rightmost part of the code unit&#39;s name).\n *\n * @deprecated Use ATTR_CODE_FUNCTION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_CODE_FUNCTION = TMP_CODE_FUNCTION;\n\n/**\n * The &#34;namespace&#34; within which `code.function` is defined. Usually the qualified class or module name, such that `code.namespace` + some separator + `code.function` form a unique identifier for the code unit.\n *\n * @deprecated Use ATTR_CODE_NAMESPACE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_CODE_NAMESPACE = TMP_CODE_NAMESPACE;\n\n/**\n * The source code file name that identifies the code unit as uniquely as possible (preferably an absolute file path).\n *\n * @deprecated Use ATTR_CODE_FILEPATH in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_CODE_FILEPATH = TMP_CODE_FILEPATH;\n\n/**\n * The line number in `code.filepath` best representing the operation. It SHOULD point within the code unit named in `code.function`.\n *\n * @deprecated Use ATTR_CODE_LINENO in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_CODE_LINENO = TMP_CODE_LINENO;\n\n/**\n * HTTP request method.\n *\n * @deprecated Use ATTR_HTTP_METHOD in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_METHOD = TMP_HTTP_METHOD;\n\n/**\n * Full HTTP request URL in the form `scheme://host[:port]/path?query[#fragment]`. Usually the fragment is not transmitted over HTTP, but if it is known, it should be included nevertheless.\n *\n * Note: `http.url` MUST NOT contain credentials passed via URL in form of `https://username:password@www.example.com/`. In such case the attribute&#39;s value should be `https://www.example.com/`.\n *\n * @deprecated Use ATTR_HTTP_URL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_URL = TMP_HTTP_URL;\n\n/**\n * The full request target as passed in a HTTP request line or equivalent.\n *\n * @deprecated Use ATTR_HTTP_TARGET in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_TARGET = TMP_HTTP_TARGET;\n\n/**\n * The value of the [HTTP host header](https://tools.ietf.org/html/rfc7230#section-5.4). An empty Host header should also be reported, see note.\n *\n * Note: When the header is present but empty the attribute SHOULD be set to the empty string. Note that this is a valid situation that is expected in certain cases, according the aforementioned [section of RFC 7230](https://tools.ietf.org/html/rfc7230#section-5.4). When the header is not set the attribute MUST NOT be set.\n *\n * @deprecated Use ATTR_HTTP_HOST in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_HOST = TMP_HTTP_HOST;\n\n/**\n * The URI scheme identifying the used protocol.\n *\n * @deprecated Use ATTR_HTTP_SCHEME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_SCHEME = TMP_HTTP_SCHEME;\n\n/**\n * [HTTP response status code](https://tools.ietf.org/html/rfc7231#section-6).\n *\n * @deprecated Use ATTR_HTTP_STATUS_CODE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_STATUS_CODE = TMP_HTTP_STATUS_CODE;\n\n/**\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n *\n * @deprecated Use ATTR_HTTP_FLAVOR in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_FLAVOR = TMP_HTTP_FLAVOR;\n\n/**\n * Value of the [HTTP User-Agent](https://tools.ietf.org/html/rfc7231#section-5.5.3) header sent by the client.\n *\n * @deprecated Use ATTR_HTTP_USER_AGENT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_USER_AGENT = TMP_HTTP_USER_AGENT;\n\n/**\n * The size of the request payload body in bytes. This is the number of bytes transferred excluding headers and is often, but not always, present as the [Content-Length](https://tools.ietf.org/html/rfc7230#section-3.3.2) header. For requests using transport encoding, this should be the compressed size.\n *\n * @deprecated Use ATTR_HTTP_REQUEST_CONTENT_LENGTH in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_REQUEST_CONTENT_LENGTH =\n  TMP_HTTP_REQUEST_CONTENT_LENGTH;\n\n/**\n * The size of the uncompressed request payload body after transport decoding. Not set if transport encoding not used.\n *\n * @deprecated Use ATTR_HTTP_REQUEST_CONTENT_LENGTH_UNCOMPRESSED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_REQUEST_CONTENT_LENGTH_UNCOMPRESSED =\n  TMP_HTTP_REQUEST_CONTENT_LENGTH_UNCOMPRESSED;\n\n/**\n * The size of the response payload body in bytes. This is the number of bytes transferred excluding headers and is often, but not always, present as the [Content-Length](https://tools.ietf.org/html/rfc7230#section-3.3.2) header. For requests using transport encoding, this should be the compressed size.\n *\n * @deprecated Use ATTR_HTTP_RESPONSE_CONTENT_LENGTH in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_RESPONSE_CONTENT_LENGTH =\n  TMP_HTTP_RESPONSE_CONTENT_LENGTH;\n\n/**\n * The size of the uncompressed response payload body after transport decoding. Not set if transport encoding not used.\n *\n * @deprecated Use ATTR_HTTP_RESPONSE_CONTENT_LENGTH_UNCOMPRESSED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_RESPONSE_CONTENT_LENGTH_UNCOMPRESSED =\n  TMP_HTTP_RESPONSE_CONTENT_LENGTH_UNCOMPRESSED;\n\n/**\n * The primary server name of the matched virtual host. This should be obtained via configuration. If no such configuration can be obtained, this attribute MUST NOT be set ( `net.host.name` should be used instead).\n *\n * Note: `http.url` is usually not readily available on the server side but would have to be assembled in a cumbersome and sometimes lossy process from other information (see e.g. open-telemetry/opentelemetry-python/pull/148). It is thus preferred to supply the raw data that is available.\n *\n * @deprecated Use ATTR_HTTP_SERVER_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_HTTP_SERVER_NAME = TMP_HTTP_SERVER_NAME;\n\n/**\n * The matched route (path template).\n *\n * @deprecated Use ATTR_HTTP_ROUTE.\n */\nexport const SEMATTRS_HTTP_ROUTE = TMP_HTTP_ROUTE;\n\n/**\n* The IP address of the original client behind all proxies, if known (e.g. from [X-Forwarded-For](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For)).\n*\n* Note: This is not necessarily the same as `net.peer.ip`, which would\nidentify the network-level peer, which may be a proxy.\n\nThis attribute should be set when a source of information different\nfrom the one used for `net.peer.ip`, is available even if that other\nsource just confirms the same value as `net.peer.ip`.\nRationale: For `net.peer.ip`, one typically does not know if it\ncomes from a proxy, reverse proxy, or the actual client. Setting\n`http.client_ip` when it&#39;s the same as `net.peer.ip` means that\none is at least somewhat confident that the address is not that of\nthe closest proxy.\n*\n* @deprecated Use ATTR_HTTP_CLIENT_IP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n*/\nexport const SEMATTRS_HTTP_CLIENT_IP = TMP_HTTP_CLIENT_IP;\n\n/**\n * The keys in the `RequestItems` object field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_TABLE_NAMES in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_TABLE_NAMES = TMP_AWS_DYNAMODB_TABLE_NAMES;\n\n/**\n * The JSON-serialized value of each item in the `ConsumedCapacity` response field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_CONSUMED_CAPACITY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_CONSUMED_CAPACITY =\n  TMP_AWS_DYNAMODB_CONSUMED_CAPACITY;\n\n/**\n * The JSON-serialized value of the `ItemCollectionMetrics` response field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_ITEM_COLLECTION_METRICS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_ITEM_COLLECTION_METRICS =\n  TMP_AWS_DYNAMODB_ITEM_COLLECTION_METRICS;\n\n/**\n * The value of the `ProvisionedThroughput.ReadCapacityUnits` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_PROVISIONED_READ_CAPACITY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_PROVISIONED_READ_CAPACITY =\n  TMP_AWS_DYNAMODB_PROVISIONED_READ_CAPACITY;\n\n/**\n * The value of the `ProvisionedThroughput.WriteCapacityUnits` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_PROVISIONED_WRITE_CAPACITY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_PROVISIONED_WRITE_CAPACITY =\n  TMP_AWS_DYNAMODB_PROVISIONED_WRITE_CAPACITY;\n\n/**\n * The value of the `ConsistentRead` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_CONSISTENT_READ in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_CONSISTENT_READ =\n  TMP_AWS_DYNAMODB_CONSISTENT_READ;\n\n/**\n * The value of the `ProjectionExpression` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_PROJECTION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_PROJECTION = TMP_AWS_DYNAMODB_PROJECTION;\n\n/**\n * The value of the `Limit` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_LIMIT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_LIMIT = TMP_AWS_DYNAMODB_LIMIT;\n\n/**\n * The value of the `AttributesToGet` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_ATTRIBUTES_TO_GET in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_ATTRIBUTES_TO_GET =\n  TMP_AWS_DYNAMODB_ATTRIBUTES_TO_GET;\n\n/**\n * The value of the `IndexName` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_INDEX_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_INDEX_NAME = TMP_AWS_DYNAMODB_INDEX_NAME;\n\n/**\n * The value of the `Select` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_SELECT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_SELECT = TMP_AWS_DYNAMODB_SELECT;\n\n/**\n * The JSON-serialized value of each item of the `GlobalSecondaryIndexes` request field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEXES in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEXES =\n  TMP_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEXES;\n\n/**\n * The JSON-serialized value of each item of the `LocalSecondaryIndexes` request field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_LOCAL_SECONDARY_INDEXES in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_LOCAL_SECONDARY_INDEXES =\n  TMP_AWS_DYNAMODB_LOCAL_SECONDARY_INDEXES;\n\n/**\n * The value of the `ExclusiveStartTableName` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_EXCLUSIVE_START_TABLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_EXCLUSIVE_START_TABLE =\n  TMP_AWS_DYNAMODB_EXCLUSIVE_START_TABLE;\n\n/**\n * The the number of items in the `TableNames` response parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_TABLE_COUNT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_TABLE_COUNT = TMP_AWS_DYNAMODB_TABLE_COUNT;\n\n/**\n * The value of the `ScanIndexForward` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_SCAN_FORWARD in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_SCAN_FORWARD = TMP_AWS_DYNAMODB_SCAN_FORWARD;\n\n/**\n * The value of the `Segment` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_SEGMENT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_SEGMENT = TMP_AWS_DYNAMODB_SEGMENT;\n\n/**\n * The value of the `TotalSegments` request parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_TOTAL_SEGMENTS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_TOTAL_SEGMENTS =\n  TMP_AWS_DYNAMODB_TOTAL_SEGMENTS;\n\n/**\n * The value of the `Count` response parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_COUNT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_COUNT = TMP_AWS_DYNAMODB_COUNT;\n\n/**\n * The value of the `ScannedCount` response parameter.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_SCANNED_COUNT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_SCANNED_COUNT =\n  TMP_AWS_DYNAMODB_SCANNED_COUNT;\n\n/**\n * The JSON-serialized value of each item in the `AttributeDefinitions` request field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_ATTRIBUTE_DEFINITIONS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_ATTRIBUTE_DEFINITIONS =\n  TMP_AWS_DYNAMODB_ATTRIBUTE_DEFINITIONS;\n\n/**\n * The JSON-serialized value of each item in the the `GlobalSecondaryIndexUpdates` request field.\n *\n * @deprecated Use ATTR_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEX_UPDATES in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEX_UPDATES =\n  TMP_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEX_UPDATES;\n\n/**\n * A string identifying the messaging system.\n *\n * @deprecated Use ATTR_MESSAGING_SYSTEM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_SYSTEM = TMP_MESSAGING_SYSTEM;\n\n/**\n * The message destination name. This might be equal to the span name but is required nevertheless.\n *\n * @deprecated Use ATTR_MESSAGING_DESTINATION_NAME in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_DESTINATION = TMP_MESSAGING_DESTINATION;\n\n/**\n * The kind of message destination.\n *\n * @deprecated Removed in semconv v1.20.0.\n */\nexport const SEMATTRS_MESSAGING_DESTINATION_KIND =\n  TMP_MESSAGING_DESTINATION_KIND;\n\n/**\n * A boolean that is true if the message destination is temporary.\n *\n * @deprecated Use ATTR_MESSAGING_DESTINATION_TEMPORARY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_TEMP_DESTINATION =\n  TMP_MESSAGING_TEMP_DESTINATION;\n\n/**\n * The name of the transport protocol.\n *\n * @deprecated Use ATTR_NETWORK_PROTOCOL_NAME.\n */\nexport const SEMATTRS_MESSAGING_PROTOCOL = TMP_MESSAGING_PROTOCOL;\n\n/**\n * The version of the transport protocol.\n *\n * @deprecated Use ATTR_NETWORK_PROTOCOL_VERSION.\n */\nexport const SEMATTRS_MESSAGING_PROTOCOL_VERSION =\n  TMP_MESSAGING_PROTOCOL_VERSION;\n\n/**\n * Connection string.\n *\n * @deprecated Removed in semconv v1.17.0.\n */\nexport const SEMATTRS_MESSAGING_URL = TMP_MESSAGING_URL;\n\n/**\n * A value used by the messaging system as an identifier for the message, represented as a string.\n *\n * @deprecated Use ATTR_MESSAGING_MESSAGE_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_MESSAGE_ID = TMP_MESSAGING_MESSAGE_ID;\n\n/**\n * The [conversation ID](#conversations) identifying the conversation to which the message belongs, represented as a string. Sometimes called &#34;Correlation ID&#34;.\n *\n * @deprecated Use ATTR_MESSAGING_MESSAGE_CONVERSATION_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_CONVERSATION_ID = TMP_MESSAGING_CONVERSATION_ID;\n\n/**\n * The (uncompressed) size of the message payload in bytes. Also use this attribute if it is unknown whether the compressed or uncompressed payload size is reported.\n *\n * @deprecated Use ATTR_MESSAGING_MESSAGE_BODY_SIZE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_MESSAGE_PAYLOAD_SIZE_BYTES =\n  TMP_MESSAGING_MESSAGE_PAYLOAD_SIZE_BYTES;\n\n/**\n * The compressed size of the message payload in bytes.\n *\n * @deprecated Removed in semconv v1.22.0.\n */\nexport const SEMATTRS_MESSAGING_MESSAGE_PAYLOAD_COMPRESSED_SIZE_BYTES =\n  TMP_MESSAGING_MESSAGE_PAYLOAD_COMPRESSED_SIZE_BYTES;\n\n/**\n * A string identifying the kind of message consumption as defined in the [Operation names](#operation-names) section above. If the operation is &#34;send&#34;, this attribute MUST NOT be set, since the operation can be inferred from the span kind in that case.\n *\n * @deprecated Use ATTR_MESSAGING_OPERATION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_OPERATION = TMP_MESSAGING_OPERATION;\n\n/**\n * The identifier for the consumer receiving a message. For Kafka, set it to `{messaging.kafka.consumer_group} - {messaging.kafka.client_id}`, if both are present, or only `messaging.kafka.consumer_group`. For brokers, such as RabbitMQ and Artemis, set it to the `client_id` of the client consuming the message.\n *\n * @deprecated Removed in semconv v1.21.0.\n */\nexport const SEMATTRS_MESSAGING_CONSUMER_ID = TMP_MESSAGING_CONSUMER_ID;\n\n/**\n * RabbitMQ message routing key.\n *\n * @deprecated Use ATTR_MESSAGING_RABBITMQ_DESTINATION_ROUTING_KEY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_RABBITMQ_ROUTING_KEY =\n  TMP_MESSAGING_RABBITMQ_ROUTING_KEY;\n\n/**\n * Message keys in Kafka are used for grouping alike messages to ensure they&#39;re processed on the same partition. They differ from `messaging.message_id` in that they&#39;re not unique. If the key is `null`, the attribute MUST NOT be set.\n *\n * Note: If the key type is not string, it&#39;s string representation has to be supplied for the attribute. If the key has no unambiguous, canonical string form, don&#39;t include its value.\n *\n * @deprecated Use ATTR_MESSAGING_KAFKA_MESSAGE_KEY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_KAFKA_MESSAGE_KEY =\n  TMP_MESSAGING_KAFKA_MESSAGE_KEY;\n\n/**\n * Name of the Kafka Consumer Group that is handling the message. Only applies to consumers, not producers.\n *\n * @deprecated Use ATTR_MESSAGING_KAFKA_CONSUMER_GROUP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_KAFKA_CONSUMER_GROUP =\n  TMP_MESSAGING_KAFKA_CONSUMER_GROUP;\n\n/**\n * Client Id for the Consumer or Producer that is handling the message.\n *\n * @deprecated Use ATTR_MESSAGING_CLIENT_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_KAFKA_CLIENT_ID = TMP_MESSAGING_KAFKA_CLIENT_ID;\n\n/**\n * Partition the message is sent to.\n *\n * @deprecated Use ATTR_MESSAGING_KAFKA_DESTINATION_PARTITION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_KAFKA_PARTITION = TMP_MESSAGING_KAFKA_PARTITION;\n\n/**\n * A boolean that is true if the message is a tombstone.\n *\n * @deprecated Use ATTR_MESSAGING_KAFKA_MESSAGE_TOMBSTONE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGING_KAFKA_TOMBSTONE = TMP_MESSAGING_KAFKA_TOMBSTONE;\n\n/**\n * A string identifying the remoting system.\n *\n * @deprecated Use ATTR_RPC_SYSTEM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_SYSTEM = TMP_RPC_SYSTEM;\n\n/**\n * The full (logical) name of the service being called, including its package name, if applicable.\n *\n * Note: This is the logical name of the service from the RPC interface perspective, which can be different from the name of any implementing class. The `code.namespace` attribute may be used to store the latter (despite the attribute name, it may include a class name; e.g., class with method actually executing the call on the server side, RPC client stub class on the client side).\n *\n * @deprecated Use ATTR_RPC_SERVICE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_SERVICE = TMP_RPC_SERVICE;\n\n/**\n * The name of the (logical) method being called, must be equal to the $method part in the span name.\n *\n * Note: This is the logical name of the method from the RPC interface perspective, which can be different from the name of any implementing method/function. The `code.function` attribute may be used to store the latter (e.g., method actually executing the call on the server side, RPC client stub method on the client side).\n *\n * @deprecated Use ATTR_RPC_METHOD in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_METHOD = TMP_RPC_METHOD;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use ATTR_RPC_GRPC_STATUS_CODE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_GRPC_STATUS_CODE = TMP_RPC_GRPC_STATUS_CODE;\n\n/**\n * Protocol version as in `jsonrpc` property of request/response. Since JSON-RPC 1.0 does not specify this, the value can be omitted.\n *\n * @deprecated Use ATTR_RPC_JSONRPC_VERSION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_JSONRPC_VERSION = TMP_RPC_JSONRPC_VERSION;\n\n/**\n * `id` property of request or response. Since protocol allows id to be int, string, `null` or missing (for notifications), value is expected to be cast to string for simplicity. Use empty string in case of `null` value. Omit entirely if this is a notification.\n *\n * @deprecated Use ATTR_RPC_JSONRPC_REQUEST_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_JSONRPC_REQUEST_ID = TMP_RPC_JSONRPC_REQUEST_ID;\n\n/**\n * `error.code` property of response if it is an error response.\n *\n * @deprecated Use ATTR_RPC_JSONRPC_ERROR_CODE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_JSONRPC_ERROR_CODE = TMP_RPC_JSONRPC_ERROR_CODE;\n\n/**\n * `error.message` property of response if it is an error response.\n *\n * @deprecated Use ATTR_RPC_JSONRPC_ERROR_MESSAGE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_RPC_JSONRPC_ERROR_MESSAGE = TMP_RPC_JSONRPC_ERROR_MESSAGE;\n\n/**\n * Whether this is a received or sent message.\n *\n * @deprecated Use ATTR_MESSAGE_TYPE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGE_TYPE = TMP_MESSAGE_TYPE;\n\n/**\n * MUST be calculated as two different counters starting from `1` one for sent messages and one for received message.\n *\n * Note: This way we guarantee that the values will be consistent between different implementations.\n *\n * @deprecated Use ATTR_MESSAGE_ID in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGE_ID = TMP_MESSAGE_ID;\n\n/**\n * Compressed size of the message in bytes.\n *\n * @deprecated Use ATTR_MESSAGE_COMPRESSED_SIZE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGE_COMPRESSED_SIZE = TMP_MESSAGE_COMPRESSED_SIZE;\n\n/**\n * Uncompressed size of the message in bytes.\n *\n * @deprecated Use ATTR_MESSAGE_UNCOMPRESSED_SIZE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const SEMATTRS_MESSAGE_UNCOMPRESSED_SIZE = TMP_MESSAGE_UNCOMPRESSED_SIZE;\n\n/**\n * Definition of available values for SemanticAttributes\n * This type is used for backward compatibility, you should use the individual exported\n * constants SemanticAttributes_XXXXX rather than the exported constant map. As any single reference\n * to a constant map value will result in all strings being included into your bundle.\n * @deprecated Use the SEMATTRS_XXXXX constants rather than the SemanticAttributes.XXXXX for bundle minification.\n */\nexport type SemanticAttributes = {\n  /**\n   * The full invoked ARN as provided on the `Context` passed to the function (`Lambda-Runtime-Invoked-Function-Arn` header on the `/runtime/invocation/next` applicable).\n   *\n   * Note: This may be different from `faas.id` if an alias is involved.\n   */\n  AWS_LAMBDA_INVOKED_ARN: 'aws.lambda.invoked_arn';\n\n  /**\n   * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n   */\n  DB_SYSTEM: 'db.system';\n\n  /**\n   * The connection string used to connect to the database. It is recommended to remove embedded credentials.\n   */\n  DB_CONNECTION_STRING: 'db.connection_string';\n\n  /**\n   * Username for accessing the database.\n   */\n  DB_USER: 'db.user';\n\n  /**\n   * The fully-qualified class name of the [Java Database Connectivity (JDBC)](https://docs.oracle.com/javase/8/docs/technotes/guides/jdbc/) driver used to connect.\n   */\n  DB_JDBC_DRIVER_CLASSNAME: 'db.jdbc.driver_classname';\n\n  /**\n   * If no [tech-specific attribute](#call-level-attributes-for-specific-technologies) is defined, this attribute is used to report the name of the database being accessed. For commands that switch the database, this should be set to the target database (even if the command fails).\n   *\n   * Note: In some SQL databases, the database name to be used is called &#34;schema name&#34;.\n   */\n  DB_NAME: 'db.name';\n\n  /**\n   * The database statement being executed.\n   *\n   * Note: The value may be sanitized to exclude sensitive information.\n   */\n  DB_STATEMENT: 'db.statement';\n\n  /**\n   * The name of the operation being executed, e.g. the [MongoDB command name](https://docs.mongodb.com/manual/reference/command/#database-operations) such as `findAndModify`, or the SQL keyword.\n   *\n   * Note: When setting this to an SQL keyword, it is not recommended to attempt any client-side parsing of `db.statement` just to get this property, but it should be set if the operation name is provided by the library being instrumented. If the SQL statement has an ambiguous operation, or performs more than one operation, this value may be omitted.\n   */\n  DB_OPERATION: 'db.operation';\n\n  /**\n   * The Microsoft SQL Server [instance name](https://docs.microsoft.com/en-us/sql/connect/jdbc/building-the-connection-url?view=sql-server-ver15) connecting to. This name is used to determine the port of a named instance.\n   *\n   * Note: If setting a `db.mssql.instance_name`, `net.peer.port` is no longer required (but still recommended if non-standard).\n   */\n  DB_MSSQL_INSTANCE_NAME: 'db.mssql.instance_name';\n\n  /**\n   * The name of the keyspace being accessed. To be used instead of the generic `db.name` attribute.\n   */\n  DB_CASSANDRA_KEYSPACE: 'db.cassandra.keyspace';\n\n  /**\n   * The fetch size used for paging, i.e. how many rows will be returned at once.\n   */\n  DB_CASSANDRA_PAGE_SIZE: 'db.cassandra.page_size';\n\n  /**\n   * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n   */\n  DB_CASSANDRA_CONSISTENCY_LEVEL: 'db.cassandra.consistency_level';\n\n  /**\n   * The name of the primary table that the operation is acting upon, including the schema name (if applicable).\n   *\n   * Note: This mirrors the db.sql.table attribute but references cassandra rather than sql. It is not recommended to attempt any client-side parsing of `db.statement` just to get this property, but it should be set if it is provided by the library being instrumented. If the operation is acting upon an anonymous table, or more than one table, this value MUST NOT be set.\n   */\n  DB_CASSANDRA_TABLE: 'db.cassandra.table';\n\n  /**\n   * Whether or not the query is idempotent.\n   */\n  DB_CASSANDRA_IDEMPOTENCE: 'db.cassandra.idempotence';\n\n  /**\n   * The number of times a query was speculatively executed. Not set or `0` if the query was not executed speculatively.\n   */\n  DB_CASSANDRA_SPECULATIVE_EXECUTION_COUNT: 'db.cassandra.speculative_execution_count';\n\n  /**\n   * The ID of the coordinating node for a query.\n   */\n  DB_CASSANDRA_COORDINATOR_ID: 'db.cassandra.coordinator.id';\n\n  /**\n   * The data center of the coordinating node for a query.\n   */\n  DB_CASSANDRA_COORDINATOR_DC: 'db.cassandra.coordinator.dc';\n\n  /**\n   * The [HBase namespace](https://hbase.apache.org/book.html#_namespace) being accessed. To be used instead of the generic `db.name` attribute.\n   */\n  DB_HBASE_NAMESPACE: 'db.hbase.namespace';\n\n  /**\n   * The index of the database being accessed as used in the [`SELECT` command](https://redis.io/commands/select), provided as an integer. To be used instead of the generic `db.name` attribute.\n   */\n  DB_REDIS_DATABASE_INDEX: 'db.redis.database_index';\n\n  /**\n   * The collection being accessed within the database stated in `db.name`.\n   */\n  DB_MONGODB_COLLECTION: 'db.mongodb.collection';\n\n  /**\n   * The name of the primary table that the operation is acting upon, including the schema name (if applicable).\n   *\n   * Note: It is not recommended to attempt any client-side parsing of `db.statement` just to get this property, but it should be set if it is provided by the library being instrumented. If the operation is acting upon an anonymous table, or more than one table, this value MUST NOT be set.\n   */\n  DB_SQL_TABLE: 'db.sql.table';\n\n  /**\n   * The type of the exception (its fully-qualified class name, if applicable). The dynamic type of the exception should be preferred over the static type in languages that support it.\n   */\n  EXCEPTION_TYPE: 'exception.type';\n\n  /**\n   * The exception message.\n   */\n  EXCEPTION_MESSAGE: 'exception.message';\n\n  /**\n   * A stacktrace as a string in the natural representation for the language runtime. The representation is to be determined and documented by each language SIG.\n   */\n  EXCEPTION_STACKTRACE: 'exception.stacktrace';\n\n  /**\n  * SHOULD be set to true if the exception event is recorded at a point where it is known that the exception is escaping the scope of the span.\n  *\n  * Note: An exception is considered to have escaped (or left) the scope of a span,\nif that span is ended while the exception is still logically &#34;in flight&#34;.\nThis may be actually &#34;in flight&#34; in some languages (e.g. if the exception\nis passed to a Context manager&#39;s `__exit__` method in Python) but will\nusually be caught at the point of recording the exception in most languages.\n\nIt is usually not possible to determine at the point where an exception is thrown\nwhether it will escape the scope of a span.\nHowever, it is trivial to know that an exception\nwill escape, if one checks for an active exception just before ending the span,\nas done in the [example above](#exception-end-example).\n\nIt follows that an exception may still escape the scope of the span\neven if the `exception.escaped` attribute was not set or set to false,\nsince the event might have been recorded at a time where it was not\nclear whether the exception will escape.\n  */\n  EXCEPTION_ESCAPED: 'exception.escaped';\n\n  /**\n   * Type of the trigger on which the function is executed.\n   */\n  FAAS_TRIGGER: 'faas.trigger';\n\n  /**\n   * The execution ID of the current function execution.\n   */\n  FAAS_EXECUTION: 'faas.execution';\n\n  /**\n   * The name of the source on which the triggering operation was performed. For example, in Cloud Storage or S3 corresponds to the bucket name, and in Cosmos DB to the database name.\n   */\n  FAAS_DOCUMENT_COLLECTION: 'faas.document.collection';\n\n  /**\n   * Describes the type of the operation that was performed on the data.\n   */\n  FAAS_DOCUMENT_OPERATION: 'faas.document.operation';\n\n  /**\n   * A string containing the time when the data was accessed in the [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html) format expressed in [UTC](https://www.w3.org/TR/NOTE-datetime).\n   */\n  FAAS_DOCUMENT_TIME: 'faas.document.time';\n\n  /**\n   * The document name/table subjected to the operation. For example, in Cloud Storage or S3 is the name of the file, and in Cosmos DB the table name.\n   */\n  FAAS_DOCUMENT_NAME: 'faas.document.name';\n\n  /**\n   * A string containing the function invocation time in the [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html) format expressed in [UTC](https://www.w3.org/TR/NOTE-datetime).\n   */\n  FAAS_TIME: 'faas.time';\n\n  /**\n   * A string containing the schedule period as [Cron Expression](https://docs.oracle.com/cd/E12058_01/doc/doc.1014/e12030/cron_expressions.htm).\n   */\n  FAAS_CRON: 'faas.cron';\n\n  /**\n   * A boolean that is true if the serverless function is executed for the first time (aka cold-start).\n   */\n  FAAS_COLDSTART: 'faas.coldstart';\n\n  /**\n   * The name of the invoked function.\n   *\n   * Note: SHOULD be equal to the `faas.name` resource attribute of the invoked function.\n   */\n  FAAS_INVOKED_NAME: 'faas.invoked_name';\n\n  /**\n   * The cloud provider of the invoked function.\n   *\n   * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n   */\n  FAAS_INVOKED_PROVIDER: 'faas.invoked_provider';\n\n  /**\n   * The cloud region of the invoked function.\n   *\n   * Note: SHOULD be equal to the `cloud.region` resource attribute of the invoked function.\n   */\n  FAAS_INVOKED_REGION: 'faas.invoked_region';\n\n  /**\n   * Transport protocol used. See note below.\n   */\n  NET_TRANSPORT: 'net.transport';\n\n  /**\n   * Remote address of the peer (dotted decimal for IPv4 or [RFC5952](https://tools.ietf.org/html/rfc5952) for IPv6).\n   */\n  NET_PEER_IP: 'net.peer.ip';\n\n  /**\n   * Remote port number.\n   */\n  NET_PEER_PORT: 'net.peer.port';\n\n  /**\n   * Remote hostname or similar, see note below.\n   */\n  NET_PEER_NAME: 'net.peer.name';\n\n  /**\n   * Like `net.peer.ip` but for the host IP. Useful in case of a multi-IP host.\n   */\n  NET_HOST_IP: 'net.host.ip';\n\n  /**\n   * Like `net.peer.port` but for the host port.\n   */\n  NET_HOST_PORT: 'net.host.port';\n\n  /**\n   * Local hostname or similar, see note below.\n   */\n  NET_HOST_NAME: 'net.host.name';\n\n  /**\n   * The internet connection type currently being used by the host.\n   */\n  NET_HOST_CONNECTION_TYPE: 'net.host.connection.type';\n\n  /**\n   * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n   */\n  NET_HOST_CONNECTION_SUBTYPE: 'net.host.connection.subtype';\n\n  /**\n   * The name of the mobile carrier.\n   */\n  NET_HOST_CARRIER_NAME: 'net.host.carrier.name';\n\n  /**\n   * The mobile carrier country code.\n   */\n  NET_HOST_CARRIER_MCC: 'net.host.carrier.mcc';\n\n  /**\n   * The mobile carrier network code.\n   */\n  NET_HOST_CARRIER_MNC: 'net.host.carrier.mnc';\n\n  /**\n   * The ISO 3166-1 alpha-2 2-character country code associated with the mobile carrier network.\n   */\n  NET_HOST_CARRIER_ICC: 'net.host.carrier.icc';\n\n  /**\n   * The [`service.name`](../../resource/semantic_conventions/README.md#service) of the remote service. SHOULD be equal to the actual `service.name` resource attribute of the remote service if any.\n   */\n  PEER_SERVICE: 'peer.service';\n\n  /**\n   * Username or client_id extracted from the access token or [Authorization](https://tools.ietf.org/html/rfc7235#section-4.2) header in the inbound request from outside the system.\n   */\n  ENDUSER_ID: 'enduser.id';\n\n  /**\n   * Actual/assumed role the client is making the request under extracted from token or application security context.\n   */\n  ENDUSER_ROLE: 'enduser.role';\n\n  /**\n   * Scopes or granted authorities the client currently possesses extracted from token or application security context. The value would come from the scope associated with an [OAuth 2.0 Access Token](https://tools.ietf.org/html/rfc6749#section-3.3) or an attribute value in a [SAML 2.0 Assertion](http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html).\n   */\n  ENDUSER_SCOPE: 'enduser.scope';\n\n  /**\n   * Current &#34;managed&#34; thread ID (as opposed to OS thread ID).\n   */\n  THREAD_ID: 'thread.id';\n\n  /**\n   * Current thread name.\n   */\n  THREAD_NAME: 'thread.name';\n\n  /**\n   * The method or function name, or equivalent (usually rightmost part of the code unit&#39;s name).\n   */\n  CODE_FUNCTION: 'code.function';\n\n  /**\n   * The &#34;namespace&#34; within which `code.function` is defined. Usually the qualified class or module name, such that `code.namespace` + some separator + `code.function` form a unique identifier for the code unit.\n   */\n  CODE_NAMESPACE: 'code.namespace';\n\n  /**\n   * The source code file name that identifies the code unit as uniquely as possible (preferably an absolute file path).\n   */\n  CODE_FILEPATH: 'code.filepath';\n\n  /**\n   * The line number in `code.filepath` best representing the operation. It SHOULD point within the code unit named in `code.function`.\n   */\n  CODE_LINENO: 'code.lineno';\n\n  /**\n   * HTTP request method.\n   */\n  HTTP_METHOD: 'http.method';\n\n  /**\n   * Full HTTP request URL in the form `scheme://host[:port]/path?query[#fragment]`. Usually the fragment is not transmitted over HTTP, but if it is known, it should be included nevertheless.\n   *\n   * Note: `http.url` MUST NOT contain credentials passed via URL in form of `https://username:password@www.example.com/`. In such case the attribute&#39;s value should be `https://www.example.com/`.\n   */\n  HTTP_URL: 'http.url';\n\n  /**\n   * The full request target as passed in a HTTP request line or equivalent.\n   */\n  HTTP_TARGET: 'http.target';\n\n  /**\n   * The value of the [HTTP host header](https://tools.ietf.org/html/rfc7230#section-5.4). An empty Host header should also be reported, see note.\n   *\n   * Note: When the header is present but empty the attribute SHOULD be set to the empty string. Note that this is a valid situation that is expected in certain cases, according the aforementioned [section of RFC 7230](https://tools.ietf.org/html/rfc7230#section-5.4). When the header is not set the attribute MUST NOT be set.\n   */\n  HTTP_HOST: 'http.host';\n\n  /**\n   * The URI scheme identifying the used protocol.\n   */\n  HTTP_SCHEME: 'http.scheme';\n\n  /**\n   * [HTTP response status code](https://tools.ietf.org/html/rfc7231#section-6).\n   */\n  HTTP_STATUS_CODE: 'http.status_code';\n\n  /**\n   * Kind of HTTP protocol used.\n   *\n   * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n   */\n  HTTP_FLAVOR: 'http.flavor';\n\n  /**\n   * Value of the [HTTP User-Agent](https://tools.ietf.org/html/rfc7231#section-5.5.3) header sent by the client.\n   */\n  HTTP_USER_AGENT: 'http.user_agent';\n\n  /**\n   * The size of the request payload body in bytes. This is the number of bytes transferred excluding headers and is often, but not always, present as the [Content-Length](https://tools.ietf.org/html/rfc7230#section-3.3.2) header. For requests using transport encoding, this should be the compressed size.\n   */\n  HTTP_REQUEST_CONTENT_LENGTH: 'http.request_content_length';\n\n  /**\n   * The size of the uncompressed request payload body after transport decoding. Not set if transport encoding not used.\n   */\n  HTTP_REQUEST_CONTENT_LENGTH_UNCOMPRESSED: 'http.request_content_length_uncompressed';\n\n  /**\n   * The size of the response payload body in bytes. This is the number of bytes transferred excluding headers and is often, but not always, present as the [Content-Length](https://tools.ietf.org/html/rfc7230#section-3.3.2) header. For requests using transport encoding, this should be the compressed size.\n   */\n  HTTP_RESPONSE_CONTENT_LENGTH: 'http.response_content_length';\n\n  /**\n   * The size of the uncompressed response payload body after transport decoding. Not set if transport encoding not used.\n   */\n  HTTP_RESPONSE_CONTENT_LENGTH_UNCOMPRESSED: 'http.response_content_length_uncompressed';\n\n  /**\n   * The primary server name of the matched virtual host. This should be obtained via configuration. If no such configuration can be obtained, this attribute MUST NOT be set ( `net.host.name` should be used instead).\n   *\n   * Note: `http.url` is usually not readily available on the server side but would have to be assembled in a cumbersome and sometimes lossy process from other information (see e.g. open-telemetry/opentelemetry-python/pull/148). It is thus preferred to supply the raw data that is available.\n   */\n  HTTP_SERVER_NAME: 'http.server_name';\n\n  /**\n   * The matched route (path template).\n   */\n  HTTP_ROUTE: 'http.route';\n\n  /**\n  * The IP address of the original client behind all proxies, if known (e.g. from [X-Forwarded-For](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For)).\n  *\n  * Note: This is not necessarily the same as `net.peer.ip`, which would\nidentify the network-level peer, which may be a proxy.\n\nThis attribute should be set when a source of information different\nfrom the one used for `net.peer.ip`, is available even if that other\nsource just confirms the same value as `net.peer.ip`.\nRationale: For `net.peer.ip`, one typically does not know if it\ncomes from a proxy, reverse proxy, or the actual client. Setting\n`http.client_ip` when it&#39;s the same as `net.peer.ip` means that\none is at least somewhat confident that the address is not that of\nthe closest proxy.\n  */\n  HTTP_CLIENT_IP: 'http.client_ip';\n\n  /**\n   * The keys in the `RequestItems` object field.\n   */\n  AWS_DYNAMODB_TABLE_NAMES: 'aws.dynamodb.table_names';\n\n  /**\n   * The JSON-serialized value of each item in the `ConsumedCapacity` response field.\n   */\n  AWS_DYNAMODB_CONSUMED_CAPACITY: 'aws.dynamodb.consumed_capacity';\n\n  /**\n   * The JSON-serialized value of the `ItemCollectionMetrics` response field.\n   */\n  AWS_DYNAMODB_ITEM_COLLECTION_METRICS: 'aws.dynamodb.item_collection_metrics';\n\n  /**\n   * The value of the `ProvisionedThroughput.ReadCapacityUnits` request parameter.\n   */\n  AWS_DYNAMODB_PROVISIONED_READ_CAPACITY: 'aws.dynamodb.provisioned_read_capacity';\n\n  /**\n   * The value of the `ProvisionedThroughput.WriteCapacityUnits` request parameter.\n   */\n  AWS_DYNAMODB_PROVISIONED_WRITE_CAPACITY: 'aws.dynamodb.provisioned_write_capacity';\n\n  /**\n   * The value of the `ConsistentRead` request parameter.\n   */\n  AWS_DYNAMODB_CONSISTENT_READ: 'aws.dynamodb.consistent_read';\n\n  /**\n   * The value of the `ProjectionExpression` request parameter.\n   */\n  AWS_DYNAMODB_PROJECTION: 'aws.dynamodb.projection';\n\n  /**\n   * The value of the `Limit` request parameter.\n   */\n  AWS_DYNAMODB_LIMIT: 'aws.dynamodb.limit';\n\n  /**\n   * The value of the `AttributesToGet` request parameter.\n   */\n  AWS_DYNAMODB_ATTRIBUTES_TO_GET: 'aws.dynamodb.attributes_to_get';\n\n  /**\n   * The value of the `IndexName` request parameter.\n   */\n  AWS_DYNAMODB_INDEX_NAME: 'aws.dynamodb.index_name';\n\n  /**\n   * The value of the `Select` request parameter.\n   */\n  AWS_DYNAMODB_SELECT: 'aws.dynamodb.select';\n\n  /**\n   * The JSON-serialized value of each item of the `GlobalSecondaryIndexes` request field.\n   */\n  AWS_DYNAMODB_GLOBAL_SECONDARY_INDEXES: 'aws.dynamodb.global_secondary_indexes';\n\n  /**\n   * The JSON-serialized value of each item of the `LocalSecondaryIndexes` request field.\n   */\n  AWS_DYNAMODB_LOCAL_SECONDARY_INDEXES: 'aws.dynamodb.local_secondary_indexes';\n\n  /**\n   * The value of the `ExclusiveStartTableName` request parameter.\n   */\n  AWS_DYNAMODB_EXCLUSIVE_START_TABLE: 'aws.dynamodb.exclusive_start_table';\n\n  /**\n   * The the number of items in the `TableNames` response parameter.\n   */\n  AWS_DYNAMODB_TABLE_COUNT: 'aws.dynamodb.table_count';\n\n  /**\n   * The value of the `ScanIndexForward` request parameter.\n   */\n  AWS_DYNAMODB_SCAN_FORWARD: 'aws.dynamodb.scan_forward';\n\n  /**\n   * The value of the `Segment` request parameter.\n   */\n  AWS_DYNAMODB_SEGMENT: 'aws.dynamodb.segment';\n\n  /**\n   * The value of the `TotalSegments` request parameter.\n   */\n  AWS_DYNAMODB_TOTAL_SEGMENTS: 'aws.dynamodb.total_segments';\n\n  /**\n   * The value of the `Count` response parameter.\n   */\n  AWS_DYNAMODB_COUNT: 'aws.dynamodb.count';\n\n  /**\n   * The value of the `ScannedCount` response parameter.\n   */\n  AWS_DYNAMODB_SCANNED_COUNT: 'aws.dynamodb.scanned_count';\n\n  /**\n   * The JSON-serialized value of each item in the `AttributeDefinitions` request field.\n   */\n  AWS_DYNAMODB_ATTRIBUTE_DEFINITIONS: 'aws.dynamodb.attribute_definitions';\n\n  /**\n   * The JSON-serialized value of each item in the the `GlobalSecondaryIndexUpdates` request field.\n   */\n  AWS_DYNAMODB_GLOBAL_SECONDARY_INDEX_UPDATES: 'aws.dynamodb.global_secondary_index_updates';\n\n  /**\n   * A string identifying the messaging system.\n   */\n  MESSAGING_SYSTEM: 'messaging.system';\n\n  /**\n   * The message destination name. This might be equal to the span name but is required nevertheless.\n   */\n  MESSAGING_DESTINATION: 'messaging.destination';\n\n  /**\n   * The kind of message destination.\n   */\n  MESSAGING_DESTINATION_KIND: 'messaging.destination_kind';\n\n  /**\n   * A boolean that is true if the message destination is temporary.\n   */\n  MESSAGING_TEMP_DESTINATION: 'messaging.temp_destination';\n\n  /**\n   * The name of the transport protocol.\n   */\n  MESSAGING_PROTOCOL: 'messaging.protocol';\n\n  /**\n   * The version of the transport protocol.\n   */\n  MESSAGING_PROTOCOL_VERSION: 'messaging.protocol_version';\n\n  /**\n   * Connection string.\n   */\n  MESSAGING_URL: 'messaging.url';\n\n  /**\n   * A value used by the messaging system as an identifier for the message, represented as a string.\n   */\n  MESSAGING_MESSAGE_ID: 'messaging.message_id';\n\n  /**\n   * The [conversation ID](#conversations) identifying the conversation to which the message belongs, represented as a string. Sometimes called &#34;Correlation ID&#34;.\n   */\n  MESSAGING_CONVERSATION_ID: 'messaging.conversation_id';\n\n  /**\n   * The (uncompressed) size of the message payload in bytes. Also use this attribute if it is unknown whether the compressed or uncompressed payload size is reported.\n   */\n  MESSAGING_MESSAGE_PAYLOAD_SIZE_BYTES: 'messaging.message_payload_size_bytes';\n\n  /**\n   * The compressed size of the message payload in bytes.\n   */\n  MESSAGING_MESSAGE_PAYLOAD_COMPRESSED_SIZE_BYTES: 'messaging.message_payload_compressed_size_bytes';\n\n  /**\n   * A string identifying the kind of message consumption as defined in the [Operation names](#operation-names) section above. If the operation is &#34;send&#34;, this attribute MUST NOT be set, since the operation can be inferred from the span kind in that case.\n   */\n  MESSAGING_OPERATION: 'messaging.operation';\n\n  /**\n   * The identifier for the consumer receiving a message. For Kafka, set it to `{messaging.kafka.consumer_group} - {messaging.kafka.client_id}`, if both are present, or only `messaging.kafka.consumer_group`. For brokers, such as RabbitMQ and Artemis, set it to the `client_id` of the client consuming the message.\n   */\n  MESSAGING_CONSUMER_ID: 'messaging.consumer_id';\n\n  /**\n   * RabbitMQ message routing key.\n   */\n  MESSAGING_RABBITMQ_ROUTING_KEY: 'messaging.rabbitmq.routing_key';\n\n  /**\n   * Message keys in Kafka are used for grouping alike messages to ensure they&#39;re processed on the same partition. They differ from `messaging.message_id` in that they&#39;re not unique. If the key is `null`, the attribute MUST NOT be set.\n   *\n   * Note: If the key type is not string, it&#39;s string representation has to be supplied for the attribute. If the key has no unambiguous, canonical string form, don&#39;t include its value.\n   */\n  MESSAGING_KAFKA_MESSAGE_KEY: 'messaging.kafka.message_key';\n\n  /**\n   * Name of the Kafka Consumer Group that is handling the message. Only applies to consumers, not producers.\n   */\n  MESSAGING_KAFKA_CONSUMER_GROUP: 'messaging.kafka.consumer_group';\n\n  /**\n   * Client Id for the Consumer or Producer that is handling the message.\n   */\n  MESSAGING_KAFKA_CLIENT_ID: 'messaging.kafka.client_id';\n\n  /**\n   * Partition the message is sent to.\n   */\n  MESSAGING_KAFKA_PARTITION: 'messaging.kafka.partition';\n\n  /**\n   * A boolean that is true if the message is a tombstone.\n   */\n  MESSAGING_KAFKA_TOMBSTONE: 'messaging.kafka.tombstone';\n\n  /**\n   * A string identifying the remoting system.\n   */\n  RPC_SYSTEM: 'rpc.system';\n\n  /**\n   * The full (logical) name of the service being called, including its package name, if applicable.\n   *\n   * Note: This is the logical name of the service from the RPC interface perspective, which can be different from the name of any implementing class. The `code.namespace` attribute may be used to store the latter (despite the attribute name, it may include a class name; e.g., class with method actually executing the call on the server side, RPC client stub class on the client side).\n   */\n  RPC_SERVICE: 'rpc.service';\n\n  /**\n   * The name of the (logical) method being called, must be equal to the $method part in the span name.\n   *\n   * Note: This is the logical name of the method from the RPC interface perspective, which can be different from the name of any implementing method/function. The `code.function` attribute may be used to store the latter (e.g., method actually executing the call on the server side, RPC client stub method on the client side).\n   */\n  RPC_METHOD: 'rpc.method';\n\n  /**\n   * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n   */\n  RPC_GRPC_STATUS_CODE: 'rpc.grpc.status_code';\n\n  /**\n   * Protocol version as in `jsonrpc` property of request/response. Since JSON-RPC 1.0 does not specify this, the value can be omitted.\n   */\n  RPC_JSONRPC_VERSION: 'rpc.jsonrpc.version';\n\n  /**\n   * `id` property of request or response. Since protocol allows id to be int, string, `null` or missing (for notifications), value is expected to be cast to string for simplicity. Use empty string in case of `null` value. Omit entirely if this is a notification.\n   */\n  RPC_JSONRPC_REQUEST_ID: 'rpc.jsonrpc.request_id';\n\n  /**\n   * `error.code` property of response if it is an error response.\n   */\n  RPC_JSONRPC_ERROR_CODE: 'rpc.jsonrpc.error_code';\n\n  /**\n   * `error.message` property of response if it is an error response.\n   */\n  RPC_JSONRPC_ERROR_MESSAGE: 'rpc.jsonrpc.error_message';\n\n  /**\n   * Whether this is a received or sent message.\n   */\n  MESSAGE_TYPE: 'message.type';\n\n  /**\n   * MUST be calculated as two different counters starting from `1` one for sent messages and one for received message.\n   *\n   * Note: This way we guarantee that the values will be consistent between different implementations.\n   */\n  MESSAGE_ID: 'message.id';\n\n  /**\n   * Compressed size of the message in bytes.\n   */\n  MESSAGE_COMPRESSED_SIZE: 'message.compressed_size';\n\n  /**\n   * Uncompressed size of the message in bytes.\n   */\n  MESSAGE_UNCOMPRESSED_SIZE: 'message.uncompressed_size';\n};\n\n/**\n * Create exported Value Map for SemanticAttributes values\n * @deprecated Use the SEMATTRS_XXXXX constants rather than the SemanticAttributes.XXXXX for bundle minification\n */\nexport const SemanticAttributes: SemanticAttributes =\n  /*#__PURE__*/ createConstMap<SemanticAttributes>([\n    TMP_AWS_LAMBDA_INVOKED_ARN,\n    TMP_DB_SYSTEM,\n    TMP_DB_CONNECTION_STRING,\n    TMP_DB_USER,\n    TMP_DB_JDBC_DRIVER_CLASSNAME,\n    TMP_DB_NAME,\n    TMP_DB_STATEMENT,\n    TMP_DB_OPERATION,\n    TMP_DB_MSSQL_INSTANCE_NAME,\n    TMP_DB_CASSANDRA_KEYSPACE,\n    TMP_DB_CASSANDRA_PAGE_SIZE,\n    TMP_DB_CASSANDRA_CONSISTENCY_LEVEL,\n    TMP_DB_CASSANDRA_TABLE,\n    TMP_DB_CASSANDRA_IDEMPOTENCE,\n    TMP_DB_CASSANDRA_SPECULATIVE_EXECUTION_COUNT,\n    TMP_DB_CASSANDRA_COORDINATOR_ID,\n    TMP_DB_CASSANDRA_COORDINATOR_DC,\n    TMP_DB_HBASE_NAMESPACE,\n    TMP_DB_REDIS_DATABASE_INDEX,\n    TMP_DB_MONGODB_COLLECTION,\n    TMP_DB_SQL_TABLE,\n    TMP_EXCEPTION_TYPE,\n    TMP_EXCEPTION_MESSAGE,\n    TMP_EXCEPTION_STACKTRACE,\n    TMP_EXCEPTION_ESCAPED,\n    TMP_FAAS_TRIGGER,\n    TMP_FAAS_EXECUTION,\n    TMP_FAAS_DOCUMENT_COLLECTION,\n    TMP_FAAS_DOCUMENT_OPERATION,\n    TMP_FAAS_DOCUMENT_TIME,\n    TMP_FAAS_DOCUMENT_NAME,\n    TMP_FAAS_TIME,\n    TMP_FAAS_CRON,\n    TMP_FAAS_COLDSTART,\n    TMP_FAAS_INVOKED_NAME,\n    TMP_FAAS_INVOKED_PROVIDER,\n    TMP_FAAS_INVOKED_REGION,\n    TMP_NET_TRANSPORT,\n    TMP_NET_PEER_IP,\n    TMP_NET_PEER_PORT,\n    TMP_NET_PEER_NAME,\n    TMP_NET_HOST_IP,\n    TMP_NET_HOST_PORT,\n    TMP_NET_HOST_NAME,\n    TMP_NET_HOST_CONNECTION_TYPE,\n    TMP_NET_HOST_CONNECTION_SUBTYPE,\n    TMP_NET_HOST_CARRIER_NAME,\n    TMP_NET_HOST_CARRIER_MCC,\n    TMP_NET_HOST_CARRIER_MNC,\n    TMP_NET_HOST_CARRIER_ICC,\n    TMP_PEER_SERVICE,\n    TMP_ENDUSER_ID,\n    TMP_ENDUSER_ROLE,\n    TMP_ENDUSER_SCOPE,\n    TMP_THREAD_ID,\n    TMP_THREAD_NAME,\n    TMP_CODE_FUNCTION,\n    TMP_CODE_NAMESPACE,\n    TMP_CODE_FILEPATH,\n    TMP_CODE_LINENO,\n    TMP_HTTP_METHOD,\n    TMP_HTTP_URL,\n    TMP_HTTP_TARGET,\n    TMP_HTTP_HOST,\n    TMP_HTTP_SCHEME,\n    TMP_HTTP_STATUS_CODE,\n    TMP_HTTP_FLAVOR,\n    TMP_HTTP_USER_AGENT,\n    TMP_HTTP_REQUEST_CONTENT_LENGTH,\n    TMP_HTTP_REQUEST_CONTENT_LENGTH_UNCOMPRESSED,\n    TMP_HTTP_RESPONSE_CONTENT_LENGTH,\n    TMP_HTTP_RESPONSE_CONTENT_LENGTH_UNCOMPRESSED,\n    TMP_HTTP_SERVER_NAME,\n    TMP_HTTP_ROUTE,\n    TMP_HTTP_CLIENT_IP,\n    TMP_AWS_DYNAMODB_TABLE_NAMES,\n    TMP_AWS_DYNAMODB_CONSUMED_CAPACITY,\n    TMP_AWS_DYNAMODB_ITEM_COLLECTION_METRICS,\n    TMP_AWS_DYNAMODB_PROVISIONED_READ_CAPACITY,\n    TMP_AWS_DYNAMODB_PROVISIONED_WRITE_CAPACITY,\n    TMP_AWS_DYNAMODB_CONSISTENT_READ,\n    TMP_AWS_DYNAMODB_PROJECTION,\n    TMP_AWS_DYNAMODB_LIMIT,\n    TMP_AWS_DYNAMODB_ATTRIBUTES_TO_GET,\n    TMP_AWS_DYNAMODB_INDEX_NAME,\n    TMP_AWS_DYNAMODB_SELECT,\n    TMP_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEXES,\n    TMP_AWS_DYNAMODB_LOCAL_SECONDARY_INDEXES,\n    TMP_AWS_DYNAMODB_EXCLUSIVE_START_TABLE,\n    TMP_AWS_DYNAMODB_TABLE_COUNT,\n    TMP_AWS_DYNAMODB_SCAN_FORWARD,\n    TMP_AWS_DYNAMODB_SEGMENT,\n    TMP_AWS_DYNAMODB_TOTAL_SEGMENTS,\n    TMP_AWS_DYNAMODB_COUNT,\n    TMP_AWS_DYNAMODB_SCANNED_COUNT,\n    TMP_AWS_DYNAMODB_ATTRIBUTE_DEFINITIONS,\n    TMP_AWS_DYNAMODB_GLOBAL_SECONDARY_INDEX_UPDATES,\n    TMP_MESSAGING_SYSTEM,\n    TMP_MESSAGING_DESTINATION,\n    TMP_MESSAGING_DESTINATION_KIND,\n    TMP_MESSAGING_TEMP_DESTINATION,\n    TMP_MESSAGING_PROTOCOL,\n    TMP_MESSAGING_PROTOCOL_VERSION,\n    TMP_MESSAGING_URL,\n    TMP_MESSAGING_MESSAGE_ID,\n    TMP_MESSAGING_CONVERSATION_ID,\n    TMP_MESSAGING_MESSAGE_PAYLOAD_SIZE_BYTES,\n    TMP_MESSAGING_MESSAGE_PAYLOAD_COMPRESSED_SIZE_BYTES,\n    TMP_MESSAGING_OPERATION,\n    TMP_MESSAGING_CONSUMER_ID,\n    TMP_MESSAGING_RABBITMQ_ROUTING_KEY,\n    TMP_MESSAGING_KAFKA_MESSAGE_KEY,\n    TMP_MESSAGING_KAFKA_CONSUMER_GROUP,\n    TMP_MESSAGING_KAFKA_CLIENT_ID,\n    TMP_MESSAGING_KAFKA_PARTITION,\n    TMP_MESSAGING_KAFKA_TOMBSTONE,\n    TMP_RPC_SYSTEM,\n    TMP_RPC_SERVICE,\n    TMP_RPC_METHOD,\n    TMP_RPC_GRPC_STATUS_CODE,\n    TMP_RPC_JSONRPC_VERSION,\n    TMP_RPC_JSONRPC_REQUEST_ID,\n    TMP_RPC_JSONRPC_ERROR_CODE,\n    TMP_RPC_JSONRPC_ERROR_MESSAGE,\n    TMP_MESSAGE_TYPE,\n    TMP_MESSAGE_ID,\n    TMP_MESSAGE_COMPRESSED_SIZE,\n    TMP_MESSAGE_UNCOMPRESSED_SIZE,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for DbSystemValues enum definition\n *\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_DBSYSTEMVALUES_OTHER_SQL = 'other_sql';\nconst TMP_DBSYSTEMVALUES_MSSQL = 'mssql';\nconst TMP_DBSYSTEMVALUES_MYSQL = 'mysql';\nconst TMP_DBSYSTEMVALUES_ORACLE = 'oracle';\nconst TMP_DBSYSTEMVALUES_DB2 = 'db2';\nconst TMP_DBSYSTEMVALUES_POSTGRESQL = 'postgresql';\nconst TMP_DBSYSTEMVALUES_REDSHIFT = 'redshift';\nconst TMP_DBSYSTEMVALUES_HIVE = 'hive';\nconst TMP_DBSYSTEMVALUES_CLOUDSCAPE = 'cloudscape';\nconst TMP_DBSYSTEMVALUES_HSQLDB = 'hsqldb';\nconst TMP_DBSYSTEMVALUES_PROGRESS = 'progress';\nconst TMP_DBSYSTEMVALUES_MAXDB = 'maxdb';\nconst TMP_DBSYSTEMVALUES_HANADB = 'hanadb';\nconst TMP_DBSYSTEMVALUES_INGRES = 'ingres';\nconst TMP_DBSYSTEMVALUES_FIRSTSQL = 'firstsql';\nconst TMP_DBSYSTEMVALUES_EDB = 'edb';\nconst TMP_DBSYSTEMVALUES_CACHE = 'cache';\nconst TMP_DBSYSTEMVALUES_ADABAS = 'adabas';\nconst TMP_DBSYSTEMVALUES_FIREBIRD = 'firebird';\nconst TMP_DBSYSTEMVALUES_DERBY = 'derby';\nconst TMP_DBSYSTEMVALUES_FILEMAKER = 'filemaker';\nconst TMP_DBSYSTEMVALUES_INFORMIX = 'informix';\nconst TMP_DBSYSTEMVALUES_INSTANTDB = 'instantdb';\nconst TMP_DBSYSTEMVALUES_INTERBASE = 'interbase';\nconst TMP_DBSYSTEMVALUES_MARIADB = 'mariadb';\nconst TMP_DBSYSTEMVALUES_NETEZZA = 'netezza';\nconst TMP_DBSYSTEMVALUES_PERVASIVE = 'pervasive';\nconst TMP_DBSYSTEMVALUES_POINTBASE = 'pointbase';\nconst TMP_DBSYSTEMVALUES_SQLITE = 'sqlite';\nconst TMP_DBSYSTEMVALUES_SYBASE = 'sybase';\nconst TMP_DBSYSTEMVALUES_TERADATA = 'teradata';\nconst TMP_DBSYSTEMVALUES_VERTICA = 'vertica';\nconst TMP_DBSYSTEMVALUES_H2 = 'h2';\nconst TMP_DBSYSTEMVALUES_COLDFUSION = 'coldfusion';\nconst TMP_DBSYSTEMVALUES_CASSANDRA = 'cassandra';\nconst TMP_DBSYSTEMVALUES_HBASE = 'hbase';\nconst TMP_DBSYSTEMVALUES_MONGODB = 'mongodb';\nconst TMP_DBSYSTEMVALUES_REDIS = 'redis';\nconst TMP_DBSYSTEMVALUES_COUCHBASE = 'couchbase';\nconst TMP_DBSYSTEMVALUES_COUCHDB = 'couchdb';\nconst TMP_DBSYSTEMVALUES_COSMOSDB = 'cosmosdb';\nconst TMP_DBSYSTEMVALUES_DYNAMODB = 'dynamodb';\nconst TMP_DBSYSTEMVALUES_NEO4J = 'neo4j';\nconst TMP_DBSYSTEMVALUES_GEODE = 'geode';\nconst TMP_DBSYSTEMVALUES_ELASTICSEARCH = 'elasticsearch';\nconst TMP_DBSYSTEMVALUES_MEMCACHED = 'memcached';\nconst TMP_DBSYSTEMVALUES_COCKROACHDB = 'cockroachdb';\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_OTHER_SQL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_OTHER_SQL = TMP_DBSYSTEMVALUES_OTHER_SQL;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_MSSQL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_MSSQL = TMP_DBSYSTEMVALUES_MSSQL;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_MYSQL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_MYSQL = TMP_DBSYSTEMVALUES_MYSQL;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_ORACLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_ORACLE = TMP_DBSYSTEMVALUES_ORACLE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_DB2 in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_DB2 = TMP_DBSYSTEMVALUES_DB2;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_POSTGRESQL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_POSTGRESQL = TMP_DBSYSTEMVALUES_POSTGRESQL;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_REDSHIFT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_REDSHIFT = TMP_DBSYSTEMVALUES_REDSHIFT;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_HIVE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_HIVE = TMP_DBSYSTEMVALUES_HIVE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_CLOUDSCAPE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_CLOUDSCAPE = TMP_DBSYSTEMVALUES_CLOUDSCAPE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_HSQLDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_HSQLDB = TMP_DBSYSTEMVALUES_HSQLDB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_PROGRESS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_PROGRESS = TMP_DBSYSTEMVALUES_PROGRESS;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_MAXDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_MAXDB = TMP_DBSYSTEMVALUES_MAXDB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_HANADB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_HANADB = TMP_DBSYSTEMVALUES_HANADB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_INGRES in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_INGRES = TMP_DBSYSTEMVALUES_INGRES;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_FIRSTSQL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_FIRSTSQL = TMP_DBSYSTEMVALUES_FIRSTSQL;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_EDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_EDB = TMP_DBSYSTEMVALUES_EDB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_CACHE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_CACHE = TMP_DBSYSTEMVALUES_CACHE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_ADABAS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_ADABAS = TMP_DBSYSTEMVALUES_ADABAS;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_FIREBIRD in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_FIREBIRD = TMP_DBSYSTEMVALUES_FIREBIRD;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_DERBY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_DERBY = TMP_DBSYSTEMVALUES_DERBY;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_FILEMAKER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_FILEMAKER = TMP_DBSYSTEMVALUES_FILEMAKER;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_INFORMIX in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_INFORMIX = TMP_DBSYSTEMVALUES_INFORMIX;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_INSTANTDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_INSTANTDB = TMP_DBSYSTEMVALUES_INSTANTDB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_INTERBASE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_INTERBASE = TMP_DBSYSTEMVALUES_INTERBASE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_MARIADB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_MARIADB = TMP_DBSYSTEMVALUES_MARIADB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_NETEZZA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_NETEZZA = TMP_DBSYSTEMVALUES_NETEZZA;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_PERVASIVE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_PERVASIVE = TMP_DBSYSTEMVALUES_PERVASIVE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_POINTBASE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_POINTBASE = TMP_DBSYSTEMVALUES_POINTBASE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_SQLITE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_SQLITE = TMP_DBSYSTEMVALUES_SQLITE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_SYBASE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_SYBASE = TMP_DBSYSTEMVALUES_SYBASE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_TERADATA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_TERADATA = TMP_DBSYSTEMVALUES_TERADATA;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_VERTICA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_VERTICA = TMP_DBSYSTEMVALUES_VERTICA;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_H2 in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_H2 = TMP_DBSYSTEMVALUES_H2;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_COLDFUSION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_COLDFUSION = TMP_DBSYSTEMVALUES_COLDFUSION;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_CASSANDRA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_CASSANDRA = TMP_DBSYSTEMVALUES_CASSANDRA;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_HBASE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_HBASE = TMP_DBSYSTEMVALUES_HBASE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_MONGODB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_MONGODB = TMP_DBSYSTEMVALUES_MONGODB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_REDIS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_REDIS = TMP_DBSYSTEMVALUES_REDIS;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_COUCHBASE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_COUCHBASE = TMP_DBSYSTEMVALUES_COUCHBASE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_COUCHDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_COUCHDB = TMP_DBSYSTEMVALUES_COUCHDB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_COSMOSDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_COSMOSDB = TMP_DBSYSTEMVALUES_COSMOSDB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_DYNAMODB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_DYNAMODB = TMP_DBSYSTEMVALUES_DYNAMODB;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_NEO4J in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_NEO4J = TMP_DBSYSTEMVALUES_NEO4J;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_GEODE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_GEODE = TMP_DBSYSTEMVALUES_GEODE;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_ELASTICSEARCH in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_ELASTICSEARCH = TMP_DBSYSTEMVALUES_ELASTICSEARCH;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_MEMCACHED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_MEMCACHED = TMP_DBSYSTEMVALUES_MEMCACHED;\n\n/**\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n *\n * @deprecated Use DB_SYSTEM_VALUE_COCKROACHDB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBSYSTEMVALUES_COCKROACHDB = TMP_DBSYSTEMVALUES_COCKROACHDB;\n\n/**\n * Identifies the Values for DbSystemValues enum definition\n *\n * An identifier for the database management system (DBMS) product being used. See below for a list of well-known identifiers.\n * @deprecated Use the DBSYSTEMVALUES_XXXXX constants rather than the DbSystemValues.XXXXX for bundle minification.\n */\nexport type DbSystemValues = {\n  /** Some other SQL database. Fallback only. See notes. */\n  OTHER_SQL: 'other_sql';\n\n  /** Microsoft SQL Server. */\n  MSSQL: 'mssql';\n\n  /** MySQL. */\n  MYSQL: 'mysql';\n\n  /** Oracle Database. */\n  ORACLE: 'oracle';\n\n  /** IBM Db2. */\n  DB2: 'db2';\n\n  /** PostgreSQL. */\n  POSTGRESQL: 'postgresql';\n\n  /** Amazon Redshift. */\n  REDSHIFT: 'redshift';\n\n  /** Apache Hive. */\n  HIVE: 'hive';\n\n  /** Cloudscape. */\n  CLOUDSCAPE: 'cloudscape';\n\n  /** HyperSQL DataBase. */\n  HSQLDB: 'hsqldb';\n\n  /** Progress Database. */\n  PROGRESS: 'progress';\n\n  /** SAP MaxDB. */\n  MAXDB: 'maxdb';\n\n  /** SAP HANA. */\n  HANADB: 'hanadb';\n\n  /** Ingres. */\n  INGRES: 'ingres';\n\n  /** FirstSQL. */\n  FIRSTSQL: 'firstsql';\n\n  /** EnterpriseDB. */\n  EDB: 'edb';\n\n  /** InterSystems Cach. */\n  CACHE: 'cache';\n\n  /** Adabas (Adaptable Database System). */\n  ADABAS: 'adabas';\n\n  /** Firebird. */\n  FIREBIRD: 'firebird';\n\n  /** Apache Derby. */\n  DERBY: 'derby';\n\n  /** FileMaker. */\n  FILEMAKER: 'filemaker';\n\n  /** Informix. */\n  INFORMIX: 'informix';\n\n  /** InstantDB. */\n  INSTANTDB: 'instantdb';\n\n  /** InterBase. */\n  INTERBASE: 'interbase';\n\n  /** MariaDB. */\n  MARIADB: 'mariadb';\n\n  /** Netezza. */\n  NETEZZA: 'netezza';\n\n  /** Pervasive PSQL. */\n  PERVASIVE: 'pervasive';\n\n  /** PointBase. */\n  POINTBASE: 'pointbase';\n\n  /** SQLite. */\n  SQLITE: 'sqlite';\n\n  /** Sybase. */\n  SYBASE: 'sybase';\n\n  /** Teradata. */\n  TERADATA: 'teradata';\n\n  /** Vertica. */\n  VERTICA: 'vertica';\n\n  /** H2. */\n  H2: 'h2';\n\n  /** ColdFusion IMQ. */\n  COLDFUSION: 'coldfusion';\n\n  /** Apache Cassandra. */\n  CASSANDRA: 'cassandra';\n\n  /** Apache HBase. */\n  HBASE: 'hbase';\n\n  /** MongoDB. */\n  MONGODB: 'mongodb';\n\n  /** Redis. */\n  REDIS: 'redis';\n\n  /** Couchbase. */\n  COUCHBASE: 'couchbase';\n\n  /** CouchDB. */\n  COUCHDB: 'couchdb';\n\n  /** Microsoft Azure Cosmos DB. */\n  COSMOSDB: 'cosmosdb';\n\n  /** Amazon DynamoDB. */\n  DYNAMODB: 'dynamodb';\n\n  /** Neo4j. */\n  NEO4J: 'neo4j';\n\n  /** Apache Geode. */\n  GEODE: 'geode';\n\n  /** Elasticsearch. */\n  ELASTICSEARCH: 'elasticsearch';\n\n  /** Memcached. */\n  MEMCACHED: 'memcached';\n\n  /** CockroachDB. */\n  COCKROACHDB: 'cockroachdb';\n};\n\n/**\n * The constant map of values for DbSystemValues.\n * @deprecated Use the DBSYSTEMVALUES_XXXXX constants rather than the DbSystemValues.XXXXX for bundle minification.\n */\nexport const DbSystemValues: DbSystemValues =\n  /*#__PURE__*/ createConstMap<DbSystemValues>([\n    TMP_DBSYSTEMVALUES_OTHER_SQL,\n    TMP_DBSYSTEMVALUES_MSSQL,\n    TMP_DBSYSTEMVALUES_MYSQL,\n    TMP_DBSYSTEMVALUES_ORACLE,\n    TMP_DBSYSTEMVALUES_DB2,\n    TMP_DBSYSTEMVALUES_POSTGRESQL,\n    TMP_DBSYSTEMVALUES_REDSHIFT,\n    TMP_DBSYSTEMVALUES_HIVE,\n    TMP_DBSYSTEMVALUES_CLOUDSCAPE,\n    TMP_DBSYSTEMVALUES_HSQLDB,\n    TMP_DBSYSTEMVALUES_PROGRESS,\n    TMP_DBSYSTEMVALUES_MAXDB,\n    TMP_DBSYSTEMVALUES_HANADB,\n    TMP_DBSYSTEMVALUES_INGRES,\n    TMP_DBSYSTEMVALUES_FIRSTSQL,\n    TMP_DBSYSTEMVALUES_EDB,\n    TMP_DBSYSTEMVALUES_CACHE,\n    TMP_DBSYSTEMVALUES_ADABAS,\n    TMP_DBSYSTEMVALUES_FIREBIRD,\n    TMP_DBSYSTEMVALUES_DERBY,\n    TMP_DBSYSTEMVALUES_FILEMAKER,\n    TMP_DBSYSTEMVALUES_INFORMIX,\n    TMP_DBSYSTEMVALUES_INSTANTDB,\n    TMP_DBSYSTEMVALUES_INTERBASE,\n    TMP_DBSYSTEMVALUES_MARIADB,\n    TMP_DBSYSTEMVALUES_NETEZZA,\n    TMP_DBSYSTEMVALUES_PERVASIVE,\n    TMP_DBSYSTEMVALUES_POINTBASE,\n    TMP_DBSYSTEMVALUES_SQLITE,\n    TMP_DBSYSTEMVALUES_SYBASE,\n    TMP_DBSYSTEMVALUES_TERADATA,\n    TMP_DBSYSTEMVALUES_VERTICA,\n    TMP_DBSYSTEMVALUES_H2,\n    TMP_DBSYSTEMVALUES_COLDFUSION,\n    TMP_DBSYSTEMVALUES_CASSANDRA,\n    TMP_DBSYSTEMVALUES_HBASE,\n    TMP_DBSYSTEMVALUES_MONGODB,\n    TMP_DBSYSTEMVALUES_REDIS,\n    TMP_DBSYSTEMVALUES_COUCHBASE,\n    TMP_DBSYSTEMVALUES_COUCHDB,\n    TMP_DBSYSTEMVALUES_COSMOSDB,\n    TMP_DBSYSTEMVALUES_DYNAMODB,\n    TMP_DBSYSTEMVALUES_NEO4J,\n    TMP_DBSYSTEMVALUES_GEODE,\n    TMP_DBSYSTEMVALUES_ELASTICSEARCH,\n    TMP_DBSYSTEMVALUES_MEMCACHED,\n    TMP_DBSYSTEMVALUES_COCKROACHDB,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for DbCassandraConsistencyLevelValues enum definition\n *\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ALL = 'all';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_EACH_QUORUM = 'each_quorum';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_QUORUM = 'quorum';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_QUORUM = 'local_quorum';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ONE = 'one';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_TWO = 'two';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_THREE = 'three';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_ONE = 'local_one';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ANY = 'any';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_SERIAL = 'serial';\nconst TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_SERIAL = 'local_serial';\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_ALL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_ALL =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ALL;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_EACH_QUORUM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_EACH_QUORUM =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_EACH_QUORUM;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_QUORUM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_QUORUM =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_QUORUM;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_LOCAL_QUORUM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_QUORUM =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_QUORUM;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_ONE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_ONE =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ONE;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_TWO in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_TWO =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_TWO;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_THREE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_THREE =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_THREE;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_LOCAL_ONE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_ONE =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_ONE;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_ANY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_ANY =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ANY;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_SERIAL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_SERIAL =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_SERIAL;\n\n/**\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n *\n * @deprecated Use DB_CASSANDRA_CONSISTENCY_LEVEL_VALUE_LOCAL_SERIAL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_SERIAL =\n  TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_SERIAL;\n\n/**\n * Identifies the Values for DbCassandraConsistencyLevelValues enum definition\n *\n * The consistency level of the query. Based on consistency values from [CQL](https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html).\n * @deprecated Use the DBCASSANDRACONSISTENCYLEVELVALUES_XXXXX constants rather than the DbCassandraConsistencyLevelValues.XXXXX for bundle minification.\n */\nexport type DbCassandraConsistencyLevelValues = {\n  /** all. */\n  ALL: 'all';\n\n  /** each_quorum. */\n  EACH_QUORUM: 'each_quorum';\n\n  /** quorum. */\n  QUORUM: 'quorum';\n\n  /** local_quorum. */\n  LOCAL_QUORUM: 'local_quorum';\n\n  /** one. */\n  ONE: 'one';\n\n  /** two. */\n  TWO: 'two';\n\n  /** three. */\n  THREE: 'three';\n\n  /** local_one. */\n  LOCAL_ONE: 'local_one';\n\n  /** any. */\n  ANY: 'any';\n\n  /** serial. */\n  SERIAL: 'serial';\n\n  /** local_serial. */\n  LOCAL_SERIAL: 'local_serial';\n};\n\n/**\n * The constant map of values for DbCassandraConsistencyLevelValues.\n * @deprecated Use the DBCASSANDRACONSISTENCYLEVELVALUES_XXXXX constants rather than the DbCassandraConsistencyLevelValues.XXXXX for bundle minification.\n */\nexport const DbCassandraConsistencyLevelValues: DbCassandraConsistencyLevelValues =\n  /*#__PURE__*/ createConstMap<DbCassandraConsistencyLevelValues>([\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ALL,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_EACH_QUORUM,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_QUORUM,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_QUORUM,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ONE,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_TWO,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_THREE,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_ONE,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_ANY,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_SERIAL,\n    TMP_DBCASSANDRACONSISTENCYLEVELVALUES_LOCAL_SERIAL,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for FaasTriggerValues enum definition\n *\n * Type of the trigger on which the function is executed.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_FAASTRIGGERVALUES_DATASOURCE = 'datasource';\nconst TMP_FAASTRIGGERVALUES_HTTP = 'http';\nconst TMP_FAASTRIGGERVALUES_PUBSUB = 'pubsub';\nconst TMP_FAASTRIGGERVALUES_TIMER = 'timer';\nconst TMP_FAASTRIGGERVALUES_OTHER = 'other';\n\n/**\n * Type of the trigger on which the function is executed.\n *\n * @deprecated Use FAAS_TRIGGER_VALUE_DATASOURCE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASTRIGGERVALUES_DATASOURCE = TMP_FAASTRIGGERVALUES_DATASOURCE;\n\n/**\n * Type of the trigger on which the function is executed.\n *\n * @deprecated Use FAAS_TRIGGER_VALUE_HTTP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASTRIGGERVALUES_HTTP = TMP_FAASTRIGGERVALUES_HTTP;\n\n/**\n * Type of the trigger on which the function is executed.\n *\n * @deprecated Use FAAS_TRIGGER_VALUE_PUBSUB in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASTRIGGERVALUES_PUBSUB = TMP_FAASTRIGGERVALUES_PUBSUB;\n\n/**\n * Type of the trigger on which the function is executed.\n *\n * @deprecated Use FAAS_TRIGGER_VALUE_TIMER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASTRIGGERVALUES_TIMER = TMP_FAASTRIGGERVALUES_TIMER;\n\n/**\n * Type of the trigger on which the function is executed.\n *\n * @deprecated Use FAAS_TRIGGER_VALUE_OTHER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASTRIGGERVALUES_OTHER = TMP_FAASTRIGGERVALUES_OTHER;\n\n/**\n * Identifies the Values for FaasTriggerValues enum definition\n *\n * Type of the trigger on which the function is executed.\n * @deprecated Use the FAASTRIGGERVALUES_XXXXX constants rather than the FaasTriggerValues.XXXXX for bundle minification.\n */\nexport type FaasTriggerValues = {\n  /** A response to some data source operation such as a database or filesystem read/write. */\n  DATASOURCE: 'datasource';\n\n  /** To provide an answer to an inbound HTTP request. */\n  HTTP: 'http';\n\n  /** A function is set to be executed when messages are sent to a messaging system. */\n  PUBSUB: 'pubsub';\n\n  /** A function is scheduled to be executed regularly. */\n  TIMER: 'timer';\n\n  /** If none of the others apply. */\n  OTHER: 'other';\n};\n\n/**\n * The constant map of values for FaasTriggerValues.\n * @deprecated Use the FAASTRIGGERVALUES_XXXXX constants rather than the FaasTriggerValues.XXXXX for bundle minification.\n */\nexport const FaasTriggerValues: FaasTriggerValues =\n  /*#__PURE__*/ createConstMap<FaasTriggerValues>([\n    TMP_FAASTRIGGERVALUES_DATASOURCE,\n    TMP_FAASTRIGGERVALUES_HTTP,\n    TMP_FAASTRIGGERVALUES_PUBSUB,\n    TMP_FAASTRIGGERVALUES_TIMER,\n    TMP_FAASTRIGGERVALUES_OTHER,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for FaasDocumentOperationValues enum definition\n *\n * Describes the type of the operation that was performed on the data.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_FAASDOCUMENTOPERATIONVALUES_INSERT = 'insert';\nconst TMP_FAASDOCUMENTOPERATIONVALUES_EDIT = 'edit';\nconst TMP_FAASDOCUMENTOPERATIONVALUES_DELETE = 'delete';\n\n/**\n * Describes the type of the operation that was performed on the data.\n *\n * @deprecated Use FAAS_DOCUMENT_OPERATION_VALUE_INSERT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASDOCUMENTOPERATIONVALUES_INSERT =\n  TMP_FAASDOCUMENTOPERATIONVALUES_INSERT;\n\n/**\n * Describes the type of the operation that was performed on the data.\n *\n * @deprecated Use FAAS_DOCUMENT_OPERATION_VALUE_EDIT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASDOCUMENTOPERATIONVALUES_EDIT =\n  TMP_FAASDOCUMENTOPERATIONVALUES_EDIT;\n\n/**\n * Describes the type of the operation that was performed on the data.\n *\n * @deprecated Use FAAS_DOCUMENT_OPERATION_VALUE_DELETE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASDOCUMENTOPERATIONVALUES_DELETE =\n  TMP_FAASDOCUMENTOPERATIONVALUES_DELETE;\n\n/**\n * Identifies the Values for FaasDocumentOperationValues enum definition\n *\n * Describes the type of the operation that was performed on the data.\n * @deprecated Use the FAASDOCUMENTOPERATIONVALUES_XXXXX constants rather than the FaasDocumentOperationValues.XXXXX for bundle minification.\n */\nexport type FaasDocumentOperationValues = {\n  /** When a new object is created. */\n  INSERT: 'insert';\n\n  /** When an object is modified. */\n  EDIT: 'edit';\n\n  /** When an object is deleted. */\n  DELETE: 'delete';\n};\n\n/**\n * The constant map of values for FaasDocumentOperationValues.\n * @deprecated Use the FAASDOCUMENTOPERATIONVALUES_XXXXX constants rather than the FaasDocumentOperationValues.XXXXX for bundle minification.\n */\nexport const FaasDocumentOperationValues: FaasDocumentOperationValues =\n  /*#__PURE__*/ createConstMap<FaasDocumentOperationValues>([\n    TMP_FAASDOCUMENTOPERATIONVALUES_INSERT,\n    TMP_FAASDOCUMENTOPERATIONVALUES_EDIT,\n    TMP_FAASDOCUMENTOPERATIONVALUES_DELETE,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for FaasInvokedProviderValues enum definition\n *\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_FAASINVOKEDPROVIDERVALUES_ALIBABA_CLOUD = 'alibaba_cloud';\nconst TMP_FAASINVOKEDPROVIDERVALUES_AWS = 'aws';\nconst TMP_FAASINVOKEDPROVIDERVALUES_AZURE = 'azure';\nconst TMP_FAASINVOKEDPROVIDERVALUES_GCP = 'gcp';\n\n/**\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n *\n * @deprecated Use FAAS_INVOKED_PROVIDER_VALUE_ALIBABA_CLOUD in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASINVOKEDPROVIDERVALUES_ALIBABA_CLOUD =\n  TMP_FAASINVOKEDPROVIDERVALUES_ALIBABA_CLOUD;\n\n/**\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n *\n * @deprecated Use FAAS_INVOKED_PROVIDER_VALUE_AWS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASINVOKEDPROVIDERVALUES_AWS = TMP_FAASINVOKEDPROVIDERVALUES_AWS;\n\n/**\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n *\n * @deprecated Use FAAS_INVOKED_PROVIDER_VALUE_AZURE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASINVOKEDPROVIDERVALUES_AZURE =\n  TMP_FAASINVOKEDPROVIDERVALUES_AZURE;\n\n/**\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n *\n * @deprecated Use FAAS_INVOKED_PROVIDER_VALUE_GCP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const FAASINVOKEDPROVIDERVALUES_GCP = TMP_FAASINVOKEDPROVIDERVALUES_GCP;\n\n/**\n * Identifies the Values for FaasInvokedProviderValues enum definition\n *\n * The cloud provider of the invoked function.\n *\n * Note: SHOULD be equal to the `cloud.provider` resource attribute of the invoked function.\n * @deprecated Use the FAASINVOKEDPROVIDERVALUES_XXXXX constants rather than the FaasInvokedProviderValues.XXXXX for bundle minification.\n */\nexport type FaasInvokedProviderValues = {\n  /** Alibaba Cloud. */\n  ALIBABA_CLOUD: 'alibaba_cloud';\n\n  /** Amazon Web Services. */\n  AWS: 'aws';\n\n  /** Microsoft Azure. */\n  AZURE: 'azure';\n\n  /** Google Cloud Platform. */\n  GCP: 'gcp';\n};\n\n/**\n * The constant map of values for FaasInvokedProviderValues.\n * @deprecated Use the FAASINVOKEDPROVIDERVALUES_XXXXX constants rather than the FaasInvokedProviderValues.XXXXX for bundle minification.\n */\nexport const FaasInvokedProviderValues: FaasInvokedProviderValues =\n  /*#__PURE__*/ createConstMap<FaasInvokedProviderValues>([\n    TMP_FAASINVOKEDPROVIDERVALUES_ALIBABA_CLOUD,\n    TMP_FAASINVOKEDPROVIDERVALUES_AWS,\n    TMP_FAASINVOKEDPROVIDERVALUES_AZURE,\n    TMP_FAASINVOKEDPROVIDERVALUES_GCP,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for NetTransportValues enum definition\n *\n * Transport protocol used. See note below.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_NETTRANSPORTVALUES_IP_TCP = 'ip_tcp';\nconst TMP_NETTRANSPORTVALUES_IP_UDP = 'ip_udp';\nconst TMP_NETTRANSPORTVALUES_IP = 'ip';\nconst TMP_NETTRANSPORTVALUES_UNIX = 'unix';\nconst TMP_NETTRANSPORTVALUES_PIPE = 'pipe';\nconst TMP_NETTRANSPORTVALUES_INPROC = 'inproc';\nconst TMP_NETTRANSPORTVALUES_OTHER = 'other';\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Use NET_TRANSPORT_VALUE_IP_TCP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETTRANSPORTVALUES_IP_TCP = TMP_NETTRANSPORTVALUES_IP_TCP;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Use NET_TRANSPORT_VALUE_IP_UDP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETTRANSPORTVALUES_IP_UDP = TMP_NETTRANSPORTVALUES_IP_UDP;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Removed in v1.21.0.\n */\nexport const NETTRANSPORTVALUES_IP = TMP_NETTRANSPORTVALUES_IP;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Removed in v1.21.0.\n */\nexport const NETTRANSPORTVALUES_UNIX = TMP_NETTRANSPORTVALUES_UNIX;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Use NET_TRANSPORT_VALUE_PIPE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETTRANSPORTVALUES_PIPE = TMP_NETTRANSPORTVALUES_PIPE;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Use NET_TRANSPORT_VALUE_INPROC in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETTRANSPORTVALUES_INPROC = TMP_NETTRANSPORTVALUES_INPROC;\n\n/**\n * Transport protocol used. See note below.\n *\n * @deprecated Use NET_TRANSPORT_VALUE_OTHER in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETTRANSPORTVALUES_OTHER = TMP_NETTRANSPORTVALUES_OTHER;\n\n/**\n * Identifies the Values for NetTransportValues enum definition\n *\n * Transport protocol used. See note below.\n * @deprecated Use the NETTRANSPORTVALUES_XXXXX constants rather than the NetTransportValues.XXXXX for bundle minification.\n */\nexport type NetTransportValues = {\n  /** ip_tcp. */\n  IP_TCP: 'ip_tcp';\n\n  /** ip_udp. */\n  IP_UDP: 'ip_udp';\n\n  /** Another IP-based protocol. */\n  IP: 'ip';\n\n  /** Unix Domain socket. See below. */\n  UNIX: 'unix';\n\n  /** Named or anonymous pipe. See note below. */\n  PIPE: 'pipe';\n\n  /** In-process communication. */\n  INPROC: 'inproc';\n\n  /** Something else (non IP-based). */\n  OTHER: 'other';\n};\n\n/**\n * The constant map of values for NetTransportValues.\n * @deprecated Use the NETTRANSPORTVALUES_XXXXX constants rather than the NetTransportValues.XXXXX for bundle minification.\n */\nexport const NetTransportValues: NetTransportValues =\n  /*#__PURE__*/ createConstMap<NetTransportValues>([\n    TMP_NETTRANSPORTVALUES_IP_TCP,\n    TMP_NETTRANSPORTVALUES_IP_UDP,\n    TMP_NETTRANSPORTVALUES_IP,\n    TMP_NETTRANSPORTVALUES_UNIX,\n    TMP_NETTRANSPORTVALUES_PIPE,\n    TMP_NETTRANSPORTVALUES_INPROC,\n    TMP_NETTRANSPORTVALUES_OTHER,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for NetHostConnectionTypeValues enum definition\n *\n * The internet connection type currently being used by the host.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_NETHOSTCONNECTIONTYPEVALUES_WIFI = 'wifi';\nconst TMP_NETHOSTCONNECTIONTYPEVALUES_WIRED = 'wired';\nconst TMP_NETHOSTCONNECTIONTYPEVALUES_CELL = 'cell';\nconst TMP_NETHOSTCONNECTIONTYPEVALUES_UNAVAILABLE = 'unavailable';\nconst TMP_NETHOSTCONNECTIONTYPEVALUES_UNKNOWN = 'unknown';\n\n/**\n * The internet connection type currently being used by the host.\n *\n * @deprecated Use NETWORK_CONNECTION_TYPE_VALUE_WIFI in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONTYPEVALUES_WIFI =\n  TMP_NETHOSTCONNECTIONTYPEVALUES_WIFI;\n\n/**\n * The internet connection type currently being used by the host.\n *\n * @deprecated Use NETWORK_CONNECTION_TYPE_VALUE_WIRED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONTYPEVALUES_WIRED =\n  TMP_NETHOSTCONNECTIONTYPEVALUES_WIRED;\n\n/**\n * The internet connection type currently being used by the host.\n *\n * @deprecated Use NETWORK_CONNECTION_TYPE_VALUE_CELL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONTYPEVALUES_CELL =\n  TMP_NETHOSTCONNECTIONTYPEVALUES_CELL;\n\n/**\n * The internet connection type currently being used by the host.\n *\n * @deprecated Use NETWORK_CONNECTION_TYPE_VALUE_UNAVAILABLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONTYPEVALUES_UNAVAILABLE =\n  TMP_NETHOSTCONNECTIONTYPEVALUES_UNAVAILABLE;\n\n/**\n * The internet connection type currently being used by the host.\n *\n * @deprecated Use NETWORK_CONNECTION_TYPE_VALUE_UNKNOWN in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONTYPEVALUES_UNKNOWN =\n  TMP_NETHOSTCONNECTIONTYPEVALUES_UNKNOWN;\n\n/**\n * Identifies the Values for NetHostConnectionTypeValues enum definition\n *\n * The internet connection type currently being used by the host.\n * @deprecated Use the NETHOSTCONNECTIONTYPEVALUES_XXXXX constants rather than the NetHostConnectionTypeValues.XXXXX for bundle minification.\n */\nexport type NetHostConnectionTypeValues = {\n  /** wifi. */\n  WIFI: 'wifi';\n\n  /** wired. */\n  WIRED: 'wired';\n\n  /** cell. */\n  CELL: 'cell';\n\n  /** unavailable. */\n  UNAVAILABLE: 'unavailable';\n\n  /** unknown. */\n  UNKNOWN: 'unknown';\n};\n\n/**\n * The constant map of values for NetHostConnectionTypeValues.\n * @deprecated Use the NETHOSTCONNECTIONTYPEVALUES_XXXXX constants rather than the NetHostConnectionTypeValues.XXXXX for bundle minification.\n */\nexport const NetHostConnectionTypeValues: NetHostConnectionTypeValues =\n  /*#__PURE__*/ createConstMap<NetHostConnectionTypeValues>([\n    TMP_NETHOSTCONNECTIONTYPEVALUES_WIFI,\n    TMP_NETHOSTCONNECTIONTYPEVALUES_WIRED,\n    TMP_NETHOSTCONNECTIONTYPEVALUES_CELL,\n    TMP_NETHOSTCONNECTIONTYPEVALUES_UNAVAILABLE,\n    TMP_NETHOSTCONNECTIONTYPEVALUES_UNKNOWN,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for NetHostConnectionSubtypeValues enum definition\n *\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_GPRS = 'gprs';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EDGE = 'edge';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_UMTS = 'umts';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_CDMA = 'cdma';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_0 = 'evdo_0';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_A = 'evdo_a';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_CDMA2000_1XRTT = 'cdma2000_1xrtt';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSDPA = 'hsdpa';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSUPA = 'hsupa';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSPA = 'hspa';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_IDEN = 'iden';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_B = 'evdo_b';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_LTE = 'lte';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EHRPD = 'ehrpd';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSPAP = 'hspap';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_GSM = 'gsm';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_TD_SCDMA = 'td_scdma';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_IWLAN = 'iwlan';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_NR = 'nr';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_NRNSA = 'nrnsa';\nconst TMP_NETHOSTCONNECTIONSUBTYPEVALUES_LTE_CA = 'lte_ca';\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_GPRS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_GPRS =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_GPRS;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_EDGE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_EDGE =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EDGE;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_UMTS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_UMTS =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_UMTS;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_CDMA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_CDMA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_CDMA;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_EVDO_0 in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_0 =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_0;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_EVDO_A in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_A =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_A;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_CDMA2000_1XRTT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_CDMA2000_1XRTT =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_CDMA2000_1XRTT;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_HSDPA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_HSDPA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSDPA;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_HSUPA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_HSUPA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSUPA;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_HSPA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_HSPA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSPA;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_IDEN in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_IDEN =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_IDEN;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_EVDO_B in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_B =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_B;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_LTE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_LTE =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_LTE;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_EHRPD in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_EHRPD =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EHRPD;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_HSPAP in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_HSPAP =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSPAP;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_GSM in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_GSM =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_GSM;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_TD_SCDMA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_TD_SCDMA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_TD_SCDMA;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_IWLAN in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_IWLAN =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_IWLAN;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_NR in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_NR =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_NR;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_NRNSA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_NRNSA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_NRNSA;\n\n/**\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n *\n * @deprecated Use NETWORK_CONNECTION_SUBTYPE_VALUE_LTE_CA in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const NETHOSTCONNECTIONSUBTYPEVALUES_LTE_CA =\n  TMP_NETHOSTCONNECTIONSUBTYPEVALUES_LTE_CA;\n\n/**\n * Identifies the Values for NetHostConnectionSubtypeValues enum definition\n *\n * This describes more details regarding the connection.type. It may be the type of cell technology connection, but it could be used for describing details about a wifi connection.\n * @deprecated Use the NETHOSTCONNECTIONSUBTYPEVALUES_XXXXX constants rather than the NetHostConnectionSubtypeValues.XXXXX for bundle minification.\n */\nexport type NetHostConnectionSubtypeValues = {\n  /** GPRS. */\n  GPRS: 'gprs';\n\n  /** EDGE. */\n  EDGE: 'edge';\n\n  /** UMTS. */\n  UMTS: 'umts';\n\n  /** CDMA. */\n  CDMA: 'cdma';\n\n  /** EVDO Rel. 0. */\n  EVDO_0: 'evdo_0';\n\n  /** EVDO Rev. A. */\n  EVDO_A: 'evdo_a';\n\n  /** CDMA2000 1XRTT. */\n  CDMA2000_1XRTT: 'cdma2000_1xrtt';\n\n  /** HSDPA. */\n  HSDPA: 'hsdpa';\n\n  /** HSUPA. */\n  HSUPA: 'hsupa';\n\n  /** HSPA. */\n  HSPA: 'hspa';\n\n  /** IDEN. */\n  IDEN: 'iden';\n\n  /** EVDO Rev. B. */\n  EVDO_B: 'evdo_b';\n\n  /** LTE. */\n  LTE: 'lte';\n\n  /** EHRPD. */\n  EHRPD: 'ehrpd';\n\n  /** HSPAP. */\n  HSPAP: 'hspap';\n\n  /** GSM. */\n  GSM: 'gsm';\n\n  /** TD-SCDMA. */\n  TD_SCDMA: 'td_scdma';\n\n  /** IWLAN. */\n  IWLAN: 'iwlan';\n\n  /** 5G NR (New Radio). */\n  NR: 'nr';\n\n  /** 5G NRNSA (New Radio Non-Standalone). */\n  NRNSA: 'nrnsa';\n\n  /** LTE CA. */\n  LTE_CA: 'lte_ca';\n};\n\n/**\n * The constant map of values for NetHostConnectionSubtypeValues.\n * @deprecated Use the NETHOSTCONNECTIONSUBTYPEVALUES_XXXXX constants rather than the NetHostConnectionSubtypeValues.XXXXX for bundle minification.\n */\nexport const NetHostConnectionSubtypeValues: NetHostConnectionSubtypeValues =\n  /*#__PURE__*/ createConstMap<NetHostConnectionSubtypeValues>([\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_GPRS,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EDGE,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_UMTS,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_CDMA,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_0,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_A,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_CDMA2000_1XRTT,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSDPA,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSUPA,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSPA,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_IDEN,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EVDO_B,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_LTE,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_EHRPD,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_HSPAP,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_GSM,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_TD_SCDMA,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_IWLAN,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_NR,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_NRNSA,\n    TMP_NETHOSTCONNECTIONSUBTYPEVALUES_LTE_CA,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for HttpFlavorValues enum definition\n *\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_HTTPFLAVORVALUES_HTTP_1_0 = '1.0';\nconst TMP_HTTPFLAVORVALUES_HTTP_1_1 = '1.1';\nconst TMP_HTTPFLAVORVALUES_HTTP_2_0 = '2.0';\nconst TMP_HTTPFLAVORVALUES_SPDY = 'SPDY';\nconst TMP_HTTPFLAVORVALUES_QUIC = 'QUIC';\n\n/**\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n *\n * @deprecated Use HTTP_FLAVOR_VALUE_HTTP_1_0 in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const HTTPFLAVORVALUES_HTTP_1_0 = TMP_HTTPFLAVORVALUES_HTTP_1_0;\n\n/**\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n *\n * @deprecated Use HTTP_FLAVOR_VALUE_HTTP_1_1 in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const HTTPFLAVORVALUES_HTTP_1_1 = TMP_HTTPFLAVORVALUES_HTTP_1_1;\n\n/**\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n *\n * @deprecated Use HTTP_FLAVOR_VALUE_HTTP_2_0 in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const HTTPFLAVORVALUES_HTTP_2_0 = TMP_HTTPFLAVORVALUES_HTTP_2_0;\n\n/**\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n *\n * @deprecated Use HTTP_FLAVOR_VALUE_SPDY in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const HTTPFLAVORVALUES_SPDY = TMP_HTTPFLAVORVALUES_SPDY;\n\n/**\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n *\n * @deprecated Use HTTP_FLAVOR_VALUE_QUIC in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const HTTPFLAVORVALUES_QUIC = TMP_HTTPFLAVORVALUES_QUIC;\n\n/**\n * Identifies the Values for HttpFlavorValues enum definition\n *\n * Kind of HTTP protocol used.\n *\n * Note: If `net.transport` is not specified, it can be assumed to be `IP.TCP` except if `http.flavor` is `QUIC`, in which case `IP.UDP` is assumed.\n * @deprecated Use the HTTPFLAVORVALUES_XXXXX constants rather than the HttpFlavorValues.XXXXX for bundle minification.\n */\nexport type HttpFlavorValues = {\n  /** HTTP 1.0. */\n  HTTP_1_0: '1.0';\n\n  /** HTTP 1.1. */\n  HTTP_1_1: '1.1';\n\n  /** HTTP 2. */\n  HTTP_2_0: '2.0';\n\n  /** SPDY protocol. */\n  SPDY: 'SPDY';\n\n  /** QUIC protocol. */\n  QUIC: 'QUIC';\n};\n\n/**\n * The constant map of values for HttpFlavorValues.\n * @deprecated Use the HTTPFLAVORVALUES_XXXXX constants rather than the HttpFlavorValues.XXXXX for bundle minification.\n */\nexport const HttpFlavorValues: HttpFlavorValues = {\n  HTTP_1_0: TMP_HTTPFLAVORVALUES_HTTP_1_0,\n  HTTP_1_1: TMP_HTTPFLAVORVALUES_HTTP_1_1,\n  HTTP_2_0: TMP_HTTPFLAVORVALUES_HTTP_2_0,\n  SPDY: TMP_HTTPFLAVORVALUES_SPDY,\n  QUIC: TMP_HTTPFLAVORVALUES_QUIC,\n};\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for MessagingDestinationKindValues enum definition\n *\n * The kind of message destination.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_MESSAGINGDESTINATIONKINDVALUES_QUEUE = 'queue';\nconst TMP_MESSAGINGDESTINATIONKINDVALUES_TOPIC = 'topic';\n\n/**\n * The kind of message destination.\n *\n * @deprecated Removed in semconv v1.20.0.\n */\nexport const MESSAGINGDESTINATIONKINDVALUES_QUEUE =\n  TMP_MESSAGINGDESTINATIONKINDVALUES_QUEUE;\n\n/**\n * The kind of message destination.\n *\n * @deprecated Removed in semconv v1.20.0.\n */\nexport const MESSAGINGDESTINATIONKINDVALUES_TOPIC =\n  TMP_MESSAGINGDESTINATIONKINDVALUES_TOPIC;\n\n/**\n * Identifies the Values for MessagingDestinationKindValues enum definition\n *\n * The kind of message destination.\n * @deprecated Use the MESSAGINGDESTINATIONKINDVALUES_XXXXX constants rather than the MessagingDestinationKindValues.XXXXX for bundle minification.\n */\nexport type MessagingDestinationKindValues = {\n  /** A message sent to a queue. */\n  QUEUE: 'queue';\n\n  /** A message sent to a topic. */\n  TOPIC: 'topic';\n};\n\n/**\n * The constant map of values for MessagingDestinationKindValues.\n * @deprecated Use the MESSAGINGDESTINATIONKINDVALUES_XXXXX constants rather than the MessagingDestinationKindValues.XXXXX for bundle minification.\n */\nexport const MessagingDestinationKindValues: MessagingDestinationKindValues =\n  /*#__PURE__*/ createConstMap<MessagingDestinationKindValues>([\n    TMP_MESSAGINGDESTINATIONKINDVALUES_QUEUE,\n    TMP_MESSAGINGDESTINATIONKINDVALUES_TOPIC,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for MessagingOperationValues enum definition\n *\n * A string identifying the kind of message consumption as defined in the [Operation names](#operation-names) section above. If the operation is &#34;send&#34;, this attribute MUST NOT be set, since the operation can be inferred from the span kind in that case.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_MESSAGINGOPERATIONVALUES_RECEIVE = 'receive';\nconst TMP_MESSAGINGOPERATIONVALUES_PROCESS = 'process';\n\n/**\n * A string identifying the kind of message consumption as defined in the [Operation names](#operation-names) section above. If the operation is &#34;send&#34;, this attribute MUST NOT be set, since the operation can be inferred from the span kind in that case.\n *\n * @deprecated Use MESSAGING_OPERATION_TYPE_VALUE_RECEIVE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const MESSAGINGOPERATIONVALUES_RECEIVE =\n  TMP_MESSAGINGOPERATIONVALUES_RECEIVE;\n\n/**\n * A string identifying the kind of message consumption as defined in the [Operation names](#operation-names) section above. If the operation is &#34;send&#34;, this attribute MUST NOT be set, since the operation can be inferred from the span kind in that case.\n *\n * @deprecated Use MESSAGING_OPERATION_TYPE_VALUE_PROCESS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const MESSAGINGOPERATIONVALUES_PROCESS =\n  TMP_MESSAGINGOPERATIONVALUES_PROCESS;\n\n/**\n * Identifies the Values for MessagingOperationValues enum definition\n *\n * A string identifying the kind of message consumption as defined in the [Operation names](#operation-names) section above. If the operation is &#34;send&#34;, this attribute MUST NOT be set, since the operation can be inferred from the span kind in that case.\n * @deprecated Use the MESSAGINGOPERATIONVALUES_XXXXX constants rather than the MessagingOperationValues.XXXXX for bundle minification.\n */\nexport type MessagingOperationValues = {\n  /** receive. */\n  RECEIVE: 'receive';\n\n  /** process. */\n  PROCESS: 'process';\n};\n\n/**\n * The constant map of values for MessagingOperationValues.\n * @deprecated Use the MESSAGINGOPERATIONVALUES_XXXXX constants rather than the MessagingOperationValues.XXXXX for bundle minification.\n */\nexport const MessagingOperationValues: MessagingOperationValues =\n  /*#__PURE__*/ createConstMap<MessagingOperationValues>([\n    TMP_MESSAGINGOPERATIONVALUES_RECEIVE,\n    TMP_MESSAGINGOPERATIONVALUES_PROCESS,\n  ]);\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for RpcGrpcStatusCodeValues enum definition\n *\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_RPCGRPCSTATUSCODEVALUES_OK = 0;\nconst TMP_RPCGRPCSTATUSCODEVALUES_CANCELLED = 1;\nconst TMP_RPCGRPCSTATUSCODEVALUES_UNKNOWN = 2;\nconst TMP_RPCGRPCSTATUSCODEVALUES_INVALID_ARGUMENT = 3;\nconst TMP_RPCGRPCSTATUSCODEVALUES_DEADLINE_EXCEEDED = 4;\nconst TMP_RPCGRPCSTATUSCODEVALUES_NOT_FOUND = 5;\nconst TMP_RPCGRPCSTATUSCODEVALUES_ALREADY_EXISTS = 6;\nconst TMP_RPCGRPCSTATUSCODEVALUES_PERMISSION_DENIED = 7;\nconst TMP_RPCGRPCSTATUSCODEVALUES_RESOURCE_EXHAUSTED = 8;\nconst TMP_RPCGRPCSTATUSCODEVALUES_FAILED_PRECONDITION = 9;\nconst TMP_RPCGRPCSTATUSCODEVALUES_ABORTED = 10;\nconst TMP_RPCGRPCSTATUSCODEVALUES_OUT_OF_RANGE = 11;\nconst TMP_RPCGRPCSTATUSCODEVALUES_UNIMPLEMENTED = 12;\nconst TMP_RPCGRPCSTATUSCODEVALUES_INTERNAL = 13;\nconst TMP_RPCGRPCSTATUSCODEVALUES_UNAVAILABLE = 14;\nconst TMP_RPCGRPCSTATUSCODEVALUES_DATA_LOSS = 15;\nconst TMP_RPCGRPCSTATUSCODEVALUES_UNAUTHENTICATED = 16;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_OK in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_OK = TMP_RPCGRPCSTATUSCODEVALUES_OK;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_CANCELLED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_CANCELLED =\n  TMP_RPCGRPCSTATUSCODEVALUES_CANCELLED;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_UNKNOWN in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_UNKNOWN =\n  TMP_RPCGRPCSTATUSCODEVALUES_UNKNOWN;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_INVALID_ARGUMENT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_INVALID_ARGUMENT =\n  TMP_RPCGRPCSTATUSCODEVALUES_INVALID_ARGUMENT;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_DEADLINE_EXCEEDED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_DEADLINE_EXCEEDED =\n  TMP_RPCGRPCSTATUSCODEVALUES_DEADLINE_EXCEEDED;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_NOT_FOUND in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_NOT_FOUND =\n  TMP_RPCGRPCSTATUSCODEVALUES_NOT_FOUND;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_ALREADY_EXISTS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_ALREADY_EXISTS =\n  TMP_RPCGRPCSTATUSCODEVALUES_ALREADY_EXISTS;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_PERMISSION_DENIED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_PERMISSION_DENIED =\n  TMP_RPCGRPCSTATUSCODEVALUES_PERMISSION_DENIED;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_RESOURCE_EXHAUSTED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_RESOURCE_EXHAUSTED =\n  TMP_RPCGRPCSTATUSCODEVALUES_RESOURCE_EXHAUSTED;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_FAILED_PRECONDITION in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_FAILED_PRECONDITION =\n  TMP_RPCGRPCSTATUSCODEVALUES_FAILED_PRECONDITION;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_ABORTED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_ABORTED =\n  TMP_RPCGRPCSTATUSCODEVALUES_ABORTED;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_OUT_OF_RANGE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_OUT_OF_RANGE =\n  TMP_RPCGRPCSTATUSCODEVALUES_OUT_OF_RANGE;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_UNIMPLEMENTED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_UNIMPLEMENTED =\n  TMP_RPCGRPCSTATUSCODEVALUES_UNIMPLEMENTED;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_INTERNAL in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_INTERNAL =\n  TMP_RPCGRPCSTATUSCODEVALUES_INTERNAL;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_UNAVAILABLE in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_UNAVAILABLE =\n  TMP_RPCGRPCSTATUSCODEVALUES_UNAVAILABLE;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_DATA_LOSS in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_DATA_LOSS =\n  TMP_RPCGRPCSTATUSCODEVALUES_DATA_LOSS;\n\n/**\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n *\n * @deprecated Use RPC_GRPC_STATUS_CODE_VALUE_UNAUTHENTICATED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const RPCGRPCSTATUSCODEVALUES_UNAUTHENTICATED =\n  TMP_RPCGRPCSTATUSCODEVALUES_UNAUTHENTICATED;\n\n/**\n * Identifies the Values for RpcGrpcStatusCodeValues enum definition\n *\n * The [numeric status code](https://github.com/grpc/grpc/blob/v1.33.2/doc/statuscodes.md) of the gRPC request.\n * @deprecated Use the RPCGRPCSTATUSCODEVALUES_XXXXX constants rather than the RpcGrpcStatusCodeValues.XXXXX for bundle minification.\n */\nexport type RpcGrpcStatusCodeValues = {\n  /** OK. */\n  OK: 0;\n\n  /** CANCELLED. */\n  CANCELLED: 1;\n\n  /** UNKNOWN. */\n  UNKNOWN: 2;\n\n  /** INVALID_ARGUMENT. */\n  INVALID_ARGUMENT: 3;\n\n  /** DEADLINE_EXCEEDED. */\n  DEADLINE_EXCEEDED: 4;\n\n  /** NOT_FOUND. */\n  NOT_FOUND: 5;\n\n  /** ALREADY_EXISTS. */\n  ALREADY_EXISTS: 6;\n\n  /** PERMISSION_DENIED. */\n  PERMISSION_DENIED: 7;\n\n  /** RESOURCE_EXHAUSTED. */\n  RESOURCE_EXHAUSTED: 8;\n\n  /** FAILED_PRECONDITION. */\n  FAILED_PRECONDITION: 9;\n\n  /** ABORTED. */\n  ABORTED: 10;\n\n  /** OUT_OF_RANGE. */\n  OUT_OF_RANGE: 11;\n\n  /** UNIMPLEMENTED. */\n  UNIMPLEMENTED: 12;\n\n  /** INTERNAL. */\n  INTERNAL: 13;\n\n  /** UNAVAILABLE. */\n  UNAVAILABLE: 14;\n\n  /** DATA_LOSS. */\n  DATA_LOSS: 15;\n\n  /** UNAUTHENTICATED. */\n  UNAUTHENTICATED: 16;\n};\n\n/**\n * The constant map of values for RpcGrpcStatusCodeValues.\n * @deprecated Use the RPCGRPCSTATUSCODEVALUES_XXXXX constants rather than the RpcGrpcStatusCodeValues.XXXXX for bundle minification.\n */\nexport const RpcGrpcStatusCodeValues: RpcGrpcStatusCodeValues = {\n  OK: TMP_RPCGRPCSTATUSCODEVALUES_OK,\n  CANCELLED: TMP_RPCGRPCSTATUSCODEVALUES_CANCELLED,\n  UNKNOWN: TMP_RPCGRPCSTATUSCODEVALUES_UNKNOWN,\n  INVALID_ARGUMENT: TMP_RPCGRPCSTATUSCODEVALUES_INVALID_ARGUMENT,\n  DEADLINE_EXCEEDED: TMP_RPCGRPCSTATUSCODEVALUES_DEADLINE_EXCEEDED,\n  NOT_FOUND: TMP_RPCGRPCSTATUSCODEVALUES_NOT_FOUND,\n  ALREADY_EXISTS: TMP_RPCGRPCSTATUSCODEVALUES_ALREADY_EXISTS,\n  PERMISSION_DENIED: TMP_RPCGRPCSTATUSCODEVALUES_PERMISSION_DENIED,\n  RESOURCE_EXHAUSTED: TMP_RPCGRPCSTATUSCODEVALUES_RESOURCE_EXHAUSTED,\n  FAILED_PRECONDITION: TMP_RPCGRPCSTATUSCODEVALUES_FAILED_PRECONDITION,\n  ABORTED: TMP_RPCGRPCSTATUSCODEVALUES_ABORTED,\n  OUT_OF_RANGE: TMP_RPCGRPCSTATUSCODEVALUES_OUT_OF_RANGE,\n  UNIMPLEMENTED: TMP_RPCGRPCSTATUSCODEVALUES_UNIMPLEMENTED,\n  INTERNAL: TMP_RPCGRPCSTATUSCODEVALUES_INTERNAL,\n  UNAVAILABLE: TMP_RPCGRPCSTATUSCODEVALUES_UNAVAILABLE,\n  DATA_LOSS: TMP_RPCGRPCSTATUSCODEVALUES_DATA_LOSS,\n  UNAUTHENTICATED: TMP_RPCGRPCSTATUSCODEVALUES_UNAUTHENTICATED,\n};\n\n/* ----------------------------------------------------------------------------------------------------------\n * Constant values for MessageTypeValues enum definition\n *\n * Whether this is a received or sent message.\n * ---------------------------------------------------------------------------------------------------------- */\n\n// Temporary local constants to assign to the individual exports and the namespaced version\n// Required to avoid the namespace exports using the unminifiable export names for some package types\nconst TMP_MESSAGETYPEVALUES_SENT = 'SENT';\nconst TMP_MESSAGETYPEVALUES_RECEIVED = 'RECEIVED';\n\n/**\n * Whether this is a received or sent message.\n *\n * @deprecated Use MESSAGE_TYPE_VALUE_SENT in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const MESSAGETYPEVALUES_SENT = TMP_MESSAGETYPEVALUES_SENT;\n\n/**\n * Whether this is a received or sent message.\n *\n * @deprecated Use MESSAGE_TYPE_VALUE_RECEIVED in [incubating entry-point]({@link https://github.com/open-telemetry/opentelemetry-js/blob/main/semantic-conventions/README.md#unstable-semconv}).\n */\nexport const MESSAGETYPEVALUES_RECEIVED = TMP_MESSAGETYPEVALUES_RECEIVED;\n\n/**\n * Identifies the Values for MessageTypeValues enum definition\n *\n * Whether this is a received or sent message.\n * @deprecated Use the MESSAGETYPEVALUES_XXXXX constants rather than the MessageTypeValues.XXXXX for bundle minification.\n */\nexport type MessageTypeValues = {\n  /** sent. */\n  SENT: 'SENT';\n\n  /** received. */\n  RECEIVED: 'RECEIVED';\n};\n\n/**\n * The constant map of values for MessageTypeValues.\n * @deprecated Use the MESSAGETYPEVALUES_XXXXX constants rather than the MessageTypeValues.XXXXX for bundle minification.\n */\nexport const MessageTypeValues: MessageTypeValues =\n  /*#__PURE__*/ createConstMap<MessageTypeValues>([\n    TMP_MESSAGETYPEVALUES_SENT,\n    TMP_MESSAGETYPEVALUES_RECEIVED,\n  ]);\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEH,OAAO,EAAE,cAAc,EAAE,MAAM,mBAAmB,CAAC;;AAEnD,4GAA4G;AAC5G,iHAAiH;AACjH,4GAA4G;AAE5G,4GAA4G;AAC5G,yCAAyC;AACzC,4GAA4G;AAE5G,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,0BAA0B,GAAG,wBAAwB,CAAC;AAC5D,MAAM,aAAa,GAAG,WAAW,CAAC;AAClC,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,WAAW,GAAG,SAAS,CAAC;AAC9B,MAAM,4BAA4B,GAAG,0BAA0B,CAAC;AAChE,MAAM,WAAW,GAAG,SAAS,CAAC;AAC9B,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,0BAA0B,GAAG,wBAAwB,CAAC;AAC5D,MAAM,yBAAyB,GAAG,uBAAuB,CAAC;AAC1D,MAAM,0BAA0B,GAAG,wBAAwB,CAAC;AAC5D,MAAM,kCAAkC,GAAG,gCAAgC,CAAC;AAC5E,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,4BAA4B,GAAG,0BAA0B,CAAC;AAChE,MAAM,4CAA4C,GAChD,0CAA0C,CAAC;AAC7C,MAAM,+BAA+B,GAAG,6BAA6B,CAAC;AACtE,MAAM,+BAA+B,GAAG,6BAA6B,CAAC;AACtE,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,2BAA2B,GAAG,yBAAyB,CAAC;AAC9D,MAAM,yBAAyB,GAAG,uBAAuB,CAAC;AAC1D,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,kBAAkB,GAAG,gBAAgB,CAAC;AAC5C,MAAM,qBAAqB,GAAG,mBAAmB,CAAC;AAClD,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,qBAAqB,GAAG,mBAAmB,CAAC;AAClD,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,kBAAkB,GAAG,gBAAgB,CAAC;AAC5C,MAAM,4BAA4B,GAAG,0BAA0B,CAAC;AAChE,MAAM,2BAA2B,GAAG,yBAAyB,CAAC;AAC9D,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,aAAa,GAAG,WAAW,CAAC;AAClC,MAAM,aAAa,GAAG,WAAW,CAAC;AAClC,MAAM,kBAAkB,GAAG,gBAAgB,CAAC;AAC5C,MAAM,qBAAqB,GAAG,mBAAmB,CAAC;AAClD,MAAM,yBAAyB,GAAG,uBAAuB,CAAC;AAC1D,MAAM,uBAAuB,GAAG,qBAAqB,CAAC;AACtD,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,4BAA4B,GAAG,0BAA0B,CAAC;AAChE,MAAM,+BAA+B,GAAG,6BAA6B,CAAC;AACtE,MAAM,yBAAyB,GAAG,uBAAuB,CAAC;AAC1D,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,cAAc,GAAG,YAAY,CAAC;AACpC,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,aAAa,GAAG,WAAW,CAAC;AAClC,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,kBAAkB,GAAG,gBAAgB,CAAC;AAC5C,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,YAAY,GAAG,UAAU,CAAC;AAChC,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,aAAa,GAAG,WAAW,CAAC;AAClC,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,oBAAoB,GAAG,kBAAkB,CAAC;AAChD,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,mBAAmB,GAAG,iBAAiB,CAAC;AAC9C,MAAM,+BAA+B,GAAG,6BAA6B,CAAC;AACtE,MAAM,4CAA4C,GAChD,0CAA0C,CAAC;AAC7C,MAAM,gCAAgC,GAAG,8BAA8B,CAAC;AACxE,MAAM,6CAA6C,GACjD,2CAA2C,CAAC;AAC9C,MAAM,oBAAoB,GAAG,kBAAkB,CAAC;AAChD,MAAM,cAAc,GAAG,YAAY,CAAC;AACpC,MAAM,kBAAkB,GAAG,gBAAgB,CAAC;AAC5C,MAAM,4BAA4B,GAAG,0BAA0B,CAAC;AAChE,MAAM,kCAAkC,GAAG,gCAAgC,CAAC;AAC5E,MAAM,wCAAwC,GAC5C,sCAAsC,CAAC;AACzC,MAAM,0CAA0C,GAC9C,wCAAwC,CAAC;AAC3C,MAAM,2CAA2C,GAC/C,yCAAyC,CAAC;AAC5C,MAAM,gCAAgC,GAAG,8BAA8B,CAAC;AACxE,MAAM,2BAA2B,GAAG,yBAAyB,CAAC;AAC9D,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,kCAAkC,GAAG,gCAAgC,CAAC;AAC5E,MAAM,2BAA2B,GAAG,yBAAyB,CAAC;AAC9D,MAAM,uBAAuB,GAAG,qBAAqB,CAAC;AACtD,MAAM,yCAAyC,GAC7C,uCAAuC,CAAC;AAC1C,MAAM,wCAAwC,GAC5C,sCAAsC,CAAC;AACzC,MAAM,sCAAsC,GAC1C,oCAAoC,CAAC;AACvC,MAAM,4BAA4B,GAAG,0BAA0B,CAAC;AAChE,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAClE,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,+BAA+B,GAAG,6BAA6B,CAAC;AACtE,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,8BAA8B,GAAG,4BAA4B,CAAC;AACpE,MAAM,sCAAsC,GAC1C,oCAAoC,CAAC;AACvC,MAAM,+CAA+C,GACnD,6CAA6C,CAAC;AAChD,MAAM,oBAAoB,GAAG,kBAAkB,CAAC;AAChD,MAAM,yBAAyB,GAAG,uBAAuB,CAAC;AAC1D,MAAM,8BAA8B,GAAG,4BAA4B,CAAC;AACpE,MAAM,8BAA8B,GAAG,4BAA4B,CAAC;AACpE,MAAM,sBAAsB,GAAG,oBAAoB,CAAC;AACpD,MAAM,8BAA8B,GAAG,4BAA4B,CAAC;AACpE,MAAM,iBAAiB,GAAG,eAAe,CAAC;AAC1C,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAClE,MAAM,wCAAwC,GAC5C,sCAAsC,CAAC;AACzC,MAAM,mDAAmD,GACvD,iDAAiD,CAAC;AACpD,MAAM,uBAAuB,GAAG,qBAAqB,CAAC;AACtD,MAAM,yBAAyB,GAAG,uBAAuB,CAAC;AAC1D,MAAM,kCAAkC,GAAG,gCAAgC,CAAC;AAC5E,MAAM,+BAA+B,GAAG,6BAA6B,CAAC;AACtE,MAAM,kCAAkC,GAAG,gCAAgC,CAAC;AAC5E,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAClE,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAClE,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAClE,MAAM,cAAc,GAAG,YAAY,CAAC;AACpC,MAAM,eAAe,GAAG,aAAa,CAAC;AACtC,MAAM,cAAc,GAAG,YAAY,CAAC;AACpC,MAAM,wBAAwB,GAAG,sBAAsB,CAAC;AACxD,MAAM,uBAAuB,GAAG,qBAAqB,CAAC;AACtD,MAAM,0BAA0B,GAAG,wBAAwB,CAAC;AAC5D,MAAM,0BAA0B,GAAG,wBAAwB,CAAC;AAC5D,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAClE,MAAM,gBAAgB,GAAG,cAAc,CAAC;AACxC,MAAM,cAAc,GAAG,YAAY,CAAC;AACpC,MAAM,2BAA2B,GAAG,yBAAyB,CAAC;AAC9D,MAAM,6BAA6B,GAAG,2BAA2B,CAAC;AAS3D,MAAM,+BAA+B,GAAG,0BAA0B,CAAC;AAOnE,MAAM,kBAAkB,GAAG,aAAa,CAAC;AAOzC,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,gBAAgB,GAAG,WAAW,CAAC;AAOrC,MAAM,iCAAiC,GAAG,4BAA4B,CAAC;AASvE,MAAM,gBAAgB,GAAG,WAAW,CAAC;AASrC,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAS/C,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAS/C,MAAM,+BAA+B,GAAG,0BAA0B,CAAC;AAOnE,MAAM,8BAA8B,GAAG,yBAAyB,CAAC;AAOjE,MAAM,+BAA+B,GAAG,0BAA0B,CAAC;AAOnE,MAAM,uCAAuC,GAClD,kCAAkC,CAAC;AAS9B,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,iCAAiC,GAAG,4BAA4B,CAAC;AAOvE,MAAM,iDAAiD,GAC5D,4CAA4C,CAAC;AAOxC,MAAM,oCAAoC,GAC/C,+BAA+B,CAAC;AAO3B,MAAM,oCAAoC,GAC/C,+BAA+B,CAAC;AAO3B,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,gCAAgC,GAAG,2BAA2B,CAAC;AAOrE,MAAM,8BAA8B,GAAG,yBAAyB,CAAC;AASjE,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAO/C,MAAM,uBAAuB,GAAG,kBAAkB,CAAC;AAOnD,MAAM,0BAA0B,GAAG,qBAAqB,CAAC;AAOzD,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAwB/D,MAAM,0BAA0B,GAAG,qBAAqB,CAAC;AAOzD,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAO/C,MAAM,uBAAuB,GAAG,kBAAkB,CAAC;AAOnD,MAAM,iCAAiC,GAAG,4BAA4B,CAAC;AAOvE,MAAM,gCAAgC,GAAG,2BAA2B,CAAC;AAOrE,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,kBAAkB,GAAG,aAAa,CAAC;AAOzC,MAAM,kBAAkB,GAAG,aAAa,CAAC;AAOzC,MAAM,uBAAuB,GAAG,kBAAkB,CAAC;AASnD,MAAM,0BAA0B,GAAG,qBAAqB,CAAC;AASzD,MAAM,8BAA8B,GAAG,yBAAyB,CAAC;AASjE,MAAM,4BAA4B,GAAG,uBAAuB,CAAC;AAO7D,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAO7C,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAO7C,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,iCAAiC,GAAG,4BAA4B,CAAC;AAOvE,MAAM,oCAAoC,GAC/C,+BAA+B,CAAC;AAO3B,MAAM,8BAA8B,GAAG,yBAAyB,CAAC;AAOjE,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAO/C,MAAM,mBAAmB,GAAG,cAAc,CAAC;AAO3C,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAO/C,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,kBAAkB,GAAG,aAAa,CAAC;AAOzC,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAO7C,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,uBAAuB,GAAG,kBAAkB,CAAC;AAOnD,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAO7C,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAS7C,MAAM,iBAAiB,GAAG,YAAY,CAAC;AAOvC,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAS7C,MAAM,kBAAkB,GAAG,aAAa,CAAC;AAOzC,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAO7C,MAAM,yBAAyB,GAAG,oBAAoB,CAAC;AASvD,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAO7C,MAAM,wBAAwB,GAAG,mBAAmB,CAAC;AAOrD,MAAM,oCAAoC,GAC/C,+BAA+B,CAAC;AAO3B,MAAM,iDAAiD,GAC5D,4CAA4C,CAAC;AAOxC,MAAM,qCAAqC,GAChD,gCAAgC,CAAC;AAO5B,MAAM,kDAAkD,GAC7D,6CAA6C,CAAC;AASzC,MAAM,yBAAyB,GAAG,oBAAoB,CAAC;AAOvD,MAAM,mBAAmB,GAAG,cAAc,CAAC;AAmB3C,MAAM,uBAAuB,GAAG,kBAAkB,CAAC;AAOnD,MAAM,iCAAiC,GAAG,4BAA4B,CAAC;AAOvE,MAAM,uCAAuC,GAClD,kCAAkC,CAAC;AAO9B,MAAM,6CAA6C,GACxD,wCAAwC,CAAC;AAOpC,MAAM,+CAA+C,GAC1D,0CAA0C,CAAC;AAOtC,MAAM,gDAAgD,GAC3D,2CAA2C,CAAC;AAOvC,MAAM,qCAAqC,GAChD,gCAAgC,CAAC;AAO5B,MAAM,gCAAgC,GAAG,2BAA2B,CAAC;AAOrE,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,uCAAuC,GAClD,kCAAkC,CAAC;AAO9B,MAAM,gCAAgC,GAAG,2BAA2B,CAAC;AAOrE,MAAM,4BAA4B,GAAG,uBAAuB,CAAC;AAO7D,MAAM,8CAA8C,GACzD,yCAAyC,CAAC;AAOrC,MAAM,6CAA6C,GACxD,wCAAwC,CAAC;AAOpC,MAAM,2CAA2C,GACtD,sCAAsC,CAAC;AAOlC,MAAM,iCAAiC,GAAG,4BAA4B,CAAC;AAOvE,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAOzE,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,oCAAoC,GAC/C,+BAA+B,CAAC;AAO3B,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,mCAAmC,GAC9C,8BAA8B,CAAC;AAO1B,MAAM,2CAA2C,GACtD,sCAAsC,CAAC;AAOlC,MAAM,oDAAoD,GAC/D,+CAA+C,CAAC;AAO3C,MAAM,yBAAyB,GAAG,oBAAoB,CAAC;AAOvD,MAAM,8BAA8B,GAAG,yBAAyB,CAAC;AAOjE,MAAM,mCAAmC,GAC9C,8BAA8B,CAAC;AAO1B,MAAM,mCAAmC,GAC9C,8BAA8B,CAAC;AAO1B,MAAM,2BAA2B,GAAG,sBAAsB,CAAC;AAO3D,MAAM,mCAAmC,GAC9C,8BAA8B,CAAC;AAO1B,MAAM,sBAAsB,GAAG,iBAAiB,CAAC;AAOjD,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAOzE,MAAM,6CAA6C,GACxD,wCAAwC,CAAC;AAOpC,MAAM,wDAAwD,GACnE,mDAAmD,CAAC;AAO/C,MAAM,4BAA4B,GAAG,uBAAuB,CAAC;AAO7D,MAAM,8BAA8B,GAAG,yBAAyB,CAAC;AAOjE,MAAM,uCAAuC,GAClD,kCAAkC,CAAC;AAS9B,MAAM,oCAAoC,GAC/C,+BAA+B,CAAC;AAO3B,MAAM,uCAAuC,GAClD,kCAAkC,CAAC;AAO9B,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAOzE,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAOzE,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAOzE,MAAM,mBAAmB,GAAG,cAAc,CAAC;AAS3C,MAAM,oBAAoB,GAAG,eAAe,CAAC;AAS7C,MAAM,mBAAmB,GAAG,cAAc,CAAC;AAO3C,MAAM,6BAA6B,GAAG,wBAAwB,CAAC;AAO/D,MAAM,4BAA4B,GAAG,uBAAuB,CAAC;AAO7D,MAAM,+BAA+B,GAAG,0BAA0B,CAAC;AAOnE,MAAM,+BAA+B,GAAG,0BAA0B,CAAC;AAOnE,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAOzE,MAAM,qBAAqB,GAAG,gBAAgB,CAAC;AAS/C,MAAM,mBAAmB,GAAG,cAAc,CAAC;AAO3C,MAAM,gCAAgC,GAAG,2BAA2B,CAAC;AAOrE,MAAM,kCAAkC,GAAG,6BAA6B,CAAC;AAgtBzE,MAAM,kBAAkB,GAC7B,WAAA,EAAa,KAAC,yNAAc,EAAqB;IAC/C,0BAA0B;IAC1B,aAAa;IACb,wBAAwB;IACxB,WAAW;IACX,4BAA4B;IAC5B,WAAW;IACX,gBAAgB;IAChB,gBAAgB;IAChB,0BAA0B;IAC1B,yBAAyB;IACzB,0BAA0B;IAC1B,kCAAkC;IAClC,sBAAsB;IACtB,4BAA4B;IAC5B,4CAA4C;IAC5C,+BAA+B;IAC/B,+BAA+B;IAC/B,sBAAsB;IACtB,2BAA2B;IAC3B,yBAAyB;IACzB,gBAAgB;IAChB,kBAAkB;IAClB,qBAAqB;IACrB,wBAAwB;IACxB,qBAAqB;IACrB,gBAAgB;IAChB,kBAAkB;IAClB,4BAA4B;IAC5B,2BAA2B;IAC3B,sBAAsB;IACtB,sBAAsB;IACtB,aAAa;IACb,aAAa;IACb,kBAAkB;IAClB,qBAAqB;IACrB,yBAAyB;IACzB,uBAAuB;IACvB,iBAAiB;IACjB,eAAe;IACf,iBAAiB;IACjB,iBAAiB;IACjB,eAAe;IACf,iBAAiB;IACjB,iBAAiB;IACjB,4BAA4B;IAC5B,+BAA+B;IAC/B,yBAAyB;IACzB,wBAAwB;IACxB,wBAAwB;IACxB,wBAAwB;IACxB,gBAAgB;IAChB,cAAc;IACd,gBAAgB;IAChB,iBAAiB;IACjB,aAAa;IACb,eAAe;IACf,iBAAiB;IACjB,kBAAkB;IAClB,iBAAiB;IACjB,eAAe;IACf,eAAe;IACf,YAAY;IACZ,eAAe;IACf,aAAa;IACb,eAAe;IACf,oBAAoB;IACpB,eAAe;IACf,mBAAmB;IACnB,+BAA+B;IAC/B,4CAA4C;IAC5C,gCAAgC;IAChC,6CAA6C;IAC7C,oBAAoB;IACpB,cAAc;IACd,kBAAkB;IAClB,4BAA4B;IAC5B,kCAAkC;IAClC,wCAAwC;IACxC,0CAA0C;IAC1C,2CAA2C;IAC3C,gCAAgC;IAChC,2BAA2B;IAC3B,sBAAsB;IACtB,kCAAkC;IAClC,2BAA2B;IAC3B,uBAAuB;IACvB,yCAAyC;IACzC,wCAAwC;IACxC,sCAAsC;IACtC,4BAA4B;IAC5B,6BAA6B;IAC7B,wBAAwB;IACxB,+BAA+B;IAC/B,sBAAsB;IACtB,8BAA8B;IAC9B,sCAAsC;IACtC,+CAA+C;IAC/C,oBAAoB;IACpB,yBAAyB;IACzB,8BAA8B;IAC9B,8BAA8B;IAC9B,sBAAsB;IACtB,8BAA8B;IAC9B,iBAAiB;IACjB,wBAAwB;IACxB,6BAA6B;IAC7B,wCAAwC;IACxC,mDAAmD;IACnD,uBAAuB;IACvB,yBAAyB;IACzB,kCAAkC;IAClC,+BAA+B;IAC/B,kCAAkC;IAClC,6BAA6B;IAC7B,6BAA6B;IAC7B,6BAA6B;IAC7B,cAAc;IACd,eAAe;IACf,cAAc;IACd,wBAAwB;IACxB,uBAAuB;IACvB,0BAA0B;IAC1B,0BAA0B;IAC1B,6BAA6B;IAC7B,gBAAgB;IAChB,cAAc;IACd,2BAA2B;IAC3B,6BAA6B;CAC9B,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,sBAAsB,GAAG,KAAK,CAAC;AACrC,MAAM,6BAA6B,GAAG,YAAY,CAAC;AACnD,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,uBAAuB,GAAG,MAAM,CAAC;AACvC,MAAM,6BAA6B,GAAG,YAAY,CAAC;AACnD,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,sBAAsB,GAAG,KAAK,CAAC;AACrC,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,0BAA0B,GAAG,SAAS,CAAC;AAC7C,MAAM,0BAA0B,GAAG,SAAS,CAAC;AAC7C,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,yBAAyB,GAAG,QAAQ,CAAC;AAC3C,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,0BAA0B,GAAG,SAAS,CAAC;AAC7C,MAAM,qBAAqB,GAAG,IAAI,CAAC;AACnC,MAAM,6BAA6B,GAAG,YAAY,CAAC;AACnD,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,0BAA0B,GAAG,SAAS,CAAC;AAC7C,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,0BAA0B,GAAG,SAAS,CAAC;AAC7C,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,2BAA2B,GAAG,UAAU,CAAC;AAC/C,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,wBAAwB,GAAG,OAAO,CAAC;AACzC,MAAM,gCAAgC,GAAG,eAAe,CAAC;AACzD,MAAM,4BAA4B,GAAG,WAAW,CAAC;AACjD,MAAM,8BAA8B,GAAG,aAAa,CAAC;AAO9C,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,kBAAkB,GAAG,sBAAsB,CAAC;AAOlD,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAOhE,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,mBAAmB,GAAG,uBAAuB,CAAC;AAOpD,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAOhE,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,kBAAkB,GAAG,sBAAsB,CAAC;AAOlD,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,iBAAiB,GAAG,qBAAqB,CAAC;AAOhD,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAOhE,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,oBAAoB,GAAG,wBAAwB,CAAC;AAOtD,MAAM,4BAA4B,GAAG,gCAAgC,CAAC;AAOtE,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,0BAA0B,GAAG,8BAA8B,CAAC;AA2JlE,MAAM,cAAc,GACzB,WAAA,EAAa,KAAC,yNAAc,EAAiB;IAC3C,4BAA4B;IAC5B,wBAAwB;IACxB,wBAAwB;IACxB,yBAAyB;IACzB,sBAAsB;IACtB,6BAA6B;IAC7B,2BAA2B;IAC3B,uBAAuB;IACvB,6BAA6B;IAC7B,yBAAyB;IACzB,2BAA2B;IAC3B,wBAAwB;IACxB,yBAAyB;IACzB,yBAAyB;IACzB,2BAA2B;IAC3B,sBAAsB;IACtB,wBAAwB;IACxB,yBAAyB;IACzB,2BAA2B;IAC3B,wBAAwB;IACxB,4BAA4B;IAC5B,2BAA2B;IAC3B,4BAA4B;IAC5B,4BAA4B;IAC5B,0BAA0B;IAC1B,0BAA0B;IAC1B,4BAA4B;IAC5B,4BAA4B;IAC5B,yBAAyB;IACzB,yBAAyB;IACzB,2BAA2B;IAC3B,0BAA0B;IAC1B,qBAAqB;IACrB,6BAA6B;IAC7B,4BAA4B;IAC5B,wBAAwB;IACxB,0BAA0B;IAC1B,wBAAwB;IACxB,4BAA4B;IAC5B,0BAA0B;IAC1B,2BAA2B;IAC3B,2BAA2B;IAC3B,wBAAwB;IACxB,wBAAwB;IACxB,gCAAgC;IAChC,4BAA4B;IAC5B,8BAA8B;CAC/B,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,yCAAyC,GAAG,KAAK,CAAC;AACxD,MAAM,iDAAiD,GAAG,aAAa,CAAC;AACxE,MAAM,4CAA4C,GAAG,QAAQ,CAAC;AAC9D,MAAM,kDAAkD,GAAG,cAAc,CAAC;AAC1E,MAAM,yCAAyC,GAAG,KAAK,CAAC;AACxD,MAAM,yCAAyC,GAAG,KAAK,CAAC;AACxD,MAAM,2CAA2C,GAAG,OAAO,CAAC;AAC5D,MAAM,+CAA+C,GAAG,WAAW,CAAC;AACpE,MAAM,yCAAyC,GAAG,KAAK,CAAC;AACxD,MAAM,4CAA4C,GAAG,QAAQ,CAAC;AAC9D,MAAM,kDAAkD,GAAG,cAAc,CAAC;AAOnE,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,6CAA6C,GACxD,iDAAiD,CAAC;AAO7C,MAAM,wCAAwC,GACnD,4CAA4C,CAAC;AAOxC,MAAM,8CAA8C,GACzD,kDAAkD,CAAC;AAO9C,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,uCAAuC,GAClD,2CAA2C,CAAC;AAOvC,MAAM,2CAA2C,GACtD,+CAA+C,CAAC;AAO3C,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,wCAAwC,GACnD,4CAA4C,CAAC;AAOxC,MAAM,8CAA8C,GACzD,kDAAkD,CAAC;AA+C9C,MAAM,iCAAiC,GAC5C,WAAA,EAAa,KAAC,yNAAc,EAAoC;IAC9D,yCAAyC;IACzC,iDAAiD;IACjD,4CAA4C;IAC5C,kDAAkD;IAClD,yCAAyC;IACzC,yCAAyC;IACzC,2CAA2C;IAC3C,+CAA+C;IAC/C,yCAAyC;IACzC,4CAA4C;IAC5C,kDAAkD;CACnD,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,gCAAgC,GAAG,YAAY,CAAC;AACtD,MAAM,0BAA0B,GAAG,MAAM,CAAC;AAC1C,MAAM,4BAA4B,GAAG,QAAQ,CAAC;AAC9C,MAAM,2BAA2B,GAAG,OAAO,CAAC;AAC5C,MAAM,2BAA2B,GAAG,OAAO,CAAC;AAOrC,MAAM,4BAA4B,GAAG,gCAAgC,CAAC;AAOtE,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAO9D,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AA6B5D,MAAM,iBAAiB,GAC5B,WAAA,EAAa,KAAC,yNAAc,EAAoB;IAC9C,gCAAgC;IAChC,0BAA0B;IAC1B,4BAA4B;IAC5B,2BAA2B;IAC3B,2BAA2B;CAC5B,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,sCAAsC,GAAG,QAAQ,CAAC;AACxD,MAAM,oCAAoC,GAAG,MAAM,CAAC;AACpD,MAAM,sCAAsC,GAAG,QAAQ,CAAC;AAOjD,MAAM,kCAAkC,GAC7C,sCAAsC,CAAC;AAOlC,MAAM,gCAAgC,GAC3C,oCAAoC,CAAC;AAOhC,MAAM,kCAAkC,GAC7C,sCAAsC,CAAC;AAuBlC,MAAM,2BAA2B,GACtC,WAAA,EAAa,KAAC,yNAAc,EAA8B;IACxD,sCAAsC;IACtC,oCAAoC;IACpC,sCAAsC;CACvC,CAAC,CAAC;AAEL;;;;;;gHAMgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,2CAA2C,GAAG,eAAe,CAAC;AACpE,MAAM,iCAAiC,GAAG,KAAK,CAAC;AAChD,MAAM,mCAAmC,GAAG,OAAO,CAAC;AACpD,MAAM,iCAAiC,GAAG,KAAK,CAAC;AASzC,MAAM,uCAAuC,GAClD,2CAA2C,CAAC;AASvC,MAAM,6BAA6B,GAAG,iCAAiC,CAAC;AASxE,MAAM,+BAA+B,GAC1C,mCAAmC,CAAC;AAS/B,MAAM,6BAA6B,GAAG,iCAAiC,CAAC;AA4BxE,MAAM,yBAAyB,GACpC,WAAA,EAAa,KAAC,yNAAc,EAA4B;IACtD,2CAA2C;IAC3C,iCAAiC;IACjC,mCAAmC;IACnC,iCAAiC;CAClC,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,6BAA6B,GAAG,QAAQ,CAAC;AAC/C,MAAM,6BAA6B,GAAG,QAAQ,CAAC;AAC/C,MAAM,yBAAyB,GAAG,IAAI,CAAC;AACvC,MAAM,2BAA2B,GAAG,MAAM,CAAC;AAC3C,MAAM,2BAA2B,GAAG,MAAM,CAAC;AAC3C,MAAM,6BAA6B,GAAG,QAAQ,CAAC;AAC/C,MAAM,4BAA4B,GAAG,OAAO,CAAC;AAOtC,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAOhE,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAOhE,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AAOxD,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,uBAAuB,GAAG,2BAA2B,CAAC;AAO5D,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAOhE,MAAM,wBAAwB,GAAG,4BAA4B,CAAC;AAmC9D,MAAM,kBAAkB,GAC7B,WAAA,EAAa,KAAC,yNAAc,EAAqB;IAC/C,6BAA6B;IAC7B,6BAA6B;IAC7B,yBAAyB;IACzB,2BAA2B;IAC3B,2BAA2B;IAC3B,6BAA6B;IAC7B,4BAA4B;CAC7B,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,oCAAoC,GAAG,MAAM,CAAC;AACpD,MAAM,qCAAqC,GAAG,OAAO,CAAC;AACtD,MAAM,oCAAoC,GAAG,MAAM,CAAC;AACpD,MAAM,2CAA2C,GAAG,aAAa,CAAC;AAClE,MAAM,uCAAuC,GAAG,SAAS,CAAC;AAOnD,MAAM,gCAAgC,GAC3C,oCAAoC,CAAC;AAOhC,MAAM,iCAAiC,GAC5C,qCAAqC,CAAC;AAOjC,MAAM,gCAAgC,GAC3C,oCAAoC,CAAC;AAOhC,MAAM,uCAAuC,GAClD,2CAA2C,CAAC;AAOvC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AA6BnC,MAAM,2BAA2B,GACtC,WAAA,EAAa,KAAC,yNAAc,EAA8B;IACxD,oCAAoC;IACpC,qCAAqC;IACrC,oCAAoC;IACpC,2CAA2C;IAC3C,uCAAuC;CACxC,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,uCAAuC,GAAG,MAAM,CAAC;AACvD,MAAM,uCAAuC,GAAG,MAAM,CAAC;AACvD,MAAM,uCAAuC,GAAG,MAAM,CAAC;AACvD,MAAM,uCAAuC,GAAG,MAAM,CAAC;AACvD,MAAM,yCAAyC,GAAG,QAAQ,CAAC;AAC3D,MAAM,yCAAyC,GAAG,QAAQ,CAAC;AAC3D,MAAM,iDAAiD,GAAG,gBAAgB,CAAC;AAC3E,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,uCAAuC,GAAG,MAAM,CAAC;AACvD,MAAM,uCAAuC,GAAG,MAAM,CAAC;AACvD,MAAM,yCAAyC,GAAG,QAAQ,CAAC;AAC3D,MAAM,sCAAsC,GAAG,KAAK,CAAC;AACrD,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,sCAAsC,GAAG,KAAK,CAAC;AACrD,MAAM,2CAA2C,GAAG,UAAU,CAAC;AAC/D,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,qCAAqC,GAAG,IAAI,CAAC;AACnD,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,yCAAyC,GAAG,QAAQ,CAAC;AAOpD,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,6CAA6C,GACxD,iDAAiD,CAAC;AAO7C,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,kCAAkC,GAC7C,sCAAsC,CAAC;AAOlC,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,kCAAkC,GAC7C,sCAAsC,CAAC;AAOlC,MAAM,uCAAuC,GAClD,2CAA2C,CAAC;AAOvC,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,iCAAiC,GAC5C,qCAAqC,CAAC;AAOjC,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AA6ErC,MAAM,8BAA8B,GACzC,WAAA,EAAa,KAAC,yNAAc,EAAiC;IAC3D,uCAAuC;IACvC,uCAAuC;IACvC,uCAAuC;IACvC,uCAAuC;IACvC,yCAAyC;IACzC,yCAAyC;IACzC,iDAAiD;IACjD,wCAAwC;IACxC,wCAAwC;IACxC,uCAAuC;IACvC,uCAAuC;IACvC,yCAAyC;IACzC,sCAAsC;IACtC,wCAAwC;IACxC,wCAAwC;IACxC,sCAAsC;IACtC,2CAA2C;IAC3C,wCAAwC;IACxC,qCAAqC;IACrC,wCAAwC;IACxC,yCAAyC;CAC1C,CAAC,CAAC;AAEL;;;;;;gHAMgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,6BAA6B,GAAG,KAAK,CAAC;AAC5C,MAAM,6BAA6B,GAAG,KAAK,CAAC;AAC5C,MAAM,6BAA6B,GAAG,KAAK,CAAC;AAC5C,MAAM,yBAAyB,GAAG,MAAM,CAAC;AACzC,MAAM,yBAAyB,GAAG,MAAM,CAAC;AASlC,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAShE,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAShE,MAAM,yBAAyB,GAAG,6BAA6B,CAAC;AAShE,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AASxD,MAAM,qBAAqB,GAAG,yBAAyB,CAAC;AA+BxD,MAAM,gBAAgB,GAAqB;IAChD,QAAQ,EAAE,6BAA6B;IACvC,QAAQ,EAAE,6BAA6B;IACvC,QAAQ,EAAE,6BAA6B;IACvC,IAAI,EAAE,yBAAyB;IAC/B,IAAI,EAAE,yBAAyB;CAChC,CAAC;AAEF;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,wCAAwC,GAAG,OAAO,CAAC;AACzD,MAAM,wCAAwC,GAAG,OAAO,CAAC;AAOlD,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAoBpC,MAAM,8BAA8B,GACzC,WAAA,EAAa,KAAC,yNAAc,EAAiC;IAC3D,wCAAwC;IACxC,wCAAwC;CACzC,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,oCAAoC,GAAG,SAAS,CAAC;AACvD,MAAM,oCAAoC,GAAG,SAAS,CAAC;AAOhD,MAAM,gCAAgC,GAC3C,oCAAoC,CAAC;AAOhC,MAAM,gCAAgC,GAC3C,oCAAoC,CAAC;AAoBhC,MAAM,wBAAwB,GACnC,WAAA,EAAa,KAAC,yNAAc,EAA2B;IACrD,oCAAoC;IACpC,oCAAoC;CACrC,CAAC,CAAC;AAEL;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,8BAA8B,GAAG,CAAC,CAAC;AACzC,MAAM,qCAAqC,GAAG,CAAC,CAAC;AAChD,MAAM,mCAAmC,GAAG,CAAC,CAAC;AAC9C,MAAM,4CAA4C,GAAG,CAAC,CAAC;AACvD,MAAM,6CAA6C,GAAG,CAAC,CAAC;AACxD,MAAM,qCAAqC,GAAG,CAAC,CAAC;AAChD,MAAM,0CAA0C,GAAG,CAAC,CAAC;AACrD,MAAM,6CAA6C,GAAG,CAAC,CAAC;AACxD,MAAM,8CAA8C,GAAG,CAAC,CAAC;AACzD,MAAM,+CAA+C,GAAG,CAAC,CAAC;AAC1D,MAAM,mCAAmC,GAAG,EAAE,CAAC;AAC/C,MAAM,wCAAwC,GAAG,EAAE,CAAC;AACpD,MAAM,yCAAyC,GAAG,EAAE,CAAC;AACrD,MAAM,oCAAoC,GAAG,EAAE,CAAC;AAChD,MAAM,uCAAuC,GAAG,EAAE,CAAC;AACnD,MAAM,qCAAqC,GAAG,EAAE,CAAC;AACjD,MAAM,2CAA2C,GAAG,EAAE,CAAC;AAOhD,MAAM,0BAA0B,GAAG,8BAA8B,CAAC;AAOlE,MAAM,iCAAiC,GAC5C,qCAAqC,CAAC;AAOjC,MAAM,+BAA+B,GAC1C,mCAAmC,CAAC;AAO/B,MAAM,wCAAwC,GACnD,4CAA4C,CAAC;AAOxC,MAAM,yCAAyC,GACpD,6CAA6C,CAAC;AAOzC,MAAM,iCAAiC,GAC5C,qCAAqC,CAAC;AAOjC,MAAM,sCAAsC,GACjD,0CAA0C,CAAC;AAOtC,MAAM,yCAAyC,GACpD,6CAA6C,CAAC;AAOzC,MAAM,0CAA0C,GACrD,8CAA8C,CAAC;AAO1C,MAAM,2CAA2C,GACtD,+CAA+C,CAAC;AAO3C,MAAM,+BAA+B,GAC1C,mCAAmC,CAAC;AAO/B,MAAM,oCAAoC,GAC/C,wCAAwC,CAAC;AAOpC,MAAM,qCAAqC,GAChD,yCAAyC,CAAC;AAOrC,MAAM,gCAAgC,GAC3C,oCAAoC,CAAC;AAOhC,MAAM,mCAAmC,GAC9C,uCAAuC,CAAC;AAOnC,MAAM,iCAAiC,GAC5C,qCAAqC,CAAC;AAOjC,MAAM,uCAAuC,GAClD,2CAA2C,CAAC;AAiEvC,MAAM,uBAAuB,GAA4B;IAC9D,EAAE,EAAE,8BAA8B;IAClC,SAAS,EAAE,qCAAqC;IAChD,OAAO,EAAE,mCAAmC;IAC5C,gBAAgB,EAAE,4CAA4C;IAC9D,iBAAiB,EAAE,6CAA6C;IAChE,SAAS,EAAE,qCAAqC;IAChD,cAAc,EAAE,0CAA0C;IAC1D,iBAAiB,EAAE,6CAA6C;IAChE,kBAAkB,EAAE,8CAA8C;IAClE,mBAAmB,EAAE,+CAA+C;IACpE,OAAO,EAAE,mCAAmC;IAC5C,YAAY,EAAE,wCAAwC;IACtD,aAAa,EAAE,yCAAyC;IACxD,QAAQ,EAAE,oCAAoC;IAC9C,WAAW,EAAE,uCAAuC;IACpD,SAAS,EAAE,qCAAqC;IAChD,eAAe,EAAE,2CAA2C;CAC7D,CAAC;AAEF;;;;gHAIgH,CAEhH,2FAA2F;AAC3F,qGAAqG;AACrG,MAAM,0BAA0B,GAAG,MAAM,CAAC;AAC1C,MAAM,8BAA8B,GAAG,UAAU,CAAC;AAO3C,MAAM,sBAAsB,GAAG,0BAA0B,CAAC;AAO1D,MAAM,0BAA0B,GAAG,8BAA8B,CAAC;AAoBlE,MAAM,iBAAiB,GAC5B,WAAA,EAAa,KAAC,yNAAc,EAAoB;IAC9C,0BAA0B;IAC1B,8BAA8B;CAC/B,CAAC,CAAC"}},
    {"offset": {"line": 8435, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/internal/validators.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/internal/validators.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nconst VALID_KEY_CHAR_RANGE = '[_0-9a-z-*/]';\nconst VALID_KEY = `[a-z]${VALID_KEY_CHAR_RANGE}{0,255}`;\nconst VALID_VENDOR_KEY = `[a-z0-9]${VALID_KEY_CHAR_RANGE}{0,240}@[a-z]${VALID_KEY_CHAR_RANGE}{0,13}`;\nconst VALID_KEY_REGEX = new RegExp(`^(?:${VALID_KEY}|${VALID_VENDOR_KEY})$`);\nconst VALID_VALUE_BASE_REGEX = /^[ -~]{0,255}[!-~]$/;\nconst INVALID_VALUE_COMMA_EQUAL_REGEX = /,|=/;\n\n/**\n * Key is opaque string up to 256 characters printable. It MUST begin with a\n * lowercase letter, and can only contain lowercase letters a-z, digits 0-9,\n * underscores _, dashes -, asterisks *, and forward slashes /.\n * For multi-tenant vendor scenarios, an at sign (@) can be used to prefix the\n * vendor name. Vendors SHOULD set the tenant ID at the beginning of the key.\n * see https://www.w3.org/TR/trace-context/#key\n */\nexport function validateKey(key: string): boolean {\n  return VALID_KEY_REGEX.test(key);\n}\n\n/**\n * Value is opaque string up to 256 characters printable ASCII RFC0020\n * characters (i.e., the range 0x20 to 0x7E) except comma , and =.\n */\nexport function validateValue(value: string): boolean {\n  return (\n    VALID_VALUE_BASE_REGEX.test(value) &&\n    !INVALID_VALUE_COMMA_EQUAL_REGEX.test(value)\n  );\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;AAEH,MAAM,oBAAoB,GAAG,cAAc,CAAC;AAC5C,MAAM,SAAS,GAAG,CAAA,KAAA,EAAQ,oBAAoB,CAAA,OAAA,CAAS,CAAC;AACxD,MAAM,gBAAgB,GAAG,CAAA,QAAA,EAAW,oBAAoB,CAAA,aAAA,EAAgB,oBAAoB,CAAA,MAAA,CAAQ,CAAC;AACrG,MAAM,eAAe,GAAG,IAAI,MAAM,CAAC,CAAA,IAAA,EAAO,SAAS,CAAA,CAAA,EAAI,gBAAgB,CAAA,EAAA,CAAI,CAAC,CAAC;AAC7E,MAAM,sBAAsB,GAAG,qBAAqB,CAAC;AACrD,MAAM,+BAA+B,GAAG,KAAK,CAAC;AAUxC,SAAU,WAAW,CAAC,GAAW;IACrC,OAAO,eAAe,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;AACnC,CAAC;AAMK,SAAU,aAAa,CAAC,KAAa;IACzC,OAAO,AACL,sBAAsB,CAAC,IAAI,CAAC,KAAK,CAAC,IAClC,CAAC,+BAA+B,CAAC,IAAI,CAAC,KAAK,CAAC,CAC7C,CAAC;AACJ,CAAC"}},
    {"offset": {"line": 8471, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/trace/TraceState.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/trace/TraceState.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '@opentelemetry/api';\nimport { validateKey, validateValue } from '../internal/validators';\n\nconst MAX_TRACE_STATE_ITEMS = 32;\nconst MAX_TRACE_STATE_LEN = 512;\nconst LIST_MEMBERS_SEPARATOR = ',';\nconst LIST_MEMBER_KEY_VALUE_SPLITTER = '=';\n\n/**\n * TraceState must be a class and not a simple object type because of the spec\n * requirement (https://www.w3.org/TR/trace-context/#tracestate-field).\n *\n * Here is the list of allowed mutations:\n * - New key-value pair should be added into the beginning of the list\n * - The value of any key can be updated. Modified keys MUST be moved to the\n * beginning of the list.\n */\nexport class TraceState implements api.TraceState {\n  private _internalState: Map<string, string> = new Map();\n\n  constructor(rawTraceState?: string) {\n    if (rawTraceState) this._parse(rawTraceState);\n  }\n\n  set(key: string, value: string): TraceState {\n    // TODO: Benchmark the different approaches(map vs list) and\n    // use the faster one.\n    const traceState = this._clone();\n    if (traceState._internalState.has(key)) {\n      traceState._internalState.delete(key);\n    }\n    traceState._internalState.set(key, value);\n    return traceState;\n  }\n\n  unset(key: string): TraceState {\n    const traceState = this._clone();\n    traceState._internalState.delete(key);\n    return traceState;\n  }\n\n  get(key: string): string | undefined {\n    return this._internalState.get(key);\n  }\n\n  serialize(): string {\n    return this._keys()\n      .reduce((agg: string[], key) => {\n        agg.push(key + LIST_MEMBER_KEY_VALUE_SPLITTER + this.get(key));\n        return agg;\n      }, [])\n      .join(LIST_MEMBERS_SEPARATOR);\n  }\n\n  private _parse(rawTraceState: string) {\n    if (rawTraceState.length > MAX_TRACE_STATE_LEN) return;\n    this._internalState = rawTraceState\n      .split(LIST_MEMBERS_SEPARATOR)\n      .reverse() // Store in reverse so new keys (.set(...)) will be placed at the beginning\n      .reduce((agg: Map<string, string>, part: string) => {\n        const listMember = part.trim(); // Optional Whitespace (OWS) handling\n        const i = listMember.indexOf(LIST_MEMBER_KEY_VALUE_SPLITTER);\n        if (i !== -1) {\n          const key = listMember.slice(0, i);\n          const value = listMember.slice(i + 1, part.length);\n          if (validateKey(key) && validateValue(value)) {\n            agg.set(key, value);\n          } else {\n            // TODO: Consider to add warning log\n          }\n        }\n        return agg;\n      }, new Map());\n\n    // Because of the reverse() requirement, trunc must be done after map is created\n    if (this._internalState.size > MAX_TRACE_STATE_ITEMS) {\n      this._internalState = new Map(\n        Array.from(this._internalState.entries())\n          .reverse() // Use reverse same as original tracestate parse chain\n          .slice(0, MAX_TRACE_STATE_ITEMS)\n      );\n    }\n  }\n\n  private _keys(): string[] {\n    return Array.from(this._internalState.keys()).reverse();\n  }\n\n  private _clone(): TraceState {\n    const traceState = new TraceState();\n    traceState._internalState = new Map(this._internalState);\n    return traceState;\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;AAGH,OAAO,EAAE,WAAW,EAAE,aAAa,EAAE,MAAM,wBAAwB,CAAC;;AAEpE,MAAM,qBAAqB,GAAG,EAAE,CAAC;AACjC,MAAM,mBAAmB,GAAG,GAAG,CAAC;AAChC,MAAM,sBAAsB,GAAG,GAAG,CAAC;AACnC,MAAM,8BAA8B,GAAG,GAAG,CAAC;AAWrC,MAAO,UAAU;IACb,cAAc,GAAwB,IAAI,GAAG,EAAE,CAAC;IAExD,YAAY,aAAsB,CAAA;QAChC,IAAI,aAAa,EAAE,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,CAAC;IAChD,CAAC;IAED,GAAG,CAAC,GAAW,EAAE,KAAa,EAAA;QAC5B,4DAA4D;QAC5D,sBAAsB;QACtB,MAAM,UAAU,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC;QACjC,IAAI,UAAU,CAAC,cAAc,CAAC,GAAG,CAAC,GAAG,CAAC,EAAE;YACtC,UAAU,CAAC,cAAc,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;SACvC;QACD,UAAU,CAAC,cAAc,CAAC,GAAG,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;QAC1C,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,KAAK,CAAC,GAAW,EAAA;QACf,MAAM,UAAU,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC;QACjC,UAAU,CAAC,cAAc,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC;QACtC,OAAO,UAAU,CAAC;IACpB,CAAC;IAED,GAAG,CAAC,GAAW,EAAA;QACb,OAAO,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IACtC,CAAC;IAED,SAAS,GAAA;QACP,OAAO,IAAI,CAAC,KAAK,EAAE,CAChB,MAAM,CAAC,CAAC,GAAa,EAAE,GAAG,EAAE,EAAE;YAC7B,GAAG,CAAC,IAAI,CAAC,GAAG,GAAG,8BAA8B,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;YAC/D,OAAO,GAAG,CAAC;QACb,CAAC,EAAE,EAAE,CAAC,CACL,IAAI,CAAC,sBAAsB,CAAC,CAAC;IAClC,CAAC;IAEO,MAAM,CAAC,aAAqB,EAAA;QAClC,IAAI,aAAa,CAAC,MAAM,GAAG,mBAAmB,EAAE,OAAO;QACvD,IAAI,CAAC,cAAc,GAAG,aAAa,CAChC,KAAK,CAAC,sBAAsB,CAAC,CAC7B,OAAO,EAAE,CAAC,2EAA2E;SACrF,MAAM,CAAC,CAAC,GAAwB,EAAE,IAAY,EAAE,EAAE;YACjD,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,qCAAqC;YACrE,MAAM,CAAC,GAAG,UAAU,CAAC,OAAO,CAAC,8BAA8B,CAAC,CAAC;YAC7D,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;gBACZ,MAAM,GAAG,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBACnC,MAAM,KAAK,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;gBACnD,QAAI,wMAAW,EAAC,GAAG,CAAC,QAAI,0MAAa,EAAC,KAAK,CAAC,EAAE;oBAC5C,GAAG,CAAC,GAAG,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;iBACrB,MAAM;gBACL,oCAAoC;iBACrC;aACF;YACD,OAAO,GAAG,CAAC;QACb,CAAC,EAAE,IAAI,GAAG,EAAE,CAAC,CAAC;QAEhB,gFAAgF;QAChF,IAAI,IAAI,CAAC,cAAc,CAAC,IAAI,GAAG,qBAAqB,EAAE;YACpD,IAAI,CAAC,cAAc,GAAG,IAAI,GAAG,CAC3B,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,cAAc,CAAC,OAAO,EAAE,CAAC,CACtC,OAAO,EAAE,CAAC,sDAAsD;aAChE,KAAK,CAAC,CAAC,EAAE,qBAAqB,CAAC,CACnC,CAAC;SACH;IACH,CAAC;IAEO,KAAK,GAAA;QACX,OAAO,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,cAAc,CAAC,IAAI,EAAE,CAAC,CAAC,OAAO,EAAE,CAAC;IAC1D,CAAC;IAEO,MAAM,GAAA;QACZ,MAAM,UAAU,GAAG,IAAI,UAAU,EAAE,CAAC;QACpC,UAAU,CAAC,cAAc,GAAG,IAAI,GAAG,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACzD,OAAO,UAAU,CAAC;IACpB,CAAC;CACF"}},
    {"offset": {"line": 8560, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/trace/suppress-tracing.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/trace/suppress-tracing.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Context, createContextKey } from '@opentelemetry/api';\n\nconst SUPPRESS_TRACING_KEY = createContextKey(\n  'OpenTelemetry SDK Context Key SUPPRESS_TRACING'\n);\n\nexport function suppressTracing(context: Context): Context {\n  return context.setValue(SUPPRESS_TRACING_KEY, true);\n}\n\nexport function unsuppressTracing(context: Context): Context {\n  return context.deleteValue(SUPPRESS_TRACING_KEY);\n}\n\nexport function isTracingSuppressed(context: Context): boolean {\n  return context.getValue(SUPPRESS_TRACING_KEY) === true;\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;;;AAEH,OAAO,EAAW,gBAAgB,EAAE,MAAM,oBAAoB,CAAC;;AAE/D,MAAM,oBAAoB,OAAG,wMAAgB,EAC3C,gDAAgD,CACjD,CAAC;AAEI,SAAU,eAAe,CAAC,OAAgB;IAC9C,OAAO,OAAO,CAAC,QAAQ,CAAC,oBAAoB,EAAE,IAAI,CAAC,CAAC;AACtD,CAAC;AAEK,SAAU,iBAAiB,CAAC,OAAgB;IAChD,OAAO,OAAO,CAAC,WAAW,CAAC,oBAAoB,CAAC,CAAC;AACnD,CAAC;AAEK,SAAU,mBAAmB,CAAC,OAAgB;IAClD,OAAO,OAAO,CAAC,QAAQ,CAAC,oBAAoB,CAAC,KAAK,IAAI,CAAC;AACzD,CAAC"}},
    {"offset": {"line": 8598, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/baggage/constants.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/baggage/constants.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport const BAGGAGE_KEY_PAIR_SEPARATOR = '=';\nexport const BAGGAGE_PROPERTIES_SEPARATOR = ';';\nexport const BAGGAGE_ITEMS_SEPARATOR = ',';\n\n// Name of the http header used to propagate the baggage\nexport const BAGGAGE_HEADER = 'baggage';\n// Maximum number of name-value pairs allowed by w3c spec\nexport const BAGGAGE_MAX_NAME_VALUE_PAIRS = 180;\n// Maximum number of bytes per a single name-value pair allowed by w3c spec\nexport const BAGGAGE_MAX_PER_NAME_VALUE_PAIRS = 4096;\n// Maximum total length of all name-value pairs allowed by w3c spec\nexport const BAGGAGE_MAX_TOTAL_LENGTH = 8192;\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;;;;;;;;;;;AAEI,MAAM,0BAA0B,GAAG,GAAG,CAAC;AACvC,MAAM,4BAA4B,GAAG,GAAG,CAAC;AACzC,MAAM,uBAAuB,GAAG,GAAG,CAAC;AAGpC,MAAM,cAAc,GAAG,SAAS,CAAC;AAEjC,MAAM,4BAA4B,GAAG,GAAG,CAAC;AAEzC,MAAM,gCAAgC,GAAG,IAAI,CAAC;AAE9C,MAAM,wBAAwB,GAAG,IAAI,CAAC"}},
    {"offset": {"line": 8639, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/baggage/utils.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/baggage/utils.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport {\n  Baggage,\n  BaggageEntryMetadata,\n  baggageEntryMetadataFromString,\n} from '@opentelemetry/api';\nimport {\n  BAGGAGE_ITEMS_SEPARATOR,\n  BAGGAGE_PROPERTIES_SEPARATOR,\n  BAGGAGE_KEY_PAIR_SEPARATOR,\n  BAGGAGE_MAX_TOTAL_LENGTH,\n} from './constants';\n\ntype ParsedBaggageKeyValue = {\n  key: string;\n  value: string;\n  metadata: BaggageEntryMetadata | undefined;\n};\n\nexport function serializeKeyPairs(keyPairs: string[]): string {\n  return keyPairs.reduce((hValue: string, current: string) => {\n    const value = `${hValue}${\n      hValue !== '' ? BAGGAGE_ITEMS_SEPARATOR : ''\n    }${current}`;\n    return value.length > BAGGAGE_MAX_TOTAL_LENGTH ? hValue : value;\n  }, '');\n}\n\nexport function getKeyPairs(baggage: Baggage): string[] {\n  return baggage.getAllEntries().map(([key, value]) => {\n    let entry = `${encodeURIComponent(key)}=${encodeURIComponent(value.value)}`;\n\n    // include opaque metadata if provided\n    // NOTE: we intentionally don't URI-encode the metadata - that responsibility falls on the metadata implementation\n    if (value.metadata !== undefined) {\n      entry += BAGGAGE_PROPERTIES_SEPARATOR + value.metadata.toString();\n    }\n\n    return entry;\n  });\n}\n\nexport function parsePairKeyValue(\n  entry: string\n): ParsedBaggageKeyValue | undefined {\n  const valueProps = entry.split(BAGGAGE_PROPERTIES_SEPARATOR);\n  if (valueProps.length <= 0) return;\n  const keyPairPart = valueProps.shift();\n  if (!keyPairPart) return;\n  const separatorIndex = keyPairPart.indexOf(BAGGAGE_KEY_PAIR_SEPARATOR);\n  if (separatorIndex <= 0) return;\n  const key = decodeURIComponent(\n    keyPairPart.substring(0, separatorIndex).trim()\n  );\n  const value = decodeURIComponent(\n    keyPairPart.substring(separatorIndex + 1).trim()\n  );\n  let metadata;\n  if (valueProps.length > 0) {\n    metadata = baggageEntryMetadataFromString(\n      valueProps.join(BAGGAGE_PROPERTIES_SEPARATOR)\n    );\n  }\n  return { key, value, metadata };\n}\n\n/**\n * Parse a string serialized in the baggage HTTP Format (without metadata):\n * https://github.com/w3c/baggage/blob/master/baggage/HTTP_HEADER_FORMAT.md\n */\nexport function parseKeyPairsIntoRecord(\n  value?: string\n): Record<string, string> {\n  const result: Record<string, string> = {};\n\n  if (typeof value === 'string' && value.length > 0) {\n    value.split(BAGGAGE_ITEMS_SEPARATOR).forEach(entry => {\n      const keyPair = parsePairKeyValue(entry);\n\n      if (keyPair !== undefined && keyPair.value.length > 0) {\n        result[keyPair.key] = keyPair.value;\n      }\n    });\n  }\n\n  return result;\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;;;;;AACH,OAAO,EAGL,8BAA8B,GAC/B,MAAM,oBAAoB,CAAC;AAC5B,OAAO,EACL,uBAAuB,EACvB,4BAA4B,EAC5B,0BAA0B,EAC1B,wBAAwB,GACzB,MAAM,aAAa,CAAC;;;AAQf,SAAU,iBAAiB,CAAC,QAAkB;IAClD,OAAO,QAAQ,CAAC,MAAM,CAAC,CAAC,MAAc,EAAE,OAAe,EAAE,EAAE;QACzD,MAAM,KAAK,GAAG,GAAG,MAAM,GACrB,MAAM,KAAK,EAAE,CAAC,CAAC,CAAC,kNAAuB,CAAC,CAAC,CAAC,EAC5C,GAAG,OAAO,EAAE,CAAC;QACb,OAAO,KAAK,CAAC,MAAM,GAAG,mNAAwB,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC;IAClE,CAAC,EAAE,EAAE,CAAC,CAAC;AACT,CAAC;AAEK,SAAU,WAAW,CAAC,OAAgB;IAC1C,OAAO,OAAO,CAAC,aAAa,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,EAAE,KAAK,CAAC,EAAE,EAAE;QAClD,IAAI,KAAK,GAAG,GAAG,kBAAkB,CAAC,GAAG,CAAC,CAAA,CAAA,EAAI,kBAAkB,CAAC,KAAK,CAAC,KAAK,CAAC,EAAE,CAAC;QAE5E,sCAAsC;QACtC,kHAAkH;QAClH,IAAI,KAAK,CAAC,QAAQ,KAAK,SAAS,EAAE;YAChC,KAAK,IAAI,uNAA4B,GAAG,KAAK,CAAC,QAAQ,CAAC,QAAQ,EAAE,CAAC;SACnE;QAED,OAAO,KAAK,CAAC;IACf,CAAC,CAAC,CAAC;AACL,CAAC;AAEK,SAAU,iBAAiB,CAC/B,KAAa;IAEb,MAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC,uNAA4B,CAAC,CAAC;IAC7D,IAAI,UAAU,CAAC,MAAM,IAAI,CAAC,EAAE,OAAO;IACnC,MAAM,WAAW,GAAG,UAAU,CAAC,KAAK,EAAE,CAAC;IACvC,IAAI,CAAC,WAAW,EAAE,OAAO;IACzB,MAAM,cAAc,GAAG,WAAW,CAAC,OAAO,CAAC,qNAA0B,CAAC,CAAC;IACvE,IAAI,cAAc,IAAI,CAAC,EAAE,OAAO;IAChC,MAAM,GAAG,GAAG,kBAAkB,CAC5B,WAAW,CAAC,SAAS,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC,IAAI,EAAE,CAChD,CAAC;IACF,MAAM,KAAK,GAAG,kBAAkB,CAC9B,WAAW,CAAC,SAAS,CAAC,cAAc,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,CACjD,CAAC;IACF,IAAI,QAAQ,CAAC;IACb,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;QACzB,QAAQ,OAAG,oNAA8B,EACvC,UAAU,CAAC,IAAI,CAAC,uNAA4B,CAAC,CAC9C,CAAC;KACH;IACD,OAAO;QAAE,GAAG;QAAE,KAAK;QAAE,QAAQ;IAAA,CAAE,CAAC;AAClC,CAAC;AAMK,SAAU,uBAAuB,CACrC,KAAc;IAEd,MAAM,MAAM,GAA2B,CAAA,CAAE,CAAC;IAE1C,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;QACjD,KAAK,CAAC,KAAK,CAAC,kNAAuB,CAAC,CAAC,OAAO,EAAC,KAAK,CAAC,EAAE;YACnD,MAAM,OAAO,GAAG,iBAAiB,CAAC,KAAK,CAAC,CAAC;YAEzC,IAAI,OAAO,KAAK,SAAS,IAAI,OAAO,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;gBACrD,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,OAAO,CAAC,KAAK,CAAC;aACrC;QACH,CAAC,CAAC,CAAC;KACJ;IAED,OAAO,MAAM,CAAC;AAChB,CAAC"}},
    {"offset": {"line": 8719, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/baggage/propagation/W3CBaggagePropagator.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/baggage/propagation/W3CBaggagePropagator.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  BaggageEntry,\n  Context,\n  propagation,\n  TextMapGetter,\n  TextMapPropagator,\n  TextMapSetter,\n} from '@opentelemetry/api';\n\nimport { isTracingSuppressed } from '../../trace/suppress-tracing';\nimport {\n  BAGGAGE_HEADER,\n  BAGGAGE_ITEMS_SEPARATOR,\n  BAGGAGE_MAX_NAME_VALUE_PAIRS,\n  BAGGAGE_MAX_PER_NAME_VALUE_PAIRS,\n} from '../constants';\nimport { getKeyPairs, parsePairKeyValue, serializeKeyPairs } from '../utils';\n\n/**\n * Propagates {@link Baggage} through Context format propagation.\n *\n * Based on the Baggage specification:\n * https://w3c.github.io/baggage/\n */\nexport class W3CBaggagePropagator implements TextMapPropagator {\n  inject(context: Context, carrier: unknown, setter: TextMapSetter): void {\n    const baggage = propagation.getBaggage(context);\n    if (!baggage || isTracingSuppressed(context)) return;\n    const keyPairs = getKeyPairs(baggage)\n      .filter((pair: string) => {\n        return pair.length <= BAGGAGE_MAX_PER_NAME_VALUE_PAIRS;\n      })\n      .slice(0, BAGGAGE_MAX_NAME_VALUE_PAIRS);\n    const headerValue = serializeKeyPairs(keyPairs);\n    if (headerValue.length > 0) {\n      setter.set(carrier, BAGGAGE_HEADER, headerValue);\n    }\n  }\n\n  extract(context: Context, carrier: unknown, getter: TextMapGetter): Context {\n    const headerValue = getter.get(carrier, BAGGAGE_HEADER);\n    const baggageString = Array.isArray(headerValue)\n      ? headerValue.join(BAGGAGE_ITEMS_SEPARATOR)\n      : headerValue;\n    if (!baggageString) return context;\n    const baggage: Record<string, BaggageEntry> = {};\n    if (baggageString.length === 0) {\n      return context;\n    }\n    const pairs = baggageString.split(BAGGAGE_ITEMS_SEPARATOR);\n    pairs.forEach(entry => {\n      const keyPair = parsePairKeyValue(entry);\n      if (keyPair) {\n        const baggageEntry: BaggageEntry = { value: keyPair.value };\n        if (keyPair.metadata) {\n          baggageEntry.metadata = keyPair.metadata;\n        }\n        baggage[keyPair.key] = baggageEntry;\n      }\n    });\n    if (Object.entries(baggage).length === 0) {\n      return context;\n    }\n    return propagation.setBaggage(context, propagation.createBaggage(baggage));\n  }\n\n  fields(): string[] {\n    return [BAGGAGE_HEADER];\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;AAEH,OAAO,EAGL,WAAW,GAIZ,MAAM,oBAAoB,CAAC;AAE5B,OAAO,EAAE,mBAAmB,EAAE,MAAM,8BAA8B,CAAC;AACnE,OAAO,EACL,cAAc,EACd,uBAAuB,EACvB,4BAA4B,EAC5B,gCAAgC,GACjC,MAAM,cAAc,CAAC;AACtB,OAAO,EAAE,WAAW,EAAE,iBAAiB,EAAE,iBAAiB,EAAE,MAAM,UAAU,CAAC;;;;;AAQvE,MAAO,oBAAoB;IAC/B,MAAM,CAAC,OAAgB,EAAE,OAAgB,EAAE,MAAqB,EAAA;QAC9D,MAAM,OAAO,GAAG,mMAAW,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC;QAChD,IAAI,CAAC,OAAO,QAAI,sNAAmB,EAAC,OAAO,CAAC,EAAE,OAAO;QACrD,MAAM,QAAQ,OAAG,kMAAW,EAAC,OAAO,CAAC,CAClC,MAAM,CAAC,CAAC,IAAY,EAAE,EAAE;YACvB,OAAO,IAAI,CAAC,MAAM,IAAI,2NAAgC,CAAC;QACzD,CAAC,CAAC,CACD,KAAK,CAAC,CAAC,EAAE,uNAA4B,CAAC,CAAC;QAC1C,MAAM,WAAW,OAAG,wMAAiB,EAAC,QAAQ,CAAC,CAAC;QAChD,IAAI,WAAW,CAAC,MAAM,GAAG,CAAC,EAAE;YAC1B,MAAM,CAAC,GAAG,CAAC,OAAO,EAAE,yMAAc,EAAE,WAAW,CAAC,CAAC;SAClD;IACH,CAAC;IAED,OAAO,CAAC,OAAgB,EAAE,OAAgB,EAAE,MAAqB,EAAA;QAC/D,MAAM,WAAW,GAAG,MAAM,CAAC,GAAG,CAAC,OAAO,EAAE,yMAAc,CAAC,CAAC;QACxD,MAAM,aAAa,GAAG,KAAK,CAAC,OAAO,CAAC,WAAW,CAAC,GAC5C,WAAW,CAAC,IAAI,CAAC,kNAAuB,CAAC,GACzC,WAAW,CAAC;QAChB,IAAI,CAAC,aAAa,EAAE,OAAO,OAAO,CAAC;QACnC,MAAM,OAAO,GAAiC,CAAA,CAAE,CAAC;QACjD,IAAI,aAAa,CAAC,MAAM,KAAK,CAAC,EAAE;YAC9B,OAAO,OAAO,CAAC;SAChB;QACD,MAAM,KAAK,GAAG,aAAa,CAAC,KAAK,CAAC,kNAAuB,CAAC,CAAC;QAC3D,KAAK,CAAC,OAAO,EAAC,KAAK,CAAC,EAAE;YACpB,MAAM,OAAO,OAAG,wMAAiB,EAAC,KAAK,CAAC,CAAC;YACzC,IAAI,OAAO,EAAE;gBACX,MAAM,YAAY,GAAiB;oBAAE,KAAK,EAAE,OAAO,CAAC,KAAK;gBAAA,CAAE,CAAC;gBAC5D,IAAI,OAAO,CAAC,QAAQ,EAAE;oBACpB,YAAY,CAAC,QAAQ,GAAG,OAAO,CAAC,QAAQ,CAAC;iBAC1C;gBACD,OAAO,CAAC,OAAO,CAAC,GAAG,CAAC,GAAG,YAAY,CAAC;aACrC;QACH,CAAC,CAAC,CAAC;QACH,IAAI,MAAM,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YACxC,OAAO,OAAO,CAAC;SAChB;QACD,OAAO,mMAAW,CAAC,UAAU,CAAC,OAAO,EAAE,mMAAW,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC,CAAC;IAC7E,CAAC;IAED,MAAM,GAAA;QACJ,OAAO;YAAC,yMAAc;SAAC,CAAC;IAC1B,CAAC;CACF"}},
    {"offset": {"line": 8793, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/version.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/version.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// this is autogenerated file, see scripts/version-update.js\nexport const VERSION = '2.2.0';\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG,CAEH,4DAA4D;;;;;AACrD,MAAM,OAAO,GAAG,OAAO,CAAC"}},
    {"offset": {"line": 8817, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/semconv.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/semconv.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/*\n * This file contains a copy of unstable semantic convention definitions\n * used by this package.\n * @see https://github.com/open-telemetry/opentelemetry-js/tree/main/semantic-conventions#unstable-semconv\n */\n\n/**\n * The name of the runtime of this process.\n *\n * @example OpenJDK Runtime Environment\n *\n * @experimental This attribute is experimental and is subject to breaking changes in minor releases of `@opentelemetry/semantic-conventions`.\n */\nexport const ATTR_PROCESS_RUNTIME_NAME = 'process.runtime.name' as const;\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG,CAEH;;;;GAIG,CAEH;;;;;;GAMG;;;;AACI,MAAM,yBAAyB,GAAG,sBAA+B,CAAC"}},
    {"offset": {"line": 8850, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/core/build/esm/platform/browser/sdk-info.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/core/src/platform/browser/sdk-info.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { VERSION } from '../../version';\nimport {\n  ATTR_TELEMETRY_SDK_NAME,\n  ATTR_TELEMETRY_SDK_LANGUAGE,\n  TELEMETRY_SDK_LANGUAGE_VALUE_WEBJS,\n  ATTR_TELEMETRY_SDK_VERSION,\n} from '@opentelemetry/semantic-conventions';\nimport { ATTR_PROCESS_RUNTIME_NAME } from '../../semconv';\n\n/** Constants describing the SDK in use */\nexport const SDK_INFO = {\n  [ATTR_TELEMETRY_SDK_NAME]: 'opentelemetry',\n  [ATTR_PROCESS_RUNTIME_NAME]: 'browser',\n  [ATTR_TELEMETRY_SDK_LANGUAGE]: TELEMETRY_SDK_LANGUAGE_VALUE_WEBJS,\n  [ATTR_TELEMETRY_SDK_VERSION]: VERSION,\n};\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;AAEH,OAAO,EAAE,OAAO,EAAE,MAAM,eAAe,CAAC;AACxC,OAAO,EACL,uBAAuB,EACvB,2BAA2B,EAC3B,kCAAkC,EAClC,0BAA0B,GAC3B,MAAM,qCAAqC,CAAC;AAC7C,OAAO,EAAE,yBAAyB,EAAE,MAAM,eAAe,CAAC;;;;AAGnD,MAAM,QAAQ,GAAG;IACtB,CAAC,kOAAuB,CAAC,EAAE,eAAe;IAC1C,CAAC,uMAAyB,CAAC,EAAE,SAAS;IACtC,CAAC,sOAA2B,CAAC,EAAE,6OAAkC;IACjE,CAAC,qOAA0B,CAAC,EAAE,qLAAO;CACtC,CAAC"}},
    {"offset": {"line": 8884, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/sdk-trace-base/build/esm/Sampler.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/sdk-trace-base/src/Sampler.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  Context,\n  Link,\n  Attributes,\n  SpanKind,\n  TraceState,\n} from '@opentelemetry/api';\n\n/**\n * A sampling decision that determines how a {@link Span} will be recorded\n * and collected.\n */\nexport enum SamplingDecision {\n  /**\n   * `Span.isRecording() === false`, span will not be recorded and all events\n   * and attributes will be dropped.\n   */\n  NOT_RECORD,\n  /**\n   * `Span.isRecording() === true`, but `Sampled` flag in {@link TraceFlags}\n   * MUST NOT be set.\n   */\n  RECORD,\n  /**\n   * `Span.isRecording() === true` AND `Sampled` flag in {@link TraceFlags}\n   * MUST be set.\n   */\n  RECORD_AND_SAMPLED,\n}\n\n/**\n * A sampling result contains a decision for a {@link Span} and additional\n * attributes the sampler would like to added to the Span.\n */\nexport interface SamplingResult {\n  /**\n   * A sampling decision, refer to {@link SamplingDecision} for details.\n   */\n  decision: SamplingDecision;\n  /**\n   * The list of attributes returned by SamplingResult MUST be immutable.\n   * Caller may call {@link Sampler}.shouldSample any number of times and\n   * can safely cache the returned value.\n   */\n  attributes?: Readonly<Attributes>;\n  /**\n   * A {@link TraceState} that will be associated with the {@link Span} through\n   * the new {@link SpanContext}. Samplers SHOULD return the TraceState from\n   * the passed-in {@link Context} if they do not intend to change it. Leaving\n   * the value undefined will also leave the TraceState unchanged.\n   */\n  traceState?: TraceState;\n}\n\n/**\n * This interface represent a sampler. Sampling is a mechanism to control the\n * noise and overhead introduced by OpenTelemetry by reducing the number of\n * samples of traces collected and sent to the backend.\n */\nexport interface Sampler {\n  /**\n   * Checks whether span needs to be created and tracked.\n   *\n   * @param context Parent Context which may contain a span.\n   * @param traceId of the span to be created. It can be different from the\n   *     traceId in the {@link SpanContext}. Typically in situations when the\n   *     span to be created starts a new trace.\n   * @param spanName of the span to be created.\n   * @param spanKind of the span to be created.\n   * @param attributes Initial set of Attributes for the Span being constructed.\n   * @param links Collection of links that will be associated with the Span to\n   *     be created. Typically useful for batch operations.\n   * @returns a {@link SamplingResult}.\n   */\n  shouldSample(\n    context: Context,\n    traceId: string,\n    spanName: string,\n    spanKind: SpanKind,\n    attributes: Attributes,\n    links: Link[]\n  ): SamplingResult;\n\n  /** Returns the sampler name or short description with the configuration. */\n  toString(): string;\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG,CAUH;;;GAGG;;;;AACH,IAAY,gBAgBX;AAhBD,CAAA,SAAY,gBAAgB;IAC1B;;;OAGG,CACH,gBAAA,CAAA,gBAAA,CAAA,aAAA,GAAA,EAAA,GAAA,YAAU,CAAA;IACV;;;OAGG,CACH,gBAAA,CAAA,gBAAA,CAAA,SAAA,GAAA,EAAA,GAAA,QAAM,CAAA;IACN;;;OAGG,CACH,gBAAA,CAAA,gBAAA,CAAA,qBAAA,GAAA,EAAA,GAAA,oBAAkB,CAAA;AACpB,CAAC,EAhBW,gBAAgB,IAAA,CAAhB,gBAAgB,GAAA,CAAA,CAAA,GAgB3B"}},
    {"offset": {"line": 8924, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/resources/build/esm/platform/browser/default-service-name.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/resources/src/platform/browser/default-service-name.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport function defaultServiceName(): string {\n  return 'unknown_service';\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;AAEG,SAAU,kBAAkB;IAChC,OAAO,iBAAiB,CAAC;AAC3B,CAAC"}},
    {"offset": {"line": 8949, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/resources/build/esm/utils.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/resources/src/utils.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport const isPromiseLike = <R>(val: unknown): val is PromiseLike<R> => {\n  return (\n    val !== null &&\n    typeof val === 'object' &&\n    typeof (val as Partial<PromiseLike<R>>).then === 'function'\n  );\n};\n\nexport function identity<T>(_: T): T {\n  return _;\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;AAEI,MAAM,aAAa,GAAG,CAAI,GAAY,EAAyB,EAAE;IACtE,OAAO,AACL,GAAG,KAAK,IAAI,IACZ,OAAO,GAAG,KAAK,QAAQ,IACvB,OAAQ,GAA+B,CAAC,IAAI,KAAK,UAAU,CAC5D,CAAC;AACJ,CAAC,CAAC;AAEI,SAAU,QAAQ,CAAI,CAAI;IAC9B,OAAO,CAAC,CAAC;AACX,CAAC"}},
    {"offset": {"line": 8979, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/@opentelemetry/resources/build/esm/ResourceImpl.js","sources":["turbopack:///[project]/node_modules/@opentelemetry/resources/src/ResourceImpl.ts"],"sourcesContent":["/*\n * Copyright The OpenTelemetry Authors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Attributes, AttributeValue, diag } from '@opentelemetry/api';\nimport { SDK_INFO } from '@opentelemetry/core';\nimport {\n  ATTR_SERVICE_NAME,\n  ATTR_TELEMETRY_SDK_LANGUAGE,\n  ATTR_TELEMETRY_SDK_NAME,\n  ATTR_TELEMETRY_SDK_VERSION,\n} from '@opentelemetry/semantic-conventions';\nimport { Resource } from './Resource';\nimport { defaultServiceName } from './platform';\nimport {\n  DetectedResource,\n  DetectedResourceAttributes,\n  MaybePromise,\n  RawResourceAttribute,\n  ResourceOptions,\n} from './types';\nimport { isPromiseLike } from './utils';\n\nclass ResourceImpl implements Resource {\n  private _rawAttributes: RawResourceAttribute[];\n  private _asyncAttributesPending = false;\n  private _schemaUrl?: string;\n\n  private _memoizedAttributes?: Attributes;\n\n  static FromAttributeList(\n    attributes: [string, MaybePromise<AttributeValue | undefined>][],\n    options?: ResourceOptions\n  ): Resource {\n    const res = new ResourceImpl({}, options);\n    res._rawAttributes = guardedRawAttributes(attributes);\n    res._asyncAttributesPending =\n      attributes.filter(([_, val]) => isPromiseLike(val)).length > 0;\n    return res;\n  }\n\n  constructor(\n    /**\n     * A dictionary of attributes with string keys and values that provide\n     * information about the entity as numbers, strings or booleans\n     * TODO: Consider to add check/validation on attributes.\n     */\n    resource: DetectedResource,\n    options?: ResourceOptions\n  ) {\n    const attributes = resource.attributes ?? {};\n    this._rawAttributes = Object.entries(attributes).map(([k, v]) => {\n      if (isPromiseLike(v)) {\n        // side-effect\n        this._asyncAttributesPending = true;\n      }\n\n      return [k, v];\n    });\n\n    this._rawAttributes = guardedRawAttributes(this._rawAttributes);\n    this._schemaUrl = validateSchemaUrl(options?.schemaUrl);\n  }\n\n  public get asyncAttributesPending(): boolean {\n    return this._asyncAttributesPending;\n  }\n\n  public async waitForAsyncAttributes(): Promise<void> {\n    if (!this.asyncAttributesPending) {\n      return;\n    }\n\n    for (let i = 0; i < this._rawAttributes.length; i++) {\n      const [k, v] = this._rawAttributes[i];\n      this._rawAttributes[i] = [k, isPromiseLike(v) ? await v : v];\n    }\n\n    this._asyncAttributesPending = false;\n  }\n\n  public get attributes(): Attributes {\n    if (this.asyncAttributesPending) {\n      diag.error(\n        'Accessing resource attributes before async attributes settled'\n      );\n    }\n\n    if (this._memoizedAttributes) {\n      return this._memoizedAttributes;\n    }\n\n    const attrs: Attributes = {};\n    for (const [k, v] of this._rawAttributes) {\n      if (isPromiseLike(v)) {\n        diag.debug(`Unsettled resource attribute ${k} skipped`);\n        continue;\n      }\n      if (v != null) {\n        attrs[k] ??= v;\n      }\n    }\n\n    // only memoize output if all attributes are settled\n    if (!this._asyncAttributesPending) {\n      this._memoizedAttributes = attrs;\n    }\n\n    return attrs;\n  }\n\n  public getRawAttributes(): RawResourceAttribute[] {\n    return this._rawAttributes;\n  }\n\n  public get schemaUrl(): string | undefined {\n    return this._schemaUrl;\n  }\n\n  public merge(resource: Resource | null): Resource {\n    if (resource == null) return this;\n\n    // Order is important\n    // Spec states incoming attributes override existing attributes\n    const mergedSchemaUrl = mergeSchemaUrl(this, resource);\n    const mergedOptions: ResourceOptions | undefined = mergedSchemaUrl\n      ? { schemaUrl: mergedSchemaUrl }\n      : undefined;\n\n    return ResourceImpl.FromAttributeList(\n      [...resource.getRawAttributes(), ...this.getRawAttributes()],\n      mergedOptions\n    );\n  }\n}\n\nexport function resourceFromAttributes(\n  attributes: DetectedResourceAttributes,\n  options?: ResourceOptions\n): Resource {\n  return ResourceImpl.FromAttributeList(Object.entries(attributes), options);\n}\n\nexport function resourceFromDetectedResource(\n  detectedResource: DetectedResource,\n  options?: ResourceOptions\n): Resource {\n  return new ResourceImpl(detectedResource, options);\n}\n\nexport function emptyResource(): Resource {\n  return resourceFromAttributes({});\n}\n\nexport function defaultResource(): Resource {\n  return resourceFromAttributes({\n    [ATTR_SERVICE_NAME]: defaultServiceName(),\n    [ATTR_TELEMETRY_SDK_LANGUAGE]: SDK_INFO[ATTR_TELEMETRY_SDK_LANGUAGE],\n    [ATTR_TELEMETRY_SDK_NAME]: SDK_INFO[ATTR_TELEMETRY_SDK_NAME],\n    [ATTR_TELEMETRY_SDK_VERSION]: SDK_INFO[ATTR_TELEMETRY_SDK_VERSION],\n  });\n}\n\nfunction guardedRawAttributes(\n  attributes: RawResourceAttribute[]\n): RawResourceAttribute[] {\n  return attributes.map(([k, v]) => {\n    if (isPromiseLike(v)) {\n      return [\n        k,\n        v.catch(err => {\n          diag.debug(\n            'promise rejection for resource attribute: %s - %s',\n            k,\n            err\n          );\n          return undefined;\n        }),\n      ];\n    }\n    return [k, v];\n  });\n}\n\nfunction validateSchemaUrl(schemaUrl?: string): string | undefined {\n  if (typeof schemaUrl === 'string' || schemaUrl === undefined) {\n    return schemaUrl;\n  }\n\n  diag.warn(\n    'Schema URL must be string or undefined, got %s. Schema URL will be ignored.',\n    schemaUrl\n  );\n\n  return undefined;\n}\n\nfunction mergeSchemaUrl(\n  old: Resource,\n  updating: Resource | null\n): string | undefined {\n  const oldSchemaUrl = old?.schemaUrl;\n  const updatingSchemaUrl = updating?.schemaUrl;\n\n  const isOldEmpty = oldSchemaUrl === undefined || oldSchemaUrl === '';\n  const isUpdatingEmpty =\n    updatingSchemaUrl === undefined || updatingSchemaUrl === '';\n\n  if (isOldEmpty) {\n    return updatingSchemaUrl;\n  }\n\n  if (isUpdatingEmpty) {\n    return oldSchemaUrl;\n  }\n\n  if (oldSchemaUrl === updatingSchemaUrl) {\n    return oldSchemaUrl;\n  }\n\n  diag.warn(\n    'Schema URL merge conflict: old resource has \"%s\", updating resource has \"%s\". Resulting resource will have undefined Schema URL.',\n    oldSchemaUrl,\n    updatingSchemaUrl\n  );\n\n  return undefined;\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;GAcG;;;;;;;;;;AAEH,OAAO,EAA8B,IAAI,EAAE,MAAM,oBAAoB,CAAC;AACtE,OAAO,EAAE,QAAQ,EAAE,MAAM,qBAAqB,CAAC;AAC/C,OAAO,EACL,iBAAiB,EACjB,2BAA2B,EAC3B,uBAAuB,EACvB,0BAA0B,GAC3B,MAAM,qCAAqC,CAAC;AAE7C,OAAO,EAAE,kBAAkB,EAAE,MAAM,YAAY,CAAC;AAQhD,OAAO,EAAE,aAAa,EAAE,MAAM,SAAS,CAAC;;;;;;AAExC,MAAM,YAAY;IACR,cAAc,CAAyB;IACvC,uBAAuB,GAAG,KAAK,CAAC;IAChC,UAAU,CAAU;IAEpB,mBAAmB,CAAc;IAEzC,MAAM,CAAC,iBAAiB,CACtB,UAAgE,EAChE,OAAyB,EAAA;QAEzB,MAAM,GAAG,GAAG,IAAI,YAAY,CAAC,CAAA,CAAE,EAAE,OAAO,CAAC,CAAC;QAC1C,GAAG,CAAC,cAAc,GAAG,oBAAoB,CAAC,UAAU,CAAC,CAAC;QACtD,GAAG,CAAC,uBAAuB,GACzB,UAAU,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE,EAAE,GAAC,8LAAa,EAAC,GAAG,CAAC,CAAC,CAAC,MAAM,GAAG,CAAC,CAAC;QACjE,OAAO,GAAG,CAAC;IACb,CAAC;IAED,YACE;;;;OAIG,CACH,QAA0B,EAC1B,OAAyB,CAAA;QAEzB,MAAM,UAAU,GAAG,QAAQ,CAAC,UAAU,IAAI,CAAA,CAAE,CAAC;QAC7C,IAAI,CAAC,cAAc,GAAG,MAAM,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE;YAC9D,QAAI,8LAAa,EAAC,CAAC,CAAC,EAAE;gBACpB,cAAc;gBACd,IAAI,CAAC,uBAAuB,GAAG,IAAI,CAAC;aACrC;YAED,OAAO;gBAAC,CAAC;gBAAE,CAAC;aAAC,CAAC;QAChB,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,cAAc,GAAG,oBAAoB,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAChE,IAAI,CAAC,UAAU,GAAG,iBAAiB,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;IAC1D,CAAC;IAED,IAAW,sBAAsB,GAAA;QAC/B,OAAO,IAAI,CAAC,uBAAuB,CAAC;IACtC,CAAC;IAEM,KAAK,CAAC,sBAAsB,GAAA;QACjC,IAAI,CAAC,IAAI,CAAC,sBAAsB,EAAE;YAChC,OAAO;SACR;QAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;YACnD,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC;YACtC,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,GAAG;gBAAC,CAAC;oBAAE,8LAAa,EAAC,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;aAAC,CAAC;SAC9D;QAED,IAAI,CAAC,uBAAuB,GAAG,KAAK,CAAC;IACvC,CAAC;IAED,IAAW,UAAU,GAAA;QACnB,IAAI,IAAI,CAAC,sBAAsB,EAAE;YAC/B,qLAAI,CAAC,KAAK,CACR,+DAA+D,CAChE,CAAC;SACH;QAED,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC5B,OAAO,IAAI,CAAC,mBAAmB,CAAC;SACjC;QAED,MAAM,KAAK,GAAe,CAAA,CAAE,CAAC;QAC7B,KAAK,MAAM,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,IAAI,CAAC,cAAc,CAAE;YACxC,QAAI,8LAAa,EAAC,CAAC,CAAC,EAAE;gBACpB,qLAAI,CAAC,KAAK,CAAC,CAAA,6BAAA,EAAgC,CAAC,CAAA,QAAA,CAAU,CAAC,CAAC;gBACxD,SAAS;aACV;YACD,IAAI,CAAC,IAAI,IAAI,EAAE;gBACb,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;aAChB;SACF;QAED,oDAAoD;QACpD,IAAI,CAAC,IAAI,CAAC,uBAAuB,EAAE;YACjC,IAAI,CAAC,mBAAmB,GAAG,KAAK,CAAC;SAClC;QAED,OAAO,KAAK,CAAC;IACf,CAAC;IAEM,gBAAgB,GAAA;QACrB,OAAO,IAAI,CAAC,cAAc,CAAC;IAC7B,CAAC;IAED,IAAW,SAAS,GAAA;QAClB,OAAO,IAAI,CAAC,UAAU,CAAC;IACzB,CAAC;IAEM,KAAK,CAAC,QAAyB,EAAA;QACpC,IAAI,QAAQ,IAAI,IAAI,EAAE,OAAO,IAAI,CAAC;QAElC,qBAAqB;QACrB,+DAA+D;QAC/D,MAAM,eAAe,GAAG,cAAc,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAC;QACvD,MAAM,aAAa,GAAgC,eAAe,GAC9D;YAAE,SAAS,EAAE,eAAe;QAAA,CAAE,GAC9B,SAAS,CAAC;QAEd,OAAO,YAAY,CAAC,iBAAiB,CACnC,CAAC;eAAG,QAAQ,CAAC,gBAAgB,EAAE,EAAE;eAAG,IAAI,CAAC,gBAAgB,EAAE;SAAC,EAC5D,aAAa,CACd,CAAC;IACJ,CAAC;CACF;AAEK,SAAU,sBAAsB,CACpC,UAAsC,EACtC,OAAyB;IAEzB,OAAO,YAAY,CAAC,iBAAiB,CAAC,MAAM,CAAC,OAAO,CAAC,UAAU,CAAC,EAAE,OAAO,CAAC,CAAC;AAC7E,CAAC;AAEK,SAAU,4BAA4B,CAC1C,gBAAkC,EAClC,OAAyB;IAEzB,OAAO,IAAI,YAAY,CAAC,gBAAgB,EAAE,OAAO,CAAC,CAAC;AACrD,CAAC;AAEK,SAAU,aAAa;IAC3B,OAAO,sBAAsB,CAAC,CAAA,CAAE,CAAC,CAAC;AACpC,CAAC;AAEK,SAAU,eAAe;IAC7B,OAAO,sBAAsB,CAAC;QAC5B,CAAC,4NAAiB,CAAC,MAAE,+OAAkB,EAAE;QACzC,CAAC,sOAA2B,CAAC,EAAE,iNAAQ,CAAC,sOAA2B,CAAC;QACpE,CAAC,kOAAuB,CAAC,EAAE,iNAAQ,CAAC,kOAAuB,CAAC;QAC5D,CAAC,qOAA0B,CAAC,EAAE,iNAAQ,CAAC,qOAA0B,CAAC;KACnE,CAAC,CAAC;AACL,CAAC;AAED,SAAS,oBAAoB,CAC3B,UAAkC;IAElC,OAAO,UAAU,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,EAAE;QAC/B,QAAI,8LAAa,EAAC,CAAC,CAAC,EAAE;YACpB,OAAO;gBACL,CAAC;gBACD,CAAC,CAAC,KAAK,EAAC,GAAG,CAAC,EAAE;oBACZ,qLAAI,CAAC,KAAK,CACR,mDAAmD,EACnD,CAAC,EACD,GAAG,CACJ,CAAC;oBACF,OAAO,SAAS,CAAC;gBACnB,CAAC,CAAC;aACH,CAAC;SACH;QACD,OAAO;YAAC,CAAC;YAAE,CAAC;SAAC,CAAC;IAChB,CAAC,CAAC,CAAC;AACL,CAAC;AAED,SAAS,iBAAiB,CAAC,SAAkB;IAC3C,IAAI,OAAO,SAAS,KAAK,QAAQ,IAAI,SAAS,KAAK,SAAS,EAAE;QAC5D,OAAO,SAAS,CAAC;KAClB;IAED,qLAAI,CAAC,IAAI,CACP,6EAA6E,EAC7E,SAAS,CACV,CAAC;IAEF,OAAO,SAAS,CAAC;AACnB,CAAC;AAED,SAAS,cAAc,CACrB,GAAa,EACb,QAAyB;IAEzB,MAAM,YAAY,GAAG,GAAG,EAAE,SAAS,CAAC;IACpC,MAAM,iBAAiB,GAAG,QAAQ,EAAE,SAAS,CAAC;IAE9C,MAAM,UAAU,GAAG,YAAY,KAAK,SAAS,IAAI,YAAY,KAAK,EAAE,CAAC;IACrE,MAAM,eAAe,GACnB,iBAAiB,KAAK,SAAS,IAAI,iBAAiB,KAAK,EAAE,CAAC;IAE9D,IAAI,UAAU,EAAE;QACd,OAAO,iBAAiB,CAAC;KAC1B;IAED,IAAI,eAAe,EAAE;QACnB,OAAO,YAAY,CAAC;KACrB;IAED,IAAI,YAAY,KAAK,iBAAiB,EAAE;QACtC,OAAO,YAAY,CAAC;KACrB;IAED,qLAAI,CAAC,IAAI,CACP,kIAAkI,EAClI,YAAY,EACZ,iBAAiB,CAClB,CAAC;IAEF,OAAO,SAAS,CAAC;AACnB,CAAC"}},
    {"offset": {"line": 9164, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/@swc/helpers/cjs/_interop_require_default.cjs"],"sourcesContent":["\"use strict\";\n\nfunction _interop_require_default(obj) {\n    return obj && obj.__esModule ? obj : { default: obj };\n}\nexports._ = _interop_require_default;\n"],"names":[],"mappings":"AAEA,SAAS,yBAAyB,GAAG;IACjC,OAAO,OAAO,IAAI,UAAU,GAAG,MAAM;QAAE,SAAS;IAAI;AACxD;AACA,QAAQ,CAAC,GAAG","ignoreList":[0]}},
    {"offset": {"line": 9174, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/@upstash/core-analytics/dist/index.js"],"sourcesContent":["\"use strict\";var g=Object.defineProperty;var k=Object.getOwnPropertyDescriptor;var _=Object.getOwnPropertyNames;var y=Object.prototype.hasOwnProperty;var w=(l,e)=>{for(var t in e)g(l,t,{get:e[t],enumerable:!0})},A=(l,e,t,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let s of _(e))!y.call(l,s)&&s!==t&&g(l,s,{get:()=>e[s],enumerable:!(i=k(e,s))||i.enumerable});return l};var x=l=>A(g({},\"__esModule\",{value:!0}),l);var S={};w(S,{Analytics:()=>b});module.exports=x(S);var p=`\nlocal key = KEYS[1]\nlocal field = ARGV[1]\n\nlocal data = redis.call(\"ZRANGE\", key, 0, -1, \"WITHSCORES\")\nlocal count = {}\n\nfor i = 1, #data, 2 do\n  local json_str = data[i]\n  local score = tonumber(data[i + 1])\n  local obj = cjson.decode(json_str)\n\n  local fieldValue = obj[field]\n\n  if count[fieldValue] == nil then\n    count[fieldValue] = score\n  else\n    count[fieldValue] = count[fieldValue] + score\n  end\nend\n\nlocal result = {}\nfor k, v in pairs(count) do\n  table.insert(result, {k, v})\nend\n\nreturn result\n`,f=`\nlocal prefix = KEYS[1]\nlocal first_timestamp = tonumber(ARGV[1]) -- First timestamp to check\nlocal increment = tonumber(ARGV[2])       -- Increment between each timestamp\nlocal num_timestamps = tonumber(ARGV[3])  -- Number of timestampts to check (24 for a day and 24 * 7 for a week)\nlocal num_elements = tonumber(ARGV[4])    -- Number of elements to fetch in each category\nlocal check_at_most = tonumber(ARGV[5])   -- Number of elements to check at most.\n\nlocal keys = {}\nfor i = 1, num_timestamps do\n  local timestamp = first_timestamp - (i - 1) * increment\n  table.insert(keys, prefix .. \":\" .. timestamp)\nend\n\n-- get the union of the groups\nlocal zunion_params = {\"ZUNION\", num_timestamps, unpack(keys)}\ntable.insert(zunion_params, \"WITHSCORES\")\nlocal result = redis.call(unpack(zunion_params))\n\n-- select num_elements many items\nlocal true_group = {}\nlocal false_group = {}\nlocal denied_group = {}\nlocal true_count = 0\nlocal false_count = 0\nlocal denied_count = 0\nlocal i = #result - 1\n\n-- index to stop at after going through \"checkAtMost\" many items:\nlocal cutoff_index = #result - 2 * check_at_most\n\n-- iterate over the results\nwhile (true_count + false_count + denied_count) < (num_elements * 3) and 1 <= i and i >= cutoff_index do\n  local score = tonumber(result[i + 1])\n  if score > 0 then\n    local element = result[i]\n    if string.find(element, \"success\\\\\":true\") and true_count < num_elements then\n      table.insert(true_group, {score, element})\n      true_count = true_count + 1\n    elseif string.find(element, \"success\\\\\":false\") and false_count < num_elements then\n      table.insert(false_group, {score, element})\n      false_count = false_count + 1\n    elseif string.find(element, \"success\\\\\":\\\\\"denied\") and denied_count < num_elements then\n      table.insert(denied_group, {score, element})\n      denied_count = denied_count + 1\n    end\n  end\n  i = i - 2\nend\n\nreturn {true_group, false_group, denied_group}\n`,h=`\nlocal prefix = KEYS[1]\nlocal first_timestamp = tonumber(ARGV[1])\nlocal increment = tonumber(ARGV[2])\nlocal num_timestamps = tonumber(ARGV[3])\n\nlocal keys = {}\nfor i = 1, num_timestamps do\n  local timestamp = first_timestamp - (i - 1) * increment\n  table.insert(keys, prefix .. \":\" .. timestamp)\nend\n\n-- get the union of the groups\nlocal zunion_params = {\"ZUNION\", num_timestamps, unpack(keys)}\ntable.insert(zunion_params, \"WITHSCORES\")\nlocal result = redis.call(unpack(zunion_params))\n\nreturn result\n`;var b=class{redis;prefix;bucketSize;constructor(e){this.redis=e.redis,this.prefix=e.prefix??\"@upstash/analytics\",this.bucketSize=this.parseWindow(e.window)}validateTableName(e){if(!/^[a-zA-Z0-9_-]+$/.test(e))throw new Error(`Invalid table name: ${e}. Table names can only contain letters, numbers, dashes and underscores.`)}parseWindow(e){if(typeof e==\"number\"){if(e<=0)throw new Error(`Invalid window: ${e}`);return e}let t=/^(\\d+)([smhd])$/;if(!t.test(e))throw new Error(`Invalid window: ${e}`);let[,i,s]=e.match(t),n=parseInt(i);switch(s){case\"s\":return n*1e3;case\"m\":return n*1e3*60;case\"h\":return n*1e3*60*60;case\"d\":return n*1e3*60*60*24;default:throw new Error(`Invalid window unit: ${s}`)}}getBucket(e){let t=e??Date.now();return Math.floor(t/this.bucketSize)*this.bucketSize}async ingest(e,...t){this.validateTableName(e),await Promise.all(t.map(async i=>{let s=this.getBucket(i.time),n=[this.prefix,e,s].join(\":\");await this.redis.zincrby(n,1,JSON.stringify({...i,time:void 0}))}))}formatBucketAggregate(e,t,i){let s={};return e.forEach(([n,r])=>{t==\"success\"&&(n=n===1?\"true\":n===null?\"false\":n),s[t]=s[t]||{},s[t][(n??\"null\").toString()]=r}),{time:i,...s}}async aggregateBucket(e,t,i){this.validateTableName(e);let s=this.getBucket(i),n=[this.prefix,e,s].join(\":\"),r=await this.redis.eval(p,[n],[t]);return this.formatBucketAggregate(r,t,s)}async aggregateBuckets(e,t,i,s){this.validateTableName(e);let n=this.getBucket(s),r=[];for(let o=0;o<i;o+=1)r.push(this.aggregateBucket(e,t,n)),n=n-this.bucketSize;return Promise.all(r)}async aggregateBucketsWithPipeline(e,t,i,s,n){this.validateTableName(e),n=n??48;let r=this.getBucket(s),o=[],c=this.redis.pipeline(),u=[];for(let a=1;a<=i;a+=1){let d=[this.prefix,e,r].join(\":\");c.eval(p,[d],[t]),o.push(r),r=r-this.bucketSize,(a%n==0||a==i)&&(u.push(c.exec()),c=this.redis.pipeline())}return(await Promise.all(u)).flat().map((a,d)=>this.formatBucketAggregate(a,t,o[d]))}async getAllowedBlocked(e,t,i){this.validateTableName(e);let s=[this.prefix,e].join(\":\"),n=this.getBucket(i),r=await this.redis.eval(h,[s],[n,this.bucketSize,t]),o={};for(let c=0;c<r.length;c+=2){let u=r[c],m=u.identifier,a=+r[c+1];o[m]||(o[m]={success:0,blocked:0}),o[m][u.success?\"success\":\"blocked\"]=a}return o}async getMostAllowedBlocked(e,t,i,s,n){this.validateTableName(e);let r=[this.prefix,e].join(\":\"),o=this.getBucket(s),c=n??i*5,[u,m,a]=await this.redis.eval(f,[r],[o,this.bucketSize,t,i,c]);return{allowed:this.toDicts(u),ratelimited:this.toDicts(m),denied:this.toDicts(a)}}toDicts(e){let t=[];for(let i=0;i<e.length;i+=1){let s=+e[i][0],n=e[i][1];t.push({identifier:n.identifier,count:s})}return t}};0&&(module.exports={Analytics});\n"],"names":[],"mappings":"AAAa,IAAI,IAAE,OAAO,cAAc;AAAC,IAAI,IAAE,OAAO,wBAAwB;AAAC,IAAI,IAAE,OAAO,mBAAmB;AAAC,IAAI,IAAE,OAAO,SAAS,CAAC,cAAc;AAAC,IAAI,IAAE,CAAC,GAAE;IAAK,IAAI,IAAI,KAAK,EAAE,EAAE,GAAE,GAAE;QAAC,KAAI,CAAC,CAAC,EAAE;QAAC,YAAW,CAAC;IAAC;AAAE,GAAE,IAAE,CAAC,GAAE,GAAE,GAAE;IAAK,IAAG,KAAG,OAAO,KAAG,YAAU,OAAO,KAAG,YAAW,KAAI,IAAI,KAAK,EAAE,GAAG,CAAC,EAAE,IAAI,CAAC,GAAE,MAAI,MAAI,KAAG,EAAE,GAAE,GAAE;QAAC,KAAI,IAAI,CAAC,CAAC,EAAE;QAAC,YAAW,CAAC,CAAC,IAAE,EAAE,GAAE,EAAE,KAAG,EAAE,UAAU;IAAA;IAAG,OAAO;AAAC;AAAE,IAAI,IAAE,CAAA,IAAG,EAAE,EAAE,CAAC,GAAE,cAAa;QAAC,OAAM,CAAC;IAAC,IAAG;AAAG,IAAI,IAAE,CAAC;AAAE,EAAE,GAAE;IAAC,WAAU,IAAI;AAAC;AAAG,OAAO,OAAO,GAAC,EAAE;AAAG,IAAI,IAAE,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2Bpe,CAAC,EAAC,IAAE,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAmDL,CAAC,EAAC,IAAE,CAAC;;;;;;;;;;;;;;;;;;AAkBL,CAAC;AAAC,IAAI,IAAE;IAAM,MAAM;IAAA,OAAO;IAAA,WAAW;IAAA,YAAY,CAAC,CAAC;QAAC,IAAI,CAAC,KAAK,GAAC,EAAE,KAAK,EAAC,IAAI,CAAC,MAAM,GAAC,EAAE,MAAM,IAAE,sBAAqB,IAAI,CAAC,UAAU,GAAC,IAAI,CAAC,WAAW,CAAC,EAAE,MAAM;IAAC;IAAC,kBAAkB,CAAC,EAAC;QAAC,IAAG,CAAC,mBAAmB,IAAI,CAAC,IAAG,MAAM,IAAI,MAAM,CAAC,oBAAoB,EAAE,EAAE,wEAAwE,CAAC;IAAC;IAAC,YAAY,CAAC,EAAC;QAAC,IAAG,OAAO,KAAG,UAAS;YAAC,IAAG,KAAG,GAAE,MAAM,IAAI,MAAM,CAAC,gBAAgB,EAAE,GAAG;YAAE,OAAO;QAAC;QAAC,IAAI,IAAE;QAAkB,IAAG,CAAC,EAAE,IAAI,CAAC,IAAG,MAAM,IAAI,MAAM,CAAC,gBAAgB,EAAE,GAAG;QAAE,IAAG,GAAE,GAAE,EAAE,GAAC,EAAE,KAAK,CAAC,IAAG,IAAE,SAAS;QAAG,OAAO;YAAG,KAAI;gBAAI,OAAO,IAAE;YAAI,KAAI;gBAAI,OAAO,IAAE,MAAI;YAAG,KAAI;gBAAI,OAAO,IAAE,MAAI,KAAG;YAAG,KAAI;gBAAI,OAAO,IAAE,MAAI,KAAG,KAAG;YAAG;gBAAQ,MAAM,IAAI,MAAM,CAAC,qBAAqB,EAAE,GAAG;QAAC;IAAC;IAAC,UAAU,CAAC,EAAC;QAAC,IAAI,IAAE,KAAG,KAAK,GAAG;QAAG,OAAO,KAAK,KAAK,CAAC,IAAE,IAAI,CAAC,UAAU,IAAE,IAAI,CAAC,UAAU;IAAA;IAAC,MAAM,OAAO,CAAC,EAAC,GAAG,CAAC,EAAC;QAAC,IAAI,CAAC,iBAAiB,CAAC,IAAG,MAAM,QAAQ,GAAG,CAAC,EAAE,GAAG,CAAC,OAAM;YAAI,IAAI,IAAE,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,GAAE,IAAE;gBAAC,IAAI,CAAC,MAAM;gBAAC;gBAAE;aAAE,CAAC,IAAI,CAAC;YAAK,MAAM,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,GAAE,GAAE,KAAK,SAAS,CAAC;gBAAC,GAAG,CAAC;gBAAC,MAAK,KAAK;YAAC;QAAG;IAAG;IAAC,sBAAsB,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC;QAAC,IAAI,IAAE,CAAC;QAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,GAAE,EAAE;YAAI,KAAG,aAAW,CAAC,IAAE,MAAI,IAAE,SAAO,MAAI,OAAK,UAAQ,CAAC,GAAE,CAAC,CAAC,EAAE,GAAC,CAAC,CAAC,EAAE,IAAE,CAAC,GAAE,CAAC,CAAC,EAAE,CAAC,CAAC,KAAG,MAAM,EAAE,QAAQ,GAAG,GAAC;QAAC,IAAG;YAAC,MAAK;YAAE,GAAG,CAAC;QAAA;IAAC;IAAC,MAAM,gBAAgB,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC;QAAC,IAAI,CAAC,iBAAiB,CAAC;QAAG,IAAI,IAAE,IAAI,CAAC,SAAS,CAAC,IAAG,IAAE;YAAC,IAAI,CAAC,MAAM;YAAC;YAAE;SAAE,CAAC,IAAI,CAAC,MAAK,IAAE,MAAM,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GAAE;YAAC;SAAE,EAAC;YAAC;SAAE;QAAE,OAAO,IAAI,CAAC,qBAAqB,CAAC,GAAE,GAAE;IAAE;IAAC,MAAM,iBAAiB,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC;QAAC,IAAI,CAAC,iBAAiB,CAAC;QAAG,IAAI,IAAE,IAAI,CAAC,SAAS,CAAC,IAAG,IAAE,EAAE;QAAC,IAAI,IAAI,IAAE,GAAE,IAAE,GAAE,KAAG,EAAE,EAAE,IAAI,CAAC,IAAI,CAAC,eAAe,CAAC,GAAE,GAAE,KAAI,IAAE,IAAE,IAAI,CAAC,UAAU;QAAC,OAAO,QAAQ,GAAG,CAAC;IAAE;IAAC,MAAM,6BAA6B,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC;QAAC,IAAI,CAAC,iBAAiB,CAAC,IAAG,IAAE,KAAG;QAAG,IAAI,IAAE,IAAI,CAAC,SAAS,CAAC,IAAG,IAAE,EAAE,EAAC,IAAE,IAAI,CAAC,KAAK,CAAC,QAAQ,IAAG,IAAE,EAAE;QAAC,IAAI,IAAI,IAAE,GAAE,KAAG,GAAE,KAAG,EAAE;YAAC,IAAI,IAAE;gBAAC,IAAI,CAAC,MAAM;gBAAC;gBAAE;aAAE,CAAC,IAAI,CAAC;YAAK,EAAE,IAAI,CAAC,GAAE;gBAAC;aAAE,EAAC;gBAAC;aAAE,GAAE,EAAE,IAAI,CAAC,IAAG,IAAE,IAAE,IAAI,CAAC,UAAU,EAAC,CAAC,IAAE,KAAG,KAAG,KAAG,CAAC,KAAG,CAAC,EAAE,IAAI,CAAC,EAAE,IAAI,KAAI,IAAE,IAAI,CAAC,KAAK,CAAC,QAAQ,EAAE;QAAC;QAAC,OAAM,CAAC,MAAM,QAAQ,GAAG,CAAC,EAAE,EAAE,IAAI,GAAG,GAAG,CAAC,CAAC,GAAE,IAAI,IAAI,CAAC,qBAAqB,CAAC,GAAE,GAAE,CAAC,CAAC,EAAE;IAAE;IAAC,MAAM,kBAAkB,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC;QAAC,IAAI,CAAC,iBAAiB,CAAC;QAAG,IAAI,IAAE;YAAC,IAAI,CAAC,MAAM;YAAC;SAAE,CAAC,IAAI,CAAC,MAAK,IAAE,IAAI,CAAC,SAAS,CAAC,IAAG,IAAE,MAAM,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GAAE;YAAC;SAAE,EAAC;YAAC;YAAE,IAAI,CAAC,UAAU;YAAC;SAAE,GAAE,IAAE,CAAC;QAAE,IAAI,IAAI,IAAE,GAAE,IAAE,EAAE,MAAM,EAAC,KAAG,EAAE;YAAC,IAAI,IAAE,CAAC,CAAC,EAAE,EAAC,IAAE,EAAE,UAAU,EAAC,IAAE,CAAC,CAAC,CAAC,IAAE,EAAE;YAAC,CAAC,CAAC,EAAE,IAAE,CAAC,CAAC,CAAC,EAAE,GAAC;gBAAC,SAAQ;gBAAE,SAAQ;YAAC,CAAC,GAAE,CAAC,CAAC,EAAE,CAAC,EAAE,OAAO,GAAC,YAAU,UAAU,GAAC;QAAC;QAAC,OAAO;IAAC;IAAC,MAAM,sBAAsB,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC,CAAC,EAAC;QAAC,IAAI,CAAC,iBAAiB,CAAC;QAAG,IAAI,IAAE;YAAC,IAAI,CAAC,MAAM;YAAC;SAAE,CAAC,IAAI,CAAC,MAAK,IAAE,IAAI,CAAC,SAAS,CAAC,IAAG,IAAE,KAAG,IAAE,GAAE,CAAC,GAAE,GAAE,EAAE,GAAC,MAAM,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,GAAE;YAAC;SAAE,EAAC;YAAC;YAAE,IAAI,CAAC,UAAU;YAAC;YAAE;YAAE;SAAE;QAAE,OAAM;YAAC,SAAQ,IAAI,CAAC,OAAO,CAAC;YAAG,aAAY,IAAI,CAAC,OAAO,CAAC;YAAG,QAAO,IAAI,CAAC,OAAO,CAAC;QAAE;IAAC;IAAC,QAAQ,CAAC,EAAC;QAAC,IAAI,IAAE,EAAE;QAAC,IAAI,IAAI,IAAE,GAAE,IAAE,EAAE,MAAM,EAAC,KAAG,EAAE;YAAC,IAAI,IAAE,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,EAAC,IAAE,CAAC,CAAC,EAAE,CAAC,EAAE;YAAC,EAAE,IAAI,CAAC;gBAAC,YAAW,EAAE,UAAU;gBAAC,OAAM;YAAC;QAAE;QAAC,OAAO;IAAC;AAAC;AAAE,KAAG,CAAC,OAAO,OAAO,GAAC;IAAC;AAAS,CAAC","ignoreList":[0]}},
    {"offset": {"line": 9448, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/@upstash/ratelimit/src/index.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/analytics.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/cache.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/duration.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/hash.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/lua-scripts/single.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/lua-scripts/multi.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/lua-scripts/reset.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/lua-scripts/hash.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/types.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/deny-list/scripts.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/deny-list/ip-deny-list.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/deny-list/time.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/deny-list/deny-list.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/ratelimit.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/multi.ts","turbopack:///[project]/node_modules/@upstash/ratelimit/src/single.ts"],"sourcesContent":["\n\n\n\n\n\n\n\n\n\n\n\nexport {Analytics, type AnalyticsConfig} from \"./analytics\";\nexport {MultiRegionRatelimit, type MultiRegionRatelimitConfig} from \"./multi\";\nexport {RegionRatelimit as Ratelimit, type RegionRatelimitConfig as RatelimitConfig} from \"./single\";\nexport {type Algorithm} from \"./types\";\nexport * as IpDenyList from \"./deny-list/ip-deny-list\";\nexport {type Duration} from \"./duration\";","import type { Aggregate } from \"@upstash/core-analytics\";\nimport { Analytics as CoreAnalytics } from \"@upstash/core-analytics\";\nimport type { Redis } from \"./types\";\n\nexport type Geo = {\n  country?: string;\n  city?: string;\n  region?: string;\n  ip?: string;\n};\n\n/**\n * denotes the success field in the analytics submission.\n * Set to true when ratelimit check passes. False when request is ratelimited.\n * Set to \"denied\" when some request value is in deny list.\n */\nexport type EventSuccess = boolean | \"denied\"\n\nexport type Event = Geo & {\n  identifier: string;\n  time: number;\n  success: EventSuccess;\n};\n\nexport type AnalyticsConfig = {\n  redis: Redis;\n  prefix?: string;\n};\n\n/**\n * The Analytics package is experimental and can change at any time.\n */\nexport class Analytics {\n  private readonly analytics: CoreAnalytics;\n  private readonly table = \"events\";\n\n  constructor(config: AnalyticsConfig) {\n    this.analytics = new CoreAnalytics({\n      // @ts-expect-error we need to fix the types in core-analytics, it should only require the methods it needs, not the whole sdk\n      redis: config.redis,\n      window: \"1h\",\n      prefix: config.prefix ?? \"@upstash/ratelimit\",\n      retention: \"90d\",\n    });\n  }\n\n  /**\n   * Try to extract the geo information from the request\n   *\n   * This handles Vercel's `req.geo` and  and Cloudflare's `request.cf` properties\n   * @param req\n   * @returns\n   */\n  public extractGeo(req: { geo?: Geo; cf?: Geo }): Geo {\n    if (req.geo !== undefined) {\n      return req.geo;\n    }\n    if (req.cf !== undefined) {\n      return req.cf;\n    }\n\n    return {};\n  }\n\n  public async record(event: Event): Promise<void> {\n    await this.analytics.ingest(this.table, event);\n  }\n\n  public async series<TFilter extends keyof Omit<Event, \"time\">>(\n    filter: TFilter,\n    cutoff: number,\n  ): Promise<Aggregate[]> {\n    const timestampCount = Math.min(\n      (\n        this.analytics.getBucket(Date.now())\n        - this.analytics.getBucket(cutoff)\n      ) / (60 * 60 * 1000),\n      256\n    )\n    return this.analytics.aggregateBucketsWithPipeline(this.table, filter, timestampCount)\n  }\n\n  public async getUsage(cutoff = 0): Promise<Record<string, { success: number; blocked: number }>> {\n    \n    const timestampCount = Math.min(\n      (\n        this.analytics.getBucket(Date.now())\n        - this.analytics.getBucket(cutoff)\n      ) / (60 * 60 * 1000),\n      256\n    )\n    const records = await this.analytics.getAllowedBlocked(this.table, timestampCount)\n    return records;\n  }\n\n  public async getUsageOverTime<TFilter extends keyof Omit<Event, \"time\">>(\n    timestampCount: number, groupby: TFilter\n  ): Promise<Aggregate[]> {\n    const result = await this.analytics.aggregateBucketsWithPipeline(this.table, groupby, timestampCount)\n    return result\n  }\n\n  public async getMostAllowedBlocked(timestampCount: number, getTop?: number, checkAtMost?: number) {\n    getTop = getTop ?? 5\n    const timestamp = undefined // let the analytics handle getting the timestamp\n    return this.analytics.getMostAllowedBlocked(this.table, timestampCount, getTop, timestamp, checkAtMost)\n  }\n}\n","import type { EphemeralCache } from \"./types\";\n\nexport class Cache implements EphemeralCache {\n  /**\n   * Stores identifier -> reset (in milliseconds)\n   */\n  private readonly cache: Map<string, number>;\n\n  constructor(cache: Map<string, number>) {\n    this.cache = cache;\n  }\n\n  public isBlocked(identifier: string): { blocked: boolean; reset: number } {\n    if (!this.cache.has(identifier)) {\n      return { blocked: false, reset: 0 };\n    }\n    const reset = this.cache.get(identifier)!;\n    if (reset < Date.now()) {\n      this.cache.delete(identifier);\n      return { blocked: false, reset: 0 };\n    }\n\n    return { blocked: true, reset: reset };\n  }\n\n  public blockUntil(identifier: string, reset: number): void {\n    this.cache.set(identifier, reset);\n  }\n\n  public set(key: string, value: number): void {\n    this.cache.set(key, value);\n  }\n  public get(key: string): number | null {\n    return this.cache.get(key) || null;\n  }\n\n  public incr(key: string, incrementAmount: number = 1): number {\n    let value = this.cache.get(key) ?? 0;\n    value += incrementAmount;\n    this.cache.set(key, value);\n    return value;\n  }\n\n  public pop(key: string): void {\n    this.cache.delete(key)\n  }\n\n  public empty(): void {\n    this.cache.clear()\n  }\n\n  public size(): number {\n    return this.cache.size;\n  }\n}\n","type Unit = \"ms\" | \"s\" | \"m\" | \"h\" | \"d\";\nexport type Duration = `${number} ${Unit}` | `${number}${Unit}`;\n\n/**\n * Convert a human readable duration to milliseconds\n */\nexport function ms(d: Duration): number {\n  const match = d.match(/^(\\d+)\\s?(ms|s|m|h|d)$/);\n  if (!match) {\n    throw new Error(`Unable to parse window size: ${d}`);\n  }\n  const time = Number.parseInt(match[1]);\n  const unit = match[2] as Unit;\n\n  switch (unit) {\n    case \"ms\": {\n      return time;\n    }\n    case \"s\": {\n      return time * 1000;\n    }\n    case \"m\": {\n      return time * 1000 * 60;\n    }\n    case \"h\": {\n      return time * 1000 * 60 * 60;\n    }\n    case \"d\": {\n      return time * 1000 * 60 * 60 * 24;\n    }\n\n    default: {\n      throw new Error(`Unable to parse window size: ${d}`);\n    }\n  }\n}\n","import type { ScriptInfo } from \"./lua-scripts/hash\";\nimport type { RegionContext } from \"./types\";\n\n/**\n * Runs the specified script with EVALSHA using the scriptHash parameter.\n * \n * If the EVALSHA fails, loads the script to redis and runs again with the\n * hash returned from Redis.\n * \n * @param ctx Regional or multi region context\n * @param script ScriptInfo of script to run. Contains the script and its hash\n * @param keys eval keys\n * @param args eval args\n */\nexport const safeEval = async (\n  ctx: RegionContext,\n  script: ScriptInfo,\n  keys: any[],\n  args: any[],\n) => {\n  try {\n    return await ctx.redis.evalsha(script.hash, keys, args)\n  } catch (error) {\n    if (`${error}`.includes(\"NOSCRIPT\")) {\n      return await ctx.redis.eval(script.script, keys, args)\n    }\n    throw error;\n  }\n}","export const fixedWindowLimitScript = `\n  local key           = KEYS[1]\n  local window        = ARGV[1]\n  local incrementBy   = ARGV[2] -- increment rate per request at a given value, default is 1\n\n  local r = redis.call(\"INCRBY\", key, incrementBy)\n  if r == tonumber(incrementBy) then\n  -- The first time this key is set, the value will be equal to incrementBy.\n  -- So we only need the expire command once\n  redis.call(\"PEXPIRE\", key, window)\n  end\n\n  return r\n`;\n\nexport const fixedWindowRemainingTokensScript = `\n      local key = KEYS[1]\n      local tokens = 0\n\n      local value = redis.call('GET', key)\n      if value then\n          tokens = value\n      end\n      return tokens\n    `;\n\nexport const slidingWindowLimitScript = `\n  local currentKey  = KEYS[1]           -- identifier including prefixes\n  local previousKey = KEYS[2]           -- key of the previous bucket\n  local tokens      = tonumber(ARGV[1]) -- tokens per window\n  local now         = ARGV[2]           -- current timestamp in milliseconds\n  local window      = ARGV[3]           -- interval in milliseconds\n  local incrementBy = tonumber(ARGV[4]) -- increment rate per request at a given value, default is 1\n\n  local requestsInCurrentWindow = redis.call(\"GET\", currentKey)\n  if requestsInCurrentWindow == false then\n    requestsInCurrentWindow = 0\n  end\n\n  local requestsInPreviousWindow = redis.call(\"GET\", previousKey)\n  if requestsInPreviousWindow == false then\n    requestsInPreviousWindow = 0\n  end\n  local percentageInCurrent = ( now % window ) / window\n  -- weighted requests to consider from the previous window\n  requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)\n\n  -- Only check limit if not refunding (negative rate)\n  if incrementBy > 0 and requestsInPreviousWindow + requestsInCurrentWindow >= tokens then\n    return -1\n  end\n\n  local newValue = redis.call(\"INCRBY\", currentKey, incrementBy)\n  if newValue == incrementBy then\n    -- The first time this key is set, the value will be equal to incrementBy.\n    -- So we only need the expire command once\n    redis.call(\"PEXPIRE\", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second\n  end\n  return tokens - ( newValue + requestsInPreviousWindow )\n`;\n\nexport const slidingWindowRemainingTokensScript = `\n  local currentKey  = KEYS[1]           -- identifier including prefixes\n  local previousKey = KEYS[2]           -- key of the previous bucket\n  local now         = ARGV[1]           -- current timestamp in milliseconds\n  local window      = ARGV[2]           -- interval in milliseconds\n\n  local requestsInCurrentWindow = redis.call(\"GET\", currentKey)\n  if requestsInCurrentWindow == false then\n    requestsInCurrentWindow = 0\n  end\n\n  local requestsInPreviousWindow = redis.call(\"GET\", previousKey)\n  if requestsInPreviousWindow == false then\n    requestsInPreviousWindow = 0\n  end\n\n  local percentageInCurrent = ( now % window ) / window\n  -- weighted requests to consider from the previous window\n  requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)\n\n  return requestsInPreviousWindow + requestsInCurrentWindow\n`;\n\nexport const tokenBucketLimitScript = `\n  local key         = KEYS[1]           -- identifier including prefixes\n  local maxTokens   = tonumber(ARGV[1]) -- maximum number of tokens\n  local interval    = tonumber(ARGV[2]) -- size of the window in milliseconds\n  local refillRate  = tonumber(ARGV[3]) -- how many tokens are refilled after each interval\n  local now         = tonumber(ARGV[4]) -- current timestamp in milliseconds\n  local incrementBy = tonumber(ARGV[5]) -- how many tokens to consume, default is 1\n        \n  local bucket = redis.call(\"HMGET\", key, \"refilledAt\", \"tokens\")\n        \n  local refilledAt\n  local tokens\n\n  if bucket[1] == false then\n    refilledAt = now\n    tokens = maxTokens\n  else\n    refilledAt = tonumber(bucket[1])\n    tokens = tonumber(bucket[2])\n  end\n        \n  if now >= refilledAt + interval then\n    local numRefills = math.floor((now - refilledAt) / interval)\n    tokens = math.min(maxTokens, tokens + numRefills * refillRate)\n\n    refilledAt = refilledAt + numRefills * interval\n  end\n\n  -- Only reject if tokens are 0 and we're consuming (not refunding)\n  if tokens == 0 and incrementBy > 0 then\n    return {-1, refilledAt + interval}\n  end\n\n  local remaining = tokens - incrementBy\n  local expireAt = math.ceil(((maxTokens - remaining) / refillRate)) * interval\n        \n  redis.call(\"HSET\", key, \"refilledAt\", refilledAt, \"tokens\", remaining)\n\n  if (expireAt > 0) then\n    redis.call(\"PEXPIRE\", key, expireAt)\n  end\n  return {remaining, refilledAt + interval}\n`;\n\nexport const tokenBucketIdentifierNotFound = -1\n\nexport const tokenBucketRemainingTokensScript = `\n  local key         = KEYS[1]\n  local maxTokens   = tonumber(ARGV[1])\n        \n  local bucket = redis.call(\"HMGET\", key, \"refilledAt\", \"tokens\")\n\n  if bucket[1] == false then\n    return {maxTokens, ${tokenBucketIdentifierNotFound}}\n  end\n        \n  return {tonumber(bucket[2]), tonumber(bucket[1])}\n`;\n\nexport const cachedFixedWindowLimitScript = `\n  local key     = KEYS[1]\n  local window  = ARGV[1]\n  local incrementBy   = ARGV[2] -- increment rate per request at a given value, default is 1\n\n  local r = redis.call(\"INCRBY\", key, incrementBy)\n  if r == incrementBy then\n  -- The first time this key is set, the value will be equal to incrementBy.\n  -- So we only need the expire command once\n  redis.call(\"PEXPIRE\", key, window)\n  end\n      \n  return r\n`;\n\nexport const cachedFixedWindowRemainingTokenScript = `\n  local key = KEYS[1]\n  local tokens = 0\n\n  local value = redis.call('GET', key)\n  if value then\n      tokens = value\n  end\n  return tokens\n`;\n","export const fixedWindowLimitScript = `\n\tlocal key           = KEYS[1]\n\tlocal id            = ARGV[1]\n\tlocal window        = ARGV[2]\n\tlocal incrementBy   = tonumber(ARGV[3])\n\n\tredis.call(\"HSET\", key, id, incrementBy)\n\tlocal fields = redis.call(\"HGETALL\", key)\n\tif #fields == 2 and tonumber(fields[2])==incrementBy then\n\t-- The first time this key is set, and the value will be equal to incrementBy.\n\t-- So we only need the expire command once\n\t  redis.call(\"PEXPIRE\", key, window)\n\tend\n\n\treturn fields\n`;\nexport const fixedWindowRemainingTokensScript = `\n      local key = KEYS[1]\n      local tokens = 0\n\n      local fields = redis.call(\"HGETALL\", key)\n\n      return fields\n    `;\n\nexport const slidingWindowLimitScript = `\n\tlocal currentKey    = KEYS[1]           -- identifier including prefixes\n\tlocal previousKey   = KEYS[2]           -- key of the previous bucket\n\tlocal tokens        = tonumber(ARGV[1]) -- tokens per window\n\tlocal now           = ARGV[2]           -- current timestamp in milliseconds\n\tlocal window        = ARGV[3]           -- interval in milliseconds\n\tlocal requestId     = ARGV[4]           -- uuid for this request\n\tlocal incrementBy   = tonumber(ARGV[5]) -- custom rate, default is  1\n\n\tlocal currentFields = redis.call(\"HGETALL\", currentKey)\n\tlocal requestsInCurrentWindow = 0\n\tfor i = 2, #currentFields, 2 do\n\trequestsInCurrentWindow = requestsInCurrentWindow + tonumber(currentFields[i])\n\tend\n\n\tlocal previousFields = redis.call(\"HGETALL\", previousKey)\n\tlocal requestsInPreviousWindow = 0\n\tfor i = 2, #previousFields, 2 do\n\trequestsInPreviousWindow = requestsInPreviousWindow + tonumber(previousFields[i])\n\tend\n\n\tlocal percentageInCurrent = ( now % window) / window\n\n\t-- Only check limit if not refunding (negative rate)\n\tif incrementBy > 0 and requestsInPreviousWindow * (1 - percentageInCurrent ) + requestsInCurrentWindow + incrementBy > tokens then\n\t  return {currentFields, previousFields, false}\n\tend\n\n\tredis.call(\"HSET\", currentKey, requestId, incrementBy)\n\n\tif requestsInCurrentWindow == 0 then \n\t  -- The first time this key is set, the value will be equal to incrementBy.\n\t  -- So we only need the expire command once\n\t  redis.call(\"PEXPIRE\", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second\n\tend\n\treturn {currentFields, previousFields, true}\n`;\n\nexport const slidingWindowRemainingTokensScript = `\n\tlocal currentKey    = KEYS[1]           -- identifier including prefixes\n\tlocal previousKey   = KEYS[2]           -- key of the previous bucket\n\tlocal now         \t= ARGV[1]           -- current timestamp in milliseconds\n  \tlocal window      \t= ARGV[2]           -- interval in milliseconds\n\n\tlocal currentFields = redis.call(\"HGETALL\", currentKey)\n\tlocal requestsInCurrentWindow = 0\n\tfor i = 2, #currentFields, 2 do\n\trequestsInCurrentWindow = requestsInCurrentWindow + tonumber(currentFields[i])\n\tend\n\n\tlocal previousFields = redis.call(\"HGETALL\", previousKey)\n\tlocal requestsInPreviousWindow = 0\n\tfor i = 2, #previousFields, 2 do\n\trequestsInPreviousWindow = requestsInPreviousWindow + tonumber(previousFields[i])\n\tend\n\n\tlocal percentageInCurrent = ( now % window) / window\n  \trequestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)\n\t\n\treturn requestsInCurrentWindow + requestsInPreviousWindow\n`;\n","export const resetScript = `\n      local pattern = KEYS[1]\n\n      -- Initialize cursor to start from 0\n      local cursor = \"0\"\n\n      repeat\n          -- Scan for keys matching the pattern\n          local scan_result = redis.call('SCAN', cursor, 'MATCH', pattern)\n\n          -- Extract cursor for the next iteration\n          cursor = scan_result[1]\n\n          -- Extract keys from the scan result\n          local keys = scan_result[2]\n\n          for i=1, #keys do\n          redis.call('DEL', keys[i])\n          end\n\n      -- Continue scanning until cursor is 0 (end of keyspace)\n      until cursor == \"0\"\n    `;\n","import * as Single from \"./single\"\nimport * as Multi from \"./multi\"\nimport { resetScript } from \"./reset\"\n\nexport type ScriptInfo = {\n  script: string,\n  hash: string\n}\n\ntype Algorithm = {\n  limit: ScriptInfo,\n  getRemaining: ScriptInfo,\n}\n\ntype AlgorithmKind =\n  | \"fixedWindow\"\n  | \"slidingWindow\"\n  | \"tokenBucket\"\n  | \"cachedFixedWindow\"\n\nexport const SCRIPTS: {\n  singleRegion: Record<AlgorithmKind, Algorithm>,\n  multiRegion: Record<Exclude<AlgorithmKind, \"tokenBucket\" | \"cachedFixedWindow\">, Algorithm>,\n} = {\n  singleRegion: {\n    fixedWindow: {\n      limit: {\n        script: Single.fixedWindowLimitScript,\n        hash: \"b13943e359636db027ad280f1def143f02158c13\"\n      },\n      getRemaining: {\n        script: Single.fixedWindowRemainingTokensScript,\n        hash: \"8c4c341934502aee132643ffbe58ead3450e5208\"\n      },\n    },\n    slidingWindow: {\n      limit: {\n        script: Single.slidingWindowLimitScript,\n        hash: \"9b7842963bd73721f1a3011650c23c0010848ee3\"\n      },\n      getRemaining: {\n        script: Single.slidingWindowRemainingTokensScript,\n        hash: \"65a73ac5a05bf9712903bc304b77268980c1c417\"\n      },\n    },\n    tokenBucket: {\n      limit: {\n        script: Single.tokenBucketLimitScript,\n        hash: \"d1f857ebbdaeca90ccd2cd4eada61d7c8e5db1ca\"\n      },\n      getRemaining: {\n        script: Single.tokenBucketRemainingTokensScript,\n        hash: \"a15be2bb1db2a15f7c82db06146f9d08983900d0\"\n      },\n    },\n    cachedFixedWindow: {\n      limit: {\n        script: Single.cachedFixedWindowLimitScript,\n        hash: \"c26b12703dd137939b9a69a3a9b18e906a2d940f\"\n      },\n      getRemaining: {\n        script: Single.cachedFixedWindowRemainingTokenScript,\n        hash: \"8e8f222ccae68b595ee6e3f3bf2199629a62b91a\"\n      },\n    }\n  },\n  multiRegion: {\n    fixedWindow: {\n      limit: {\n        script: Multi.fixedWindowLimitScript,\n        hash: \"a8c14f3835aa87bd70e5e2116081b81664abcf5c\"\n      },\n      getRemaining: {\n        script: Multi.fixedWindowRemainingTokensScript,\n        hash: \"8ab8322d0ed5fe5ac8eb08f0c2e4557f1b4816fd\"\n      },\n    },\n    slidingWindow: {\n      limit: {\n        script: Multi.slidingWindowLimitScript,\n        hash: \"1e7ca8dcd2d600a6d0124a67a57ea225ed62921b\"\n      },\n      getRemaining: {\n        script: Multi.slidingWindowRemainingTokensScript,\n        hash: \"558c9306b7ec54abb50747fe0b17e5d44bd24868\"\n      },\n    },\n  }\n}\n\n/** COMMON */\nexport const RESET_SCRIPT: ScriptInfo = {\n  script: resetScript,\n  hash: \"54bd274ddc59fb3be0f42deee2f64322a10e2b50\"\n}\n","import type { Redis as RedisCore } from \"@upstash/redis\";\nimport type { Geo } from \"./analytics\";\n\n/**\n * EphemeralCache is used to block certain identifiers right away in case they have already exceeded the ratelimit.\n */\nexport type EphemeralCache = {\n  isBlocked: (identifier: string) => { blocked: boolean; reset: number };\n  blockUntil: (identifier: string, reset: number) => void;\n\n  set: (key: string, value: number) => void;\n  get: (key: string) => number | null;\n\n  incr: (key: string, incrementAmount?: number) => number;\n\n  pop: (key: string) => void;\n  empty: () => void;\n\n  size: () => number;\n}\n\nexport type RegionContext = {\n  redis: Redis;\n  cache?: EphemeralCache,\n};\nexport type MultiRegionContext = { regionContexts: Omit<RegionContext[], \"cache\">; cache?: EphemeralCache };\n\nexport type RatelimitResponseType = \"timeout\" | \"cacheBlock\" | \"denyList\"\n\nexport type Context = RegionContext | MultiRegionContext;\nexport type RatelimitResponse = {\n  /**\n   * Whether the request may pass(true) or exceeded the limit(false)\n   */\n  success: boolean;\n  /**\n   * Maximum number of requests allowed within a window.\n   */\n  limit: number;\n  /**\n   * How many requests the user has left within the current window.\n   */\n  remaining: number;\n  /**\n   * Unix timestamp in milliseconds when the limits are reset.\n   */\n  reset: number;\n\n  /**\n   * For the MultiRegion setup we do some synchronizing in the background, after returning the current limit.\n   * Or when analytics is enabled, we send the analytics asynchronously after returning the limit.\n   * In most case you can simply ignore this.\n   *\n   * On Vercel Edge or Cloudflare workers, you need to explicitly handle the pending Promise like this:\n   *\n   * ```ts\n   * const { pending } = await ratelimit.limit(\"id\")\n   * context.waitUntil(pending)\n   * ```\n   *\n   * See `waitUntil` documentation in\n   * [Cloudflare](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/#contextwaituntil)\n   * and [Vercel](https://vercel.com/docs/functions/edge-middleware/middleware-api#waituntil)\n   * for more details.\n   * ```\n   */\n  pending: Promise<unknown>;\n\n  /**\n   * Reason behind the result in `success` field.\n   * - Is set to \"timeout\" when request times out\n   * - Is set to \"cacheBlock\" when an identifier is blocked through cache without calling redis because it was\n   *    rate limited previously.\n   * - Is set to \"denyList\" when identifier or one of ip/user-agent/country parameters is in deny list. To enable\n   *    deny list, see `enableProtection` parameter. To edit the deny list, see the Upstash Ratelimit Dashboard\n   *    at https://console.upstash.com/ratelimit.\n   * - Is set to undefined if rate limit check had to use Redis. This happens in cases when `success` field in\n   *    the response is true. It can also happen the first time sucecss is false.\n   */\n  reason?: RatelimitResponseType;\n\n  /**\n   * The value which was in the deny list if reason: \"denyList\"\n   */\n  deniedValue?: DeniedValue\n};\n\nexport type Algorithm<TContext> = () => {\n  limit: (\n    ctx: TContext,\n    identifier: string,\n    rate?: number,\n    opts?: {\n      cache?: EphemeralCache;\n    },\n  ) => Promise<RatelimitResponse>;\n  getRemaining: (ctx: TContext, identifier: string) => Promise<{\n    remaining: number,\n    reset: number\n  }>;\n  resetTokens: (ctx: TContext, identifier: string) => Promise<void>;\n};\n\nexport type IsDenied = 0 | 1;\n\nexport type DeniedValue = string | undefined;\nexport type DenyListResponse = { deniedValue: DeniedValue, invalidIpDenyList: boolean }\n\nexport const DenyListExtension = \"denyList\" as const\nexport const IpDenyListKey = \"ipDenyList\" as const\nexport const IpDenyListStatusKey = \"ipDenyListStatus\" as const\n\nexport type LimitPayload = [RatelimitResponse, DenyListResponse];\nexport type LimitOptions = {\n  geo?: Geo,\n  rate?: number,\n  ip?: string,\n  userAgent?: string,\n  country?: string\n}\n\nexport type Redis = RedisCore\n","export const checkDenyListScript = `\n  -- Checks if values provideed in ARGV are present in the deny lists.\n  -- This is done using the allDenyListsKey below.\n\n  -- Additionally, checks the status of the ip deny list using the\n  -- ipDenyListStatusKey below. Here are the possible states of the\n  -- ipDenyListStatusKey key:\n  -- * status == -1: set to \"disabled\" with no TTL\n  -- * status == -2: not set, meaning that is was set before but expired\n  -- * status  >  0: set to \"valid\", with a TTL\n  --\n  -- In the case of status == -2, we set the status to \"pending\" with\n  -- 30 second ttl. During this time, the process which got status == -2\n  -- will update the ip deny list.\n\n  local allDenyListsKey     = KEYS[1]\n  local ipDenyListStatusKey = KEYS[2]\n\n  local results = redis.call('SMISMEMBER', allDenyListsKey, unpack(ARGV))\n  local status  = redis.call('TTL', ipDenyListStatusKey)\n  if status == -2 then\n    redis.call('SETEX', ipDenyListStatusKey, 30, \"pending\")\n  end\n\n  return { results, status }\n`","import type { Redis } from \"../types\";\nimport { DenyListExtension, IpDenyListKey, IpDenyListStatusKey } from \"../types\"\nimport { getIpListTTL } from \"./time\"\n\nconst baseUrl = \"https://raw.githubusercontent.com/stamparm/ipsum/master/levels\"\n\nexport class ThresholdError extends Error {\n  constructor(threshold: number) {\n    super(`Allowed threshold values are from 1 to 8, 1 and 8 included. Received: ${threshold}`);\n    this.name = \"ThresholdError\";\n  }\n}\n\n/**\n * Fetches the ips from the ipsum.txt at github\n * \n * In the repo we are using, 30+ ip lists are aggregated. The results are\n * stores in text files from 1 to 8.\n * https://github.com/stamparm/ipsum/tree/master/levels\n * \n * X.txt file holds ips which are in at least X of the lists.\n *\n * @param threshold ips with less than or equal to the threshold are not included\n * @returns list of ips\n */\nconst getIpDenyList = async (threshold: number) => {\n  if (typeof threshold !== \"number\" || threshold < 1 || threshold > 8) {\n    throw new ThresholdError(threshold)\n  }\n\n  try {\n    // Fetch data from the URL\n    const response = await fetch(`${baseUrl}/${threshold}.txt`)\n    if (!response.ok) {\n      throw new Error(`Error fetching data: ${response.statusText}`)\n    }\n    const data = await response.text()\n\n    // Process the data\n    const lines = data.split(\"\\n\")\n    return lines.filter((value) => value.length > 0) // remove empty values\n  } catch (error) {\n    throw new Error(`Failed to fetch ip deny list: ${error}`)\n  }\n}\n\n/**\n * Gets the list of ips from the github source which are not in the\n * deny list already\n * \n * First, gets the ip list from github using the threshold. Then, calls redis with\n * a transaction which does the following:\n * - subtract the current ip deny list from all\n * - delete current ip deny list\n * - recreate ip deny list with the ips from github. Ips already in the users own lists\n *   are excluded.\n * - status key is set to valid with ttl until next 2 AM UTC, which is a bit later than\n *   when the list is updated on github.\n *\n * @param redis redis instance\n * @param prefix ratelimit prefix\n * @param threshold ips with less than or equal to the threshold are not included\n * @param ttl time to live in milliseconds for the status flag. Optional. If not\n *  passed, ttl is infferred from current time.\n * @returns list of ips which are not in the deny list\n */\nexport const updateIpDenyList = async (\n  redis: Redis,\n  prefix: string,\n  threshold: number,\n  ttl?: number\n) => {\n  const allIps = await getIpDenyList(threshold)\n\n  const allDenyLists = [prefix, DenyListExtension, \"all\"].join(\":\")\n  const ipDenyList = [prefix, DenyListExtension, IpDenyListKey].join(\":\")\n  const statusKey = [prefix, IpDenyListStatusKey].join(\":\")\n\n  const transaction = redis.multi()\n\n  // remove the old ip deny list from the all set\n  transaction.sdiffstore(allDenyLists, allDenyLists, ipDenyList)\n\n  // delete the old ip deny list and create new one\n  transaction.del(ipDenyList)\n\n  transaction.sadd(ipDenyList, allIps.at(0), ...allIps.slice(1))\n\n  // make all deny list and ip deny list disjoint by removing duplicate\n  // ones from ip deny list\n  transaction.sdiffstore(ipDenyList, ipDenyList, allDenyLists)\n\n  // add remaining ips to all list\n  transaction.sunionstore(allDenyLists, allDenyLists, ipDenyList)\n\n  // set status key with ttl\n  transaction.set(statusKey, \"valid\", {px: ttl ?? getIpListTTL()})\n\n  return await transaction.exec()\n}\n\n/**\n * Disables the ip deny list by removing the ip deny list from the all\n * set and removing the ip deny list. Also sets the status key to disabled\n * with no ttl.\n * \n * @param redis redis instance\n * @param prefix ratelimit prefix\n * @returns \n */\nexport const disableIpDenyList = async (redis: Redis, prefix: string) => {\n  const allDenyListsKey = [prefix, DenyListExtension, \"all\"].join(\":\")\n  const ipDenyListKey = [prefix, DenyListExtension, IpDenyListKey].join(\":\")\n  const statusKey = [prefix, IpDenyListStatusKey].join(\":\")\n\n  const transaction = redis.multi()\n\n  // remove the old ip deny list from the all set\n  transaction.sdiffstore(allDenyListsKey, allDenyListsKey, ipDenyListKey)\n\n  // delete the old ip deny list\n  transaction.del(ipDenyListKey)\n\n  // set to disabled\n  // this way, the TTL command in checkDenyListScript will return -1.\n  transaction.set(statusKey, \"disabled\")\n\n  return await transaction.exec()\n}\n","\n// Number of milliseconds in one hour\nconst MILLISECONDS_IN_HOUR = 60 * 60 * 1000;\n\n// Number of milliseconds in one day\nconst MILLISECONDS_IN_DAY = 24 * MILLISECONDS_IN_HOUR;\n\n// Number of milliseconds from the current time to 2 AM UTC\nconst MILLISECONDS_TO_2AM = 2 * MILLISECONDS_IN_HOUR;\n\nexport const getIpListTTL = (time?: number) => {\n  const now = time || Date.now();\n\n  // Time since the last 2 AM UTC\n  const timeSinceLast2AM = (now - MILLISECONDS_TO_2AM) % MILLISECONDS_IN_DAY;\n\n  // Remaining time until the next 2 AM UTC\n  return MILLISECONDS_IN_DAY - timeSinceLast2AM;\n}\n  ","import type { DeniedValue, DenyListResponse, LimitPayload} from \"../types\";\nimport { DenyListExtension, IpDenyListStatusKey } from \"../types\"\nimport type { RatelimitResponse, Redis } from \"../types\"\nimport { Cache } from \"../cache\";\nimport { checkDenyListScript } from \"./scripts\";\nimport { updateIpDenyList } from \"./ip-deny-list\";\n\n\nconst denyListCache = new Cache(new Map());\n\n/**\n * Checks items in members list and returns the first denied member\n * in denyListCache if there are any.\n * \n * @param members list of values to check against the cache\n * @returns a member from the cache. If there is none, returns undefined\n */\nexport const checkDenyListCache = (members: string[]): DeniedValue => {\n  return members.find(\n    member => denyListCache.isBlocked(member).blocked\n  );\n}\n\n/**\n * Blocks a member for 1 minute.\n * \n * If there are more than 1000 elements in the cache, empties\n * it so that the cache doesn't grow in size indefinetely.\n * \n * @param member member to block\n */\nconst blockMember = (member: string) => {\n  if (denyListCache.size() > 1000) denyListCache.empty();\n  denyListCache.blockUntil(member, Date.now() + 60_000);\n}\n\n/**\n * Checks if identifier or any of the values are in any of\n * the denied lists in Redis.\n * \n * If some value is in a deny list, we block the identifier for a minute.\n * \n * @param redis redis client\n * @param prefix ratelimit prefix\n * @param members List of values (identifier, ip, user agent, country)\n * @returns true if a member is in deny list at Redis\n */\nexport const checkDenyList = async (\n  redis: Redis,\n  prefix: string,\n  members: string[]\n): Promise<DenyListResponse> => {\n  const [ deniedValues, ipDenyListStatus ] = await redis.eval(\n    checkDenyListScript,\n    [\n      [prefix, DenyListExtension, \"all\"].join(\":\"),\n      [prefix, IpDenyListStatusKey].join(\":\"),\n    ],\n    members\n  ) as [boolean[], number];\n\n  let deniedValue: DeniedValue = undefined;\n  deniedValues.map((memberDenied, index) => {\n    if (memberDenied) {\n      blockMember(members[index])\n      deniedValue = members[index]\n    }\n  })\n\n  return {\n    deniedValue,\n    invalidIpDenyList: ipDenyListStatus === -2\n  };\n};\n\n/**\n * Overrides the rate limit response if deny list\n * response indicates that value is in deny list.\n * \n * @param ratelimitResponse \n * @param denyListResponse \n * @returns \n */\nexport const resolveLimitPayload = (\n  redis: Redis,\n  prefix: string,\n  [ratelimitResponse, denyListResponse]: LimitPayload,\n  threshold: number\n): RatelimitResponse => {\n\n  if (denyListResponse.deniedValue) {\n    ratelimitResponse.success = false;\n    ratelimitResponse.remaining = 0;\n    ratelimitResponse.reason = \"denyList\";\n    ratelimitResponse.deniedValue = denyListResponse.deniedValue\n  }\n\n  if (denyListResponse.invalidIpDenyList) {\n    const updatePromise = updateIpDenyList(redis, prefix, threshold)\n    ratelimitResponse.pending = Promise.all([\n      ratelimitResponse.pending,\n      updatePromise\n    ])\n  }\n\n  return ratelimitResponse;\n};\n\n/**\n * \n * @returns Default response to return when some item\n *  is in deny list.\n */\nexport const defaultDeniedResponse = (deniedValue: string): RatelimitResponse => {\n  return {\n    success: false,\n    limit: 0,\n    remaining: 0,\n    reset: 0,\n    pending: Promise.resolve(),\n    reason: \"denyList\",\n    deniedValue: deniedValue\n  }\n}\n","import { Analytics } from \"./analytics\";\nimport { Cache } from \"./cache\";\nimport type { Algorithm, Context, LimitOptions, LimitPayload, RatelimitResponse, Redis } from \"./types\";\nimport { checkDenyList, checkDenyListCache, defaultDeniedResponse, resolveLimitPayload } from \"./deny-list/index\";\n\nexport class TimeoutError extends Error {\n  constructor() {\n    super(\"Timeout\");\n    this.name = \"TimeoutError\";\n  }\n}\nexport type RatelimitConfig<TContext> = {\n  /**\n   * The ratelimiter function to use.\n   *\n   * Choose one of the predefined ones or implement your own.\n   * Available algorithms are exposed via static methods:\n   * - Ratelimiter.fixedWindow\n   * - Ratelimiter.slidingWindow\n   * - Ratelimiter.tokenBucket\n   */\n\n  limiter: Algorithm<TContext>;\n\n  ctx: TContext;\n  /**\n   * All keys in redis are prefixed with this.\n   *\n   * @default `@upstash/ratelimit`\n   */\n  prefix?: string;\n\n  /**\n   * If enabled, the ratelimiter will keep a global cache of identifiers, that have\n   * exhausted their ratelimit. In serverless environments this is only possible if\n   * you create the ratelimiter instance outside of your handler function. While the\n   * function is still hot, the ratelimiter can block requests without having to\n   * request data from redis, thus saving time and money.\n   *\n   * Whenever an identifier has exceeded its limit, the ratelimiter will add it to an\n   * internal list together with its reset timestamp. If the same identifier makes a\n   * new request before it is reset, we can immediately reject it.\n   *\n   * Set to `false` to disable.\n   *\n   * If left undefined, a map is created automatically, but it can only work\n   * if the map or the  ratelimit instance is created outside your serverless function handler.\n   */\n  ephemeralCache?: Map<string, number> | false;\n\n  /**\n   * If set, the ratelimiter will allow requests to pass after this many milliseconds.\n   *\n   * Use this if you want to allow requests in case of network problems\n   *\n   * @default 5000\n   */\n  timeout?: number;\n\n  /**\n   * If enabled, the ratelimiter will store analytics data in redis, which you can check out at\n   * https://console.upstash.com/ratelimit\n   *\n   * @default false\n   */\n  analytics?: boolean;\n\n  /**\n   * Enables deny list. If set to true, requests with identifier or ip/user-agent/countrie\n   * in the deny list will be rejected automatically. To edit the deny list, check out the\n   * ratelimit dashboard at https://console.upstash.com/ratelimit\n   * \n   * @default false\n   */\n  enableProtection?: boolean\n\n  denyListThreshold?: number\n};\n\n/**\n * Ratelimiter using serverless redis from https://upstash.com/\n *\n * @example\n * ```ts\n * const { limit } = new Ratelimit({\n *    redis: Redis.fromEnv(),\n *    limiter: Ratelimit.slidingWindow(\n *      10,     // Allow 10 requests per window of 30 minutes\n *      \"30 m\", // interval of 30 minutes\n *    ),\n * })\n *\n * ```\n */\nexport abstract class Ratelimit<TContext extends Context> {\n  protected readonly limiter: Algorithm<TContext>;\n\n  protected readonly ctx: TContext;\n\n  protected readonly prefix: string;\n\n  protected readonly timeout: number;\n\n  protected readonly primaryRedis: Redis;\n\n  protected readonly analytics?: Analytics;\n\n  protected readonly enableProtection: boolean;\n\n  protected readonly denyListThreshold: number\n\n  constructor(config: RatelimitConfig<TContext>) {\n    this.ctx = config.ctx;\n    this.limiter = config.limiter;\n    this.timeout = config.timeout ?? 5000;\n    this.prefix = config.prefix ?? \"@upstash/ratelimit\";\n\n    this.enableProtection = config.enableProtection ?? false;\n    this.denyListThreshold = config.denyListThreshold ?? 6;\n\n    this.primaryRedis = (\"redis\" in this.ctx) ? this.ctx.redis : this.ctx.regionContexts[0].redis\n    this.analytics = config.analytics\n      ? new Analytics({\n        redis: this.primaryRedis,\n        prefix: this.prefix,\n      })\n      : undefined;\n\n    if (config.ephemeralCache instanceof Map) {\n      this.ctx.cache = new Cache(config.ephemeralCache);\n    } else if (config.ephemeralCache === undefined) {\n      this.ctx.cache = new Cache(new Map());\n    }\n  }\n\n  /**\n   * Determine if a request should pass or be rejected based on the identifier and previously chosen ratelimit.\n   *\n   * Use this if you want to reject all requests that you can not handle right now.\n   *\n   * @example\n   * ```ts\n   *  const ratelimit = new Ratelimit({\n   *    redis: Redis.fromEnv(),\n   *    limiter: Ratelimit.slidingWindow(10, \"10 s\")\n   *  })\n   *\n   *  const { success } = await ratelimit.limit(id)\n   *  if (!success){\n   *    return \"Nope\"\n   *  }\n   *  return \"Yes\"\n   * ```\n   *\n   * @param req.rate - The rate at which tokens will be added or consumed from the token bucket. A higher rate allows for more requests to be processed. Defaults to 1 token per interval if not specified.\n   *\n   * Usage with `req.rate`\n   * @example\n   * ```ts\n   *  const ratelimit = new Ratelimit({\n   *    redis: Redis.fromEnv(),\n   *    limiter: Ratelimit.slidingWindow(100, \"10 s\")\n   *  })\n   *\n   *  const { success } = await ratelimit.limit(id, {rate: 10})\n   *  if (!success){\n   *    return \"Nope\"\n   *  }\n   *  return \"Yes\"\n   * ```\n   */\n  public limit = async (\n    identifier: string,\n    req?: LimitOptions,\n  ): Promise<RatelimitResponse> => {\n\n    let timeoutId: any = null;\n    try {\n      const response = this.getRatelimitResponse(identifier, req);\n      const { responseArray, newTimeoutId } = this.applyTimeout(response);\n      timeoutId = newTimeoutId;\n\n      const timedResponse = await Promise.race(responseArray);\n      const finalResponse = this.submitAnalytics(timedResponse, identifier, req);\n      return finalResponse;\n    } finally {\n      if (timeoutId) {\n        clearTimeout(timeoutId);\n      }\n    }\n  };\n\n  /**\n   * Block until the request may pass or timeout is reached.\n   *\n   * This method returns a promise that resolves as soon as the request may be processed\n   * or after the timeout has been reached.\n   *\n   * Use this if you want to delay the request until it is ready to get processed.\n   *\n   * @example\n   * ```ts\n   *  const ratelimit = new Ratelimit({\n   *    redis: Redis.fromEnv(),\n   *    limiter: Ratelimit.slidingWindow(10, \"10 s\")\n   *  })\n   *\n   *  const { success } = await ratelimit.blockUntilReady(id, 60_000)\n   *  if (!success){\n   *    return \"Nope\"\n   *  }\n   *  return \"Yes\"\n   * ```\n   */\n  public blockUntilReady = async (\n    /**\n     * An identifier per user or api.\n     * Choose a userID, or api token, or ip address.\n     *\n     * If you want to limit your api across all users, you can set a constant string.\n     */\n    identifier: string,\n    /**\n     * Maximum duration to wait in milliseconds.\n     * After this time the request will be denied.\n     */\n    timeout: number,\n  ): Promise<RatelimitResponse> => {\n    if (timeout <= 0) {\n      throw new Error(\"timeout must be positive\");\n    }\n    let res: RatelimitResponse;\n\n    const deadline = Date.now() + timeout;\n    while (true) {\n      res = await this.limit(identifier);\n      if (res.success) {\n        break;\n      }\n      if (res.reset === 0) {\n        throw new Error(\"This should not happen\");\n      }\n\n      const wait = Math.min(res.reset, deadline) - Date.now();\n      await new Promise((r) => setTimeout(r, wait));\n\n      if (Date.now() > deadline) {\n        break;\n      }\n    }\n    return res!;\n  };\n\n  public resetUsedTokens = async (identifier: string) => {\n    const pattern = [this.prefix, identifier].join(\":\");\n    await this.limiter().resetTokens(this.ctx, pattern);\n  };\n\n  /**\n   * Returns the remaining token count together with a reset timestamps\n   * \n   * @param identifier identifir to check\n   * @returns object with `remaining` and reset fields. `remaining` denotes\n   *          the remaining tokens and reset denotes the timestamp when the\n   *          tokens reset.\n   */\n  public getRemaining = async (identifier: string): Promise<{\n    remaining: number;\n    reset: number;\n  }> => {\n    const pattern = [this.prefix, identifier].join(\":\");\n\n    return await this.limiter().getRemaining(this.ctx, pattern);\n  };\n\n  /**\n   * Checks if the identifier or the values in req are in the deny list cache.\n   * If so, returns the default denied response.\n   * \n   * Otherwise, calls redis to check the rate limit and deny list. Returns after\n   * resolving the result. Resolving is overriding the rate limit result if\n   * the some value is in deny list.\n   * \n   * @param identifier identifier to block\n   * @param req options with ip, user agent, country, rate and geo info\n   * @returns rate limit response\n   */\n  private getRatelimitResponse = async (\n    identifier: string,\n    req?: LimitOptions\n  ): Promise<RatelimitResponse> => {\n    const key = this.getKey(identifier);\n    const definedMembers = this.getDefinedMembers(identifier, req);\n\n    const deniedValue = checkDenyListCache(definedMembers)\n\n    const result: LimitPayload = deniedValue ? [defaultDeniedResponse(deniedValue), { deniedValue, invalidIpDenyList: false }] : (await Promise.all([\n      this.limiter().limit(this.ctx, key, req?.rate),\n      this.enableProtection\n        ? checkDenyList(this.primaryRedis, this.prefix, definedMembers)\n        : { deniedValue: undefined, invalidIpDenyList: false }\n    ]));\n\n    return resolveLimitPayload(this.primaryRedis, this.prefix, result, this.denyListThreshold)\n  };\n\n  /**\n   * Creates an array with the original response promise and a timeout promise\n   * if this.timeout > 0.\n   * \n   * @param response Ratelimit response promise\n   * @returns array with the response and timeout promise. also includes the timeout id\n   */\n  private applyTimeout = (response: Promise<RatelimitResponse>) => {\n    let newTimeoutId: any = null;\n    const responseArray: Array<Promise<RatelimitResponse>> = [response];\n\n    if (this.timeout > 0) {\n      const timeoutResponse = new Promise<RatelimitResponse>((resolve) => {\n        newTimeoutId = setTimeout(() => {\n          resolve({\n            success: true,\n            limit: 0,\n            remaining: 0,\n            reset: 0,\n            pending: Promise.resolve(),\n            reason: \"timeout\"\n          });\n        }, this.timeout);\n      })\n      responseArray.push(timeoutResponse);\n    }\n\n    return {\n      responseArray,\n      newTimeoutId,\n    }\n  }\n\n  /**\n   * submits analytics if this.analytics is set\n   * \n   * @param ratelimitResponse final rate limit response\n   * @param identifier identifier to submit\n   * @param req limit options\n   * @returns rate limit response after updating the .pending field\n   */\n  private submitAnalytics = (\n    ratelimitResponse: RatelimitResponse,\n    identifier: string,\n    req?: Pick<LimitOptions, \"geo\">,\n  ) => {\n    if (this.analytics) {\n      try {\n        const geo = req ? this.analytics.extractGeo(req) : undefined;\n        const analyticsP = this.analytics\n          .record({\n            identifier: ratelimitResponse.reason === \"denyList\" // if in denyList, use denied value as identifier\n              ? ratelimitResponse.deniedValue!\n              : identifier,\n            time: Date.now(),\n            success: ratelimitResponse.reason === \"denyList\" // if in denyList, label success as \"denied\"\n              ? \"denied\"\n              : ratelimitResponse.success,\n            ...geo,\n          })\n          .catch((error) => {\n            let errorMessage = \"Failed to record analytics\"\n            if (`${error}`.includes(\"WRONGTYPE\")) {\n              errorMessage = `\n    Failed to record analytics. See the information below:\n\n    This can occur when you uprade to Ratelimit version 1.1.2\n    or later from an earlier version.\n\n    This occurs simply because the way we store analytics data\n    has changed. To avoid getting this error, disable analytics\n    for *an hour*, then simply enable it back.\\n\n    `\n            }\n            console.warn(errorMessage, error);\n          });\n        ratelimitResponse.pending = Promise.all([ratelimitResponse.pending, analyticsP]);\n      } catch (error) {\n        console.warn(\"Failed to record analytics\", error);\n      };\n    };\n    return ratelimitResponse;\n  }\n\n  private getKey = (identifier: string): string => {\n    return [this.prefix, identifier].join(\":\");\n  }\n\n  /**\n   * returns a list of defined values from\n   * [identifier, req.ip, req.userAgent, req.country]\n   * \n   * @param identifier identifier\n   * @param req limit options\n   * @returns list of defined values\n   */\n  private getDefinedMembers = (\n    identifier: string,\n    req?: Pick<LimitOptions, \"ip\" | \"userAgent\" | \"country\">\n  ): string[] => {\n    const members = [identifier, req?.ip, req?.userAgent, req?.country];\n    return (members as string[]).filter(Boolean);\n  }\n}\n","import { Cache } from \"./cache\";\nimport type { Duration } from \"./duration\";\nimport { ms } from \"./duration\";\nimport { safeEval } from \"./hash\";\nimport { RESET_SCRIPT, SCRIPTS } from \"./lua-scripts/hash\";\n\nimport { Ratelimit } from \"./ratelimit\";\nimport type { Algorithm, MultiRegionContext } from \"./types\";\n\nimport type { Redis } from \"./types\";\n\nfunction randomId(): string {\n  let result = \"\";\n  const characters =\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\";\n  const charactersLength = characters.length;\n  for (let i = 0; i < 16; i++) {\n    result += characters.charAt(Math.floor(Math.random() * charactersLength));\n  }\n  return result;\n}\n\nexport type MultiRegionRatelimitConfig = {\n  /**\n   * Instances of `@upstash/redis`\n   * @see https://github.com/upstash/upstash-redis#quick-start\n   */\n  redis: Redis[];\n  /**\n   * The ratelimiter function to use.\n   *\n   * Choose one of the predefined ones or implement your own.\n   * Available algorithms are exposed via static methods:\n   * - MultiRegionRatelimit.fixedWindow\n   */\n  limiter: Algorithm<MultiRegionContext>;\n  /**\n   * All keys in redis are prefixed with this.\n   *\n   * @default `@upstash/ratelimit`\n   */\n  prefix?: string;\n\n  /**\n   * If enabled, the ratelimiter will keep a global cache of identifiers, that have\n   * exhausted their ratelimit. In serverless environments this is only possible if\n   * you create the ratelimiter instance outside of your handler function. While the\n   * function is still hot, the ratelimiter can block requests without having to\n   * request data from redis, thus saving time and money.\n   *\n   * Whenever an identifier has exceeded its limit, the ratelimiter will add it to an\n   * internal list together with its reset timestamp. If the same identifier makes a\n   * new request before it is reset, we can immediately reject it.\n   *\n   * Set to `false` to disable.\n   *\n   * If left undefined, a map is created automatically, but it can only work\n   * if the map or the ratelimit instance is created outside your serverless function handler.\n   */\n  ephemeralCache?: Map<string, number> | false;\n\n  /**\n   * If set, the ratelimiter will allow requests to pass after this many milliseconds.\n   *\n   * Use this if you want to allow requests in case of network problems\n   */\n  timeout?: number;\n\n  /**\n   * If enabled, the ratelimiter will store analytics data in redis, which you can check out at\n   * https://console.upstash.com/ratelimit\n   *\n   * @default false\n   */\n  analytics?: boolean;\n\n  /**\n   * If enabled, lua scripts will be sent to Redis with SCRIPT LOAD durint the first request.\n   * In the subsequent requests, hash of the script will be used to invoke it\n   *\n   * @default true\n   */\n  cacheScripts?: boolean;\n};\n\n/**\n * Ratelimiter using serverless redis from https://upstash.com/\n *\n * @example\n * ```ts\n * const { limit } = new MultiRegionRatelimit({\n *    redis: Redis.fromEnv(),\n *    limiter: MultiRegionRatelimit.fixedWindow(\n *      10,     // Allow 10 requests per window of 30 minutes\n *      \"30 m\", // interval of 30 minutes\n *    )\n * })\n *\n * ```\n */\nexport class MultiRegionRatelimit extends Ratelimit<MultiRegionContext> {\n  /**\n   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithn of your choice.\n   */\n  constructor(config: MultiRegionRatelimitConfig) {\n    super({\n      prefix: config.prefix,\n      limiter: config.limiter,\n      timeout: config.timeout,\n      analytics: config.analytics,\n      ctx: {\n        regionContexts: config.redis.map((redis) => ({\n          redis: redis,\n        })),\n        cache: config.ephemeralCache\n          ? new Cache(config.ephemeralCache)\n          : undefined,\n      },\n    });\n  }\n\n  /**\n   * Each request inside a fixed time increases a counter.\n   * Once the counter reaches the maximum allowed number, all further requests are\n   * rejected.\n   *\n   * **Pro:**\n   *\n   * - Newer requests are not starved by old ones.\n   * - Low storage cost.\n   *\n   * **Con:**\n   *\n   * A burst of requests near the boundary of a window can result in a very\n   * high request rate because two windows will be filled with requests quickly.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - A fixed timeframe\n   */\n  static fixedWindow(\n    /**\n     * How many requests are allowed per window.\n     */\n    tokens: number,\n    /**\n     * The duration in which `tokens` requests are allowed.\n     */\n    window: Duration\n  ): Algorithm<MultiRegionContext> {\n    const windowDuration = ms(window);\n\n    return () => ({\n      async limit(ctx: MultiRegionContext, identifier: string, rate?: number) {\n        const requestId = randomId();\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const incrementBy = rate ?? 1;\n\n        // Only check cache block if not refunding (negative rate)\n        if (ctx.cache && incrementBy > 0) {\n          const { blocked, reset } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\",\n            };\n          }\n        }\n\n        const dbs: { redis: Redis; request: Promise<string[]> }[] =\n          ctx.regionContexts.map((regionContext) => ({\n            redis: regionContext.redis,\n            request: safeEval(\n              regionContext,\n              SCRIPTS.multiRegion.fixedWindow.limit,\n              [key],\n              [requestId, windowDuration, incrementBy]\n            ) as Promise<string[]>,\n          }));\n\n        // The firstResponse is an array of string at every EVEN indexes and rate at which the tokens are used at every ODD indexes\n        const firstResponse = await Promise.any(dbs.map((s) => s.request));\n\n        const usedTokens = firstResponse.reduce(\n          (accTokens: number, usedToken, index) => {\n            let parsedToken = 0;\n            if (index % 2) {\n              parsedToken = Number.parseInt(usedToken);\n            }\n\n            return accTokens + parsedToken;\n          },\n          0\n        );\n\n        const remaining = tokens - usedTokens;\n\n        /**\n         * If the length between two databases does not match, we sync the two databases\n         */\n        async function sync() {\n          const individualIDs = await Promise.all(dbs.map((s) => s.request));\n\n          const allIDs = [\n            ...new Set(\n              individualIDs.flat().reduce((acc: string[], curr, index) => {\n                if (index % 2 === 0) {\n                  acc.push(curr);\n                }\n                return acc;\n              }, [])\n            ).values(),\n          ];\n\n          for (const db of dbs) {\n            const usedDbTokensRequest = await db.request;\n            const usedDbTokens = usedDbTokensRequest.reduce(\n              (accTokens: number, usedToken, index) => {\n                let parsedToken = 0;\n                if (index % 2) {\n                  parsedToken = Number.parseInt(usedToken);\n                }\n\n                return accTokens + parsedToken;\n              },\n              0\n            );\n\n            const dbIdsRequest = await db.request;\n            const dbIds = dbIdsRequest.reduce(\n              (ids: string[], currentId, index) => {\n                if (index % 2 === 0) {\n                  ids.push(currentId);\n                }\n                return ids;\n              },\n              []\n            );\n            /**\n             * If the bucket in this db is already full, it doesn't matter which ids it contains.\n             * So we do not have to sync.\n             */\n            if (usedDbTokens >= tokens) {\n              continue;\n            }\n            const diff = allIDs.filter((id) => !dbIds.includes(id));\n            /**\n             * Don't waste a request if there is nothing to send\n             */\n            if (diff.length === 0) {\n              continue;\n            }\n\n            for (const requestId of diff) {\n              await db.redis.hset(key, { [requestId]: incrementBy });\n            }\n          }\n        }\n\n        /**\n         * Do not await sync. This should not run in the critical path.\n         */\n\n        const success = remaining >= 0;\n        const reset = (bucket + 1) * windowDuration;\n\n        if (ctx.cache) {\n          if (!success) {\n            ctx.cache.blockUntil(identifier, reset);\n          } else if (incrementBy < 0) {\n            // Successful refund: unblock from cache\n            ctx.cache.pop(identifier);\n          }\n        }\n        return {\n          success,\n          limit: tokens,\n          remaining,\n          reset,\n          pending: sync(),\n        };\n      },\n      async getRemaining(ctx: MultiRegionContext, identifier: string) {\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n\n        const dbs: { redis: Redis; request: Promise<string[]> }[] =\n          ctx.regionContexts.map((regionContext) => ({\n            redis: regionContext.redis,\n            request: safeEval(\n              regionContext,\n              SCRIPTS.multiRegion.fixedWindow.getRemaining,\n              [key],\n              [null]\n            ) as Promise<string[]>,\n          }));\n\n        // The firstResponse is an array of string at every EVEN indexes and rate at which the tokens are used at every ODD indexes\n        const firstResponse = await Promise.any(dbs.map((s) => s.request));\n        const usedTokens = firstResponse.reduce(\n          (accTokens: number, usedToken, index) => {\n            let parsedToken = 0;\n            if (index % 2) {\n              parsedToken = Number.parseInt(usedToken);\n            }\n\n            return accTokens + parsedToken;\n          },\n          0\n        );\n\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (bucket + 1) * windowDuration,\n        };\n      },\n      async resetTokens(ctx: MultiRegionContext, identifier: string) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n\n        await Promise.all(\n          ctx.regionContexts.map((regionContext) => {\n            safeEval(regionContext, RESET_SCRIPT, [pattern], [null]);\n          })\n        );\n      },\n    });\n  }\n\n  /**\n   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage\n   * costs than `slidingLogs` and improved boundary behavior by calculating a\n   * weighted score between two windows.\n   *\n   * **Pro:**\n   *\n   * Good performance allows this to scale to very high loads.\n   *\n   * **Con:**\n   *\n   * Nothing major.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - The duration in which the user can max X requests.\n   */\n  static slidingWindow(\n    /**\n     * How many requests are allowed per window.\n     */\n    tokens: number,\n    /**\n     * The duration in which `tokens` requests are allowed.\n     */\n    window: Duration\n  ): Algorithm<MultiRegionContext> {\n    const windowSize = ms(window);\n\n    const windowDuration = ms(window);\n\n    return () => ({\n      async limit(ctx: MultiRegionContext, identifier: string, rate?: number) {\n        const requestId = randomId();\n        const now = Date.now();\n\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n        const incrementBy = rate ?? 1;\n\n        // Only check cache block if not refunding (negative rate)\n        if (ctx.cache && incrementBy > 0) {\n          const { blocked, reset } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\",\n            };\n          }\n        }\n\n        const dbs = ctx.regionContexts.map((regionContext) => ({\n          redis: regionContext.redis,\n          request: safeEval(\n            regionContext,\n            SCRIPTS.multiRegion.slidingWindow.limit,\n            [currentKey, previousKey],\n            [tokens, now, windowDuration, requestId, incrementBy]\n            // lua seems to return `1` for true and `null` for false\n          ) as Promise<[string[], string[], 1 | null]>,\n        }));\n\n        const percentageInCurrent = (now % windowDuration) / windowDuration;\n        const [current, previous, success] = await Promise.any(\n          dbs.map((s) => s.request)\n        );\n\n        // in the case of success, the new request is not included in the current array.\n        // add it manually\n        if (success) {\n          current.push(requestId, incrementBy.toString());\n        }\n\n        const previousUsedTokens = previous.reduce(\n          (accTokens: number, usedToken, index) => {\n            let parsedToken = 0;\n            if (index % 2) {\n              parsedToken = Number.parseInt(usedToken);\n            }\n\n            return accTokens + parsedToken;\n          },\n          0\n        );\n\n        const currentUsedTokens = current.reduce(\n          (accTokens: number, usedToken, index) => {\n            let parsedToken = 0;\n            if (index % 2) {\n              parsedToken = Number.parseInt(usedToken);\n            }\n\n            return accTokens + parsedToken;\n          },\n          0\n        );\n\n        const previousPartialUsed = Math.ceil(\n          previousUsedTokens * (1 - percentageInCurrent)\n        );\n\n        const usedTokens = previousPartialUsed + currentUsedTokens;\n\n        const remaining = tokens - usedTokens;\n\n        /**\n         * If a database differs from the consensus, we sync it\n         */\n        async function sync() {\n          const res = await Promise.all(dbs.map((s) => s.request));\n\n          const allCurrentIds = [\n            ...new Set(\n              res\n                .flatMap(([current]) => current)\n                .reduce((acc: string[], curr, index) => {\n                  if (index % 2 === 0) {\n                    acc.push(curr);\n                  }\n                  return acc;\n                }, [])\n            ).values(),\n          ];\n\n          for (const db of dbs) {\n            const [current, _previous, _success] = await db.request;\n            const dbIds = current.reduce((ids: string[], currentId, index) => {\n              if (index % 2 === 0) {\n                ids.push(currentId);\n              }\n              return ids;\n            }, []);\n\n            const usedDbTokens = current.reduce(\n              (accTokens: number, usedToken, index) => {\n                let parsedToken = 0;\n                if (index % 2) {\n                  parsedToken = Number.parseInt(usedToken);\n                }\n\n                return accTokens + parsedToken;\n              },\n              0\n            );\n            /**\n             * If the bucket in this db is already full, it doesn't matter which ids it contains.\n             * So we do not have to sync.\n             */\n            if (usedDbTokens >= tokens) {\n              continue;\n            }\n            const diff = allCurrentIds.filter((id) => !dbIds.includes(id));\n            /**\n             * Don't waste a request if there is nothing to send\n             */\n            if (diff.length === 0) {\n              continue;\n            }\n\n            for (const requestId of diff) {\n              await db.redis.hset(currentKey, { [requestId]: incrementBy });\n            }\n          }\n        }\n\n        // const success = remaining >= 0;\n        const reset = (currentWindow + 1) * windowDuration;\n        if (ctx.cache) {\n          if (!success) {\n            ctx.cache.blockUntil(identifier, reset);\n          } else if (incrementBy < 0) {\n            // Successful refund: unblock from cache\n            ctx.cache.pop(identifier);\n          }\n        }\n        return {\n          success: Boolean(success),\n          limit: tokens,\n          remaining: Math.max(0, remaining),\n          reset,\n          pending: sync(),\n        };\n      },\n      async getRemaining(ctx: MultiRegionContext, identifier: string) {\n        const now = Date.now();\n\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n\n        const dbs = ctx.regionContexts.map((regionContext) => ({\n          redis: regionContext.redis,\n          request: safeEval(\n            regionContext,\n            SCRIPTS.multiRegion.slidingWindow.getRemaining,\n            [currentKey, previousKey],\n            [now, windowSize]\n            // lua seems to return `1` for true and `null` for false\n          ) as Promise<number>,\n        }));\n\n        const usedTokens = await Promise.any(dbs.map((s) => s.request));\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (currentWindow + 1) * windowSize,\n        };\n      },\n      async resetTokens(ctx: MultiRegionContext, identifier: string) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n\n        await Promise.all(\n          ctx.regionContexts.map((regionContext) => {\n            safeEval(regionContext, RESET_SCRIPT, [pattern], [null]);\n          })\n        );\n      },\n    });\n  }\n}\n","import type { Duration } from \"./duration\";\nimport { ms } from \"./duration\";\nimport { safeEval } from \"./hash\";\nimport { RESET_SCRIPT, SCRIPTS } from \"./lua-scripts/hash\";\nimport { tokenBucketIdentifierNotFound } from \"./lua-scripts/single\";\n\nimport { Ratelimit } from \"./ratelimit\";\nimport type { Algorithm, RegionContext } from \"./types\";\nimport type { Redis as RedisCore } from \"./types\";\n\n// Fix for https://github.com/upstash/ratelimit-js/issues/125\ntype Redis = Pick<RedisCore, \"evalsha\" | \"get\" | \"set\">\n\nexport type RegionRatelimitConfig = {\n  /**\n   * Instance of `@upstash/redis`\n   * @see https://github.com/upstash/upstash-redis#quick-start\n   */\n  redis: Redis;\n  /**\n   * The ratelimiter function to use.\n   *\n   * Choose one of the predefined ones or implement your own.\n   * Available algorithms are exposed via static methods:\n   * - Ratelimiter.fixedWindow\n   * - Ratelimiter.slidingWindow\n   * - Ratelimiter.tokenBucket\n   */\n  limiter: Algorithm<RegionContext>;\n  /**\n   * All keys in redis are prefixed with this.\n   *\n   * @default `@upstash/ratelimit`\n   */\n  prefix?: string;\n\n  /**\n   * If enabled, the ratelimiter will keep a global cache of identifiers, that have\n   * exhausted their ratelimit. In serverless environments this is only possible if\n   * you create the ratelimiter instance outside of your handler function. While the\n   * function is still hot, the ratelimiter can block requests without having to\n   * request data from redis, thus saving time and money.\n   *\n   * Whenever an identifier has exceeded its limit, the ratelimiter will add it to an\n   * internal list together with its reset timestamp. If the same identifier makes a\n   * new request before it is reset, we can immediately reject it.\n   *\n   * Set to `false` to disable.\n   *\n   * If left undefined, a map is created automatically, but it can only work\n   * if the map or the ratelimit instance is created outside your serverless function handler.\n   */\n  ephemeralCache?: Map<string, number> | false;\n\n  /**\n   * If set, the ratelimiter will allow requests to pass after this many milliseconds.\n   *\n   * Use this if you want to allow requests in case of network problems\n   */\n  timeout?: number;\n\n  /**\n   * If enabled, the ratelimiter will store analytics data in redis, which you can check out at\n   * https://console.upstash.com/ratelimit\n   *\n   * @default false\n   */\n  analytics?: boolean;\n\n  /**\n   * @deprecated Has no affect since v2.0.3. Instead, hash values of scripts are\n   * hardcoded in the sdk and it attempts to run the script using EVALSHA (with the hash).\n   * If it fails, runs script load.\n   * \n   * Previously, if enabled, lua scripts were sent to Redis with SCRIPT LOAD durint the first request.\n   * In the subsequent requests, hash of the script would be used to invoke the scripts\n   * \n   * @default true\n   */\n  cacheScripts?: boolean;\n\n  /**\n   * @default false\n   */\n  enableProtection?: boolean\n\n  /**\n   * @default 6\n   */\n  denyListThreshold?: number\n};\n\n/**\n * Ratelimiter using serverless redis from https://upstash.com/\n *\n * @example\n * ```ts\n * const { limit } = new Ratelimit({\n *    redis: Redis.fromEnv(),\n *    limiter: Ratelimit.slidingWindow(\n *      \"30 m\", // interval of 30 minutes\n *      10,     // Allow 10 requests per window of 30 minutes\n *    )\n * })\n *\n * ```\n */\nexport class RegionRatelimit extends Ratelimit<RegionContext> {\n  /**\n   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithm of your choice.\n   */\n\n  constructor(config: RegionRatelimitConfig) {\n    super({\n      prefix: config.prefix,\n      limiter: config.limiter,\n      timeout: config.timeout,\n      analytics: config.analytics,\n      ctx: {\n        redis: config.redis as RedisCore,\n      },\n      ephemeralCache: config.ephemeralCache,\n      enableProtection: config.enableProtection,\n      denyListThreshold: config.denyListThreshold\n    });\n  }\n\n  /**\n   * Each request inside a fixed time increases a counter.\n   * Once the counter reaches the maximum allowed number, all further requests are\n   * rejected.\n   *\n   * **Pro:**\n   *\n   * - Newer requests are not starved by old ones.\n   * - Low storage cost.\n   *\n   * **Con:**\n   *\n   * A burst of requests near the boundary of a window can result in a very\n   * high request rate because two windows will be filled with requests quickly.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - A fixed timeframe\n   */\n  static fixedWindow(\n    /**\n     * How many requests are allowed per window.\n     */\n    tokens: number,\n    /**\n     * The duration in which `tokens` requests are allowed.\n     */\n    window: Duration,\n  ): Algorithm<RegionContext> {\n    const windowDuration = ms(window);\n    return () => ({\n      async limit(ctx: RegionContext, identifier: string, rate?: number) {\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const incrementBy = rate ?? 1;\n\n        // Only check cache block if not refunding (negative rate)\n        if (ctx.cache && incrementBy > 0) {\n          const { blocked, reset } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n\n        const usedTokensAfterUpdate = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.fixedWindow.limit,\n          [key],\n          [windowDuration, incrementBy],\n        ) as number;\n\n        const success = usedTokensAfterUpdate <= tokens;\n\n        const remainingTokens = Math.max(0, tokens - usedTokensAfterUpdate);\n\n        const reset = (bucket + 1) * windowDuration;\n        if (ctx.cache) {\n          if (!success) {\n            ctx.cache.blockUntil(identifier, reset);\n          } else if (incrementBy < 0) {\n            // Successful refund: unblock from cache\n            ctx.cache.pop(identifier);\n          }\n        }\n\n        return {\n          success,\n          limit: tokens,\n          remaining: remainingTokens,\n          reset,\n          pending: Promise.resolve(),\n        };\n      },\n      async getRemaining(ctx: RegionContext, identifier: string) {\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n\n        const usedTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.fixedWindow.getRemaining,\n          [key],\n          [null],\n        ) as number;\n\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (bucket + 1) * windowDuration\n        };\n      },\n      async resetTokens(ctx: RegionContext, identifier: string) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier)\n        }\n\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null],\n        ) as number;\n      },\n    });\n  }\n\n  /**\n   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage\n   * costs than `slidingLogs` and improved boundary behavior by calculating a\n   * weighted score between two windows.\n   *\n   * **Pro:**\n   *\n   * Good performance allows this to scale to very high loads.\n   *\n   * **Con:**\n   *\n   * Nothing major.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - The duration in which the user can max X requests.\n   */\n  static slidingWindow(\n    /**\n     * How many requests are allowed per window.\n     */\n    tokens: number,\n    /**\n     * The duration in which `tokens` requests are allowed.\n     */\n    window: Duration,\n  ): Algorithm<RegionContext> {\n    const windowSize = ms(window);\n    return () => ({\n      async limit(ctx: RegionContext, identifier: string, rate?: number) {\n        const now = Date.now();\n\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n        const incrementBy = rate ?? 1;\n\n        // Only check cache block if not refunding (negative rate)\n        if (ctx.cache && incrementBy > 0) {\n          const { blocked, reset } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n\n        const remainingTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.slidingWindow.limit,\n          [currentKey, previousKey],\n          [tokens, now, windowSize, incrementBy],\n        ) as number;\n\n        const success = remainingTokens >= 0;\n\n        const reset = (currentWindow + 1) * windowSize;\n        if (ctx.cache) {\n          if (!success) {\n            ctx.cache.blockUntil(identifier, reset);\n          } else if (incrementBy < 0) {\n            // Successful refund: unblock from cache\n            ctx.cache.pop(identifier);\n          }\n        }\n        return {\n          success,\n          limit: tokens,\n          remaining: Math.max(0, remainingTokens),\n          reset,\n          pending: Promise.resolve(),\n        };\n      },\n      async getRemaining(ctx: RegionContext, identifier: string) {\n        const now = Date.now();\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n\n        const usedTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.slidingWindow.getRemaining,\n          [currentKey, previousKey],\n          [now, windowSize],\n        ) as number;\n\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (currentWindow + 1) * windowSize\n        }\n      },\n      async resetTokens(ctx: RegionContext, identifier: string) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier)\n        }\n\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null],\n        ) as number;\n      },\n    });\n  }\n\n  /**\n   * You have a bucket filled with `{maxTokens}` tokens that refills constantly\n   * at `{refillRate}` per `{interval}`.\n   * Every request will remove one token from the bucket and if there is no\n   * token to take, the request is rejected.\n   *\n   * **Pro:**\n   *\n   * - Bursts of requests are smoothed out and you can process them at a constant\n   * rate.\n   * - Allows to set a higher initial burst limit by setting `maxTokens` higher\n   * than `refillRate`\n   */\n  static tokenBucket(\n    /**\n     * How many tokens are refilled per `interval`\n     *\n     * An interval of `10s` and refillRate of 5 will cause a new token to be added every 2 seconds.\n     */\n    refillRate: number,\n    /**\n     * The interval for the `refillRate`\n     */\n    interval: Duration,\n    /**\n     * Maximum number of tokens.\n     * A newly created bucket starts with this many tokens.\n     * Useful to allow higher burst limits.\n     */\n    maxTokens: number,\n  ): Algorithm<RegionContext> {\n    const intervalDuration = ms(interval);\n    return () => ({\n      async limit(ctx: RegionContext, identifier: string, rate?: number) {\n        const now = Date.now();\n        const incrementBy = rate ?? 1;\n\n        // Only check cache block if not refunding (negative rate)\n        if (ctx.cache && incrementBy > 0) {\n          const { blocked, reset } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: maxTokens,\n              remaining: 0,\n              reset: reset,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n\n        const [remaining, reset] = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.tokenBucket.limit,\n          [identifier],\n          [maxTokens, intervalDuration, refillRate, now, incrementBy],\n        ) as [number, number];\n\n        const success = remaining >= 0;\n        if (ctx.cache) {\n          if (!success) {\n            ctx.cache.blockUntil(identifier, reset);\n          } else if (incrementBy < 0) {\n            // Successful refund: unblock from cache\n            ctx.cache.pop(identifier);\n          }\n        }\n\n        return {\n          success,\n          limit: maxTokens,\n          remaining,\n          reset,\n          pending: Promise.resolve(),\n        };\n      },\n      async getRemaining(ctx: RegionContext, identifier: string) {\n\n        const [remainingTokens, refilledAt] = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.tokenBucket.getRemaining,\n          [identifier],\n          [maxTokens],\n        ) as [number, number];\n\n        const freshRefillAt = Date.now() + intervalDuration\n        const identifierRefillsAt = refilledAt + intervalDuration\n\n        return {\n          remaining: remainingTokens,\n          reset: refilledAt === tokenBucketIdentifierNotFound ? freshRefillAt : identifierRefillsAt\n        };\n      },\n      async resetTokens(ctx: RegionContext, identifier: string) {\n        const pattern = identifier;\n        if (ctx.cache) {\n          ctx.cache.pop(identifier)\n        }\n\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null],\n        ) as number;\n      },\n    });\n  }\n  /**\n   * cachedFixedWindow first uses the local cache to decide if a request may pass and then updates\n   * it asynchronously.\n   * This is experimental and not yet recommended for production use.\n   *\n   * @experimental\n   *\n   * Each request inside a fixed time increases a counter.\n   * Once the counter reaches the maximum allowed number, all further requests are\n   * rejected.\n   *\n   * **Pro:**\n   *\n   * - Newer requests are not starved by old ones.\n   * - Low storage cost.\n   *\n   * **Con:**\n   *\n   * A burst of requests near the boundary of a window can result in a very\n   * high request rate because two windows will be filled with requests quickly.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - A fixed timeframe\n   */\n  static cachedFixedWindow(\n    /**\n     * How many requests are allowed per window.\n     */\n    tokens: number,\n    /**\n     * The duration in which `tokens` requests are allowed.\n     */\n    window: Duration,\n  ): Algorithm<RegionContext> {\n    const windowDuration = ms(window);\n\n    return () => ({\n      async limit(ctx: RegionContext, identifier: string, rate?: number) {\n        if (!ctx.cache) {\n          throw new Error(\"This algorithm requires a cache\");\n        }\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const reset = (bucket + 1) * windowDuration;\n        const incrementBy = rate ?? 1;\n\n        const hit = typeof ctx.cache.get(key) === \"number\";\n        if (hit) {\n          const cachedTokensAfterUpdate = ctx.cache.incr(key, incrementBy);\n          const success = cachedTokensAfterUpdate < tokens;\n\n          const pending = success\n            ? safeEval(\n              ctx,\n              SCRIPTS.singleRegion.cachedFixedWindow.limit,\n              [key],\n              [windowDuration, incrementBy]\n            )\n            : Promise.resolve();\n\n          return {\n            success,\n            limit: tokens,\n            remaining: tokens - cachedTokensAfterUpdate,\n            reset: reset,\n            pending,\n          };\n        }\n\n        const usedTokensAfterUpdate = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.cachedFixedWindow.limit,\n          [key],\n          [windowDuration, incrementBy]\n        ) as number;\n        ctx.cache.set(key, usedTokensAfterUpdate);\n        const remaining = tokens - usedTokensAfterUpdate;\n\n        return {\n          success: remaining >= 0,\n          limit: tokens,\n          remaining,\n          reset: reset,\n          pending: Promise.resolve(),\n        };\n      },\n      async getRemaining(ctx: RegionContext, identifier: string) {\n        if (!ctx.cache) {\n          throw new Error(\"This algorithm requires a cache\");\n        }\n\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n\n        const hit = typeof ctx.cache.get(key) === \"number\";\n        if (hit) {\n          const cachedUsedTokens = ctx.cache.get(key) ?? 0;\n          return {\n            remaining: Math.max(0, tokens - cachedUsedTokens),\n            reset: (bucket + 1) * windowDuration\n          };\n        }\n\n        const usedTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.cachedFixedWindow.getRemaining,\n          [key],\n          [null],\n        ) as number;\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (bucket + 1) * windowDuration\n        };\n      },\n      async resetTokens(ctx: RegionContext, identifier: string) {\n        // Empty the cache\n        if (!ctx.cache) {\n          throw new Error(\"This algorithm requires a cache\");\n        }\n\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        ctx.cache.pop(key)\n\n        const pattern = [identifier, \"*\"].join(\":\");\n\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null],\n        ) as number;\n      },\n    });\n  }\n}\n"],"names":["CoreAnalytics","fixedWindowLimitScript","fixedWindowRemainingTokensScript","slidingWindowLimitScript","slidingWindowRemainingTokensScript","fixedWindowLimitScript","fixedWindowRemainingTokensScript","slidingWindowLimitScript","slidingWindowRemainingTokensScript","reset","requestId","current","reset"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAAA,IAAA,cAAA,CAAA;AAAA,SAAA,aAAA;IAAA,WAAA,IAAA;IAAA,YAAA,IAAA;IAAA,sBAAA,IAAA;IAAA,WAAA,IAAA;AAAA;AAAA,OAAA,OAAA,GAAA,aAAA;;ACCA,IAAA,wBAA2C;AA+BpC,IAAM,YAAN,MAAgB;IACJ,UAAA;IACA,QAAQ,SAAA;IAEzB,YAAY,MAAA,CAAyB;QACnC,IAAA,CAAK,SAAA,GAAY,IAAI,sBAAAA,SAAAA,CAAc;YAAA,8HAAA;YAEjC,OAAO,OAAO,KAAA;YACd,QAAQ;YACR,QAAQ,OAAO,MAAA,IAAU;YACzB,WAAW;QACb,CAAC;IACH;IAAA;;;;;;GAAA,GASO,WAAW,GAAA,EAAmC;QACnD,IAAI,IAAI,GAAA,KAAQ,KAAA,GAAW;YACzB,OAAO,IAAI,GAAA;QACb;QACA,IAAI,IAAI,EAAA,KAAO,KAAA,GAAW;YACxB,OAAO,IAAI,EAAA;QACb;QAEA,OAAO,CAAC;IACV;IAEA,MAAa,OAAO,KAAA,EAA6B;QAC/C,MAAM,IAAA,CAAK,SAAA,CAAU,MAAA,CAAO,IAAA,CAAK,KAAA,EAAO,KAAK;IAC/C;IAEA,MAAa,OACX,MAAA,EACA,MAAA,EACsB;QACtB,MAAM,iBAAiB,KAAK,GAAA,CAAA,CAExB,IAAA,CAAK,SAAA,CAAU,SAAA,CAAU,KAAK,GAAA,CAAI,CAAC,IACjC,IAAA,CAAK,SAAA,CAAU,SAAA,CAAU,MAAM,CAAA,IAAA,CAC9B,KAAK,KAAK,GAAA,GACf;QAEF,OAAO,IAAA,CAAK,SAAA,CAAU,4BAAA,CAA6B,IAAA,CAAK,KAAA,EAAO,QAAQ,cAAc;IACvF;IAEA,MAAa,SAAS,SAAS,CAAA,EAAkE;QAE/F,MAAM,iBAAiB,KAAK,GAAA,CAAA,CAExB,IAAA,CAAK,SAAA,CAAU,SAAA,CAAU,KAAK,GAAA,CAAI,CAAC,IACjC,IAAA,CAAK,SAAA,CAAU,SAAA,CAAU,MAAM,CAAA,IAAA,CAC9B,KAAK,KAAK,GAAA,GACf;QAEF,MAAM,UAAU,MAAM,IAAA,CAAK,SAAA,CAAU,iBAAA,CAAkB,IAAA,CAAK,KAAA,EAAO,cAAc;QACjF,OAAO;IACT;IAEA,MAAa,iBACX,cAAA,EAAwB,OAAA,EACF;QACtB,MAAM,SAAS,MAAM,IAAA,CAAK,SAAA,CAAU,4BAAA,CAA6B,IAAA,CAAK,KAAA,EAAO,SAAS,cAAc;QACpG,OAAO;IACT;IAEA,MAAa,sBAAsB,cAAA,EAAwB,MAAA,EAAiB,WAAA,EAAsB;QAChG,SAAS,UAAU;QACnB,MAAM,YAAY,KAAA;QAClB,OAAO,IAAA,CAAK,SAAA,CAAU,qBAAA,CAAsB,IAAA,CAAK,KAAA,EAAO,gBAAgB,QAAQ,WAAW,WAAW;IACxG;AACF;;ACzGO,IAAM,QAAN,MAAsC;IAAA;;GAAA,GAI1B,MAAA;IAEjB,YAAY,KAAA,CAA4B;QACtC,IAAA,CAAK,KAAA,GAAQ;IACf;IAEO,UAAU,UAAA,EAAyD;QACxE,IAAI,CAAC,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,UAAU,GAAG;YAC/B,OAAO;gBAAE,SAAS;gBAAO,OAAO;YAAE;QACpC;QACA,MAAM,QAAQ,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,UAAU;QACvC,IAAI,QAAQ,KAAK,GAAA,CAAI,GAAG;YACtB,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,UAAU;YAC5B,OAAO;gBAAE,SAAS;gBAAO,OAAO;YAAE;QACpC;QAEA,OAAO;YAAE,SAAS;YAAM;QAAa;IACvC;IAEO,WAAW,UAAA,EAAoB,KAAA,EAAqB;QACzD,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,YAAY,KAAK;IAClC;IAEO,IAAI,GAAA,EAAa,KAAA,EAAqB;QAC3C,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,KAAK,KAAK;IAC3B;IACO,IAAI,GAAA,EAA4B;QACrC,OAAO,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,GAAG,KAAK;IAChC;IAEO,KAAK,GAAA,EAAa,kBAA0B,CAAA,EAAW;QAC5D,IAAI,QAAQ,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,GAAG,KAAK;QACnC,SAAS;QACT,IAAA,CAAK,KAAA,CAAM,GAAA,CAAI,KAAK,KAAK;QACzB,OAAO;IACT;IAEO,IAAI,GAAA,EAAmB;QAC5B,IAAA,CAAK,KAAA,CAAM,MAAA,CAAO,GAAG;IACvB;IAEO,QAAc;QACnB,IAAA,CAAK,KAAA,CAAM,KAAA,CAAM;IACnB;IAEO,OAAe;QACpB,OAAO,IAAA,CAAK,KAAA,CAAM,IAAA;IACpB;AACF;;AChDO,SAAS,GAAG,CAAA,EAAqB;IACtC,MAAM,QAAQ,EAAE,KAAA,CAAM,wBAAwB;IAC9C,IAAI,CAAC,OAAO;QACV,MAAM,IAAI,MAAM,CAAA,6BAAA,EAAgC,CAAC,EAAE;IACrD;IACA,MAAM,OAAO,OAAO,QAAA,CAAS,KAAA,CAAM,CAAC,CAAC;IACrC,MAAM,OAAO,KAAA,CAAM,CAAC,CAAA;IAEpB,OAAQ,MAAM;QACZ,KAAK;YAAM;gBACT,OAAO;YACT;QACA,KAAK;YAAK;gBACR,OAAO,OAAO;YAChB;QACA,KAAK;YAAK;gBACR,OAAO,OAAO,MAAO;YACvB;QACA,KAAK;YAAK;gBACR,OAAO,OAAO,MAAO,KAAK;YAC5B;QACA,KAAK;YAAK;gBACR,OAAO,OAAO,MAAO,KAAK,KAAK;YACjC;QAEA;YAAS;gBACP,MAAM,IAAI,MAAM,CAAA,6BAAA,EAAgC,CAAC,EAAE;YACrD;IACF;AACF;;ACrBO,IAAM,WAAW,OACtB,KACA,QACA,MACA,SACG;IACH,IAAI;QACF,OAAO,MAAM,IAAI,KAAA,CAAM,OAAA,CAAQ,OAAO,IAAA,EAAM,MAAM,IAAI;IACxD,EAAA,OAAS,OAAO;QACd,IAAI,GAAG,KAAK,EAAA,CAAG,QAAA,CAAS,UAAU,GAAG;YACnC,OAAO,MAAM,IAAI,KAAA,CAAM,IAAA,CAAK,OAAO,MAAA,EAAQ,MAAM,IAAI;QACvD;QACA,MAAM;IACR;AACF;;AC5BO,IAAM,yBAAyB,CAAA;;;;;;;;;;;;;AAAA,CAAA;AAe/B,IAAM,mCAAmC,CAAA;;;;;;;;;IAAA,CAAA;AAWzC,IAAM,2BAA2B,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,CAAA;AAmCjC,IAAM,qCAAqC,CAAA;;;;;;;;;;;;;;;;;;;;;AAAA,CAAA;AAuB3C,IAAM,yBAAyB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,CAAA;AA4C/B,IAAM,gCAAgC,CAAA;AAEtC,IAAM,mCAAmC,CAAA;;;;;;;uBAAA,EAOvB,6BAA6B,CAAA;;;;AAAA,CAAA;AAM/C,IAAM,+BAA+B,CAAA;;;;;;;;;;;;;AAAA,CAAA;AAerC,IAAM,wCAAwC,CAAA;;;;;;;;;AAAA,CAAA;;AC9J9C,IAAMC,0BAAyB,CAAA;;;;;;;;;;;;;;;AAAA,CAAA;AAgB/B,IAAMC,oCAAmC,CAAA;;;;;;;IAAA,CAAA;AASzC,IAAMC,4BAA2B,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,CAAA;AAsCjC,IAAMC,sCAAqC,CAAA;;;;;;;;;;;;;;;;;;;;;;AAAA,CAAA;;AC/D3C,IAAM,cAAc,CAAA;;;;;;;;;;;;;;;;;;;;;;IAAA,CAAA;;ACoBpB,IAAM,UAGT;IACF,cAAc;QACZ,aAAa;YACX,OAAO;gBACL,QAAe;gBACf,MAAM;YACR;YACA,cAAc;gBACZ,QAAe;gBACf,MAAM;YACR;QACF;QACA,eAAe;YACb,OAAO;gBACL,QAAe;gBACf,MAAM;YACR;YACA,cAAc;gBACZ,QAAe;gBACf,MAAM;YACR;QACF;QACA,aAAa;YACX,OAAO;gBACL,QAAe;gBACf,MAAM;YACR;YACA,cAAc;gBACZ,QAAe;gBACf,MAAM;YACR;QACF;QACA,mBAAmB;YACjB,OAAO;gBACL,QAAe;gBACf,MAAM;YACR;YACA,cAAc;gBACZ,QAAe;gBACf,MAAM;YACR;QACF;IACF;IACA,aAAa;QACX,aAAa;YACX,OAAO;gBACL,QAAcC;gBACd,MAAM;YACR;YACA,cAAc;gBACZ,QAAcC;gBACd,MAAM;YACR;QACF;QACA,eAAe;YACb,OAAO;gBACL,QAAcC;gBACd,MAAM;YACR;YACA,cAAc;gBACZ,QAAcC;gBACd,MAAM;YACR;QACF;IACF;AACF;AAGO,IAAM,eAA2B;IACtC,QAAQ;IACR,MAAM;AACR;;ACcO,IAAM,oBAAoB;AAC1B,IAAM,gBAAgB;AACtB,IAAM,sBAAsB;;AC9G5B,IAAM,sBAAsB,CAAA;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,CAAA;;ACAnC,IAAA,uBAAA,CAAA;AAAA,SAAA,sBAAA;IAAA,gBAAA,IAAA;IAAA,mBAAA,IAAA;IAAA,kBAAA,IAAA;AAAA;;ACEA,IAAM,uBAAuB,KAAK,KAAK;AAGvC,IAAM,sBAAsB,KAAK;AAGjC,IAAM,sBAAsB,IAAI;AAEzB,IAAM,eAAe,CAAC,SAAkB;IAC7C,MAAM,MAAM,QAAQ,KAAK,GAAA,CAAI;IAG7B,MAAM,mBAAA,CAAoB,MAAM,mBAAA,IAAuB;IAGvD,OAAO,sBAAsB;AAC/B;;ADdA,IAAM,UAAU;AAET,IAAM,iBAAN,cAA6B,MAAM;IACxC,YAAY,SAAA,CAAmB;QAC7B,KAAA,CAAM,CAAA,sEAAA,EAAyE,SAAS,EAAE;QAC1F,IAAA,CAAK,IAAA,GAAO;IACd;AACF;AAcA,IAAM,gBAAgB,OAAO,cAAsB;IACjD,IAAI,OAAO,cAAc,YAAY,YAAY,KAAK,YAAY,GAAG;QACnE,MAAM,IAAI,eAAe,SAAS;IACpC;IAEA,IAAI;QAEF,MAAM,WAAW,MAAM,MAAM,GAAG,OAAO,CAAA,CAAA,EAAI,SAAS,CAAA,IAAA,CAAM;QAC1D,IAAI,CAAC,SAAS,EAAA,EAAI;YAChB,MAAM,IAAI,MAAM,CAAA,qBAAA,EAAwB,SAAS,UAAU,EAAE;QAC/D;QACA,MAAM,OAAO,MAAM,SAAS,IAAA,CAAK;QAGjC,MAAM,QAAQ,KAAK,KAAA,CAAM,IAAI;QAC7B,OAAO,MAAM,MAAA,CAAO,CAAC,QAAU,MAAM,MAAA,GAAS,CAAC;IACjD,EAAA,OAAS,OAAO;QACd,MAAM,IAAI,MAAM,CAAA,8BAAA,EAAiC,KAAK,EAAE;IAC1D;AACF;AAsBO,IAAM,mBAAmB,OAC9B,OACA,QACA,WACA,QACG;IACH,MAAM,SAAS,MAAM,cAAc,SAAS;IAE5C,MAAM,eAAe;QAAC;QAAQ;QAAmB,KAAK;KAAA,CAAE,IAAA,CAAK,GAAG;IAChE,MAAM,aAAa;QAAC;QAAQ;QAAmB,aAAa;KAAA,CAAE,IAAA,CAAK,GAAG;IACtE,MAAM,YAAY;QAAC;QAAQ,mBAAmB;KAAA,CAAE,IAAA,CAAK,GAAG;IAExD,MAAM,cAAc,MAAM,KAAA,CAAM;IAGhC,YAAY,UAAA,CAAW,cAAc,cAAc,UAAU;IAG7D,YAAY,GAAA,CAAI,UAAU;IAE1B,YAAY,IAAA,CAAK,YAAY,OAAO,EAAA,CAAG,CAAC,GAAG,GAAG,OAAO,KAAA,CAAM,CAAC,CAAC;IAI7D,YAAY,UAAA,CAAW,YAAY,YAAY,YAAY;IAG3D,YAAY,WAAA,CAAY,cAAc,cAAc,UAAU;IAG9D,YAAY,GAAA,CAAI,WAAW,SAAS;QAAC,IAAI,OAAO,aAAa;IAAC,CAAC;IAE/D,OAAO,MAAM,YAAY,IAAA,CAAK;AAChC;AAWO,IAAM,oBAAoB,OAAO,OAAc,WAAmB;IACvE,MAAM,kBAAkB;QAAC;QAAQ;QAAmB,KAAK;KAAA,CAAE,IAAA,CAAK,GAAG;IACnE,MAAM,gBAAgB;QAAC;QAAQ;QAAmB,aAAa;KAAA,CAAE,IAAA,CAAK,GAAG;IACzE,MAAM,YAAY;QAAC;QAAQ,mBAAmB;KAAA,CAAE,IAAA,CAAK,GAAG;IAExD,MAAM,cAAc,MAAM,KAAA,CAAM;IAGhC,YAAY,UAAA,CAAW,iBAAiB,iBAAiB,aAAa;IAGtE,YAAY,GAAA,CAAI,aAAa;IAI7B,YAAY,GAAA,CAAI,WAAW,UAAU;IAErC,OAAO,MAAM,YAAY,IAAA,CAAK;AAChC;;AExHA,IAAM,gBAAgB,IAAI,MAAM,aAAA,GAAA,IAAI,IAAI,CAAC;AASlC,IAAM,qBAAqB,CAAC,YAAmC;IACpE,OAAO,QAAQ,IAAA,CACb,CAAA,SAAU,cAAc,SAAA,CAAU,MAAM,EAAE,OAAA;AAE9C;AAUA,IAAM,cAAc,CAAC,WAAmB;IACtC,IAAI,cAAc,IAAA,CAAK,IAAI,KAAM,cAAc,KAAA,CAAM;IACrD,cAAc,UAAA,CAAW,QAAQ,KAAK,GAAA,CAAI,IAAI,GAAM;AACtD;AAaO,IAAM,gBAAgB,OAC3B,OACA,QACA,YAC8B;IAC9B,MAAM,CAAE,cAAc,gBAAiB,CAAA,GAAI,MAAM,MAAM,IAAA,CACrD,qBACA;QACE;YAAC;YAAQ;YAAmB,KAAK;SAAA,CAAE,IAAA,CAAK,GAAG;QAC3C;YAAC;YAAQ,mBAAmB;SAAA,CAAE,IAAA,CAAK,GAAG;KACxC,EACA;IAGF,IAAI,cAA2B,KAAA;IAC/B,aAAa,GAAA,CAAI,CAAC,cAAc,UAAU;QACxC,IAAI,cAAc;YAChB,YAAY,OAAA,CAAQ,KAAK,CAAC;YAC1B,cAAc,OAAA,CAAQ,KAAK,CAAA;QAC7B;IACF,CAAC;IAED,OAAO;QACL;QACA,mBAAmB,qBAAqB,CAAA;IAC1C;AACF;AAUO,IAAM,sBAAsB,CACjC,OACA,QACA,CAAC,mBAAmB,gBAAgB,CAAA,EACpC,cACsB;IAEtB,IAAI,iBAAiB,WAAA,EAAa;QAChC,kBAAkB,OAAA,GAAU;QAC5B,kBAAkB,SAAA,GAAY;QAC9B,kBAAkB,MAAA,GAAS;QAC3B,kBAAkB,WAAA,GAAc,iBAAiB,WAAA;IACnD;IAEA,IAAI,iBAAiB,iBAAA,EAAmB;QACtC,MAAM,gBAAgB,iBAAiB,OAAO,QAAQ,SAAS;QAC/D,kBAAkB,OAAA,GAAU,QAAQ,GAAA,CAAI;YACtC,kBAAkB,OAAA;YAClB;SACD;IACH;IAEA,OAAO;AACT;AAOO,IAAM,wBAAwB,CAAC,gBAA2C;IAC/E,OAAO;QACL,SAAS;QACT,OAAO;QACP,WAAW;QACX,OAAO;QACP,SAAS,QAAQ,OAAA,CAAQ;QACzB,QAAQ;QACR;IACF;AACF;;AC7BO,IAAe,YAAf,MAAmD;IACrC,QAAA;IAEA,IAAA;IAEA,OAAA;IAEA,QAAA;IAEA,aAAA;IAEA,UAAA;IAEA,iBAAA;IAEA,kBAAA;IAEnB,YAAY,MAAA,CAAmC;QAC7C,IAAA,CAAK,GAAA,GAAM,OAAO,GAAA;QAClB,IAAA,CAAK,OAAA,GAAU,OAAO,OAAA;QACtB,IAAA,CAAK,OAAA,GAAU,OAAO,OAAA,IAAW;QACjC,IAAA,CAAK,MAAA,GAAS,OAAO,MAAA,IAAU;QAE/B,IAAA,CAAK,gBAAA,GAAmB,OAAO,gBAAA,IAAoB;QACnD,IAAA,CAAK,iBAAA,GAAoB,OAAO,iBAAA,IAAqB;QAErD,IAAA,CAAK,YAAA,GAAgB,WAAW,IAAA,CAAK,GAAA,GAAO,IAAA,CAAK,GAAA,CAAI,KAAA,GAAQ,IAAA,CAAK,GAAA,CAAI,cAAA,CAAe,CAAC,CAAA,CAAE,KAAA;QACxF,IAAA,CAAK,SAAA,GAAY,OAAO,SAAA,GACpB,IAAI,UAAU;YACd,OAAO,IAAA,CAAK,YAAA;YACZ,QAAQ,IAAA,CAAK,MAAA;QACf,CAAC,IACC,KAAA;QAEJ,IAAI,OAAO,cAAA,YAA0B,KAAK;YACxC,IAAA,CAAK,GAAA,CAAI,KAAA,GAAQ,IAAI,MAAM,OAAO,cAAc;QAClD,OAAA,IAAW,OAAO,cAAA,KAAmB,KAAA,GAAW;YAC9C,IAAA,CAAK,GAAA,CAAI,KAAA,GAAQ,IAAI,MAAM,aAAA,GAAA,IAAI,IAAI,CAAC;QACtC;IACF;IAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GAAA,GAsCO,QAAQ,OACb,YACA,QAC+B;QAE/B,IAAI,YAAiB;QACrB,IAAI;YACF,MAAM,WAAW,IAAA,CAAK,oBAAA,CAAqB,YAAY,GAAG;YAC1D,MAAM,EAAE,aAAA,EAAe,YAAA,CAAa,CAAA,GAAI,IAAA,CAAK,YAAA,CAAa,QAAQ;YAClE,YAAY;YAEZ,MAAM,gBAAgB,MAAM,QAAQ,IAAA,CAAK,aAAa;YACtD,MAAM,gBAAgB,IAAA,CAAK,eAAA,CAAgB,eAAe,YAAY,GAAG;YACzE,OAAO;QACT,SAAE;YACA,IAAI,WAAW;gBACb,aAAa,SAAS;YACxB;QACF;IACF,EAAA;IAAA;;;;;;;;;;;;;;;;;;;;;GAAA,GAwBO,kBAAkB,OAOvB,YAKA,YAC+B;QAC/B,IAAI,WAAW,GAAG;YAChB,MAAM,IAAI,MAAM,0BAA0B;QAC5C;QACA,IAAI;QAEJ,MAAM,WAAW,KAAK,GAAA,CAAI,IAAI;QAC9B,MAAO,KAAM;YACX,MAAM,MAAM,IAAA,CAAK,KAAA,CAAM,UAAU;YACjC,IAAI,IAAI,OAAA,EAAS;gBACf;YACF;YACA,IAAI,IAAI,KAAA,KAAU,GAAG;gBACnB,MAAM,IAAI,MAAM,wBAAwB;YAC1C;YAEA,MAAM,OAAO,KAAK,GAAA,CAAI,IAAI,KAAA,EAAO,QAAQ,IAAI,KAAK,GAAA,CAAI;YACtD,MAAM,IAAI,QAAQ,CAAC,IAAM,WAAW,GAAG,IAAI,CAAC;YAE5C,IAAI,KAAK,GAAA,CAAI,IAAI,UAAU;gBACzB;YACF;QACF;QACA,OAAO;IACT,EAAA;IAEO,kBAAkB,OAAO,eAAuB;QACrD,MAAM,UAAU;YAAC,IAAA,CAAK,MAAA;YAAQ,UAAU;SAAA,CAAE,IAAA,CAAK,GAAG;QAClD,MAAM,IAAA,CAAK,OAAA,CAAQ,EAAE,WAAA,CAAY,IAAA,CAAK,GAAA,EAAK,OAAO;IACpD,EAAA;IAAA;;;;;;;GAAA,GAUO,eAAe,OAAO,eAGvB;QACJ,MAAM,UAAU;YAAC,IAAA,CAAK,MAAA;YAAQ,UAAU;SAAA,CAAE,IAAA,CAAK,GAAG;QAElD,OAAO,MAAM,IAAA,CAAK,OAAA,CAAQ,EAAE,YAAA,CAAa,IAAA,CAAK,GAAA,EAAK,OAAO;IAC5D,EAAA;IAAA;;;;;;;;;;;GAAA,GAcQ,uBAAuB,OAC7B,YACA,QAC+B;QAC/B,MAAM,MAAM,IAAA,CAAK,MAAA,CAAO,UAAU;QAClC,MAAM,iBAAiB,IAAA,CAAK,iBAAA,CAAkB,YAAY,GAAG;QAE7D,MAAM,cAAc,mBAAmB,cAAc;QAErD,MAAM,SAAuB,cAAc;YAAC,sBAAsB,WAAW;YAAG;gBAAE;gBAAa,mBAAmB;YAAM,CAAC;SAAA,GAAK,MAAM,QAAQ,GAAA,CAAI;YAC9I,IAAA,CAAK,OAAA,CAAQ,EAAE,KAAA,CAAM,IAAA,CAAK,GAAA,EAAK,KAAK,KAAK,IAAI;YAC7C,IAAA,CAAK,gBAAA,GACD,cAAc,IAAA,CAAK,YAAA,EAAc,IAAA,CAAK,MAAA,EAAQ,cAAc,IAC5D;gBAAE,aAAa,KAAA;gBAAW,mBAAmB;YAAM;SACxD;QAED,OAAO,oBAAoB,IAAA,CAAK,YAAA,EAAc,IAAA,CAAK,MAAA,EAAQ,QAAQ,IAAA,CAAK,iBAAiB;IAC3F,EAAA;IAAA;;;;;;GAAA,GASQ,eAAe,CAAC,aAAyC;QAC/D,IAAI,eAAoB;QACxB,MAAM,gBAAmD;YAAC,QAAQ;SAAA;QAElE,IAAI,IAAA,CAAK,OAAA,GAAU,GAAG;YACpB,MAAM,kBAAkB,IAAI,QAA2B,CAAC,YAAY;gBAClE,eAAe,WAAW,MAAM;oBAC9B,QAAQ;wBACN,SAAS;wBACT,OAAO;wBACP,WAAW;wBACX,OAAO;wBACP,SAAS,QAAQ,OAAA,CAAQ;wBACzB,QAAQ;oBACV,CAAC;gBACH,GAAG,IAAA,CAAK,OAAO;YACjB,CAAC;YACD,cAAc,IAAA,CAAK,eAAe;QACpC;QAEA,OAAO;YACL;YACA;QACF;IACF,EAAA;IAAA;;;;;;;GAAA,GAUQ,kBAAkB,CACxB,mBACA,YACA,QACG;QACH,IAAI,IAAA,CAAK,SAAA,EAAW;YAClB,IAAI;gBACF,MAAM,MAAM,MAAM,IAAA,CAAK,SAAA,CAAU,UAAA,CAAW,GAAG,IAAI,KAAA;gBACnD,MAAM,aAAa,IAAA,CAAK,SAAA,CACrB,MAAA,CAAO;oBACN,YAAY,kBAAkB,MAAA,KAAW,aACrC,kBAAkB,WAAA,GAClB;oBACJ,MAAM,KAAK,GAAA,CAAI;oBACf,SAAS,kBAAkB,MAAA,KAAW,aAClC,WACA,kBAAkB,OAAA;oBACtB,GAAG,GAAA;gBACL,CAAC,EACA,KAAA,CAAM,CAAC,UAAU;oBAChB,IAAI,eAAe;oBACnB,IAAI,GAAG,KAAK,EAAA,CAAG,QAAA,CAAS,WAAW,GAAG;wBACpC,eAAe,CAAA;;;;;;;;;;IAAA,CAAA;oBAUjB;oBACA,QAAQ,IAAA,CAAK,cAAc,KAAK;gBAClC,CAAC;gBACH,kBAAkB,OAAA,GAAU,QAAQ,GAAA,CAAI;oBAAC,kBAAkB,OAAA;oBAAS,UAAU;iBAAC;YACjF,EAAA,OAAS,OAAO;gBACd,QAAQ,IAAA,CAAK,8BAA8B,KAAK;YAClD;;QACF;;QACA,OAAO;IACT,EAAA;IAEQ,SAAS,CAAC,eAA+B;QAC/C,OAAO;YAAC,IAAA,CAAK,MAAA;YAAQ,UAAU;SAAA,CAAE,IAAA,CAAK,GAAG;IAC3C,EAAA;IAAA;;;;;;;GAAA,GAUQ,oBAAoB,CAC1B,YACA,QACa;QACb,MAAM,UAAU;YAAC;YAAY,KAAK;YAAI,KAAK;YAAW,KAAK,OAAO;SAAA;QAClE,OAAQ,QAAqB,MAAA,CAAO,OAAO;IAC7C,EAAA;AACF;;AC9YA,SAAS,WAAmB;IAC1B,IAAI,SAAS;IACb,MAAM,aACJ;IACF,MAAM,mBAAmB,WAAW,MAAA;IACpC,IAAA,IAAS,IAAI,GAAG,IAAI,IAAI,IAAK;QAC3B,UAAU,WAAW,MAAA,CAAO,KAAK,KAAA,CAAM,KAAK,MAAA,CAAO,IAAI,gBAAgB,CAAC;IAC1E;IACA,OAAO;AACT;AAgFO,IAAM,uBAAN,cAAmC,UAA8B;IAAA;;GAAA,GAItE,YAAY,MAAA,CAAoC;QAC9C,KAAA,CAAM;YACJ,QAAQ,OAAO,MAAA;YACf,SAAS,OAAO,OAAA;YAChB,SAAS,OAAO,OAAA;YAChB,WAAW,OAAO,SAAA;YAClB,KAAK;gBACH,gBAAgB,OAAO,KAAA,CAAM,GAAA,CAAI,CAAC,QAAA,CAAW;wBAC3C;oBACF,CAAA,CAAE;gBACF,OAAO,OAAO,cAAA,GACV,IAAI,MAAM,OAAO,cAAc,IAC/B,KAAA;YACN;QACF,CAAC;IACH;IAAA;;;;;;;;;;;;;;;;;GAAA,GAoBA,OAAO,YAIL,MAAA,EAIA,MAAA,EAC+B;QAC/B,MAAM,iBAAiB,GAAG,MAAM;QAEhC,OAAO,IAAA,CAAO;gBACZ,MAAM,OAAM,GAAA,EAAyB,UAAA,EAAoB,IAAA,EAAe;oBACtE,MAAM,YAAY,SAAS;oBAC3B,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACzC,MAAM,cAAc,QAAQ;oBAG5B,IAAI,IAAI,KAAA,IAAS,cAAc,GAAG;wBAChC,MAAM,EAAE,OAAA,EAAS,OAAAC,MAAAA,CAAM,CAAA,GAAI,IAAI,KAAA,CAAM,SAAA,CAAU,UAAU;wBACzD,IAAI,SAAS;4BACX,OAAO;gCACL,SAAS;gCACT,OAAO;gCACP,WAAW;gCACX,OAAOA;gCACP,SAAS,QAAQ,OAAA,CAAQ;gCACzB,QAAQ;4BACV;wBACF;oBACF;oBAEA,MAAM,MACJ,IAAI,cAAA,CAAe,GAAA,CAAI,CAAC,gBAAA,CAAmB;4BACzC,OAAO,cAAc,KAAA;4BACrB,SAAS,SACP,eACA,QAAQ,WAAA,CAAY,WAAA,CAAY,KAAA,EAChC;gCAAC,GAAG;6BAAA,EACJ;gCAAC;gCAAW;gCAAgB,WAAW;6BAAA;wBAE3C,CAAA,CAAE;oBAGJ,MAAM,gBAAgB,MAAM,QAAQ,GAAA,CAAI,IAAI,GAAA,CAAI,CAAC,IAAM,EAAE,OAAO,CAAC;oBAEjE,MAAM,aAAa,cAAc,MAAA,CAC/B,CAAC,WAAmB,WAAW,UAAU;wBACvC,IAAI,cAAc;wBAClB,IAAI,QAAQ,GAAG;4BACb,cAAc,OAAO,QAAA,CAAS,SAAS;wBACzC;wBAEA,OAAO,YAAY;oBACrB,GACA;oBAGF,MAAM,YAAY,SAAS;oBAK3B,eAAe,OAAO;wBACpB,MAAM,gBAAgB,MAAM,QAAQ,GAAA,CAAI,IAAI,GAAA,CAAI,CAAC,IAAM,EAAE,OAAO,CAAC;wBAEjE,MAAM,SAAS;+BACV,IAAI,IACL,cAAc,IAAA,CAAK,EAAE,MAAA,CAAO,CAAC,KAAe,MAAM,UAAU;gCAC1D,IAAI,QAAQ,MAAM,GAAG;oCACnB,IAAI,IAAA,CAAK,IAAI;gCACf;gCACA,OAAO;4BACT,GAAG,CAAC,CAAC,GACL,MAAA,CAAO;yBACX;wBAEA,KAAA,MAAW,MAAM,IAAK;4BACpB,MAAM,sBAAsB,MAAM,GAAG,OAAA;4BACrC,MAAM,eAAe,oBAAoB,MAAA,CACvC,CAAC,WAAmB,WAAW,UAAU;gCACvC,IAAI,cAAc;gCAClB,IAAI,QAAQ,GAAG;oCACb,cAAc,OAAO,QAAA,CAAS,SAAS;gCACzC;gCAEA,OAAO,YAAY;4BACrB,GACA;4BAGF,MAAM,eAAe,MAAM,GAAG,OAAA;4BAC9B,MAAM,QAAQ,aAAa,MAAA,CACzB,CAAC,KAAe,WAAW,UAAU;gCACnC,IAAI,QAAQ,MAAM,GAAG;oCACnB,IAAI,IAAA,CAAK,SAAS;gCACpB;gCACA,OAAO;4BACT,GACA,CAAC,CAAA;4BAMH,IAAI,gBAAgB,QAAQ;gCAC1B;4BACF;4BACA,MAAM,OAAO,OAAO,MAAA,CAAO,CAAC,KAAO,CAAC,MAAM,QAAA,CAAS,EAAE,CAAC;4BAItD,IAAI,KAAK,MAAA,KAAW,GAAG;gCACrB;4BACF;4BAEA,KAAA,MAAWC,cAAa,KAAM;gCAC5B,MAAM,GAAG,KAAA,CAAM,IAAA,CAAK,KAAK;oCAAE,CAACA,UAAS,CAAA,EAAG;gCAAY,CAAC;4BACvD;wBACF;oBACF;oBAMA,MAAM,UAAU,aAAa;oBAC7B,MAAM,QAAA,CAAS,SAAS,CAAA,IAAK;oBAE7B,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,CAAC,SAAS;4BACZ,IAAI,KAAA,CAAM,UAAA,CAAW,YAAY,KAAK;wBACxC,OAAA,IAAW,cAAc,GAAG;4BAE1B,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;wBAC1B;oBACF;oBACA,OAAO;wBACL;wBACA,OAAO;wBACP;wBACA;wBACA,SAAS,KAAK;oBAChB;gBACF;gBACA,MAAM,cAAa,GAAA,EAAyB,UAAA,EAAoB;oBAC9D,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAEzC,MAAM,MACJ,IAAI,cAAA,CAAe,GAAA,CAAI,CAAC,gBAAA,CAAmB;4BACzC,OAAO,cAAc,KAAA;4BACrB,SAAS,SACP,eACA,QAAQ,WAAA,CAAY,WAAA,CAAY,YAAA,EAChC;gCAAC,GAAG;6BAAA,EACJ;gCAAC,IAAI;6BAAA;wBAET,CAAA,CAAE;oBAGJ,MAAM,gBAAgB,MAAM,QAAQ,GAAA,CAAI,IAAI,GAAA,CAAI,CAAC,IAAM,EAAE,OAAO,CAAC;oBACjE,MAAM,aAAa,cAAc,MAAA,CAC/B,CAAC,WAAmB,WAAW,UAAU;wBACvC,IAAI,cAAc;wBAClB,IAAI,QAAQ,GAAG;4BACb,cAAc,OAAO,QAAA,CAAS,SAAS;wBACzC;wBAEA,OAAO,YAAY;oBACrB,GACA;oBAGF,OAAO;wBACL,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS,UAAU;wBAC1C,OAAA,CAAQ,SAAS,CAAA,IAAK;oBACxB;gBACF;gBACA,MAAM,aAAY,GAAA,EAAyB,UAAA,EAAoB;oBAC7D,MAAM,UAAU;wBAAC;wBAAY,GAAG;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAC1C,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;oBAC1B;oBAEA,MAAM,QAAQ,GAAA,CACZ,IAAI,cAAA,CAAe,GAAA,CAAI,CAAC,kBAAkB;wBACxC,SAAS,eAAe,cAAc;4BAAC,OAAO;yBAAA,EAAG;4BAAC,IAAI;yBAAC;oBACzD,CAAC;gBAEL;YACF,CAAA;IACF;IAAA;;;;;;;;;;;;;;;GAAA,GAkBA,OAAO,cAIL,MAAA,EAIA,MAAA,EAC+B;QAC/B,MAAM,aAAa,GAAG,MAAM;QAE5B,MAAM,iBAAiB,GAAG,MAAM;QAEhC,OAAO,IAAA,CAAO;gBACZ,MAAM,OAAM,GAAA,EAAyB,UAAA,EAAoB,IAAA,EAAe;oBACtE,MAAM,YAAY,SAAS;oBAC3B,MAAM,MAAM,KAAK,GAAA,CAAI;oBAErB,MAAM,gBAAgB,KAAK,KAAA,CAAM,MAAM,UAAU;oBACjD,MAAM,aAAa;wBAAC;wBAAY,aAAa;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACvD,MAAM,iBAAiB,gBAAgB;oBACvC,MAAM,cAAc;wBAAC;wBAAY,cAAc;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACzD,MAAM,cAAc,QAAQ;oBAG5B,IAAI,IAAI,KAAA,IAAS,cAAc,GAAG;wBAChC,MAAM,EAAE,OAAA,EAAS,OAAAD,MAAAA,CAAM,CAAA,GAAI,IAAI,KAAA,CAAM,SAAA,CAAU,UAAU;wBACzD,IAAI,SAAS;4BACX,OAAO;gCACL,SAAS;gCACT,OAAO;gCACP,WAAW;gCACX,OAAOA;gCACP,SAAS,QAAQ,OAAA,CAAQ;gCACzB,QAAQ;4BACV;wBACF;oBACF;oBAEA,MAAM,MAAM,IAAI,cAAA,CAAe,GAAA,CAAI,CAAC,gBAAA,CAAmB;4BACrD,OAAO,cAAc,KAAA;4BACrB,SAAS,SACP,eACA,QAAQ,WAAA,CAAY,aAAA,CAAc,KAAA,EAClC;gCAAC;gCAAY,WAAW;6BAAA,EACxB;gCAAC;gCAAQ;gCAAK;gCAAgB;gCAAW,WAAW;6BAAA;wBAGxD,CAAA,CAAE;oBAEF,MAAM,sBAAuB,MAAM,iBAAkB;oBACrD,MAAM,CAAC,SAAS,UAAU,OAAO,CAAA,GAAI,MAAM,QAAQ,GAAA,CACjD,IAAI,GAAA,CAAI,CAAC,IAAM,EAAE,OAAO;oBAK1B,IAAI,SAAS;wBACX,QAAQ,IAAA,CAAK,WAAW,YAAY,QAAA,CAAS,CAAC;oBAChD;oBAEA,MAAM,qBAAqB,SAAS,MAAA,CAClC,CAAC,WAAmB,WAAW,UAAU;wBACvC,IAAI,cAAc;wBAClB,IAAI,QAAQ,GAAG;4BACb,cAAc,OAAO,QAAA,CAAS,SAAS;wBACzC;wBAEA,OAAO,YAAY;oBACrB,GACA;oBAGF,MAAM,oBAAoB,QAAQ,MAAA,CAChC,CAAC,WAAmB,WAAW,UAAU;wBACvC,IAAI,cAAc;wBAClB,IAAI,QAAQ,GAAG;4BACb,cAAc,OAAO,QAAA,CAAS,SAAS;wBACzC;wBAEA,OAAO,YAAY;oBACrB,GACA;oBAGF,MAAM,sBAAsB,KAAK,IAAA,CAC/B,qBAAA,CAAsB,IAAI,mBAAA;oBAG5B,MAAM,aAAa,sBAAsB;oBAEzC,MAAM,YAAY,SAAS;oBAK3B,eAAe,OAAO;wBACpB,MAAM,MAAM,MAAM,QAAQ,GAAA,CAAI,IAAI,GAAA,CAAI,CAAC,IAAM,EAAE,OAAO,CAAC;wBAEvD,MAAM,gBAAgB;+BACjB,IAAI,IACL,IACG,OAAA,CAAQ,CAAC,CAACE,QAAO,CAAA,GAAMA,QAAO,EAC9B,MAAA,CAAO,CAAC,KAAe,MAAM,UAAU;gCACtC,IAAI,QAAQ,MAAM,GAAG;oCACnB,IAAI,IAAA,CAAK,IAAI;gCACf;gCACA,OAAO;4BACT,GAAG,CAAC,CAAC,GACP,MAAA,CAAO;yBACX;wBAEA,KAAA,MAAW,MAAM,IAAK;4BACpB,MAAM,CAACA,UAAS,WAAW,QAAQ,CAAA,GAAI,MAAM,GAAG,OAAA;4BAChD,MAAM,QAAQA,SAAQ,MAAA,CAAO,CAAC,KAAe,WAAW,UAAU;gCAChE,IAAI,QAAQ,MAAM,GAAG;oCACnB,IAAI,IAAA,CAAK,SAAS;gCACpB;gCACA,OAAO;4BACT,GAAG,CAAC,CAAC;4BAEL,MAAM,eAAeA,SAAQ,MAAA,CAC3B,CAAC,WAAmB,WAAW,UAAU;gCACvC,IAAI,cAAc;gCAClB,IAAI,QAAQ,GAAG;oCACb,cAAc,OAAO,QAAA,CAAS,SAAS;gCACzC;gCAEA,OAAO,YAAY;4BACrB,GACA;4BAMF,IAAI,gBAAgB,QAAQ;gCAC1B;4BACF;4BACA,MAAM,OAAO,cAAc,MAAA,CAAO,CAAC,KAAO,CAAC,MAAM,QAAA,CAAS,EAAE,CAAC;4BAI7D,IAAI,KAAK,MAAA,KAAW,GAAG;gCACrB;4BACF;4BAEA,KAAA,MAAWD,cAAa,KAAM;gCAC5B,MAAM,GAAG,KAAA,CAAM,IAAA,CAAK,YAAY;oCAAE,CAACA,UAAS,CAAA,EAAG;gCAAY,CAAC;4BAC9D;wBACF;oBACF;oBAGA,MAAM,QAAA,CAAS,gBAAgB,CAAA,IAAK;oBACpC,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,CAAC,SAAS;4BACZ,IAAI,KAAA,CAAM,UAAA,CAAW,YAAY,KAAK;wBACxC,OAAA,IAAW,cAAc,GAAG;4BAE1B,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;wBAC1B;oBACF;oBACA,OAAO;wBACL,SAAS,QAAQ,OAAO;wBACxB,OAAO;wBACP,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS;wBAChC;wBACA,SAAS,KAAK;oBAChB;gBACF;gBACA,MAAM,cAAa,GAAA,EAAyB,UAAA,EAAoB;oBAC9D,MAAM,MAAM,KAAK,GAAA,CAAI;oBAErB,MAAM,gBAAgB,KAAK,KAAA,CAAM,MAAM,UAAU;oBACjD,MAAM,aAAa;wBAAC;wBAAY,aAAa;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACvD,MAAM,iBAAiB,gBAAgB;oBACvC,MAAM,cAAc;wBAAC;wBAAY,cAAc;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAEzD,MAAM,MAAM,IAAI,cAAA,CAAe,GAAA,CAAI,CAAC,gBAAA,CAAmB;4BACrD,OAAO,cAAc,KAAA;4BACrB,SAAS,SACP,eACA,QAAQ,WAAA,CAAY,aAAA,CAAc,YAAA,EAClC;gCAAC;gCAAY,WAAW;6BAAA,EACxB;gCAAC;gCAAK,UAAU;6BAAA;wBAGpB,CAAA,CAAE;oBAEF,MAAM,aAAa,MAAM,QAAQ,GAAA,CAAI,IAAI,GAAA,CAAI,CAAC,IAAM,EAAE,OAAO,CAAC;oBAC9D,OAAO;wBACL,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS,UAAU;wBAC1C,OAAA,CAAQ,gBAAgB,CAAA,IAAK;oBAC/B;gBACF;gBACA,MAAM,aAAY,GAAA,EAAyB,UAAA,EAAoB;oBAC7D,MAAM,UAAU;wBAAC;wBAAY,GAAG;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAC1C,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;oBAC1B;oBAEA,MAAM,QAAQ,GAAA,CACZ,IAAI,cAAA,CAAe,GAAA,CAAI,CAAC,kBAAkB;wBACxC,SAAS,eAAe,cAAc;4BAAC,OAAO;yBAAA,EAAG;4BAAC,IAAI;yBAAC;oBACzD,CAAC;gBAEL;YACF,CAAA;IACF;AACF;;ACvcO,IAAM,kBAAN,cAA8B,UAAyB;IAAA;;GAAA,GAK5D,YAAY,MAAA,CAA+B;QACzC,KAAA,CAAM;YACJ,QAAQ,OAAO,MAAA;YACf,SAAS,OAAO,OAAA;YAChB,SAAS,OAAO,OAAA;YAChB,WAAW,OAAO,SAAA;YAClB,KAAK;gBACH,OAAO,OAAO,KAAA;YAChB;YACA,gBAAgB,OAAO,cAAA;YACvB,kBAAkB,OAAO,gBAAA;YACzB,mBAAmB,OAAO,iBAAA;QAC5B,CAAC;IACH;IAAA;;;;;;;;;;;;;;;;;GAAA,GAoBA,OAAO,YAIL,MAAA,EAIA,MAAA,EAC0B;QAC1B,MAAM,iBAAiB,GAAG,MAAM;QAChC,OAAO,IAAA,CAAO;gBACZ,MAAM,OAAM,GAAA,EAAoB,UAAA,EAAoB,IAAA,EAAe;oBACjE,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACzC,MAAM,cAAc,QAAQ;oBAG5B,IAAI,IAAI,KAAA,IAAS,cAAc,GAAG;wBAChC,MAAM,EAAE,OAAA,EAAS,OAAAE,MAAAA,CAAM,CAAA,GAAI,IAAI,KAAA,CAAM,SAAA,CAAU,UAAU;wBACzD,IAAI,SAAS;4BACX,OAAO;gCACL,SAAS;gCACT,OAAO;gCACP,WAAW;gCACX,OAAOA;gCACP,SAAS,QAAQ,OAAA,CAAQ;gCACzB,QAAQ;4BACV;wBACF;oBACF;oBAEA,MAAM,wBAAwB,MAAM,SAClC,KACA,QAAQ,YAAA,CAAa,WAAA,CAAY,KAAA,EACjC;wBAAC,GAAG;qBAAA,EACJ;wBAAC;wBAAgB,WAAW;qBAAA;oBAG9B,MAAM,UAAU,yBAAyB;oBAEzC,MAAM,kBAAkB,KAAK,GAAA,CAAI,GAAG,SAAS,qBAAqB;oBAElE,MAAM,QAAA,CAAS,SAAS,CAAA,IAAK;oBAC7B,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,CAAC,SAAS;4BACZ,IAAI,KAAA,CAAM,UAAA,CAAW,YAAY,KAAK;wBACxC,OAAA,IAAW,cAAc,GAAG;4BAE1B,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;wBAC1B;oBACF;oBAEA,OAAO;wBACL;wBACA,OAAO;wBACP,WAAW;wBACX;wBACA,SAAS,QAAQ,OAAA,CAAQ;oBAC3B;gBACF;gBACA,MAAM,cAAa,GAAA,EAAoB,UAAA,EAAoB;oBACzD,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAEzC,MAAM,aAAa,MAAM,SACvB,KACA,QAAQ,YAAA,CAAa,WAAA,CAAY,YAAA,EACjC;wBAAC,GAAG;qBAAA,EACJ;wBAAC,IAAI;qBAAA;oBAGP,OAAO;wBACL,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS,UAAU;wBAC1C,OAAA,CAAQ,SAAS,CAAA,IAAK;oBACxB;gBACF;gBACA,MAAM,aAAY,GAAA,EAAoB,UAAA,EAAoB;oBACxD,MAAM,UAAU;wBAAC;wBAAY,GAAG;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAC1C,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;oBAC1B;oBAEA,MAAM,SACJ,KACA,cACA;wBAAC,OAAO;qBAAA,EACR;wBAAC,IAAI;qBAAA;gBAET;YACF,CAAA;IACF;IAAA;;;;;;;;;;;;;;;GAAA,GAkBA,OAAO,cAIL,MAAA,EAIA,MAAA,EAC0B;QAC1B,MAAM,aAAa,GAAG,MAAM;QAC5B,OAAO,IAAA,CAAO;gBACZ,MAAM,OAAM,GAAA,EAAoB,UAAA,EAAoB,IAAA,EAAe;oBACjE,MAAM,MAAM,KAAK,GAAA,CAAI;oBAErB,MAAM,gBAAgB,KAAK,KAAA,CAAM,MAAM,UAAU;oBACjD,MAAM,aAAa;wBAAC;wBAAY,aAAa;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACvD,MAAM,iBAAiB,gBAAgB;oBACvC,MAAM,cAAc;wBAAC;wBAAY,cAAc;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACzD,MAAM,cAAc,QAAQ;oBAG5B,IAAI,IAAI,KAAA,IAAS,cAAc,GAAG;wBAChC,MAAM,EAAE,OAAA,EAAS,OAAAA,MAAAA,CAAM,CAAA,GAAI,IAAI,KAAA,CAAM,SAAA,CAAU,UAAU;wBACzD,IAAI,SAAS;4BACX,OAAO;gCACL,SAAS;gCACT,OAAO;gCACP,WAAW;gCACX,OAAOA;gCACP,SAAS,QAAQ,OAAA,CAAQ;gCACzB,QAAQ;4BACV;wBACF;oBACF;oBAEA,MAAM,kBAAkB,MAAM,SAC5B,KACA,QAAQ,YAAA,CAAa,aAAA,CAAc,KAAA,EACnC;wBAAC;wBAAY,WAAW;qBAAA,EACxB;wBAAC;wBAAQ;wBAAK;wBAAY,WAAW;qBAAA;oBAGvC,MAAM,UAAU,mBAAmB;oBAEnC,MAAM,QAAA,CAAS,gBAAgB,CAAA,IAAK;oBACpC,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,CAAC,SAAS;4BACZ,IAAI,KAAA,CAAM,UAAA,CAAW,YAAY,KAAK;wBACxC,OAAA,IAAW,cAAc,GAAG;4BAE1B,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;wBAC1B;oBACF;oBACA,OAAO;wBACL;wBACA,OAAO;wBACP,WAAW,KAAK,GAAA,CAAI,GAAG,eAAe;wBACtC;wBACA,SAAS,QAAQ,OAAA,CAAQ;oBAC3B;gBACF;gBACA,MAAM,cAAa,GAAA,EAAoB,UAAA,EAAoB;oBACzD,MAAM,MAAM,KAAK,GAAA,CAAI;oBACrB,MAAM,gBAAgB,KAAK,KAAA,CAAM,MAAM,UAAU;oBACjD,MAAM,aAAa;wBAAC;wBAAY,aAAa;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACvD,MAAM,iBAAiB,gBAAgB;oBACvC,MAAM,cAAc;wBAAC;wBAAY,cAAc;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAEzD,MAAM,aAAa,MAAM,SACvB,KACA,QAAQ,YAAA,CAAa,aAAA,CAAc,YAAA,EACnC;wBAAC;wBAAY,WAAW;qBAAA,EACxB;wBAAC;wBAAK,UAAU;qBAAA;oBAGlB,OAAO;wBACL,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS,UAAU;wBAC1C,OAAA,CAAQ,gBAAgB,CAAA,IAAK;oBAC/B;gBACF;gBACA,MAAM,aAAY,GAAA,EAAoB,UAAA,EAAoB;oBACxD,MAAM,UAAU;wBAAC;wBAAY,GAAG;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAC1C,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;oBAC1B;oBAEA,MAAM,SACJ,KACA,cACA;wBAAC,OAAO;qBAAA,EACR;wBAAC,IAAI;qBAAA;gBAET;YACF,CAAA;IACF;IAAA;;;;;;;;;;;;GAAA,GAeA,OAAO,YAML,UAAA,EAIA,QAAA,EAMA,SAAA,EAC0B;QAC1B,MAAM,mBAAmB,GAAG,QAAQ;QACpC,OAAO,IAAA,CAAO;gBACZ,MAAM,OAAM,GAAA,EAAoB,UAAA,EAAoB,IAAA,EAAe;oBACjE,MAAM,MAAM,KAAK,GAAA,CAAI;oBACrB,MAAM,cAAc,QAAQ;oBAG5B,IAAI,IAAI,KAAA,IAAS,cAAc,GAAG;wBAChC,MAAM,EAAE,OAAA,EAAS,OAAAA,MAAAA,CAAM,CAAA,GAAI,IAAI,KAAA,CAAM,SAAA,CAAU,UAAU;wBACzD,IAAI,SAAS;4BACX,OAAO;gCACL,SAAS;gCACT,OAAO;gCACP,WAAW;gCACX,OAAOA;gCACP,SAAS,QAAQ,OAAA,CAAQ;gCACzB,QAAQ;4BACV;wBACF;oBACF;oBAEA,MAAM,CAAC,WAAW,KAAK,CAAA,GAAI,MAAM,SAC/B,KACA,QAAQ,YAAA,CAAa,WAAA,CAAY,KAAA,EACjC;wBAAC,UAAU;qBAAA,EACX;wBAAC;wBAAW;wBAAkB;wBAAY;wBAAK,WAAW;qBAAA;oBAG5D,MAAM,UAAU,aAAa;oBAC7B,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,CAAC,SAAS;4BACZ,IAAI,KAAA,CAAM,UAAA,CAAW,YAAY,KAAK;wBACxC,OAAA,IAAW,cAAc,GAAG;4BAE1B,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;wBAC1B;oBACF;oBAEA,OAAO;wBACL;wBACA,OAAO;wBACP;wBACA;wBACA,SAAS,QAAQ,OAAA,CAAQ;oBAC3B;gBACF;gBACA,MAAM,cAAa,GAAA,EAAoB,UAAA,EAAoB;oBAEzD,MAAM,CAAC,iBAAiB,UAAU,CAAA,GAAI,MAAM,SAC1C,KACA,QAAQ,YAAA,CAAa,WAAA,CAAY,YAAA,EACjC;wBAAC,UAAU;qBAAA,EACX;wBAAC,SAAS;qBAAA;oBAGZ,MAAM,gBAAgB,KAAK,GAAA,CAAI,IAAI;oBACnC,MAAM,sBAAsB,aAAa;oBAEzC,OAAO;wBACL,WAAW;wBACX,OAAO,eAAe,gCAAgC,gBAAgB;oBACxE;gBACF;gBACA,MAAM,aAAY,GAAA,EAAoB,UAAA,EAAoB;oBACxD,MAAM,UAAU;oBAChB,IAAI,IAAI,KAAA,EAAO;wBACb,IAAI,KAAA,CAAM,GAAA,CAAI,UAAU;oBAC1B;oBAEA,MAAM,SACJ,KACA,cACA;wBAAC,OAAO;qBAAA,EACR;wBAAC,IAAI;qBAAA;gBAET;YACF,CAAA;IACF;IAAA;;;;;;;;;;;;;;;;;;;;;;;GAAA,GAyBA,OAAO,kBAIL,MAAA,EAIA,MAAA,EAC0B;QAC1B,MAAM,iBAAiB,GAAG,MAAM;QAEhC,OAAO,IAAA,CAAO;gBACZ,MAAM,OAAM,GAAA,EAAoB,UAAA,EAAoB,IAAA,EAAe;oBACjE,IAAI,CAAC,IAAI,KAAA,EAAO;wBACd,MAAM,IAAI,MAAM,iCAAiC;oBACnD;oBACA,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACzC,MAAM,QAAA,CAAS,SAAS,CAAA,IAAK;oBAC7B,MAAM,cAAc,QAAQ;oBAE5B,MAAM,MAAM,OAAO,IAAI,KAAA,CAAM,GAAA,CAAI,GAAG,MAAM;oBAC1C,IAAI,KAAK;wBACP,MAAM,0BAA0B,IAAI,KAAA,CAAM,IAAA,CAAK,KAAK,WAAW;wBAC/D,MAAM,UAAU,0BAA0B;wBAE1C,MAAM,UAAU,UACZ,SACA,KACA,QAAQ,YAAA,CAAa,iBAAA,CAAkB,KAAA,EACvC;4BAAC,GAAG;yBAAA,EACJ;4BAAC;4BAAgB,WAAW;yBAAA,IAE5B,QAAQ,OAAA,CAAQ;wBAEpB,OAAO;4BACL;4BACA,OAAO;4BACP,WAAW,SAAS;4BACpB;4BACA;wBACF;oBACF;oBAEA,MAAM,wBAAwB,MAAM,SAClC,KACA,QAAQ,YAAA,CAAa,iBAAA,CAAkB,KAAA,EACvC;wBAAC,GAAG;qBAAA,EACJ;wBAAC;wBAAgB,WAAW;qBAAA;oBAE9B,IAAI,KAAA,CAAM,GAAA,CAAI,KAAK,qBAAqB;oBACxC,MAAM,YAAY,SAAS;oBAE3B,OAAO;wBACL,SAAS,aAAa;wBACtB,OAAO;wBACP;wBACA;wBACA,SAAS,QAAQ,OAAA,CAAQ;oBAC3B;gBACF;gBACA,MAAM,cAAa,GAAA,EAAoB,UAAA,EAAoB;oBACzD,IAAI,CAAC,IAAI,KAAA,EAAO;wBACd,MAAM,IAAI,MAAM,iCAAiC;oBACnD;oBAEA,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAEzC,MAAM,MAAM,OAAO,IAAI,KAAA,CAAM,GAAA,CAAI,GAAG,MAAM;oBAC1C,IAAI,KAAK;wBACP,MAAM,mBAAmB,IAAI,KAAA,CAAM,GAAA,CAAI,GAAG,KAAK;wBAC/C,OAAO;4BACL,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS,gBAAgB;4BAChD,OAAA,CAAQ,SAAS,CAAA,IAAK;wBACxB;oBACF;oBAEA,MAAM,aAAa,MAAM,SACvB,KACA,QAAQ,YAAA,CAAa,iBAAA,CAAkB,YAAA,EACvC;wBAAC,GAAG;qBAAA,EACJ;wBAAC,IAAI;qBAAA;oBAEP,OAAO;wBACL,WAAW,KAAK,GAAA,CAAI,GAAG,SAAS,UAAU;wBAC1C,OAAA,CAAQ,SAAS,CAAA,IAAK;oBACxB;gBACF;gBACA,MAAM,aAAY,GAAA,EAAoB,UAAA,EAAoB;oBAExD,IAAI,CAAC,IAAI,KAAA,EAAO;wBACd,MAAM,IAAI,MAAM,iCAAiC;oBACnD;oBAEA,MAAM,SAAS,KAAK,KAAA,CAAM,KAAK,GAAA,CAAI,IAAI,cAAc;oBACrD,MAAM,MAAM;wBAAC;wBAAY,MAAM;qBAAA,CAAE,IAAA,CAAK,GAAG;oBACzC,IAAI,KAAA,CAAM,GAAA,CAAI,GAAG;oBAEjB,MAAM,UAAU;wBAAC;wBAAY,GAAG;qBAAA,CAAE,IAAA,CAAK,GAAG;oBAE1C,MAAM,SACJ,KACA,cACA;wBAAC,OAAO;qBAAA,EACR;wBAAC,IAAI;qBAAA;gBAET;YACF,CAAA;IACF;AACF"}},
    {"offset": {"line": 11230, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/node_modules/uncrypto/dist/crypto.web.mjs"],"sourcesContent":["const webCrypto = globalThis.crypto;\nconst subtle = webCrypto.subtle;\nconst randomUUID = () => {\n  return webCrypto.randomUUID();\n};\nconst getRandomValues = (array) => {\n  return webCrypto.getRandomValues(array);\n};\nconst _crypto = {\n  randomUUID,\n  getRandomValues,\n  subtle\n};\n\nexport { _crypto as default, getRandomValues, randomUUID, subtle };\n"],"names":[],"mappings":";;;;;;;;;;AAAA,MAAM,YAAY,WAAW,MAAM;AACnC,MAAM,SAAS,UAAU,MAAM;AAC/B,MAAM,aAAa;IACjB,OAAO,UAAU,UAAU;AAC7B;AACA,MAAM,kBAAkB,CAAC;IACvB,OAAO,UAAU,eAAe,CAAC;AACnC;AACA,MAAM,UAAU;IACd;IACA;IACA;AACF","ignoreList":[0]}}]
}